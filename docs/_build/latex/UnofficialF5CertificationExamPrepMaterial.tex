%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjornstrup]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Intro:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\makeatletter
\def\fnum@figure{\figurename\thefigure{}}
\makeatother
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\makeatletter
\def\fnum@table{\tablename\thetable{}}
\makeatother
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{0}

%% LaTeX preamble.

\usepackage{type1cm}
\usepackage{helvet}
\usepackage{wallpaper}

% Bypass unicode character not supported errors
\usepackage[utf8]{inputenc}

\makeatletter
\def\UTFviii@defined#1{%
  \ifx#1\relax
      ?%
  \else\expandafter
    #1%
  \fi
}
\makeatother

\pagestyle{plain}
\pagenumbering{arabic}

\renewcommand{\familydefault}{\sfdefault}

\definecolor{f5red}{RGB}{235, 28, 35}

\def\frontcoverpage{
  \begin{titlepage}
  \ThisURCornerWallPaper{1.0}{front_cover}
  \vspace*{2.5cm}
  \hspace{4.5cm}
  {\color{f5red} \text{\Large Agility 2020 Hands-on Lab Guide}\par}
  \vspace{.5cm}
  \hspace{4.5cm}
  {\color{white} \text{\huge Unofficial - F5 Certification Exam Prep Material}\par}
  \vspace{0.5cm}
  \hspace{4.5cm}
  {\color{white} \text{\large F5 Networks, Inc.}\par}
  \vfill
  \end{titlepage}
  \newpage
}

\def\backcoverpage{
  \newpage
  \thispagestyle{empty}
  \phantom{100}
  \ThisURCornerWallPaper{1.0}{back_cover}
}

\def\contentspage{
    \tableofcontents
}

%% Disable standard title (but keep PDF info).
\renewcommand{\maketitle}{
  \begingroup
  % These \defs are required to deal with multi-line authors; it
  % changes \\ to ', ' (comma-space), making it pass muster for
  % generating document info in the PDF file.
  \def\\{, }
  \def\and{and }
  \pdfinfo{
    /Title (Unofficial - F5 Certification Exam Prep Material)
    /Author (F5 Networks, Inc.)
  }
  \endgroup
}


\title{Unofficial - F5 Certification Exam Prep Material Documentation}
\date{Aug 13, 2020}
\release{}
\author{F5 Networks, Inc.}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}

\frontcoverpage
\contentspage

\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Getting Started with the F5 Certification Program 03/29/19}
\label{\detokenize{intro:getting-started-with-the-f5-certification-program-03-29-19}}\label{\detokenize{intro::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Congratulations on beginning your adventure into F5 Certifications}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

The F5 Certified! Program was developed to foster individual professional development through a high-quality, credible technology certification. Certifications are earned by completing a series of exams to verify skills in application delivery, design, installation, and management of F5 technology. These certifications provide a competitive advantage for candidates and employers in the marketplace. There is increasing industry recognition of the integrity, credibility, and quality of F5 certifications and the individuals who obtain them.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Introduction}
\label{\detokenize{intro:introduction}}
\sphinxstylestrong{About this Guide}

This introduction guide is for candidates who are just getting started with the F5 Certification Program.  It will help guide you through registration, preparing for your first certification exam, and scheduling.
When you register for the program, you will be assigned an F5 Candidate ID number. The F5 Candidate ID number is your primary identifier for the program and is 12 characters long formatted like the following:

F50000000000

As you read through this guide, you will find resources and embedded links. At the end of the handbook is a list of the full URLs associated with the embedded links.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Certifications Summary}

The F5 Certified! Program is progressive and builds on the skills and knowledge demonstrated in previous exams. The graphic below shows how certification levels progress through the program. Requirements for each certification are shown beside the image.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline

\sphinxincludegraphics{{1p112}.png}
&
\sphinxstyleemphasis{F5 Certified BIG-IP Administrator (F5-CA)}

F5-CA, BIG-IP Administrator Requirements
\begin{itemize}
\item {} 
Exam 101 - Application Delivery Fundamentals

\item {} 
Exam 201 - F5 TMOS Administration

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{F5 Certified Sales Professional (F5-SP)}

F5-SP, F5 Sales Professional Requirements
\begin{itemize}
\item {} 
Exam 101 - Application Delivery Fundamentals

\item {} 
Exam 202 - Pre-Sales Fundamentals

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{F5 Certified Technology Specialists (F5-CTS)}

F5-CTS, BIG-IP, Local Traffic Manger Requirements
\begin{itemize}
\item {} 
F5-CA, BIG-IP Administrator

\item {} 
Exam 301a - BIG-IP LTM: Architect, Setup, and Deploy

\item {} 
Exam 301b - BIG-IP LTM: Maintain and Troubleshoot

\end{itemize}

F5-CTS, BIG-IP DNS Requirements
\begin{itemize}
\item {} 
F5-CA, BIG-IP Administrator

\item {} 
Exam 302 - BIG-IP DNS Specialist

\end{itemize}

F5-CTS, BIG-IP Application Security Manager Requirements
\begin{itemize}
\item {} 
F5-CA, BIG-IP Administrator

\item {} 
Exam 303 - BIG-IP ASM Specialist

\end{itemize}

F5-CTS, BIG-IP Application Policy Manager Requirements
\begin{itemize}
\item {} 
F5-CA, BIG-IP Administrator

\item {} 
Exam 304 - BIG-APM Specialist

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{F5 Certified Solution Expert (F5-CSE)}

F5-CSE Security Requirements
\begin{itemize}
\item {} 
F5-CA, BIG-IP Administrator

\item {} 
F5-CTS, BIG-IP LTM Certification

\item {} 
F5-CTS, BIG-IP GTM Certification

\item {} 
F5-CTS, BIG-IP ASM Certification

\item {} 
F5-CTS, BIG-IP APM Certification

\item {} 
Exam 401 - Security Solution Expert

\end{itemize}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Getting Registered in the F5 Program}
\label{\detokenize{intro:getting-registered-in-the-f5-program}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Every candidate must have an F5 Certification ID as well as a Pearson Vue/F5 ID in order to participate in the F5 Certified! Program.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Process to get an F5 Certification ID:}
\begin{itemize}
\item {} 
The candidate must go to certification.f5.com and create an account.

\noindent\sphinxincludegraphics[scale=0.7]{{1p212}.png}

\item {} 
The candidate will receive an email from F5 with their F5 Certification ID in it. The email will have the candidate go back out to the certification.f5.com website and login with the new account and set the password and agree to EUA. Once they complete the instructions in this email, F5 will kick off a backend process to create an F5 Pearson Vue ID for them.

\item {} 
The candidate will then receive another email with their F5 Pearson Vue ID. The email will have the candidate go to the Pearson Vue website to Activate the new account.

\noindent\sphinxincludegraphics{{1p36}.png}

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Activate your Pearson VUE account:}

Certification exams are administered at Pearson VUE Testing Centers. To schedule an exam at a Pearson VUE Testing Center, you will first need to activate your account with Pearson VUE for the F5 Certified! Program. Please note that if you already have an account with Pearson VUE, the F5 Certified! account will be a different one.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
When you registered on the F5 Candidate Portal, you received an email from the testing vendor, Pearson VUE. The sender was \sphinxhref{mailto:PearsonVUEConfirmation@Pearson.com}{PearsonVUEConfirmation@Pearson.com}. This email was sent within 24 hours of registering in the F5 Candidate Portal.  If you cannot find the email from \sphinxhref{mailto:PearsonVUEConfirmation@Pearson.com}{PearsonVUEConfirmation@Pearson.com}, please contact \sphinxhref{mailto:support@cert.f5.com}{support@cert.f5.com}.

\item {} 
In the email from the testing vendor, you will see the username and temporary password which will allow you to complete the process of activating your Pearson VUE account:

\noindent\sphinxincludegraphics{{1p42}.png}

\item {} 
Use this \sphinxhref{https://home.pearsonvue.com/f5}{link} to go to Pearson VUE’s F5 Certified! page. Click on the “Sign In” button on the right side of the page:

\noindent\sphinxincludegraphics{{1p51}.png}

\item {} 
You’ll now be on the Sign in page. Enter your username and temporary password and click the “Sign in” button:

\noindent\sphinxincludegraphics{{1p62}.png}

\item {} 
A new screen will appear, and you will be prompted to create a permanent password. You should see a screen confirming that the account sign in was successfully updated, and you be automatically signed in to your Pearson VUE account home page:

\noindent\sphinxincludegraphics{{1p72}.png}

\item {} 
To sign out of your Pearson VUE account, go to the Home page and click on “Sign Out”:

\noindent\sphinxincludegraphics{{1p82}.png}

\end{enumerate}

Your Pearson VUE account for the F5 Certified! Program is now active. You can now schedule your first exam (see \sphinxhref{file:///Users/emitchell/Documents/GitHub/f5-certification-materials/docs/\_build/html/intro.html\#scheduling-the-exam}{Scheduling the Exam} below).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Your First F5 Certification}
\label{\detokenize{intro:your-first-f5-certification}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

F5 Certified Sales Professional (F5-SP)
There are two paths to take to for your first F5 certification.  Each path is separate from the other.  The first professional certification in the program is the F5 Certified! Administrator, BIG-IP (F5- CA). This certification consists of two exams: 101 - Application Delivery Fundamentals and 201 - TMOS Administration. Exam 101 is a prerequisite to Exam 201; no certificate is issued after passing Exam 101.

The sections that follow give a brief overview of the first two exams and the skills needed to pass them.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Exam 101 - Application Delivery Fundamentals}

This is the first exam required to achieve either F5 Certified BIG-IP Administrator status or F5 Certified Sales Professional. All candidates must take this exam to move forward in the program.

Successful completion of the 101-Application Delivery Fundamentals exam acknowledges the skills and understanding necessary for day-to-day management of Application Delivery Networks (ADNs). This exam identifies candidates that possess the knowledge that is necessary to work with F5 products and technologies.

\sphinxstyleemphasis{Summary description of the minimally qualified candidate (MQC)}

The MQC has a basic understanding of network fundamentals, protocols, and common traffic management concepts. The MQC also understands the basic concepts of F5 technology as applied to network fundamentals, protocols, and traffic management (for example, TMOS).

The MQC can do the following without assistance:
\begin{itemize}
\item {} 
Articulate the advantages of a full application proxy.

\item {} 
Explain the seven layers of the Open Systems Interconnection (OSI) model.

\item {} 
Describe valid uses/methods of HTTP.

\item {} 
Identify and define the components of TMOS.

\end{itemize}

\sphinxstyleemphasis{Prerequisite for exam:}
\begin{itemize}
\item {} 
None

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Exam 201 - TMOS Administration}

This is the second exam required to achieve Certified F5 BIG-IP Administrator status. Candidates must have passed the 101-Application Delivery Fundamentals exam in order to be eligible for the 201 exam.

Successful completion of the BIG-IP Administrator exam identifies candidates who can independently perform day-to-day operations and basic troubleshooting of TMOS-based devices in various application environments after it has been installed, configured, and implemented.

\sphinxstyleemphasis{Summary description of the MQC}

The MQC is capable of performing day-to-day operations of TMOS-based devices which have already been installed. The MQC is also capable of basic troubleshooting of a TMOS-based device in order to provide full, accurate, and appropriate information to senior engineers and/or F5 support.

The MQC can do the following without assistance:

-Enable a virtual server that has already been defined.

-Locate where iRules are facilitated within QKView.

-Use QKView troubleshooting tools (for example, obtain a Transmission Control Protocol (TCP) dump and a qkview using QKView, and upload a qkview to BIG-IP iHealth).

\sphinxstyleemphasis{Prerequisite for exam:}
\begin{itemize}
\item {} 
Exam 101 - Application Delivery Fundamentals

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Exam 202 - Pre-Sales Fundamentals}

This is the second exam required to achieve F5 Certified Sales Professional status. All candidates must have passed the 101-Application Delivery Fundamentals exam in order to achieve F5 Certified Sales Professional status.

Successful completion of the 202 Pre-Sales Fundamentals exam acknowledges the skills and understanding necessary for technical selling of F5 solutions.

Summary description of the MQC

The MQC has a proven track record of successfully selling F5 solutions. The MQC should have a working understanding of F5 solutions and be able to:

Prepare and deliver technical presentations explaining products or services to customers and prospective customers.
Confer with customers to assess business and technical requirements, and collaborate with sales teams to understand customer landscape and provide technical sales advisement.
Plan and design solutions to meet customer needs/requirements, and align solution with existing customer initiatives and infrastructure.
Recommend and explain proposed solutions and benefits to customers.
Understand market awareness that differentiates industry solutions (Security, Cloud, ADC).

\sphinxstyleemphasis{Prerequisite for exam:}
\begin{itemize}
\item {} 
Exam 101 - Application Delivery Fundamentals

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Exam Preparation}
\label{\detokenize{intro:exam-preparation}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Available Resources}

To prepare for certification exams, there are a number of resources available to candidates. Seven of these resources are listed below. Please know that there are no specific “exam prep” classes that guarantee you will pass an exam the first time. Earning an F5 certification typically requires both hands-on experience as well as studying the material. It is important to note that the responsibility of preparation lies with you, the candidate.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{AskF5}

\sphinxhref{https://support.f5.com/csp/home}{AskF5} is a centralized knowledge base of documents, links, and resources—including sections on the F5 Certified! Program. You can find official exam blueprints, community-created study guides, program policies, exam descriptions, and more on AskF5. Most of the information within this guide is pulled from the certification pages found on AskF5.
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K93611383}{F5 certification and introduction}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K29900360}{Exams and study materials}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K90101564}{Policies and program details}

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Exam Blueprint}

Each exam has its own unique blueprint that was developed by subject matter experts (SMEs). The blueprint provides a detailed breakdown of the skills and knowledge that you should possess in order to pass the exam. Blueprints can be used to identify areas for additional study and are best used in conjunction with the exam study guides.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Exam Study Guides}

Exam-specific study guides are available here on F5 Cloud Docs as well as on AskF5 in PDF format. These study guides feature a collection of information and resources that may be helpful for exam preparation. Study guides have been created by the F5 Certified! community and are not refreshed at the same time as exams.  The content here on F5 Cloud Docs will be the most current study guide content available.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Learn F5}

\sphinxhref{https://account.f5.com/learnf5/signin}{Learn F5} provides several free web-based trainings appropriate to use to prepare for Exam 101. A good place to start with F5 web-based training is the “Getting Started” series.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{LinkedIn Groups}

F5 Certified! LinkedIn groups are a great place to engage with a community of candidates and Certification Team support. In the various LinkedIn groups, you may ask or answer questions, provide and gather resources, and give feedback on the program.
The “F5 Certified! Professionals” group is the main group, and there are separate study groups for each exam. To find a group, log into your LinkedIn account and perform a search. The two groups that are the most helpful for getting started are:
\begin{itemize}
\item {} 
F5 Certified! Professionals

\item {} 
F5 Certified! 101 Study Group

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p92}.png}

As you become more familiar with the F5 Certified! Program and advance to subsequent exams, you can access additional F5 Certified! groups that have been created specifically for the next level that you wish to pursue.

\sphinxstylestrong{The following is strictly prohibited in the LinkedIn groups:} sharing specific exam questions or topics; detailed exam questions; and sharing exam scenarios, situations, examples, or exhibits. Failure to follow these guidelines will lead to expulsion from the certification program.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Practice Exams}

F5 Certified! practice exams are designed to help gauge preparedness for the production (“real”) exams. They contain the same number of items, time constraints, and level of difficulty. They simulate the proctored, production exam experience. In addition, practice exams provide a score report with section-level guidance on your performance. This score report is only available with the official F5 Certified! practice exam. A nominal fee is charged for practice exams.
An example of a practice exam score report is shown below:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p102}.png}

The feedback in the score report provides a general assessment of your readiness for each section in the exam. Feedback is provided based on the following general levels of preparedness:
\begin{itemize}
\item {} 
Below: You are not prepared for this section. More study is required.

\item {} 
Borderline: You demonstrate understanding, but not consistently. More study would benefit your exam performance.

\item {} 
Meets: Suggests that you have sufficiently mastered this section.

\end{itemize}

This section-level feedback is intended only as guidance. While earning a “Meets” score for all sections in the practice exam suggests that you would likely pass the real exam, it does not guarantee it. A practice exam is merely a tool to help you evaluate where you would benefit from additional preparation.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{How to Purchase a Practice Exam:}

Practice exams can be purchased via ExamStudio, a third-party vendor with which we have partnered to deliver our practice exams. You must be a registered F5 Certified! candidate to get an ExamStudio account allowing you to purchase practice exams.

Please note, your ExamStudio account and your F5 Certified! account are not the same, although both will use your F5 Candidate ID as the username.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
When you registered on the F5 Candidate Portal you received an email from support@ examstudio.com. The email contains a link and credentials for ExamStudio. (Please note: After registering, it can take 24-48 hours to receive this email.)

\noindent\sphinxincludegraphics{{1p113}.png}

\item {} 
When you follow the link, you must first create a password by clicking the “Reset your password now” link in the email. You will be redirected to a site where you will be prompted to create and confirm a new password:

\noindent\sphinxincludegraphics{{1p122}.png}

\item {} 
Once your password is created, you will be automatically logged in and directed to the home page of your ExamStudio account. To complete a purchase of practice exams, proceed to the “Shop Front” tab:

\noindent\sphinxincludegraphics{{1p132}.png}

\item {} 
In the Shop Front you will see a list of the available practice exams, details around allowed attempts, and the price of practice exams available for purchase (in USD). To purchase a practice exam, you must select the exam and agree to the “Terms and Conditions” before clicking the “Checkout Now” button:

\noindent\sphinxincludegraphics{{1p142}.png}

\item {} 
After you have selected the practice exam, accepted the terms and conditions, and clicked “Checkout Now” you will be directed to a Payment Methods page. Accepted forms of payment are PayPal or bank card. After you have entered your payment information, click “Confirm Payment”:

\noindent\sphinxincludegraphics{{1p152}.png}

\item {} 
Next you will see a purchase confirmation page:

\noindent\sphinxincludegraphics{{1p162}.png}

\item {} 
Click on the “My Exams” tab and you will see your practice exam listed in the “Available Exams” section. When you are ready to start your practice exam click the “Start Exam” link under “Actions”: Note - As soon as you click on the “Start Exam” link, your practice exam will begin.

\noindent\sphinxincludegraphics{{1p172}.png}

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{F5.com}

An overview of basic information about the F5 Certified! Program is available on the F5 corporate website, \sphinxhref{https://www.f5.com}{f5.com}. This website contains information that will help you understand the F5 product suite and provides a high-level overview of the F5 Certified! Program.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{F5 Candidate Portal}

The first step to certification was creating an account in the \sphinxhref{https://www.certmetrics.com/f5certified/login.aspx?ReturnUrl=\%2ff5certified\%2f}{F5 Candidate Portal}. If you are reading this handbook, you have already completed this step and have been assigned a Candidate ID.
The F5 Candidate Portal continues to be a helpful resource even after creating an account. You can log into the F5 Candidate Portal to get program updates, track your certification progress, check exam scores, update your personal information, and schedule exams at Pearson VUE testing centers.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p181}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Additional Resources}

A commercially available study guide has been created for Exam 101. The book is titled \sphinxstyleemphasis{F5 Networks Application Delivery Fundamentals Study Guide} by Philip Jonsson and Steven Iverson. It is available for purchase in either hardcopy or electronic formats. Please know that the commercially available study guide was written and produced independent of the F5 Certified! Program. It may not align with the current version of the exam, although exam versioning is of minor concern for content included in Exam 101.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Scheduling the Exam}
\label{\detokenize{intro:scheduling-the-exam}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Test Centers}

Pearson VUE is the official global test delivery partner for the F5 Certified! Program. Pearson VUE testing centers are secure and conveniently located. To find a Pearson VUE testing center near you, Pearson VUE provides a \sphinxhref{http://www.pearsonvue/com/f5/locate}{test center locator}.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p191}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If you live more than 55 miles/100km from a Pearson VUE testing facility, you can request a test center closer to your location. Your request will be reviewed to determine if there is a closer facility that meets the security requirements for the programs.

To request an additional test center:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log into the \sphinxhref{https://www.certmetrics.com/f5certified/login.aspx?ReturnUrl=\%2ff5certified\%2f}{F5 Candidate Portal}

\item {} 
Click on the “Test Center Additions” button.

\noindent\sphinxincludegraphics{{1p202}.png}

\end{enumerate}

Do not use the “Submit” button at the bottom of the form. Instead, continue with the following steps:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Download and complete the form.

\item {} 
Email the form to \sphinxhref{mailto:Support@Cert.F5.com}{Support@Cert.F5.com}.

\end{enumerate}

Once the F5 Certified! Team receives the completed form they will submit it to Pearson VUE. Keep in mind that making a request does not guarantee that a new test center will be opened.

NOTE: If the request is approved, it can take up to 30 days to open a new test center.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{How to Schedule an Exam}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Scheduling the Exam}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Go to the F5 Candidate Portal \sphinxhref{https://www.certmetrics.com/f5certified/login.aspx?ReturnUrl=\%2ff5certified\%2f}{here}.

\item {} 
Log in to your account using the F5 portal credentials that you created when you first registered for the program.

\item {} 
Once you log in, click the “Schedule an exam” button:

\noindent\sphinxincludegraphics{{1p213}.png}

\item {} 
A new page will give you the option to “click here” to schedule your exam:

\noindent\sphinxincludegraphics{{1p222}.png}

\item {} 
This will direct you to the Pearson VUE sign in portal. Sign in with your Pearson VUE account credentials:

\noindent\sphinxincludegraphics{{1p232}.png}

\item {} 
You will see a screen displaying the exams for which you can schedule a testing date. Click the link embedded in the name of the exam (in this example, it is “101: Application Delivery Fundamentals”):

\noindent\sphinxincludegraphics{{1p242}.png}

\item {} 
You will then see the following image, where you can view the Pearson VUE testing policies, as well as the price and available testing language. To proceed, click “Schedule this Exam.” (Note that the price for the testing is currently \$135 USD or your local equivalent.)

\noindent\sphinxincludegraphics{{1p252}.png}

\item {} 
Once you proceed to the next screen, the Pearson VUE portal will automatically find the closest test center to your entered location. From the options that appear, select the option most convenient for you and click “Next.” (If a test center is not found near your location, please see section 4.1 to request a new location.)

\noindent\sphinxincludegraphics{{1p262}.png}

\item {} 
From the options available, select the date and time that best works for you:

\noindent\sphinxincludegraphics{{1p272}.png}

\item {} 
Once the date and time has been confirmed, you will be taken to a checkout section where you can verify your selected options before clicking “Proceed to Checkout”:

\noindent\sphinxincludegraphics{{1p281}.png}

\item {} 
Once you have completed the purchasing process, you will receive an email confirming your appointment details:

\noindent\sphinxincludegraphics{{1p291}.png}

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Changing a Scheduled Appointment}

If you need to reschedule an exam, you must contact Pearson VUE at least 24 hours before the scheduled exam time. Pearson VUE’s \sphinxhref{http://pearsonvue.com/f5/contact/}{customer service} page lists contact details, including an online chat service.

\sphinxstylestrong{Note: F5 cannot reschedule your exam for you.} You \sphinxstylestrong{must} reschedule on the Pearson VUE website or contact them directly.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Test Site Requirements}

Test site requirements are defined by Pearson VUE testing centers. Always check the Pearson VUE website for up-to-date information regarding test site requirements. Watch this video to help you prepare: \sphinxhref{https://home.pearsonvue.com/test-taker/security.aspx}{What to expect in a Pearson VUE test center}.

The following are examples of some test site guidelines:
\begin{itemize}
\item {} 
Personal items are not allowed in the testing room.

\item {} 
Eating, drinking, smoking, talking, or disturbing other candidates is prohibited.

\item {} 
Engaging in misconduct or other irregular activities may invalidate your score as well as existing certifications.

\item {} 
An erasable note board and pen are provided for notes and calculations during the exam.

\item {} 
Removing an erasable note board, or other provided items, from the testing area is an act of misconduct.

\item {} 
Erasable note board and other exam materials may not be used before the exam starts.

\item {} 
You will be monitored at all times during the exam.

\item {} 
Candidates must keep personal identification (ID) with them at all times.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Identification Requirements}

When taking an exam at a Pearson VUE testing center, you must bring two forms of valid, signed ID. One must be government-issued and include a photo. The name on the ID must match the name listed on the Pearson VUE account. If it does not match, please email F5 Certified! Support (\sphinxhref{mailto:support@cert.f5.com}{support@cert.f5.com}) to get your name changed before the exam. Please allow enough time before your exam appointment.
When you sign in at the Pearson VUE testing center, they will confirm your identity by taking a photograph, having you sign a digital pad, and scanning your palm. The information you provide will be treated in accordance with the \sphinxhref{https://f5.com/about-us/policies/privacy-policy}{F5 Privacy Notice}. If you prefer to opt out, please use the process shown below.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{To request an admissions data waiver:}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log into the \sphinxhref{https://www.certmetrics.com/f5certified/login.aspx?ReturnUrl=\%2ff5certified\%2f}{F5 Candidate Portal}

\item {} 
Click on the “Admissions Data Waiver” button.

\noindent\sphinxincludegraphics{{1p301}.png}

\end{enumerate}

Do not use the “Submit” button at the bottom of the form. Instead, continue with the following steps:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Download and complete the form.

\item {} 
Send the form to \sphinxhref{mailto:Support@Cert.F5.com}{Support@Cert.F5.com}.

\end{enumerate}

NOTE: In order to ensure the security of our program and prevent fraud, you may only opt-out of one (1) of the three (3) admissions data requirements.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Test Length and Number of Questions}

Exam 101 — Application Delivery Fundamentals is 90 minutes long, with 80 multiple choice questions. Some items may include exhibits that will need to be opened and viewed before moving on to the next items. Scrolling (both vertical and horizontal) may be required before answering or moving on to the next item.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Exam Scoring}
\label{\detokenize{intro:exam-scoring}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Preliminary Results}

When you complete the exam, you will receive a preliminary “pass” or “fail” score report. This is only a preliminary result and is subject to change until official results are posted to your account in the F5 Candidate Portal.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{When Final Results Are Available}

You will receive an email notification of your final results. It could take up to 72 hours for this email to arrive. You can then log into the F5 Candidate Portal and click the “Exam History” tab to download and view your test results. It will show the percentage you answered correctly along with the required passing score.

\noindent\sphinxincludegraphics{{1p312}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Retake Policy}

In the event of failing an exam one or more times, the following waiting periods apply:
\begin{itemize}
\item {} 
The first time you fail an exam, you must wait 15 days before taking the exam again.

\item {} 
The second time, you must wait 30 days.

\item {} 
The third time, you must wait 45 days.

\item {} 
The fourth time, you must wait one year.

\item {} 
The fifth time (or more), you must wait 90 days between retakes.

\end{itemize}

At the end of the waiting period, you will receive an email as soon as you are eligible to schedule a retake exam. Though you are required to wait the times detailed above, you can log in to Pearson VUE and schedule an exam before the end of the exam-hold period. This retake count is reset when you pass an exam.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Need Further Help?}
\label{\detokenize{intro:need-further-help}}
If there are any questions or suggestions concerning the F5 Certified! Program or the content listed in this guide, please contact us at: \sphinxhref{mailto:support@cert.f5.com}{support@cert.f5.com}


\chapter{F5 101 - App Delivery Fundamentals Study Guide 11/01/19}
\label{\detokenize{class1/class1:f5-101-app-delivery-fundamentals-study-guide-11-01-19}}\label{\detokenize{class1/class1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{The 101 Exam was updated to a new version (v3) based on TMOS v13.1 on 10/1/19 without notification.}

\sphinxstylestrong{The release of the new exam version has placed this content out of date.}

\sphinxstylestrong{You can find the new blueprint published here:}
\sphinxurl{https://support.f5.com/csp/article/K29900360}

\sphinxstylestrong{Although the content does not follow the new 101 Exam Bluepint, the material is still revelavent to the knowledge level of the exam.}

\sphinxstylestrong{I will be working to get this doc updated as soon as possible.}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview  101 - App Delivery Fundamentals}

Welcome to the F5 101 - Application Delivery Fundamentals compiled
Study Guide. The purpose of this guide is to help you prepare for the
F5 101 - Application Delivery Fundamentals exam. The contents of this document
are based on the 101 - Application Delivery Fundamentals Exam Blueprint for
TMOS v11.4.

\sphinxstylestrong{This study guide provides students with some of the basic foundational knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from sources that
are located on the Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the referenced information easier without having
to search through a formal appendix. This guide also references a book that
should be basic reading for some of the topics on this exam.

There are not any pre-requisites to this exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Reading = Knowledge = Power}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Printed References}

These referenced books are important and should be considered basic reading
material for this exam.

(Ref:1) Kozierok, Charles M. 2005. The TCP/IP Guide. No Starch Press, Inc. San
Francisco, CA. 94103. ISBN 1-59327-047-X  pp 947 -1080

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Section 1 - OSI}
\label{\detokenize{class1/modules/module1:section-1-osi}}\label{\detokenize{class1/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.01 Explain, compare, and contrast the OSI layers}
\label{\detokenize{class1/modules/module1:objective-1-01-explain-compare-and-contrast-the-osi-layers}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Describe the function of each OSI layer}

\sphinxstylestrong{Ref: 1, pp. 168-181.}

\sphinxhref{http://www.windowsnetworking.com/articles-tutorials/netgeneral/Networking-Basics-Part17.html}{Link to Online Topic Content}

\sphinxhref{https://support.microsoft.com/en-us/kb/103884}{Link to Online Topic Content}

\sphinxstylestrong{The OSI Model}

The term OSI Model is short for Open System Interconnection Basic
Reference Model. The OSI Model consists of seven different layers. Each
layer of the model is designed so that it can perform a specific task,
and facilitates communications between the layer above it and the layer
below it. You can see what the OSI Model looks like in the figure below.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p1}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{The Application Layer}

The top layer of the OSI model is the Application layer. The first thing
that you need to understand about the application layer is that it does
not refer to the actual applications that users run. Instead, it
provides the framework that the actual applications run on top of.

To understand what the application layer does, suppose that a user
wanted to use Internet Explorer to open an FTP session and transfer a
file. In this particular case, the application layer would define the
file transfer protocol. This protocol is not directly accessible to the
end user. The end user must still use an application that is designed to
interact with the file transfer protocol. In this case, Internet
Explorer would be that application.

\sphinxstylestrong{The Presentation Layer}

The presentation layer does some rather complex things, but everything
that the presentation layer does can be summed up in one sentence. The
presentation layer takes the data that is provided by the application
layer, and converts it into a standard format that the other layers can
understand. Likewise, this layer converts the inbound data that is
received from the session layer into something that the application
layer can understand. The reason why this layer is necessary is because
applications handle data differently from one another. In order for
network communications to function properly, the data needs to be
structured in a standard way.

\sphinxstylestrong{The Session Layer}

Once the data has been put into the correct format, the sending host
must establish a session with the receiving host. This is where the
session layer comes into play. It is responsible for establishing,
maintaining, and eventually terminating the session with the remote
host.

The interesting thing about the session layer is that it is more closely
related to the application layer than it is to the physical layer. It is
easy to think of connecting a network session as being a hardware
function, but sessions are established between applications. If a user
is running multiple applications, several of those applications may have
established sessions with remote resources at any time.

\sphinxstylestrong{The Transport Layer}

The Transport layer is responsible for maintaining flow control. An
operating system allows users to run multiple applications
simultaneously and it is therefore possible that multiple applications
may need to communicate over the network simultaneously. The Transport
Layer takes the data from each application, and integrates it all into a
single stream. This layer is also responsible for providing error
checking and performing data recovery when necessary. In essence, the
Transport Layer is responsible for ensuring that all of the data makes
it from the sending host to the receiving host.

\sphinxstylestrong{The Network Layer}

The Network Layer is responsible for determining how the data will reach
the recipient. This layer handles things like addressing, routing, and
logical protocols. Since this series is geared toward beginners, I do
not want to get too technical, but I will tell you that the Network
Layer creates logical paths, known as virtual circuits, between the
source and destination hosts. This circuit provides the individual
packets with a way to reach their destination. The Network Layer is also
responsible for its own error handling, and for packet sequencing and
congestion control.

Packet sequencing is necessary because each protocol limits the maximum
size of a packet. The amount of data that must be transmitted often
exceeds the maximum packet size. Therefore, the data is fragmented into
multiple packets. When this happens, the Network Layer assigns each
packet a sequence number. When the data is received by the remote host,
that device’s Network layer examines the sequence numbers of the inbound
packets, and uses the sequence number to reassemble the data and to
figure out if any packets are missing. If you are having trouble
understanding this concept, then imagine that you need to mail a large
document to a friend, but do not have a big enough envelope. You could
put a few pages into several small envelopes, and then label the
envelopes so that your friend knows what order the pages go in. This is
exactly the same thing that the Network Layer does.

\sphinxstylestrong{The Data Link Layer}

The data link layer can be sub divided into two other layers; the Media
Access Control (MAC) layer, and the Logical Link Control (LLC) layer.
The MAC layer basically establishes the computer’s identity on the
network, via its MAC address. A MAC address is the address that is
assigned to a network adapter at the hardware level. This is the address
that is ultimately used when sending and receiving packets. The LLC
layer controls frame synchronization and provides a degree of error
checking.

\sphinxstylestrong{The Physical Layer}

The physical layer of the OSI model refers to the actual hardware
specifications. The Physical Layer defines characteristics such as
timing and voltage. The physical layer defines the hardware
specifications used by network adapters and by the network cables
(assuming that the connection is not wireless). To put it simply, the
physical layer defines what it means to transmit and to receive data.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Differentiate between the OSI layers}

\sphinxhref{https://learningnetwork.cisco.com/docs/DOC-15624}{Link to Online Topic Content}

\sphinxstylestrong{OSI Layers}

Application (Layer 7)

This layer supports application and end-user processes. Communication
partners are identified, quality of service is identified, user
authentication and privacy are considered, and any constraints on data
syntax are identified. Everything at this layer is application-specific.
This layer provides application services for file transfers, e-mail, and
other network software services.

Presentation (Layer 6)

This layer provides independence from differences in data representation
(e.g., encryption) by translating from application to network format,
and vice versa. This layer formats and encrypts data to be sent across a
network, providing freedom from compatibility problems. It is sometimes
called the syntax layer.

Transport (Layer 4)

This layer provides transparent transfer of data between end systems, or
hosts, and is responsible for end-to-end error recovery and flow
control. It ensures complete data transfer.

Network (Layer 3)

This layer provides switching and routing technologies, creating logical
paths, known as virtual circuits, for transmitting data from node to
node. Routing and forwarding are functions of this layer, as well as
addressing, internetworking, error handling, congestion control and
packet sequencing.

Data Link (Layer 2)

This layer provides switching and routing technologies, creating logical
paths, known as virtual circuits, for transmitting data from node to
node. Routing and forwarding are functions of this layer, as well as
addressing, internetworking, error handling, congestion control and
packet sequencing.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p2}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Describe the purpose of the various address types at different
OSI layers}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{OSI layers functional}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Physical - Hubs, Repeaters, Cables, Optical Fiber, SONET/SDN,Coaxial Cable,
Twisted Pair Cable and Connectors

\item {} 
Data Link - 802.11 (WLAN), Wi-Fi, WiMAX, ATM, Ethernet, Token Ring, Frame
Relay, PPTP, L2TP and ISDN

\item {} 
Network - IPv4, IPV6, IPX, OSPF, ICMP, IGMP and ARP

\item {} 
Transport - TCP, SPX and UDP

\item {} 
Session layer - Logical Ports 21, 22, 23, 80 etc.

\item {} 
Presentation layer - SSL, WEP, WPA, Kerberos,

\item {} 
Application Layer - DHCP, DNS, FTP, HTTP, IMAP4, NNTP, POP3, SMTP, SNMP,
SSH, TELNET and NTP

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.02 Explain Protocols and Technologies Specific to the Data Link Layer}
\label{\detokenize{class1/modules/module1:objective-1-02-explain-protocols-and-technologies-specific-to-the-data-link-layer}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose of a switch’s forwarding database}

\sphinxstylestrong{Forwarding Database}

A forwarding database is a table used by a Layer 2 device
(switch/bridge) to store the learned MAC addresses of nodes on the
attached local broadcast domain/domains (VLANS) and the port (interface)
that MAC address was learned on. The MAC addresses are learned
transparently as the switch forwards traffic.

How it works

When an Ethernet frame arrives at a Layer 2 device, the Layer 2 device
will inspect the source MAC address of the frame and associate it to the
port that the frame arrived on in the forwarding database. This simply
creates a table that can be cross-referenced for device locations. When
the table is populated it allows the Layer 2 device to look at the
destination MAC address of the arriving Ethernet frame and find the
destination port for that MAC address, to know where to send that
specific Ethernet frame. If the FDB table doesn’t have any information
on that specific MAC address it will flood the Ethernet frame out to all
ports in the broadcast domain (VLAN).


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose and functionality of ARP}

\sphinxhref{http://linux-ip.net/html/ether-arp.html}{Link to Online Topic Content}

\sphinxstylestrong{ARP}

ARP defines the exchanges between network interfaces connected to an
Ethernet media segment in order to map an IP address to a link layer
address on demand. Link layer addresses are hardware addresses (although
they are not immutable) on Ethernet cards and IP addresses are logical
addresses assigned to machines attached to the Ethernet. Link layer
addresses may be known by many different names: Ethernet addresses,
Media Access Control (MAC) addresses, and even hardware addresses.

Address Resolution Protocol (ARP) exists solely to glue together the IP
and Ethernet networking layers. Since networking hardware such as
switches, hubs, and bridges operate on Ethernet frames, they are unaware
of the higher layer data carried by these frames. Similarly, IP layer
devices, operating on IP packets need to be able to transmit their IP
data on Ethernets. ARP defines the conversation by which IP capable
hosts can exchange mappings of their Ethernet and IP addressing.

ARP is used to locate the Ethernet address associated with a desired IP
address. When a machine has a packet bound for another IP on a locally
connected Ethernet network, it will send a broadcast Ethernet frame
containing an ARP request onto the Ethernet. All machines with the same
Ethernet broadcast address will receive this packet. If a machine
receives the ARP request and it hosts the IP requested, it will respond
with the link layer address on which it will receive packets for that IP
address.

Once the requestor receives the response packet, it associates the MAC
address and the IP address. This information is stored in the ARP cache.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose and functionality of MAC addresses}

\sphinxhref{http://www.tech-faq.com/ethernet-at-the-data-link-layer.html}{Link to Online Topic Content}

\sphinxstylestrong{MAC Addresses}

Every network device has a unique physical identity that is assigned by
the manufacturing vendor is called MAC address or Ethernet address. The
MAC address is also known as the hardware address while the IP address
is the logical address of the device. The MAC address is defined in the
Hexadecimal format generally. It consists of 6-byte (48 bits) where the
first three bytes are used as the identity of the vendor and the last
three bytes are used as the node identity. The MAC address works on the
MAC sub-layer of the data link layer of the OSI model.

Switches give network managers the ability to increase bandwidth without
adding unnecessary complexity to the network. Layer 2 data frames
consist of both infrastructure content, such as end user content and MAC
Media Access Control address also known as Ethernet address. At Data
Link layer, no modification is required to the MAC address of the data
frame when going between like physical layer interfaces, such as from
Ethernet to Fast Ethernet. However, changes to Media Access Control
(MAC) address of the data frames might occur when bridging between
unlike media types such as FDDI and Ethernet or Token Ring and Ethernet.

Switches learn the MAC address and build a table on the base of MAC
addressing of the LAN segment called MAC Address Table. The Address
Resolution Protocol (ARP) is the protocol that resolves the IP addresses
into MAC addresses. RARP, the Reverse Address Resolution Protocol is a
reverse of ARP and resolves MAC addresses into IP addresses.

The MAC layer of the Gigabit Ethernet is similar to those of standard
Ethernet and Fast Ethernet. Media Access Layer of Gigabit Ethernet
should maintain full duplex and half duplex broadcasting. The
characteristics of Ethernet, such as collision detection, maximum
network diameter, repeater rules, MAC addressing and so forth, will be
the same of the Gigabit Ethernet. Support for half duplex Ethernet adds
frame bursting and carrier extension, two functions not found in
Ethernet and Fast Ethernet.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p3}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose and functionality of a broadcast domain}

\sphinxhref{http://www.tech-faq.com/broadcast-domain.html}{Link to Online Topic Content}

\sphinxstylestrong{Broadcast Domain}

A broadcast domain is a logical part of a network (a network segment) in
which any network equipment can transmit data directly to other
equipment or device without going through a routing device (assuming the
devices share the same subnet and use the same gateway; also, they must
be in the same VLAN).

A more specific broadcast domain definition is the area of the computer
network that consists of every single computer or network-attached
device that can be reached directly by sending a simple frame to the
data link layer’s broadcast address.

\sphinxstylestrong{Details on Broadcast Domains}

While any layer 2 device is able to divide the collision domains,
broadcast domains are only divided by layer 3 network devices such as
routers or layer 3 switches. Frames are normally addressed to a specific
destination device on the network. While all devices detect the frame
transmission on the network, only the device to which the frame is
addressed actually receives it. A special broadcast address consisting
of all is used to send frames to all devices on the network. The VLAN
(Virtual Local Area Network) technology can also create a so-called
“virtual” broadcast domain. A network built with switching devices can
see each network device as an independent system. These groups of
independent systems can be joined into one broadcast domain, even if the
computers are not physically connected to each other. This is very
useful when administrating large networks where there is the need for
better network management and control.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p4}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{How to Restrict the Broadcast Domain}

Since a broadcast domain is the area where broadcasts can be received,
routers restrict broadcasts. If a router receives a broadcast signal, it
simply drops it. In other words, the edge or border router connected to
the Internet will not up-broadcast or will not relay that broadcast
message. This is problematic and not foolproof either. Suppose two
networks exist that are connected to each other through a router and the
first network has a running DHCP server that offers IP addresses to
networked systems. On the other side, there is no valid DHCP server
running on the second network. Offering IP addresses from the first
network’s DHCP server to the second network’s systems can be a difficult
task to accomplish since DHCP is a broadcast and the router that joins
the networks drops the broadcast traffic. This leaves any DHCP request
in the second network unanswered. Many router manufacturers provide
capabilities for DHCP forwarding to solve this problem. This can be
bypassed by connecting the two networks with a well-configured,
Linux-based, purpose oriented software router. That will handle the job
properly and prevent further issues.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose and functionality of VLANs}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos\_management\_guide\_10\_1/tmos\_vlans.html}{Link to Online Topic Content}

\sphinxhref{http://shinesgeorge.blogspot.com/2013/11/what-is-vlan-how-to-setup-vlan-on-cisco.html}{Link to Online Topic Content}

\sphinxstylestrong{Virtual Local Area Network (VLAN)}

In technical terms, a VLAN is a virtual broadcast domain created inside
a switch. Normally, a Layer2 device acts as a single LAN with all ports
active in the LAN. In a manageable switch, the switch has the ability to
be configured to group any amount of its physical ports into logical
VLANs where each is an individual broadcast domain.

Because switches can talk to each other when linked together, if the
same VLAN number exists in both switches devices in each switch in the
same VLAN can talk to each other as if it were all one switch.
Broadcasts between these devices will not be seen on any other port in
any other VLAN, other than the one in which they are configured. Just
like with physical LANs, without a router they would not be able to
communicate with any devices in a different VLAN.

\sphinxstylestrong{Are VLANs required?}

It is important to point out that you don’t have to configure a VLAN
until your network gets so large and has so much traffic that you need
one. Many times, people are simply using VLAN’s because the network they
are working on was already using them.

Another important fact is that, on a Cisco switch, VLAN’s are enabled by
default and ALL devices are already in a VLAN. The VLAN that all devices
are already in is VLAN 1. So, by default, you can just use all the ports
on a switch and all devices will be able to talk to one another.

\sphinxstylestrong{When do I need a VLAN?}

You need to consider using VLAN’s in any of the following situations:
\begin{itemize}
\item {} 
You have more than 200 devices on your LAN

\item {} 
You have a lot of broadcast traffic on your LAN

\item {} 
Groups of users need more security or are being slowed down by too
many broadcasts?

\item {} 
Groups of users need to be on the same broadcast domain because they
are running the same applications. An example would be a company that
has VoIP phones. The users using the phone could be on a different
VLAN, not with the regular users.

\item {} 
Or, just to make a single switch into multiple virtual switches.

\end{itemize}

\sphinxstylestrong{Why not just subnet my network?}

A common question is why not just subnet the network instead of using
VLAN’s? Each VLAN should be in its own subnet. The benefit that a VLAN
provides over a subnetted network is that devices in different physical
locations, not going back to the same router, can be on the same
network. The limitation of subnetting a network with a router is that
all devices on that subnet must be connected to the same switch and that
switch must be connected to a port on the router. With a VLAN, one
device can be connected to one switch, another device can be connected
to another switch, and those devices can still be on the same VLAN
(broadcast domain).

\sphinxstylestrong{How can devices on different VLAN’s communicate?}

Devices on different VLAN’s can communicate with a router or a Layer 3
switch. As each VLAN is its own subnet, a router or Layer 3 switch must
be used to route between the subnets.

\sphinxstylestrong{What is a trunk port?}

When there is a link between two switches or a router and a switch that
carries the traffic of more than one VLAN, that port is a trunk port. A
trunk port must run a special trunking protocol. The protocol used would
be Cisco’s proprietary Inter- switch link (ISL) or the IEEE standard
802.1q, which is the protocol F5 devices support.

\sphinxstylestrong{What do VLAN’s offer?}

VLAN’s offer higher performance for medium and large LAN’s because they
limit broadcasts. As the amount of traffic and the number of devices
grow, so does the number of broadcast packets. By using VLAN’s you are
containing broadcasts. VLAN’s also provide security because you are
essentially putting one group of devices, in one VLAN, on their own
network.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the purpose and functionality of link aggregation}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos\_management\_guide\_10\_1/tmos\_trunks.html}{Link to Online Topic Content}

\sphinxstylestrong{Introducing trunks}

A trunk is a logical grouping of interfaces on the BIG-IP system. When
you create a trunk, this logical group of interfaces functions as a
single interface. The BIG-IP system uses a trunk to distribute traffic
across multiple links, in a process known as \sphinxstylestrong{link aggregation}.
With link aggregation, a trunk increases the bandwidth of a link by
adding the bandwidth of multiple links together. For example, four fast
Ethernet (100 Mbps) links, if aggregated, create a single 400 Mbps link.

With one trunk, you can aggregate a maximum of eight links. For optimal
performance, you should aggregate links in powers of two. Thus, you
ideally aggregate two, four, or eight links.

The purpose of a trunk is two-fold: To increase bandwidth without
upgrading hardware, and to provide link failover if a member link
becomes unavailable.

You can use trunks to transmit traffic from a BIG-IP system to another
vendor switch. Two systems that use trunks to exchange frames are known
as peer systems.

How do trunks work?

In a typical configuration where trunks are configured, the member links
of the trunk are connected through Ethernet cables to corresponding
links on a peer system. Figure 9.1 shows an example of a typical trunk
configuration with two peers and three member links on each peer.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p5}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

A primary goal of the trunks feature is to ensure that frames exchanged
between peer systems are never sent out of order or duplicated on the
receiving end. The BIG-IP system is able to maintain frame order by
using the source and destination addresses in each frame to calculate a
hash value, and then transmitting all frames with that hash value on the
same member link.

The BIG-IP system automatically assigns a unique MAC address to a trunk.
However, by default, the MAC address that the system uses as the source
and destination address for frames that the system transmits and
receives (respectively), is the MAC address of the lowest-numbered
interface of the trunk.

The BIG-IP system also uses the lowest-numbered interface of a trunk as
a reference link. The BIG-IP system uses the reference link to take
certain aggregation actions, such as implementing the automatic link
selection policy. For frames coming into the reference link, the BIG-IP
system load balances the frames across all member links that the BIG-IP
system knows to be available. For frames going from any link in the
trunk to a destination host, the BIG-IP system treats those frames as if
they came from the reference link.

Finally, the BIG-IP system uses the MAC address of an individual member
link as the source address for any LACP control frames.

\sphinxstylestrong{Overview of LACP}

A key aspect of trunks is Link Aggregation Control Protocol, or LACP.
Defined by IEEE standard 802.3ad, LACP is a protocol that detects error
conditions on member links and redistributes traffic to other member
links, thus preventing any loss of traffic on the failed link. On a
BIG-IP system, LACP is an optional feature that you can configure.

You can also customize LACP behavior. For example, you can specify the
way that LACP communicates its control messages from the BIG-IP system
to a peer system. You can also specify the rate at which the peer system
sends LACP packets to the BIG-IP system. If you want to affect the way
that the BIG-IP system chooses links for link aggregation, you can
specify a link control policy.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.03 Explain protocols and apply technologies specific to the network layer}
\label{\detokenize{class1/modules/module1:objective-1-03-explain-protocols-and-apply-technologies-specific-to-the-network-layer}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Explain the purpose and functionality of IP addressing and
subnetting}

\sphinxhref{http://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13788-3.html}{Link to Online Topic Content}

\sphinxstylestrong{Understanding IP Addresses}

An IP address is an address used in order to uniquely identify a device
on an IP network. The address is made up of 32 binary bits, which can be
divisible into a network portion and host portion with the help of a
subnet mask. The 32 binary bits are broken into four octets (1 octet = 8
bits). Each octet is converted to decimal and separated by a period
(dot). For this reason, an IP address is expressed in dotted decimal
format (for example, 172.16.81.100). The value in each octet ranges from
0 to 255 decimal, or 00000000 - 11111111 binary.

Here is how binary octets convert to decimal: The right most bit, or
least significant bit, of an octet holds a value of 2\textasciicircum{}0. The bit just to
the left of that holds a value of 2\textasciicircum{}1. This continues until the
left-most bit, or most significant bit, which holds a value of 2\textasciicircum{}7. So
if all binary bits were a one, the decimal equivalent would be 255 as
shown here:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily \\
\hline
128
&
64
&
32
&
16
&
8
&
4
&
2
&
1
&
(128+64+32+16+8+4+2+1=255)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Here is a sample octet conversion when not all of the bits are set to 1.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily \\
\hline
0
&
64
&
0
&
0
&
0
&
0
&
0
&
1
&
(0+64+0+0+0+0+0+1=65)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

And this is sample shows an IP address represented in both binary and
decimal.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{5}{\X{1}{5}|}}
\hline
\sphinxstyletheadfamily \begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
\end{enumerate}
&\sphinxstyletheadfamily \begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
\end{enumerate}
&\sphinxstyletheadfamily \begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{22}
\item {} 
\end{enumerate}
&\sphinxstyletheadfamily 
19
&\sphinxstyletheadfamily 
decimal
\\
\hline
00001010 .
&
00000001 .
&
00010111 .
&
00010011 .
&
binary
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

These octets are broken down to provide an addressing scheme that can
accommodate large and small networks. There are five different classes
of networks, A to E. This document focuses on addressing classes A to C,
since classes D and E are reserved and discussion of them is beyond the
scope of this document.

\sphinxstyleemphasis{Note - Also note that the terms “Class A, Class B and so on” are used in this document to help facilitate the understanding of IP addressing and subnetting. These terms are rarely used in the industry anymore because of the introduction of classless inter-domain routing (CIDR), although CIDR is beyond the scope of this document. Given an IP address, its class can be determined from the three high-order bits. The Figure below shows the significance of the three high order bits and the range of addresses that fall into each class. For informational purposes, Class D and Class E addresses are also shown.}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p6}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Given an IP address and net mask, determine the network IP and
the broadcast IP}

\sphinxhref{http://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13788-3.html}{Link to Online Topic Content}

\sphinxstylestrong{Network Masks}

A network mask helps you know which portion of the address identifies
the network and which portion of the address identifies the node. Class
A, B, and C networks have default masks, also known as natural masks, as
shown here:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Class A:
&\sphinxstyletheadfamily 
255.0.0.0
\\
\hline
Class B:
&
255.255.0.0
\\
\hline
Class C:
&
255.255.255.0
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

An IP address on a Class A network that has not been subnetted would
have an address/mask pair similar to: 8.20.15.1 255.0.0.0. To see how
the mask helps you identify the network and node parts of the address,
convert the address and mask to binary numbers.

8.20.15.1 = 00001000.00010100.00001111.00000001 255.0.0.0 =
11111111.00000000.00000000.00000000

Once you have the address and the mask represented in binary, then
identifying the network and host ID is easier. Any address bits that
have corresponding mask bits set to 1 represent the network ID. Any
address bits that have corresponding mask bits set to 0 represent the
node ID.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

8.20.15.1 =
&
00001000
&
00010100
&
00001111
&
00000001
\\
\hline
255.0.0.0 =
&
11111111
&
00000000
&
00000000
&
00000000
\\
\hline&
Net id
&&
Host id
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Understanding Subnetting

Subnetting allows you to create multiple logical networks that exist
within a single Class A, B, or C network. If you do not subnet, you are
only able to use one network from your Class A, B, or C network, which
is unrealistic.

Each data link on a network must have a unique network ID, with every
node on that link being a member of the same network. If you break a
major network (Class A, B, or C) into smaller subnets, it allows you to
create a network of interconnecting subnets. Each data link on this
network would then have a unique network/sub-network ID. Any device, or
gateway, connecting n networks/subnets has n distinct IP addresses, one
for each network / sub-network that it interconnects. In order to subnet
a network, extend the natural mask using some of the bits from the host
ID portion of the address to create a sub-network ID. For example, given
a Class C network of 204.17.5.0, which has a natural mask of
255.255.255.0, you can create subnets in this manner:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

204.17.5.0 =
&
11001100
&
00010001
&
0000010
&
00000000
\\
\hline
255.255.255.224 =
&
11111111
&
11111111
&
11111111
&
11100000
\\
\hline&&&&
—-\textbar{} sub \textbar{}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

By extending the mask to be 255.255.255.224, you have taken three bits
(indicated by “sub”) from the original host portion of the address and
used them to make subnets. With these three bits, it is possible to
create eight subnets. With the remaining five host ID bits, each subnet
can have up to 32 host addresses, 30 of which can actually be assigned
to a device since host ids of all zeros or all ones are not allowed (it
is very important to remember this). So, with this in mind, these
subnets have been created.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
204.17.5.0
&\sphinxstyletheadfamily 
255.255.255.224
&\sphinxstyletheadfamily 
host address range 1 to 30
\\
\hline
204.17.5.32
&
255.255.255.224
&
host address range 33 to 62
\\
\hline
204.17.5.64
&
255.255.255.224
&
host address range 65 to 94
\\
\hline
204.17.5.96
&
255.255.255.224
&
host address range 97 to 126
\\
\hline
204.17.5.128
&
255.255.255.224
&
host address range 129 to 158
\\
\hline
204.17.5.160
&
255.255.255.224
&
host address range 161 to 190
\\
\hline
204.17.5.192
&
255.255.255.224
&
host address range 193 to 222
\\
\hline
204.17.5.224
&
255.255.255.224
&
host address range 225 to 254
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstyleemphasis{Note:
There are two ways to denote these masks. First, since you are using three bits more than the “natural” Class C mask, you can denote these addresses as having a 3-bit subnet mask. Or, secondly, the mask of 255.255.255.224 can also be denoted as /27 as there are 27 bits that are set in the mask. This second method is used with CIDR. With this method, one of these networks can be described with the notation pre-fix/length. For example, 204.17.5.32/27 denotes the network 204.17.5.32 255.255.255.224. When appropriate the prefix/length notation is used to denote the mask throughout the rest of this document.}

The network subnetting scheme in this section allows for eight subnets,
and the network might appear as:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p7}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Notice that each of the routers in the figure is attached to four
subnets, one sub-network is common to both routers. Also, each router
has an IP address for each subnets to which it is attached. Each
sub-network could potentially support up to 30 host addresses.

This brings up an interesting point. The more host bits you use for a
subnet mask, the more subnets you have available. However, the more
subnets available, the less host addresses available per subnet. For
example, a Class C network of 204.17.5.0 and a mask of 255.255.255.224
(/27) allows you to have eight subnets, each with 32 host addresses (30
of which could be assigned to devices). If you use a mask of
255.255.255.240 (/28), the break down is:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

204.17.5.0 =
&
11001100
&
00010001
&
00000101
&
00000000
\\
\hline
255.255.255.240 =
&
11111111
&
11111111
&
11111111
&
11110000
\\
\hline&&&&
—-\textbar{} sub \textbar{}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Since you now have four bits to make subnets with, you only have four
bits left for host addresses. So in this case you can have up to 16
subnets, each of which can have up to 16 host addresses (14 of which can
be assigned to devices).

Take a look at how a Class B network might be subnetted. If you have
network 172.16.0.0, then you know that its natural mask is 255.255.0.0
or 172.16.0.0/16. Extending the mask to anything beyond 255.255.0.0
means you are subnetting. You can quickly see that you have the ability
to create a lot more subnets than with the Class C network. If you use a
mask of 255.255.248.0 (/21), how many subnets and hosts per subnet does
this allow for?


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

172.16.0.0 =
&
11001100
&
00010001
&
00000101
&
00000000
\\
\hline
255.255.248.0 =
&
11111111
&
11111111
&
11111000
&
00000000
\\
\hline&&&
—-\textbar{} sub \textbar{}
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

You are using five bits from the original host bits for subnets. This
allows you to have 32 subnets (2\textasciicircum{}5). After using the five bits for
subnetting, you are left with 11 bits for host addresses. This allows
each subnet so have 2048 host addresses (2\textasciicircum{}11), 2046 of which could be
assigned to devices.

\sphinxstyleemphasis{Note -
In the past, there were limitations to the use of a subnet 0 (all subnet bits are set to zero) and all ones subnet (all subnet bits set to one). Some devices would not allow the use of these subnets. Cisco Systems devices allow the use of these subnets when the IP subnet zero command is configured.}

A broadcast address is an IP address that targets all systems on a
specific subnet instead of single hosts. The broadcast address of any IP
address can be calculated by taking the bit compliment of the subnet
mask, sometimes referred to as the reverse mask, and then applying it
with a bitwise OR calculation to the IP address in question.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p8}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Some systems that are derived from BSD use zeros broadcasts instead of
ones-broadcasts. This means that when a broadcast address is created,
the host area of the IP address is filled while displayed using binary
values with zeros instead of ones. Most operating systems use ones
broadcasts. Changing systems to use zeros-broadcasts will break some
communications in the wrong environments, so the user should understand
his/her needs before changing the broadcast address or type.

\sphinxstylestrong{Math Example}

If a system has the IP address 192.168.12.220 and a network mask of
255.255.255.128, what should the broadcast address for the system be? To
do this calculation, convert all numbers to binary values. For bitwise,
remember that any two values where at least one value is 1, the result
will be 1, otherwise the result is 0.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{2}}
\sphinxstylestrong{IP Address:}     \textbar{} 11000000.10101000.00001100.11011100
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{2}}
\sphinxstylestrong{Reverse Mask:}   \textbar{} 00000000.00000000.00000000.01111111
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{2}}
\sphinxstylestrong{bitwise OR:}     \textbar{} ——————————————
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{2}}
\sphinxstylestrong{Broadcast:}      \textbar{} 11000000.10101000.00001100.11111111
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Convert the binary value back to octal and the resulting value is
192.168.12.255.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Given a routing table and a destination IP address, identify
which routing table entry the destination IP address will match}

\sphinxhref{https://technet.microsoft.com/en-us/library/Cc779122(v=WS.10).aspx}{Link to Online Topic Content}

\sphinxstylestrong{Route Tables}

Every computer that runs TCP/IP makes routing decisions. The IP routing
table controls these decisions. To display the IP routing table on
computers running Windows Server 2003 operating systems, you can type
“route print” at a command prompt.

The following table shows an example of an IP routing table. This
example is for a computer running Windows Server 2003, Standard Edition
with one 10 megabit per second (Mbit/s) network adapter and the
following configuration:
\begin{itemize}
\item {} 
IP address: 10.0.0.169

\item {} 
Subnet mask: 255.0.0.0

\item {} 
Default gateway: 10.0.0.1

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p9}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

The routing table is built automatically, based on the current TCP/IP
configuration of your computer. Each route occupies a single line in the
displayed table. Your computer searches the routing table for an entry
that most closely matches the destination IP address.

Your computer uses the default route if no other host or network route
matches the destination address included in an IP datagram. The default
route typically forwards an IP datagram (for which there is no matching
or explicit local route) to a default gateway address for a router on
the local subnet. In the previous example, the default route forwards
the datagram to a router with a gateway address of 10.0.0.1.

Because the router that corresponds to the default gateway contains
information about the network IDs of the other IP subnets within the
larger TCP/IP Internet, it forwards the datagram to other routers until
the datagram is eventually delivered to an IP router that is connected
to the specified destination host or subnet within the larger network.

The following sections describe each of the columns displayed in the IP
routing table: network destination, netmask, gateway, interface, and
metric.

\sphinxstylestrong{Network destination}

The network destination is used with the netmask to match the
destination IP address. The network destination can range from 0.0.0.0
for the default route through 255.255.255.255 for the limited broadcast,
which is a special broadcast address to all hosts on the same network
segment.

\sphinxstylestrong{Gateway}

The gateway address is the IP address that the local host uses to
forward IP datagrams to other IP networks. This is either the IP address
of a local network adapter or the IP address of an IP router (such as a
default gateway router) on the local network segment.

Interface

The interface is the IP address that is configured on the local computer
for the local network adapter that is used when an IP datagram is
forwarded on the network.

\sphinxstylestrong{Metric}

A metric indicates the cost of using a route, which is typically the
number of hops to the IP destination. Anything on the local subnet is
one hop, and each router crossed after that is an additional hop. If
there are multiple routes to the same destination with different
metrics, the route with the lowest metric is selected.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Explain the purpose and functionality of Routing protocols}

\sphinxhref{http://www.orbit-computer-solutions.com/Routing-Protocols.php}{Link to Online Topic Content}

\sphinxstylestrong{Routing Protocols}

A routing protocol is a set of rules or standard that determines how
routers on a network communicate and exchange information with each
other, enabling them to select best routes to a remote network. Each
router has priority knowledge only of networks attached to it directly.
A router running routing protocol shares this information first, among
immediate neighbors, then throughout the entire network. This way,
routers gain insight knowledge of the topology of the network.

Routing protocols perform several activities, including:
\begin{itemize}
\item {} 
Network discovery

\item {} 
Updating and maintaining routing tables

\end{itemize}

The router that sits at the base of a network maintains a routing table,
which is a list of networks and possible routes known by the router. The
routing table includes network addresses for its own interfaces, which
are the directly connected networks, as well as network addresses for
remote networks. A remote network is a network that can only be reached
by forwarding the packet to another router.

Remote networks are added to the routing table in two ways:
\begin{itemize}
\item {} 
By the network administrator manually configuring static routes.

\item {} 
By implementing a dynamic routing protocol.

\end{itemize}

Routers use Dynamic Routing protocols to share information about the
reachability and status of remote networks.

\sphinxstylestrong{IP Routing Protocols (Dynamic)}

There are several dynamic routing protocols for IP. Here are some of the
more common dynamic routing protocols for routing IP packets:
\begin{itemize}
\item {} 
RIP (Routing Information Protocol)

\item {} 
IGRP (Interior Gateway Routing Protocol)

\item {} 
EIGRP (Enhanced Interior Gateway Routing Protocol)

\item {} 
OSPF (Open Shortest Path First)

\item {} 
IS-IS (Intermediate System-to-Intermediate System)

\item {} 
BGP (Border Gateway Protocol

\end{itemize}

\sphinxstylestrong{Advantages of dynamic routing protocols}
\begin{itemize}
\item {} 
Dynamic routing protocols update and maintain the networks in their
routing tables.

\item {} 
Dynamic routing protocols not only make a best path determination to
various networks, they will also determine a new best path if the
initial path becomes unusable or there is a change in the topology.

\item {} 
Routers that use dynamic routing protocols automatically share
routing information with other routers and compensate for any
topology changes without involving the network administrator.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Explain the purpose of fragmentation}

\sphinxhref{https://en.wikipedia.org/wiki/IP\_fragmentation}{Link to Online Topic Content}

\sphinxstylestrong{Why does fragmentation occur?}

Fragmentation happens when a large IP datagram has to travel through a
network with a maximum transmission unit (MTU) that is smaller than the
size of the IP datagram. If an IP datagram that is bigger than 1500
bytes (typical MTU size) is sent on an Ethernet network, the datagram
needs to be fragmented prior to being placed on the network. The network
packets are then assembled at the receiving host. Fragmentation can
happen at either at the origination host or at an intermediate router.

IP fragmentation can cause excessive retransmissions when fragments
encounter packet loss and reliable protocols such as TCP must retransmit
all of the fragments in order to recover from the loss of a single
fragment.{[}4{]} Thus, senders typically use two approaches to decide the
size of IP datagrams to send over the network. The first is for the
sending host to send an IP datagram of size equal to the MTU of the
first hop of the source destination pair. The second is to run the path
MTU discovery algorithm,{[}5{]} described in RFC 1191, to determine the path
MTU between two IP hosts, so that IP fragmentation can be avoided.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Given a fragment, identify what information is needed for
reassembly}

\sphinxhref{http://news.hitb.org/content/understanding-ip-fragmentation}{Link to Online Topic Content}

\sphinxstylestrong{How are the packets reassembled?}

Note that with IP fragmentation, packets are not reassembled until they
reach the final destination. It is reassembled at the IP layer at the
receiving end. This is make fragmentation and reassembly transparent to
the protocol layer (TCP and UDP). If one of the packets is lost, the
whole packets need to be transmitted again. Packets are reassembled at
the receiving host by associating each fragment with an identical
fragment identification number, or frag id for short. The frag ID is
actually a copy of the ID field (IP identification number) in the IP
header. Besides that, each fragment must carry its “position” or
“offset” in the original unfragmented packet. Thus the first fragment
will have an offset of 0, since its seat is at the front row and
counting starts from 0. Each fragment must also tell the length of data
that it carries. This is like the compartments in a train. And finally,
each fragment must flag the MF (more fragments) bit if it is not the
last fragment.

\sphinxstylestrong{Fragmenting a Packet}

Here is a hypothetical example. Suppose that we want to send a 110 bytes
ICMP packet on a network with MTU of 40 (well that’s damn small, but
this is for illustration purposes). This is a diagram of the original
packet:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
IP
&\sphinxstyletheadfamily 
ICMP
&\sphinxstyletheadfamily 
Data
\\
\hline
Header
&&
Header
\\
\hline
20
&
8
&
82 (bytes)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The packet will be fragmented as shown below.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet 1 \textbar{} IP header (20) \textbar{} ICMP (8) \textbar{} Data (12) \textbar{} ID=88, Len=20,
Off=0, MF=1


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet 2 \textbar{} IP header (20) \textbar{} Data (20) \textbar{} ID=88, Len=20, Off=20, MF=1


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet 3 \textbar{} IP header (20) \textbar{} Data (20) \textbar{} ID=88, Len=20, Off=40, MF=1


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet 4 \textbar{} IP header (20) \textbar{} Data (20) \textbar{} ID=88, Len=20, Off=60, MF=1


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet 5 \textbar{} IP header (20) \textbar{} Data (10) \textbar{} ID=88, Len=10, Off=80, MF=0


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|}
\hline

\end{tabulary}
\par
\sphinxattableend\end{savenotes}

ID - IP identification number

Len - Data Length (data length does not include IP header)

Off - Offset

MF - More Fragment

Notice that the second packet and subsequent packets contains IP header
that is copied from the original packet. There are no ICMP headers,
except in the first packet. In a nutshell, the 110 ICMP packet is broke
into 5 packet, with total lengths of 40, 40, 40, 40 and 30 bytes each.
The ICMP data is broken into lengths of 12, 20, 20, 20, and 10 bytes
each.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Explain the purpose of TTL functionality}

\sphinxhref{https://en.wikipedia.org/wiki/Time\_to\_live}{Link to Online Topic Content}

\sphinxstylestrong{TTL}

TTL may be implemented as a counter or timestamp attached to or embedded
in the data. Once the prescribed event count or timespan has elapsed,
data is discarded. In computer networking, TTL prevents a data packet
from circulating indefinitely. In computing applications, TTL is used to
improve performance of caching or to improve privacy.

Under the Internet Protocol, TTL is an 8-bit field. In the IPv4 header,
TTL is the 9th octet of 20. In the IPv6 header, it is the 8th octet of
40. The maximum TTL value is 255, the maximum value of a single octet. A
recommended initial value is 64.

The time-to-live value can be thought of as an upper bound on the time
that an IP datagram can exist in an Internet system. The TTL field is
set by the sender of the datagram, and reduced by every router on the
route to its destination. If the TTL field reaches zero before the
datagram arrives at its destination, then the datagram is discarded and
an ICMP error datagram (11 - Time Exceeded) is sent back to the sender.
The purpose of the TTL field is to avoid a situation in which an
undeliverable datagram keeps circulating on an Internet system, and such
a system eventually becoming swamped by such “immortals”.

In theory, under IPv4, time to live is measured in seconds, although
every host that passes the datagram must reduce the TTL by at least one
unit. In practice, the TTL field is reduced by one with every hop. To
reflect this practice, the field is renamed hop limit in IPv6.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Given a packet traversing a topology, document the
source/destination IP address/MAC address changes at each hop}

\sphinxstylestrong{Packet Traversing a Topology}

If Host A wants to talk to host B on the network and there are multiple
routed networks between the two devices, can you describe the changes to
the packet will look like as it passes through each network device?

Here is an example network and we will discuss the process of the packet
traversing the network below.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p10}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

So as Host A attempts to communicate to Host B (via an application like
a browser) this will either be a connection based on a DNS name or an IP
address. If it is DNS name, it will resolve the host name to an IP
address or if not, it will use the known IP address in the browser path.
The operating system will look to see if Host B is on it own local IP
subnet. If it were it would look in it’s ARP cache to see if it has an
entry for Host B’s IP address. Since Host B is not on its local IP
subnet it will send the traffic to it’s default gateway. The packet will
not be destined for the IP of the default gateway (in this case Router
A’s IP on the green subnet) but it will look in ARP cache for the MAC
address of the gateway and the packet will look like this as it leaves
Host A:

Src MAC = Host A

Dest MAC = DGW Router A

Src IP = Host A

Dest IP = Host B

The default gateway will receive the packet and will process it since it
is destine for its MAC Address. Router A will send the packet to the
next hop router within the network (based on static routes or routes via
routing protocols) and the packet will look like the following:

Src MAC = Router A

Dest MAC = Router B

Src IP = Host A

Dest IP = Host B

Router B will receive the packet and will process it since it is destine
for its MAC Address. Router B will send the packet to the next hop
router within the network and the packet will look like the following:

Src MAC = Router B

Dest MAC = Router C

Src IP = Host A

Dest IP = Host B

Router C will receive the packet and will process it since it is destine
for its MAC Address. Router C will See that the destination IP is on a
locally attached subnet and will check its ARP Cache for the MAC address
of Host B’s IP address. If it has a known MAC Address it will use it and
if it does not it will ARP for the IP to add the entry to it’s ARP
table. Once it knows the MAC address it will send on the packet that
will look like the following:

Src MAC = Router C

Dest MAC = Host B

Src IP = Host A

Dest IP = Host B


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - IP version 6 (not in depth on exam)}

\sphinxhref{http://www.enterprisenetworkingplanet.com/netsp/article.php/3633211/Understand-IPv6-Addresses.htm}{Link to Online Topic Content}

\sphinxstylestrong{IPv6}

Increasing the IP address pool was one of the major forces behind
developing IPv6. It uses a 128-bit address, meaning that we have a
maximum of 2128 addresses available, or
340,282,366,920,938,463,463,374,607,431,768,211,456, or enough to give
multiple IP addresses to every grain of sand on the planet. So our
friendly old 32-bit IPv4 dotted-quads don’t do the job anymore; these
newfangled IPs require eight 16-bit hexadecimal colon-delimited blocks.
So not only are they longer, they use numbers and letters. At first
glance, those huge IPv6 addresses look like impenetrable secret code:

2001:0db8:3c4d:0015:0000:0000:abcd:ef12

We’ll dissect this in a moment and learn that’s it not such a scary
thing, but first let’s look at the different types of IPv6 addressing.

Under IPv4 we have the old familiar unicast, broadcast and multicast
addresses. In IPv6 we have unicast, multicast and anycast. With IPv6 the
broadcast addresses are not used anymore, because they are replaced with
multicast addressing.

\sphinxstylestrong{IPv6 Unicast}

This is similar to the unicast address in IPv4 - a single address
identifying a single interface. There are four types of unicast
addresses:
\begin{itemize}
\item {} 
Global unicast addresses, which are conventional, publicly routable
address, just like conventional IPv4 publicly routable addresses.

\item {} 
Link-local addresses are akin to the private, non-routable addresses
in IPv4 (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16). They are not
meant to be routed, but confined to a single network segment.
Link-local addresses mean you can easily throw together a temporary
LAN, such as for conferences or meetings, or set up a permanent small
LAN the easy way.

\item {} 
Unique local addresses are also meant for private addressing, with
the addition of being unique, so that joining two subnets does not
cause address collisions.

\item {} 
Special addresses are loopback addresses, IPv4-address mapped spaces,
and 6-to-4 addresses for crossing from an IPv4 network to an IPv6
network.

\end{itemize}

If you read about site-local IPv6 addresses, which are related to
link-local, these have been deprecated, so you don’t need to bother with
them.

\sphinxstylestrong{Multicast}

Multicast in IPv6 is similar to the old IPv4 broadcast address a packet
sent to a multicast address is delivered to every interface in a group.
The IPv6 difference is it’s targeted instead of annoying every single
host on the segment with broadcast blather, only hosts who are members
of the multicast group receive the multicast packets. IPv6 multicast is
routable, and routers will not forward multicast packets unless there
are members of the multicast groups to forward the packets to. Anyone
who has ever suffered from broadcast storms will appreciate this
mightily.

\sphinxstylestrong{Anycast}

An anycast address is a single address assigned to multiple nodes. A
packet sent to an anycast address is then delivered to the first
available node. This is a slick way to provide both load-balancing and
automatic failover. The idea of anycast has been around for a long time;
it was proposed for inclusion in IPv4 but it never happened.

Several of the DNS root servers use a router-based anycast
implementation, which is really a shared unicast addressing scheme.
(While there are only thirteen authoritative root server names, the
total number of actual servers is considerably larger, and they are
spread all over the globe.) The same IP address is assigned to multiple
interfaces, and then multiple routing tables entries are needed to move
everything along.

IPv6 anycast addresses contain fields that identify them as anycast, so
all you need to do is configure your network interfaces appropriately.
The IPv6 protocol itself takes care of getting the packets to their
final destinations. It’s a lot simpler to administer than shared unicast
addressing.

\sphinxstylestrong{Address Dissection}

Let’s take another look at our example IPv6 address:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|}
\hline
\sphinxstyletheadfamily 
2001:0db8:3c4d:0015:0000:0000:abcd:ef12
\\
\hline
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\textbar{}\_\_\_\_\textbar{}\_\_\_\_\_\_\_\_\_\_\_\_\_\_
\\
\hline
global   prefix  subnet  Interface ID
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The prefix identifies it as a global unicast address. It has three
parts: the network identifier, the subnet, and the interface identifier.

The global routing prefix comes from a pool assigned to you, either by
direct assignment from a Regional Internet Registry like APNIC, ARIN, or
RIPE NCC, or more likely from your Internet service provider. The local
network administrator controls the subnet and interface IDs.

You’ll probably be running mixed IPv6/IPv4 networks for some time. IPv6
addresses must have 128 bits. IPv4 addresses are therefore represented
like this:

0000:0000:0000:0000:0000:0000:192.168.1.25

Eight blocks of 16 bits each are required in an IPv6 address. The IPv4
address occupies 32 bits, so that is why there are only seven
colon-delimited blocks.

The localhost address is 0000:0000:0000:0000:0000:0000:0000:0001.

Naturally we want shortcuts, because these are long and all those zeroes
are just dumb-looking. Leading zeroes can be omitted, and contiguous
blocks of zeroes can be omitted entirely, so we end up with these:

2001:0db8:3c4d:0015:0:0:abcd:ef12

2001:0db8:3c4d:0015::abcd:ef12

::192.168.1.25

::1

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.04 Explain the features and functionality of protocols and technologies specific to the transport layer}
\label{\detokenize{class1/modules/module1:objective-1-04-explain-the-features-and-functionality-of-protocols-and-technologies-specific-to-the-transport-layer}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Compare/Contrast purpose and functionality of MTU and MSS}

\sphinxhref{http://compnetworking.about.com/od/networkprotocols/g/mtu-maximum.htm}{Link to Online Topic Content}

\sphinxstylestrong{MTU}

The MTU is the maximum size of a single data unit (e.g., a frame) of
digital communications. MTU sizes are inherent properties of physical
network interfaces, normally measured in bytes. The MTU for Ethernet,
for instance, is 1500 bytes. Some types of networks (like Token Ring)
have larger MTUs, and some types have smaller MTUs, but the values are
fixed for each physical technology.

Higher-level network protocols like TCP/IP can be configured with a
maximum packet size, a parameter independent of the physical layer MTU
over which TCP/IP runs. Unfortunately, many network devices use the
terms interchangeably. On both home broadband routers and Xbox Live
enabled game consoles, for example, the parameter called MTU is in fact
the maximum TCP packet size and not the physical MTU.

In Microsoft Windows, the maximum packet size for protocols like TCP can
be set in the Registry. If this value is set too low, streams of network
traffic will be broken up into a relatively large number of small
packets that adversely affects performance. Xbox Live, for example,
requires the value of MTU (packet size) by at least 1365 bytes. If the
maximum TCP packet size is set too high, it will exceed the network’s
physical MTU and also degrade performance by requiring that each packet
be subdivided into smaller ones (a process known as fragmentation).
Microsoft Windows computers default to a maximum packet size of 1500
bytes for broadband connections and 576 bytes for dialup connections.

Performance problems may also occur if the TCP “MTU” setting on the home
broadband router differs from the setting on individual devices
connected to it.

\sphinxhref{https://www.juniper.net/techpubs/software/jseries/junos93/jseries-config-guide-basic/tcp-maximum-segment-size-mss.html}{Link to Online Topic Content}

\sphinxstylestrong{MSS}

During session connection establishment, two peers, or hosts, engage in
negotiations to determine the IP segment size of packets that they will
exchange during their communication. The segment size is based on the
MSS option (maximum segment size) value set in the TCP SYN (synchronize)
packets that the peers exchange during session negotiation. The MSS
field value to be used is largely determined by the maximum transmission
unit (MTU) of the interfaces that the peers are directly connected to.

\sphinxstylestrong{About TCP and MSS}

The TCP protocol is designed to limit the size of segments of data to a
maximum of number of bytes. The purpose for this is to constrain the
need to fragment segments of data for transmission at the IP level. The
TCP MSS specifies the maximum number of bytes that a TCP packet’s data
field, or segment, can contain. It refers to the maximum amount of TCP
data in a single IP datagram that the local system can accept and
reassemble.

A TCP packet includes data for headers as well as data contained in the
segment. If the MSS value is set too low, the result is inefficient use
of bandwidth; more packets are required to transmit the data. An MSS
value that is set too high could result in an IP datagram that is too
large to send and that must be fragmented.

Typically a host bases its MSS value on its outgoing interface’s maximum
transmission unit (MTU) size. The MTU is the maximum frame size along
the path between peers. A packet is fragmented when it exceeds the MTU
size. Because of variation of the MTU size of the interfaces of hosts in
the path taken by TCP packets between two peers, some packets that are
within the negotiated MSS size of the two peers might be fragmented but
instead are dropped and an ICMP error message is sent to the source host
of the packet.

To diminish the likelihood of fragmentation and to protect against
packet loss, you can decrease the TCP MSS.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Explain the purpose and functionality of TCP}

\sphinxhref{http://www.linktionary.com/t/tcp.html}{Link to Online Topic Content}

\sphinxstylestrong{TCP}

TCP is a subset of the Internet protocol suite, which is often called
TCP/IP, although the acronym TCP/IP refers to only two of the many
protocols in the Internet protocol suite. Still, most people refer to
the Internet protocols as TCP/IP and that style is retained here.

TCP is a connection-oriented protocol that provides the flow controls
and reliable data delivery services listed next. These services run in
the host computers at either end of a connection, not in the network
itself. Therefore, TCP is a protocol for managing end-to-end
connections. Since end-to-end connections may exist across a series of
point-to-point connections, they are often called virtual circuits.

\sphinxstylestrong{Quick terminology}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Connections
&\sphinxstyletheadfamily 
Two computers set up a connection to exchange data. The systems synchronize with one another to manage packet flows and adapt to congestion in the network.
\\
\hline
Full-duplex operation
&
A TCP connection is a pair of virtual circuits (one in each direction). Only the two end systems can use the connection.
\\
\hline
Error checking
&
A checksum technique is used to verify that packets are not corrupted.
\\
\hline
Sequencing
&
Packets are numbered so that the destination can reorder packets and determine if a packet is missing.
\\
\hline
Acknowledgements
&
Upon receipt of one or more packets, the receiver returns an acknowledgement (called an “ACK”) to the sender indicating that it received the packets. If packets are not ACKed, the sender may retransmit the packets (or terminate the connection if it thinks the receiver has crashed).
\\
\hline
Flow control
&
If the sender is overflowing the receiver by transmitting too quickly, the receiver drops packets. Failed ACKs alert the sender to slow down or stop sending.
\\
\hline
Packet recovery services
&
The receiver can request retransmission of a packet. Also, if packet receipt is not ACKed, the sender will resend the packets.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Reliable data delivery services are critical for applications such as
file transfers, database services, transaction processing, and other
mission-critical applications in which every packet must be
delivered-guaranteed.

While TCP provides these reliable services, it depends on IP to delivery
packets. IP is often referred to as an unreliable or best effort
service. While it seems odd to build a network that is unreliable, the
original Internet architects wanted to remove as many services from the
network itself to support fast packet delivery rather than reliability.
Routers do not keep track of packets or do anything to ensure delivery.
They just forward packets.

The assumption was that end systems would be relatively smart devices
with memory and processors. The end devices could handle all the
reliability functions rather than the network. This was actually a
radical approach at the time, but the implications have been profound.
It meant that end systems would become the focus of application
development for the Internet, not the network.

In contrast, the telephone network implements an architecture in which
end devices (phones) are dumb and the network is supposedly “smart.” The
only problem with this model is that you can’t run applications on your
phone that takes advantage of the network. In fact, you are totally
dependent on the phone company to deploy new applications (call waiting
and caller ID are examples). Compared to the Internet, the phone system
is a dinosaur. Consider that the user interface for the Web is a
full-color graphical browser, while the interface for the telephone
network is a 12-key pad!

While end-systems provide TCP’s reliability functions, not all
applications need them. For example, there is no need to recover lost
packets in a live video stream. By the time they are recovered, the
viewer has already seen the barely visible glitch caused by the missing
packet. These applications just need speed. So UDP was created to
provide an application interface to the network for real-time
applications that don’t need TCP’s extra services. UDP provides a very
simple port connection between applications and IP.

\sphinxstylestrong{TCP Three-way handshake}

A TCP Three-way handshake is a method of initializing a Transmission
Control Protocol (TCP) session between two hosts on a TCP/IP network.
The handshake establishes a logical connection between the hosts by
synchronizing the sending and receiving of packets and communicating TCP
parameters between the hosts.

\sphinxstylestrong{How the TCP Three-way Handshake works}

All TCP communication is connection oriented. A TCP session must be
established before the hosts in the connection exchange data. Packets
that are transferred between hosts are accounted for by assigning a
sequence number to each packet. An ACK, or acknowledgment, is sent after
every packet is received. If no ACK is received for a packet, the packet
is re-sent. The three-way handshake ensures that the initial request is
acknowledged, that the data is sent, and that the data is acknowledged.

\sphinxstylestrong{These are the three stages of a TCP three-way handshake:}
\begin{itemize}
\item {} 
The initiating host sends a TCP packet requesting a new session. This
packet contains the initiating host’s sequence number for the
connection. The packet includes information such as a set SYN
(synchronization) flag and data about the size of the window buffer
on the initiating host.

\item {} 
The target host sends a TCP packet with its own sequence number and
an ACK of the initiating host’s sequence number.

\item {} 
The initiating host sends an ACK containing the target sequence
number that it received.

\end{itemize}

\sphinxstyleemphasis{Note - A similar three-way process is used to terminate a TCP session between two hosts. Using the same type of handshake to end the connection ensures that the hosts have completed their transactions and that all data is accounted for.}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Explain the purpose and functionality of UDP}

\sphinxhref{http://www.jguru.com/faq/view.jsp?EID=9472}{Link to Online Topic Content}

\sphinxstylestrong{UDP}

UDP stands for User Datagram Protocol. UDP provides an unreliable packet
delivery system built on top of the IP protocol. As with IP, each packet
is individual and is handled separately. Because of this, the amount of
data that can be sent in a UDP packet is limited to the amount that can
be contained in a single IP packet. Thus, a UDP packet can contain at
most 65507 bytes (this is the 65535-byte IP packet size minus the
minimum IP header of 20 bytes and minus the 8-byte UDP header).

UDP packets can arrive out of order or not at all. No packet has any
knowledge of the preceding or following packet. The recipient does not
acknowledge packets, so the sender does not know that the transmission
was successful. UDP has no provisions for flow control\textendash{}packets can be
received faster than they can be used. We call this type of
communication connectionless because the packets have no relationship to
each other and because there is no state maintained.

The destination IP address and port number are encapsulated in each UDP
packet. These two numbers together uniquely identify the recipient and
are used by the underlying operating system to deliver the packet to a
specific process (application). Each UDP packet also contains the
sender’s IP address and port number.

One way to think of UDP is by analogy to communications via a letter.
You write the letter (this is the data you are sending); put the letter
inside an envelope (the UDP packet); address the envelope (using an IP
address and a port number); put your return address on the envelope
(your local IP address and port number); and then you send the letter.

Like a real letter, you have no way of knowing whether a UDP packet was
received. If you send a second letter one day after the first, the
second one may be received before the first. Or, the second one may
never be received.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Explain the purpose and functionality of ports in general}

\sphinxhref{http://computer.howstuffworks.com/internet/basics/internet-infrastructure10.htm}{Link to Online Topic Content}

\sphinxstylestrong{Protocol Ports}

In TCP/IP and UDP networks, a port is an endpoint to a logical
connection and the way a client program specifies a specific server
program on a computer in a network. There are 65535 available ports per
IP address and many of these ports are reserved as well known
application ports.

A server makes its services available using numbered ports; one for each
service that is available on the server. For example, if a server
machine is running a Web server and a file transfer protocol (FTP)
server, the Web server would typically be available on port 80, and the
FTP server would be available on port 21. Clients connect to a service
at a specific IP address and on a specific port number.

Once a client has connected to a service on a particular port, it
accesses the service using a specific protocol. Protocols are often text
and simply describe how the client and server will have their
conversation. Every Web server on the Internet conforms to the hypertext
transfer protocol (HTTP).


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Explain how retransmissions occur}

\sphinxhref{https://en.wikipedia.org/wiki/Transmission\_Control\_Protocol\#Development}{Link to Online Topic Content}

\sphinxstylestrong{TCP Timeout and Retransmission}

The Transmission Control Protocol provides a communication service at an
intermediate level between an application program and the Internet
Protocol. It provides host-to-host connectivity at the Transport Layer
of the Internet model. An application does not need to know the
particular mechanisms for sending data via a link to another host, such
as the required packet fragmentation on the transmission medium. At the
transport layer, the protocol handles all handshaking and transmission
details and presents an abstraction of the network connection to the
application.

At the lower levels of the protocol stack, due to network congestion,
traffic load balancing, or other unpredictable network behavior, IP
packets may be lost, duplicated, or delivered out of order. TCP detects
these problems, requests retransmission of lost data, rearranges
out-of-order data, and even helps minimize network congestion to reduce
the occurrence of the other problems. If the data still remains
undelivered, its source is notified of this failure. Once the TCP
receiver has reassembled the sequence of octets originally transmitted,
it passes them to the receiving application. Thus, TCP abstracts the
application’s communication from the underlying networking details.

TCP is a reliable stream delivery service that guarantees that all bytes
received will be identical with bytes sent and in the correct order.
Since packet transfer over many networks is not reliable, a technique
known as positive acknowledgment with retransmission is used to
guarantee reliability of packet transfers. This fundamental technique
requires the receiver to respond with an acknowledgment message as it
receives the data. The sender keeps a record of each packet it sends.
The sender also maintains a timer from when the packet was sent, and
retransmits a packet if the timer expires before the message has been
acknowledged. The timer is needed in case a packet gets lost or
corrupted.

While IP handles actual delivery of the data, TCP keeps track of the
individual units of data transmission, called segments, which a message
is divided into for efficient routing through the network. For example,
when an HTML file is sent from a web server, the TCP software layer of
that server divides the sequence of octets of the file into segments and
forwards them individually to the IP software layer (Internet Layer).
The Internet Layer encapsulates each TCP segment into an IP packet by
adding a header that includes (among other data) the destination IP
address. When the client program on the destination computer receives
them, the TCP layer (Transport Layer) reassembles the individual
segments and ensures they are correctly ordered and error free as it
streams them to an application.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Explain the purpose and process of a reset}

\sphinxhref{http://myaccount.flukenetworks.com/fnet/en-us/supportAndDownloads/KB/IT+Networking/protocol+expert/What\_are\_TCP\_RST\_Packets\_-\_Protocol\_Expert}{Link to Online Topic Content}

\sphinxstylestrong{What are TCP RST Packets?}

According to RFC 793, which specifies an Option in the Flags portion of
the TCP header called Reset (or RST). The Reset bit is designed to allow
a station to abort the TCP connection with another station. This can
happen for a number of reasons.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p11}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If a station involved in a TCP session notices that it is not receiving
acknowledgements for anything it sends, the connection is now
unsynchronized, and the station should send a reset. This is a half-open
connection where only one side is involved in the TCP session. This
cannot work by definition of the protocol.

RST packets are a sign that the TCP connections are half open. One
station or the other stopped sending information or ACKs for some
reason. There are acceptable times for RST packets, however, if there
are a large number of RST packets in a conversation, this is definitely
something to troubleshoot. Which side is sending the RST? What is
causing it to send the RST? Does this happen right away in the TCP
setup, or is it later in the session? If later, is there any reason that
the station would abort the session in the middle of the data transfer?


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Describe various TCP options}

\sphinxhref{https://en.wikipedia.org/wiki/Transmission\_Control\_Protocol\#Development}{Link to Online Topic Content}

\sphinxstylestrong{TCP Options}

The length of this field is determined by the data offset field. Options
have up to three fields: Option-Kind (1 byte), Option-Length (1 byte),
Option-Data (variable). The Option-Kind field indicates the type of
option, and is the only field that is not optional. Depending on what
kind of option we are dealing with, the next two fields may be set: the
Option-Length field indicates the total length of the option, and the
Option-Data field contains the value of the option, if applicable. For
example, an Option-Kind byte of 0x01 indicates that this is a No-Op
option used only for padding, and does not have an Option-Length or
Option-Data byte following it. An Option-Kind byte of 0 is the End Of
Options option, and is also only one byte. An Option-Kind byte of 0x02
indicates that this is the Maximum Segment Size option, and will be
followed by a byte specifying the length of the MSS field (should be
0x04). Note that this length is the total length of the given options
field, including Option-Kind and Option-Length bytes. So while the MSS
value is typically expressed in two bytes, the length of the field will
be 4 bytes (+2 bytes of kind and length). In short, an MSS option field
with a value of 0x05B4 will show up as (0x02 0x04 0x05B4) in the TCP
options section.

Some options may only be sent when SYN is set. Option-Kind and standard
lengths given as (Option-Kind, Option-Length).
\begin{itemize}
\item {} 
0 (8 bits) - End of options list

\item {} 
1 (8 bits) - No operation (NOP, Padding). This may be used to align option
fields on 32-bit boundaries for better performance.

\item {} 
2,4,SS (32 bits) - Maximum segment size (see maximum segment size)

\item {} 
3,3,S (24 bits) - Window scale (see window scaling for details)

\item {} 
4,2 (16 bits) - Selective Acknowledgement permitted. (See selective
acknowledgments for details)

\item {} 
5,N,BBBB,EEEE,… (variable bits, N is either 10, 18, 26, or 34)- Selective
ACKnowledgement (SACK). These first two bytes are followed by a list of 1-4
blocks being selectively acknowledged, specified as 32-bit begin/end
pointers.

\item {} 
8,10,TTTT,EEEE (80 bits)- Timestamp and echo of previous timestamp (see TCP
timestamps for details)

\end{itemize}

(The remaining options are historical, obsolete, experimental, not yet
standardized, or unassigned)


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Describe a TCP checksum error}

\sphinxhref{http://www.tcpipguide.com/free/t\_TCPChecksumCalculationandtheTCPPseudoHeader.htm}{Link to Online Topic Content}

\sphinxstylestrong{TCP Checksum}

The Transmission Control Protocol is designed to provide reliable data
transfer between a pair of devices on an IP internetwork. Much of the
effort required to ensure reliable delivery of data segments is of
necessity focused on the problem of ensuring that data is not lost in
transit. But there’s another important critical impediment to the safe
transmission of data: the risk of errors being introduced into a TCP
segment during its travel across the internetwork.

\sphinxstylestrong{Detecting Transmission Errors Using Checksums}

If the data gets where it needs to go but is corrupted and we do not
detect the corruption, this is in some ways worse than it never showing
up at all. To provide basic protection against errors in transmission,
TCP includes a 16-bit Checksum field in its header. The idea behind a
checksum is very straightforward: take a string of data bytes and add
them all together. Then send this sum with the data stream and have the
receiver check the sum. In TCP, a special algorithm is used to calculate
this checksum by the device sending the segment; the same algorithm is
then employed by the recipient to check the data it received and ensure
that there were no errors.

The checksum calculation used by TCP is a bit different than a regular
checksum algorithm. A conventional checksum is performed over all the
bytes that the checksum is intended to protect, and can detect most bit
errors in any of those fields. The designers of TCP wanted this bit
error protection, but also desired to protect against other type of
problems.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Describe how TCP addresses error correction}

\sphinxhref{https://en.wikipedia.org/wiki/Transmission\_Control\_Protocol\#Checksum\_computation}{Link to Online Topic Content}

\sphinxstylestrong{TCP Error Correction}

Sequence numbers allow receivers to discard duplicate packets and
properly sequence reordered packets. Acknowledgments allow senders to
determine when to retransmit lost packets.

To assure correctness a checksum field is included. When TCP runs over
IPv4, the method used to compute the checksum is defined in RFC 793. The
TCP checksum is a weak check by modern standards. Data Link Layers with
high bit error rates may require additional link error
correction/detection capabilities. The weak checksum is partially
compensated for by the common use of a CRC or better integrity check at
layer 2, below both TCP and IP, such as is used in PPP or the Ethernet
frame. However, this does not mean that the 16-bit TCP checksum is
redundant: remarkably, introduction of errors in packets between
CRC-protected hops is common, but the end-to-end 16-bit TCP checksum
catches most of these simple errors. This is the end-to-end principle at
work.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Describe how the flow control process occurs}

\sphinxhref{https://en.wikipedia.org/wiki/Transmission\_Control\_Protocol\#Flow\_control}{Link to Online Topic Content}

\sphinxstylestrong{Flow Control}

TCP uses an end-to-end flow control protocol to avoid having the sender
send data too fast for the TCP receiver to receive and process it
reliably. Having a mechanism for flow control is essential in an
environment where machines of diverse network speeds communicate. For
example, if a PC sends data to a smartphone that is slowly processing
received data, the smartphone must regulate the data flow so as not to
be overwhelmed.

TCP uses a sliding window flow control protocol. In each TCP segment,
the receiver specifies in the receive window field the amount of
additionally received data (in bytes) that it is willing to buffer for
the connection. The sending host can send only up to that amount of data
before it must wait for an acknowledgment and window update from the
receiving host.

TCP sequence numbers and receive windows behave very much like a clock.
The receive window shifts each time the receiver receives and
acknowledges a new segment of data. Once it runs out of sequence
numbers, the sequence number loops back to 0.

When a receiver advertises a window size of 0, the sender stops sending
data and starts the persist timer. The persist timer is used to protect
TCP from a deadlock situation that could arise if a subsequent window
size update from the receiver is lost, and the sender cannot send more
data until receiving a new window size update from the receiver. When
the persist-timer expires, the TCP sender attempts recovery by sending a
small packet so that the receiver responds by sending another
acknowledgement containing the new window size.

If a receiver is processing incoming data in small increments, it may
repeatedly advertise a small receive window. This is referred to as the
silly window syndrome, since it is inefficient to send only a few bytes
of data in a TCP segment, given the relatively large overhead of the TCP
header.

\sphinxstylestrong{Congestion control}

The final main aspect of TCP is congestion control. TCP uses a number of
mechanisms to achieve high performance and avoid congestion collapse,
where network performance can fall by several orders of magnitude. These
mechanisms control the rate of data entering the network, keeping the
data flow below a rate that would trigger collapse. They also yield an
approximately max-min fair allocation between flows.

Senders infer network conditions between the TCP sender and receiver use
acknowledgments for data sent, or lack of acknowledgments. Coupled with
timers, TCP senders and receivers can alter the behavior of the flow of
data. This is more generally referred to as congestion control and/or
network congestion avoidance.

Modern implementations of TCP contain four intertwined algorithms:
Slow-start, congestion avoidance, fast retransmit, and fast recovery
(RFC 5681).

In addition, senders employ a retransmission timeout (RTO) that is based
on the estimated round-trip time (or RTT) between the sender and
receiver, as well as the variance in this round trip time. The behavior
of this timer is specified in RFC 6298. There are subtleties in the
estimation of RTT. For example, senders must be careful when calculating
RTT samples for retransmitted packets; typically they use Karn’s
Algorithm or TCP timestamps (see RFC 1323). These individual RTT samples
are then averaged over time to create a Smoothed Round Trip Time (SRTT)
using Jacobson’s algorithm. This SRTT value is what is finally used as
the round-trip time estimate.

Enhancing TCP to reliably handle loss, minimize errors, manage
congestion and go fast in very high-speed environments are ongoing areas
of research and standards development. As a result, there are a number
of TCP congestion avoidance algorithm variations.

\sphinxstylestrong{Delayed Binding}

Delayed binding, also called TCP connection splicing, is the
postponement of the connection between the client and the server in
order to obtain sufficient information to make a routing decision. Some
application switches and routers delay binding the client session to the
server until the proper handshakes are complete so as to prevent Denial
of Service attacks.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.05 Explain the features and functionality of protocols and technologies specific to the application layer}
\label{\detokenize{class1/modules/module1:objective-1-05-explain-the-features-and-functionality-of-protocols-and-technologies-specific-to-the-application-layer}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain the purpose and functionality of HTTP}

\sphinxhref{https://en.wikipedia.org/wiki/Hypertext\_Transfer\_Protocol}{Link to Online Topic Content}

\sphinxstylestrong{HTTP Protocol}

HTTP functions as a request-response protocol in the client-server
computing model. A web browser, for example, may be the client and an
application running on a computer hosting a web site may be the server.
The client submits an HTTP request message to the server. The server,
which provides resources such as HTML files and other content, or
performs other functions on behalf of the client, returns a response
message to the client. The response contains completion status
information about the request and may also contain requested content in
its message body.

A web browser is an example of a user agent (UA). Other types of user
agent include the indexing software used by search providers (web
crawlers), voice browsers, mobile apps, and other software that
accesses, consumes, or displays web content.

HTTP is designed to permit intermediate network elements to improve or
enable communications between clients and servers. High-traffic websites
often benefit from web cache servers that deliver content on behalf of
upstream servers to improve response time. Web browsers cache previously
accessed web resources and reuses them when possible to reduce network
traffic. HTTP proxy servers at private network boundaries can facilitate
communication for clients without a globally routable address, by
relaying messages with external servers.

HTTP is an application layer protocol designed within the framework of
the Internet Protocol Suite. Its definition presumes an underlying and
reliable transport layer protocol, and Transmission Control Protocol
(TCP) is commonly used. However HTTP can use unreliable protocols such
as the User Datagram Protocol (UDP), for example in Simple Service
Discovery Protocol (SSDP).

HTTP resources are identified and located on the network by Uniform
Resource Identifiers (URIs)—or, more specifically, Uniform Resource
Locators (URLs)—using the http or https URI schemes. URIs and hyperlinks
in Hypertext Markup Language (HTML) documents form webs of inter-linked
hypertext documents.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Differentiate between HTTP versions}

\sphinxhref{https://en.wikipedia.org/wiki/Hypertext\_Transfer\_Protocol\#History}{Link to Online Topic Content}

\sphinxstylestrong{HTTP versions}

The first documented version of HTTP was HTTP V0.9 (1991). Dave Raggett
led the HTTP Working Group (HTTP WG) in 1995 and wanted to expand the
protocol with extended operations, extended negotiation, richer
meta-information, tied with a security protocol which became more
efficient by adding additional methods and header fields. RFC 1945
officially introduced and recognized HTTP V1.0 in 1996.

The HTTP WG planned to publish new standards in December 1995 and the
support for pre-standard HTTP/1.1 based on the then developing RFC 2068
(called HTTP-NG) was rapidly adopted by the major browser developers in
early 1996. By March 1996, pre-standard HTTP/1.1 was supported in Arena,
Netscape 2.0, Netscape Navigator Gold 2.01, Mosaic 2.7, Lynx 2.5, and in
Internet Explorer 2.0. End-user adoption of the new browsers was rapid.
In March 1996, one web hosting company reported that over 40\% of
browsers in use on the Internet were HTTP 1.1 compliant. That same web
hosting company reported that by June 1996, 65\% of all browsers
accessing their servers were HTTP/1.1 compliant. The HTTP/1.1 standard
as defined in RFC 2068 was officially released in January 1997.
Improvements and updates to the HTTP/1.1 standard were released under
RFC 2616 in June 1999.

Some of the major changes from version 1.0 to version 1.1 were based
around request methods. HTTP defines methods (sometimes referred to as
verbs) to indicate the desired action to be performed on the identified
resource. What this resource represents, whether pre-existing data or
data that is generated dynamically, depends on the implementation of the
server. Often, the resource corresponds to a file or the output of an
executable residing on the server. The HTTP/1.0 specification defined
the GET, POST and HEAD methods and the HTTP/1.1 specification added 5
new methods: OPTIONS, PUT, DELETE, TRACE and CONNECT.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Interpret HTTP status codes}

\sphinxhref{http://www.jmarshall.com/easy/http/}{Link to Online Topic Content}

\sphinxstylestrong{Structure of HTTP Transactions}

Like most network protocols, HTTP uses the client-server model: An HTTP
client opens a connection and sends a request message to an HTTP server;
the server then returns a response message, usually containing the
resource that was requested. After delivering the response, the server
closes the connection (making HTTP a stateless protocol, i.e. not
maintaining any connection information between transactions).

The formats of the request and response messages are similar, and
English-oriented. Both kinds of messages consist of:
\begin{itemize}
\item {} 
an initial line,

\item {} 
zero or more header lines,

\item {} 
a blank line (i.e. a CRLF by itself), and

\item {} 
an optional message body (e.g. a file, or query data, or query output).

\end{itemize}

Put another way, the format of an HTTP message is:

\textless{}initial line, different for request vs. response\textgreater{}

Header1: value1

Header2: value2

Header3: value3

\textless{}optional message body goes here, like file contents or query data; it
can be many lines long, or even binary data \sphinxhref{mailto:\$\&*\%@!\textasciicircum{}\$@}{\$\&*\%@!\textasciicircum{}\$@}\textgreater{}

Initial lines and headers should end in CRLF, though you should
gracefully handle lines ending in just LF. (More exactly, CR and LF here
mean ASCII values 13 and 10, even though some platforms may use
different characters.)

Initial Request Line

The initial line is different for the request than for the response. A
request line has three parts, separated by spaces: a method name, the
local path of the requested resource, and the version of HTTP being
used. A typical request line is:

GET /path/to/file/index.html HTTP/1.0
\begin{itemize}
\item {} 
GET is the most common HTTP method; it says “give me this resource”. Other
methods include POST and HEAD- - more on those later. Method names are
always uppercase.

\item {} 
The path is the part of the URL after the host name, also called the
request URI (a URI is like a URL, but more general).

\item {} 
The HTTP version always takes the form “HTTP/x.x”, uppercase.

\end{itemize}

\sphinxstylestrong{Initial Response Line (Status Line)}

The initial response line, called the status line, also has three parts
separated by spaces: the HTTP version, a response status code that gives
the result of the request, and an English reason phrase describing the
status code. Typical status lines are:

HTTP/1.0 200 OK or HTTP/1.0 404 Not Found
\begin{itemize}
\item {} 
The HTTP version is in the same format as in the request line, “HTTP/x.x”.

\item {} 
The status code is meant to be computer-readable; the reason phrase is
meant to be human-readable, and may vary.

\item {} 
The status code is a three-digit integer, and the first digit identifies
the general category of response:

\item {} 
1xx indicates an informational message only

\item {} 
2xx indicates success of some kind

\item {} 
3xx redirects the client to another URL

\item {} 
4xx indicates an error on the client’s part

\item {} 
5xx indicates an error on the server’s part

\end{itemize}

The most common status codes are:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{200 OK}
&\sphinxstyletheadfamily 
The request succeeded, and the resulting resource (e.g. file or script output) is returned in the message body.
\\
\hline
\sphinxstylestrong{301}
&
Moved Permanently
\\
\hline
\sphinxstylestrong{302}
&
Moved Temporarily
\\
\hline
\sphinxstylestrong{303 See Other (HTTP 1.1 only)}
&
The resource has moved to another URL (given by the Location: response header), and should be automatically retrieved by the client. This is often used by a CGI script to redirect the browser to an existing file.
\\
\hline
\sphinxstylestrong{403 Forbidden}
&
The request was a valid request, but the server is refusing to respond to it.
\\
\hline
\sphinxstylestrong{404 Not Found}
&
The requested resource doesn’t exist.
\\
\hline
\sphinxstylestrong{500 Internal Server Error}
&
An unexpected server error. The most common cause is a server-side script that has bad syntax, fails, or otherwise can’t run correctly.
\\
\hline
\sphinxstylestrong{503 Service Unavailable}
&
The server is currently unavailable (because it is overloaded or down for maintenance). Generally, this is a temporary state.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Header Lines

Header lines provide information about the request or response, or about
the object sent in the message body. The header lines are in the usual
text header format, which is: one line per header, of the form
“Header-Name: value”, ending with CRLF. It’s the same format used for
email and news postings.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Determine an HTTP request method for a given use case}

\sphinxhref{http://www.jmarshall.com/easy/http/\#othermethods}{Link to Online Topic Content}

\sphinxstylestrong{Other HTTP Methods, Like HEAD and POST}

Besides GET, the two most commonly used methods are HEAD and POST.

\sphinxstylestrong{The HEAD Method}

A HEAD request is just like a GET request, except it asks the server to
return the response headers only, and not the actual resource (i.e. no
message body). This is useful to check characteristics of a resource
without actually downloading it, thus saving bandwidth. Use HEAD when
you don’t actually need a file’s contents.

The response to a HEAD request must never contain a message body, just
the status line and headers.

\sphinxstylestrong{The POST Method}

A POST request is used to send data to the server to be processed in
some way, like by a CGI script. A POST request is different from a GET
request in the following ways:
\begin{itemize}
\item {} 
There’s a block of data sent with the request, in the message body. There
are usually extra headers to describe this message body, like
Content-Type: and Content-Length:.

\item {} 
The request URI is not a resource to retrieve; it’s usually a program to
handle the data you’re sending.

\item {} 
The HTTP response is normally program output, not a static file.

\end{itemize}

The most common use of POST, by far, is to submit HTML form data to CGI
scripts. In this case, the Content-Type: header is usually
application/x-www-form-urlencoded, and the Content-Length: header gives
the length of the URL-encoded form data (here’s a note on URL-encoding).
The CGI script receives the message body through STDIN, and decodes it.
Here’s a typical form submission, using POST:

POST /path/script.cgi HTTP/1.0

From: \sphinxhref{mailto:frog@jmarshall.com}{frog@jmarshall.com}

User-Agent: HTTPTool/1.0

Content-Type: application/x-www-form-urlencoded

Content-Length: 32

home=Cosby\&favorite+flavor=flies

You can use a POST request to send whatever data you want, not just form
submissions. Just make sure the sender and the receiving program agree
on the format.

The GET method can also be used to submit forms. The form data is
URL-encoded and appended to the request URI.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain the purpose and functionality of HTTP Keep-alives, HTTP
headers, DNS, SIP, FTP}

\sphinxhref{https://en.wikipedia.org/wiki/HTTP\_persistent\_connection}{Link to Online Topic Content}

\sphinxstylestrong{HTTP Keep-alives}

HTTP keep-alive, also called HTTP persistent connection, or HTTP
connection reuse, is the idea of using a single TCP connection to send
and receive multiple HTTP requests/responses, as opposed to opening a
new connection for every single request/response pair.

The Keep-Alive header field and the additional information it provides
are optional and do not need to be present to indicate a persistent
connection has been established.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p12}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{https://en.wikipedia.org/wiki/List\_of\_HTTP\_header\_fields\#Field\_names}{Link to Online Topic Content}

\sphinxstylestrong{HTTP Headers}

HTTP header fields are components of the header section of request and
response messages in the Hypertext Transfer Protocol (HTTP). They define
the operating parameters of an HTTP transaction.

The header fields are transmitted after the request or response line,
which is the first line of a message. Header fields are colon-separated
name-value pairs in clear-text string format, terminated by a carriage
return (CR) and line feed (LF) character sequence. The end of the header
section is indicated by an empty field, resulting in the transmission of
two consecutive CR-LF pairs. Historically, long lines could be folded
into multiple lines; continuation lines are indicated by the presence of
a space (SP) or horizontal tab (HT) as the first character on the next
line. This folding is now deprecated.

\sphinxhref{http://computer.howstuffworks.com/dns.htm}{Link to Online Topic Content}

\sphinxstylestrong{Domain Name System (DNS)}

If you’ve ever used the Internet, it’s a good bet that you’ve used the
Domain Name System, or DNS, even without realizing it. DNS is a protocol
within the set of standards for how computers exchange data on the
Internet and on many private networks, known as the TCP/IP protocol
suite. Its basic job is to turn a user-friendly domain name like
“howstuffworks.com” into an Internet Protocol (IP) address like
70.42.251.42 that computers use to identify each other on the network.
It’s like your computer’s GPS for the Internet.

Computers and other network devices on the Internet use an IP address to
route your request to the site you’re trying to reach. This is similar
to dialing a phone number to connect to the person you’re trying to
call. Thanks to DNS, though, you don’t have to keep your own address
book of IP addresses. Instead, you just connect through a domain name
server, also called a DNS server or name server, which manages a massive
database that maps domain names to IP addresses.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p13}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Whether you’re accessing a Web site or sending e-mail, your computer
uses a DNS server to lookup the domain name you’re trying to
access. The proper term for this process is DNS name resolution, and you
would say that the DNS server resolves the domain name to the IP
address. For example, when you enter “\sphinxurl{http://www.howstuffworks.com}” in
your browser, part of the network connection includes resolving the
domain name “howstuffworks.com” into an IP address, like 70.42.251.42,
for ‘HowStuffWorks’ Web servers.

You can always bypass a DNS lookup by entering 70.42.251.42 directly in
your browser (give it a try). However, you’re probably more likely to
remember “howstuffworks.com” when you want to return later. In addition,
a Web site’s IP address can change over time, and some sites associate
multiple IP addresses with a single domain name.

Without DNS servers, the Internet would shut down very quickly. But how
does your computer know what DNS server to use? Typically, when you
connect to your home network, Internet service provider (ISP) or WiFi
network, the modem or router that assigns your computer’s network
address also sends some important network configuration information to
your computer or mobile device.

That configuration includes one or more DNS servers that the device
should use when translating DNS names to IP address.

\sphinxhref{http://www.cisco.com/c/dam/en/us/products/collateral/unified-communications/business-edition-3000/what\_sip.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Session Initiation Protocol (SIP)}

Session Initiation Protocol (SIP) is a communications protocol used for
communicating between different devices on a company network, whether on
the LAN, the WAN, or across the Internet. An example of this could be a
simple two-way phone conversation, using voice over IP (VoIP) on the LAN
or WAN or a SIP trunk across the Internet to a service provider. A SIP
trunk provides a new way of connecting to a service provider for
incoming and outgoing calls; it is a connection over the Internet
instead of a traditional telephone connection such as ISDN.

SIP allows you to take full advantage of applications such as video
conferencing, presence, and instant messaging. These applications, and
others like them, when working together are known as unified
communications. Unified communications opens up a new world of
possibilities in how you interact with your customers and prospects,
giving them a richer experience when dealing with you and your staff.

SIP provides businesses many benefits over older, proprietary telephony
solutions, and best of all, it can save you money.

In the past, connections to the service provider (telephone company)
were possible only using a dedicated telephone line, such as an ISDN
connection.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p14}.png}

\noindent\sphinxincludegraphics{{1p15}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{https://en.wikipedia.org/wiki/File\_Transfer\_Protocol}{Link to Online Topic Content}

\sphinxstylestrong{File Transfer Protocol (FTP)}

File Transfer Protocol (FTP) is a standard network protocol used to
transfer files from one host to another host over a TCP-based network,
such as the Internet. FTP is built on client-server architecture and
uses separate control and data connections between the client and the
server. FTP users may authenticate themselves using a clear-text sign-in
protocol, normally in the form of a username and password, but can
connect anonymously if the server is configured to allow it. For secure
transmission that hides (encrypts) the username and password, and
encrypts the content, FTP is often secured with SSL/TLS (“FTPS”). SSH
File Transfer Protocol (“SFTP”) is sometimes also used instead, but is
technologically different.

The first FTP client applications were command-line applications
developed before operating systems had graphical user interfaces, and
are still shipped with most Windows, Unix, and Linux operating systems.
Dozens of FTP clients and automation utilities have since been developed
for desktops, servers, mobile devices, and hardware, and FTP has been
incorporated into hundreds of productivity applications, such as Web
page editors.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Differentiate between passive and active FTP}

\sphinxhref{http://slacksite.com/other/ftp.html}{Link to Online Topic Content}

\sphinxstylestrong{Active FTP vs. Passive FTP}

One of the most commonly seen questions when dealing with firewalls and
other Internet connectivity issues is the difference between active and
passive FTP and how best to support either or both of them. Hopefully
the following text will help to clear up some of the confusion over how
to support FTP in a firewalled environment.

\sphinxstylestrong{The Basics}

FTP is a TCP based service exclusively. There is no UDP component to
FTP. FTP is an unusual service in that it utilizes two ports, a ‘data’
port and a ‘command’ port (also known as the control port).
Traditionally these are port 21 for the command port and port 20 for the
data port. The confusion begins however, when we find that depending on
the mode, the data port is not always on port 20.

\sphinxstylestrong{Active FTP}

In active mode FTP the client connects from a random unprivileged port
(N \textgreater{} 1023) to the FTP server’s command port, port 21. Then, the client
starts listening to port N+1 and sends the FTP command PORT N+1 to the
FTP server. The server will then connect back to the client’s specified
data port from its local data port, which is port 20.

From the server-side firewall’s standpoint, to support active mode FTP
the following communication channels need to be opened:

FTP server’s port 21 from anywhere (Client initiates connection)

FTP server’s port 21 to ports \textgreater{} 1023 (Server responds to client’s
control port)

FTP server’s port 20 to ports \textgreater{} 1023 (Server initiates data connection
to client’s data port)

FTP server’s port 20 from ports \textgreater{} 1023 (Client sends ACKs to server’s
data port)

When drawn out, the connection appears as follows:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p16}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}
\begin{itemize}
\item {} 
The client’s command port contacts the server’s command port and
sends the command PORT 1027.

\item {} 
The server then sends an ACK back to the client’s command port

\item {} 
The server initiates a connection on its local data port to the data port the
client specified earlier.

\item {} 
Finally, the client sends an ACK.

\end{itemize}

The main problem with active mode FTP actually falls on the client side.
The FTP client doesn’t make the actual connection to the data port of
the server\textendash{}it simply tells the server what port it is listening on and
the server connects back to the specified port on the client. From the
client-side firewall this appears to be an outside system initiating a
connection to an internal client\textendash{}something that is usually blocked.

\sphinxstylestrong{Passive FTP}

In order to resolve the issue of the server initiating the connection to
the client a different method for FTP connections was developed. This
was known as passive mode, or PASV, after the command used by the client
to tell the server it is in passive mode.

In passive mode FTP the client initiates both connections to the server,
solving the problem of firewalls filtering the incoming data port
connection to the client from the server. When opening an FTP
connection, the client opens two random unprivileged ports locally (N \textgreater{}
1023 and N+1). The first port contacts the server on port 21, but
instead of then issuing a PORT command and allowing the server to
connect back to its data port, the client will issue the PASV command.
The result of this is that the server then opens a random unprivileged
port (P \textgreater{} 1023) and sends P back to the client in response to the PASV
command. The client then initiates the connection from port N+1 to port
P on the server to transfer data.

From the server-side firewall’s standpoint, to support passive mode FTP
the following communication channels need to be opened:
\begin{itemize}
\item {} 
FTP server’s port 21 from anywhere (Client initiates connection)

\item {} 
FTP server’s port 21 to ports \textgreater{} 1023 (Server responds to client’s control
port)

\item {} 
FTP server’s ports \textgreater{} 1023 from anywhere (Client initiates data connection to
random port specified by server

\item {} 
FTP server’s ports \textgreater{} 1023 to remote ports \textgreater{} 1023 (Server sends ACKs (and
data) to client’s data port)

\end{itemize}

When drawn, a passive mode FTP connection looks like this:

\noindent\sphinxincludegraphics{{1p17}.png}
\begin{itemize}
\item {} 
The client contacts the server on the command port and issues the PASV
command.

\item {} 
The server then replies with PORT 2024, telling the client which port it is
listening to for the data connection.

\item {} 
The client then initiates the data connection from its data port to the
specified server data port.

\item {} 
Finally, the server sends back an ACK to the client’s data port.

\end{itemize}

While passive mode FTP solves many of the problems from the client side,
it opens up a whole range of problems on the server side. The biggest
issue is the need to allow any remote connection to high numbered ports
on the server. Fortunately, many FTP daemons, including the popular
WU-FTPD allow the administrator to specify a range of ports, which the
FTP server will use.

The second issue involves supporting and troubleshooting clients, which
do (or do not) support passive mode. As an example, the command line FTP
utility provided with Solaris does not support passive mode,
necessitating a third-party FTP client, such as ncftp.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain the purpose and functionality of SMTP}

\sphinxhref{http://computer.howstuffworks.com/e-mail-messaging/email3.htm}{Link to Online Topic Content}

\sphinxstylestrong{The SMTP Server}

Whenever you send a piece of e-mail, your e-mail client interacts with
the SMTP server to handle the sending. The SMTP server on your host may
have conversations with other SMTP servers to deliver the e-mail. Let’s
assume that I want to send a piece of e-mail. My e-mail ID is brain, and
I have my account on howstuffworks.com. I want to send e-mail to
\sphinxhref{mailto:jsmith@mindspring.com}{jsmith@mindspring.com}. I am using a stand-alone e-mail client like
Outlook Express.

When I set up my account at HowStuffWorks, I told Outlook Express the
name of the mail server \textendash{} mail.howstuffworks.com. When I compose a
message and press the Send button, here is what happens:
\begin{itemize}
\item {} 
Outlook Express connects to the SMTP server at mail.howstuffworks.com using
port 25.

\item {} 
Outlook Express has a conversation with the SMTP server, telling the SMTP
server the address of the sender and the address of the recipient, as well as
the body of the message.

\item {} 
The SMTP server takes the “to” address (\sphinxhref{mailto:jsmith@mindspring.com}{jsmith@mindspring.com}) and breaks it
into two parts: the recipient name (jsmith) and the domain name
(mindspring.com). If the “to” address had been another user at
howstuffworks.com, the SMTP server would simply hand the message to the POP3
server for howstuffworks.com (using a little program called the delivery
agent). Since the recipient is at another domain, SMTP needs to communicate
with that domain.

\item {} 
The SMTP server has a conversation with a Domain Name Server, or DNS. It
says, “Can you give me the IP address of the SMTP server for mindspring.com?”
The DNS replies with the one or more IP addresses for the SMTP server(s)
that Mindspring operates.

\item {} 
The SMTP server at howstuffworks.com connects with the SMTP server at
Mindspring using port 25. It has the same simple text conversation that my
e-mail client had with the SMTP server for HowStuffWorks, and gives the
message to the Mindspring server. The Mindspring server recognizes that the
domain name for jsmith is at Mindspring, so it hands the message to
Mindspring’s POP3 server, which puts the message in jsmith’s mailbox.

\end{itemize}

If, for some reason, the SMTP server at HowStuffWorks cannot connect
with the SMTP server at Mindspring, then the message goes into a queue.
The SMTP server on most machines uses a program called sendmail to do
the actual sending, so this queue is called the sendmail queue. Sendmail
will periodically try to resend the messages in its queue. For example,
it might retry every 15 minutes. After four hours, it will usually send
you a piece of mail that tells you there is some sort of problem. After
five days, most sendmail configurations give up and return the mail to
you undelivered.

The SMTP server understands very simple text commands like HELO, MAIL,
RCPT and DATA. The most common commands are:
\begin{itemize}
\item {} 
HELO - introduce yourself

\item {} 
EHLO - introduce yourself and request extended mode

\item {} 
MAIL FROM: - specify the sender

\item {} 
RCPT TO: - specify the recipient

\item {} 
DATA - specify the body of the message (To, From and Subject should be the
first three lines.)

\item {} 
RSET - reset

\item {} 
QUIT - quit the session

\item {} 
HELP - get help on commands

\item {} 
VRFY - verify an address

\item {} 
EXPN - expand an address

\item {} 
VERB - verbose

\end{itemize}

\noindent\sphinxincludegraphics{{1p18}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain the purpose and functionality of a cookie}

\sphinxhref{http://www.howstuffworks.com/cookie.htm/printable}{Link to Online Topic Content}

\sphinxstylestrong{How HTTP Cookies Work}

A cookie is a piece of text that a Web server can store on a user’s hard
disk. Cookies allow a Web site to store information on a user’s machine
and later retrieve it. The pieces of information are stored as
name-value pairs.

For example, a Web site might generate a unique ID number for each
visitor and store the ID number on each user’s machine using a cookie
file.

If you use Microsoft’s Internet Explorer to browse the Web, you can see
all of the cookies that are stored on your machine. The most common
place for them to reside is in a directory called c:/windowscookies.
When I look in that directory on my machine, I find 165 files. Each file
is a text file that contains name-value pairs, and there is one file for
each Web site that has placed cookies on my machine.

You can see in the directory that each of these files is a simple,
normal text file. You can see which Web site placed the file on your
machine by looking at the file name (the information is also stored
inside the file). You can open each file by clicking on it.

For example, I have visited goto.com, and the site has placed a cookie
on my machine. The cookie file for goto.com contains the following
information:

UserID A9A3BECE0563982D www.goto.com/

Goto.com has stored on my machine a single name-value pair. The name of
the pair is UserID, and the value is A9A3BECE0563982D. The first time I
visited goto.com, the site assigned me a unique ID value and stored it
on my machine.

(Note that there probably are several other values stored in the file
after the three shown above. That is housekeeping information for the
browser.)

The vast majority of sites store just one piece of information \textendash{} a user
ID \textendash{} on your machine. But a site can store many name-value pairs if it
wants to.

A name-value pair is simply a named piece of data. It is not a program,
and it cannot “do” anything. A Web site can retrieve only the
information that it has placed on your machine. It cannot retrieve
information from other cookie files, or any other information from your
machine.

\sphinxstylestrong{How do Web sites use cookies?}

Cookies evolved because they solve a big problem for the people who
implement Web sites. In the broadest sense, a cookie allows a site to
store state information on your machine. This information lets a Web
site remember what state your browser is in. An ID is one simple piece
of state information \textendash{} if an ID exists on your machine, the site knows
that you have visited before. The state is, “Your browser has visited
the site at least one time,” and the site knows your ID from that visit.

Web sites use cookies in many different ways. Here are some of the most
common examples:

Sites can accurately determine how many people actually visit the site.
It turns out that because of proxy servers, caching, concentrators and
so on, the only way for a site to accurately count visitors is to set a
cookie with a unique ID for each visitor. Using cookies, sites can
determine how many visitors arrive, how many are new versus repeat
visitors and how often a visitor has visited. Sites can store user
preferences so that the site can look different for each visitor (often
referred to as customization). For example, if you visit msn.com, it
offers you the ability to “change content/layout/color.” It also allows
you to enter your zip code and get customized weather information. When
you enter your zip code, the following name-value pair gets added to
MSN’s cookie file:

WEAT CC=NC\%5FRaleigh\%2DDurham®ION= www.msn.com/
\begin{itemize}
\item {} 
Since I live in Raleigh, N.C., this makes sense.

\item {} 
Most sites seem to store preferences like this in the site’s database and
store nothing but an ID as a cookie, but storing the actual values in
name-value pairs is another way to do it.

\end{itemize}

E-commerce sites can implement things like shopping carts and “quick
checkout” options. The cookie contains an ID and lets the site keep
track of you as you add different things to your cart. Each item you add
to your shopping cart is stored in the site’s database along with your
ID value.

When you check out, the site knows what is in your cart by retrieving
all of your selections from the database. It would be impossible to
implement a convenient shopping mechanism without cookies or something
like them.

In all of these examples, note that what the database is able to store
are items you have selected from the site, pages you have viewed from
the site, information you have given to the site in online forms, etc.
All of the information is stored in the site’s database, and in most
cases, a cookie containing your unique ID is all that is stored on your
computer.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Given a situation in which a client connects to a remote host,
explain how the name resolution process occurs}

\sphinxstylestrong{REF 1 p 970 - 982}

\sphinxstylestrong{Name Resolution Process}

If a user wants to connect to an application or website on a network,
either public or private, they must know where to go to get to the
application. As we have been discussing in the prior sections, all of
the locations on a network have an IP address that can be connected to
for the residing application or service. The challenge is remembering
all of the IP addresses of the sites or applications that we need to
connect to on a day-to-day basis. It is easier for a human to remember a
name than an IP address. For instance it is easier to remember
www.google.com than 74.125.229.178. However to use a name instead of an
IP address means a record of what names correlate to which IP address
has to be maintained and be made available to search by all network
attached nodes. The Domain Name System (DNS) is a hierarchical
distributed naming system used for this function.

In the DNS name resolution process, for a client to connect to a remote
host, quite a few steps take place. Lets go through those steps at a
high level.

A user wants to get to the website www.google.com. So he/she opens a
browser and types www.google.com in the path bar in the browser. The
users system doesn’t inherently know the IP address of the website. So
it does a DNS lookup of the name and the process is basically like this:
\begin{itemize}
\item {} 
The user system will look in its local host file for a matching entry for
www.google.com. If an entry matches it will use that IP address, and the
process ends here.

\item {} 
If an entry is not found in the local host file, the user system will look to
its local name cache for a matching entry for www.google.com. If an entry
exists then it will attempt to connect to that address, and the process ends
here.

\item {} 
If there is no record in the user system’s cache then the system will request
the IP address from its local DNS server for www.google.com.

\item {} 
If the local DNS server has an entry for www.google.com in its cache then it
will respond to the user system with that IP address. The system will put the
entry in its cache and connect to the address. The process is then complete.

\item {} 
If the local DNS server does not have an entry for www.google.com in its
cache then the local DNS server will make a call to the root servers in its
DNS configuration for the IP address of the Authoritative Name Server for the
.com domain. The Local DNS server will then query the Authoritative Name
Server of the .com domain for the Authoritative Name Server of the
.google.com domain. Once the local DNS server has that IP address, it will
query the Authoritative Name Server of the .google.com domain for the A
record (IP address) of www.google.com.

\item {} 
The local DNS server will place that response into its cache and then it will
respond to the user system with that IP address. The user system will put the
entry in its cache and connect to the address. The process is then complete.

\end{itemize}

All of these steps will take place extremely fast and only add
milliseconds to the process of the connection to the website but for
every name that the user system is told to connect to, this process
takes place.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain the purpose and functionality of a URL}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{URL - Uniform Resource Locator}

A uniform resource locator (URL) is a reference to a resource that
specifies the location of the resource on a computer network and a
mechanism for retrieving it. A URL is a specific type of uniform
resource identifier (URI), although many people use the two terms
interchangeably. A URL implies the means to access an indicated
resource, which is not true of every URI. URLs occur most commonly to
reference web pages (HTTP), but are also used for file transfer (FTP),
email (mailto), database access (JDBC), and many other applications.

Most web browsers display the URL of a web page above the page in an
address bar.

Every HTTP URL consists of the following, in the given order. Several
schemes other than HTTP also share this general format, with some
variation.

The syntax is:

scheme://{[}user:password@{]}domain:port/path?query\_string\#fragment\_id

Component details:
\begin{itemize}
\item {} 
The scheme, which in many cases is the name of a protocol (but not always),
defines how the resource will be obtained. Examples include HTTP, HTTPS, FTP,
file and many others. Although schemes are case-insensitive, the canonical
form is lowercase.

\item {} 
The domain name or literal numeric IP address gives the destination location
for the URL. A literal numeric IPv6 address may be given, but must be
enclosed in {[} {]}. e.g. {[}db8:0cec::99:123a{]}. The domain google.com, or its
numeric IP address 173.194.34.5, is the address of Google’s website.

\item {} 
The domain name portion of a URL is not case sensitive since DNS ignores
case: \sphinxurl{http://en.example.org/} and \sphinxurl{HTTP://EN.EXAMPLE.ORG/} both open the same
page.

\item {} 
The port number, given in decimal, is optional; if omitted, the default for
the scheme is used. For example, \sphinxurl{http://vnc.example.com:5800} connects to port
5800 of vnc.example.com, which may be appropriate for a VNC remote control
session. If the port number is omitted for an http: URL, the browser will
connect on port 80, the default HTTP port. The default port for an https:
request is 443.

\item {} 
The path is used to specify and perhaps find the resource requested. This
path may or may not describe folders on the file system in the web server. It
may be very different from the arrangement of folders on the web server. It
is case-sensitive, {[}14{]} though it may be treated as case-insensitive by some
servers, especially those based on Microsoft Windows. If the server is case
sensitive and \sphinxurl{http://en.example.org/wiki/URL} is correct, then
\sphinxurl{http://en.example.org/WIKI/URL} or \sphinxurl{http://en.example.org/wiki/url} will display
an HTTP 404 error page, unless these URLs point to valid resources
themselves.

\item {} 
The query string contains data to be passed to software running on the
server. It may contain name/value pairs separated by ampersands, for example:
?first\_name=John\&last\_name=Doe.

\item {} 
The fragment identifier, if present, specifies a part or a position within
the overall resource or document. When used with HTML, it usually specifies a
section or location within the page, and used in combination with Anchor
elements or the “id” attribute of an element, the browser is scrolled to
display that part of the page.

\end{itemize}

The scheme name defines the namespace, purpose, and the syntax of the
remaining part of the URL. Software will try to process a URL according
to its scheme and context. For example, a web browser will usually
dereference the URL \sphinxurl{http://example.org:80} by performing an HTTP request
to the host at example.org, using port number 80.

Other schemes do not follow the HTTP pattern. For example, the mailto
scheme only uses valid email addresses. When clicked on in an
application, the URL \sphinxurl{mailto:bob@example.com} may start an e-mail composer
with the address \sphinxhref{mailto:bob@example.com}{bob@example.com} in the To field. The tel scheme is even
more different; it uses the public switched telephone network for
addressing, instead of domain names representing Internet hosts.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 2 - F5 Solutions and Technology}
\label{\detokenize{class1/modules/module2:section-2-f5-solutions-and-technology}}\label{\detokenize{class1/modules/module2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.01 Articulate the role of F5 products}
\label{\detokenize{class1/modules/module2:objective-2-01-articulate-the-role-of-f5-products}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Explain the purpose, use, and benefits of APM, LTM, ASM, GTM}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{BIG-IP Access Policy Manager (APM)}

Today, business resources, such as applications and data, are accessed
inside and outside the traditional business perimeter. Local and remote
employees, partners, and customers often access applications without
context or security. A central policy control point delivers access
based on context and is critical to managing a scalable, secure, and
dynamic environment.

BIG-IP Access Policy Manager (APM) is a flexible, high-performance
access and security solution that provides unified global access to your
applications and network. By converging and consolidating remote access,
LAN access, and wireless connections within a single management
interface, and providing easy-to-manage access policies, BIG-IP APM
helps you free up valuable IT resources and scale cost-effectively

\sphinxstylestrong{Provide unified global access}

BIG-IP APM protects your public-facing applications by providing
policy-based, context-aware access to users while consolidating your
access infrastructure. It also provides secure remote access to
corporate resources from all networks and devices. BIG-IP APM is the
most scalable remote access solution and it is IPv6 ready.

\sphinxstylestrong{Obtain flexibility, high performance, and scalability}

BIG-IP APM is available in three deployment options—as an add-on module
for BIG-IP Local Traffic Manager (LTM) for protecting Internet-facing
applications, delivered in BIG-IP Edge Gateway for accelerated remote
access, and run on BIG-IP LTM Virtual Edition to deliver flexible
application access in virtualized environments.

\sphinxstylestrong{Consolidate and simplify}

BIG-IP APM helps you consolidate your infrastructure and simplify access
management by providing centralized authentication, authorization, and
accounting (AAA) control directly on the BIG-IP system. BIG-IP APM
integrates with Oracle Access Manager. It simplifies virtual application
deployment by supporting Citrix XenApp and XenDesktop, VMware View,
Microsoft Remote Desktop Protocol (RDP), and Java RDP, all in one
WebTop. With BIG-IP APM, you can consolidate and unify elements such as
access, security, and policy management to help further reduce costs.

\sphinxstylestrong{The purpose of the Access Policy Manager is to create a secure access
to internal applications by using a single authentication and provide
control using a single management interface.}


\bigskip\hrule\bigskip


\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{BIG-IP Local Traffic Manager (LTM)}

BIG-IP Local Traffic Manager (LTM) turns your network into an agile
infrastructure for application delivery. It’s a full proxy between users
and application servers, creating a layer of abstraction to secure,
optimize, and load balance application traffic. This gives you the
flexibility and control to add applications and servers easily,
eliminate downtime, improve application performance, and meet your
security requirements.

\sphinxstylestrong{Easily deploy applications and ensure availability}

BIG-IP LTM gives you the industry’s most advanced load balancing and
application health monitoring capabilities. F5 iApp enables you to
easily deploy and manage applications using user-defined application
centric configuration templates. The associated application related
statistics provide complete visibility into the health and performance
of your apps for faster troubleshooting and resolution of issues.

\sphinxstylestrong{Accelerate your applications up to 3x}

BIG-IP LTM reduces traffic volumes and minimizes the effect of client
connection bottlenecks as well as WAN, LAN, and Internet latency to
improve application and replication performance up to 3x. You can
achieve additional performance increases with BIG-IP Application
Acceleration Manager (see section below).

\sphinxstylestrong{Take control over application delivery}

The F5 TMOS platform gives you complete control of the connection,
packets, and payload for applications. Using F5’s event driven iRules
you can customize how you intercept, inspect, transform, and direct
inbound and outbound application traffic. The F5 iControl API makes it
easy to integrate with third-party management systems. Device Service
Clustering provides flexible high-availability scaling and configuration
syncing of live application traffic among a cluster of active or standby
BIG-IP devices

\sphinxstylestrong{Reduce servers, bandwidth, and management costs}

Advanced TCP connection management, TCP optimization, and server
offloading enable you to optimize the utilization of your existing
infrastructure—tripling server capacity and reducing bandwidth costs by
up to 80 percent. BIG-IP LTM helps you simplify system management by
consolidating security, acceleration, and availability in one
easy-to-manage platform. By using fewer servers, less bandwidth, less
power, and less cooling, while reducing the time spent managing your
infrastructure, you can significantly reduce your operational costs.

\sphinxstylestrong{The purpose of the Local Traffic Manager is to load balance
applications in your environment by using advanced TCP connection
management, TCP optimization and server offloading and also provides a
high security solution. The LTMs iApps functionality is a powerful set
of features that enable you to manage application services rather than
individual devices and objects.}


\bigskip\hrule\bigskip


\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{BIG-IP Application Security Manager (ASM)}

F5 BIG-IP Application Security Manager (ASM) is a flexible web
application firewall that secures web applications in traditional,
virtual, and private cloud environments. BIG-IP ASM provides unmatched
web application and website protection, helps secure deployed
applications against unknown vulnerabilities, and enables compliance for
key regulatory mandates—all on a platform that consolidates application
delivery with data center firewall capabilities, and network and
application access control.

\sphinxstylestrong{Deliver comprehensive security}

BIG-IP ASM blocks web application attacks in minutes to help protect
against a broad spectrum of threats, including the latest distributed
denial-of-service (DDoS) and SQL injection attacks. It also helps secure
interactive web applications that use the latest coding, such as AJAX
widgets and JSON payloads. Advanced vulnerability assessment
integrations can scan web applications and BIG-IP ASM patches
vulnerabilities in minutes to help protect against web threats. BIG-IP
ASM stops hackers and attacks from any location and ensures that
legitimate users can access applications.

\sphinxstylestrong{The purpose of the Application Security Manager is to secure web
applications using a certified web application firewall and offer threat
assessment and visibility.}


\bigskip\hrule\bigskip


\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{BIG-IP Global Traffic Manager (GTM)}

F5 BIG-IP Global Traffic Manager (GTM) distributes DNS and user
application requests based on business policies, data center and network
conditions, user location, and application performance. BIG-IP GTM
delivers F5’s high-performance DNS Services with visibility, reporting,
and analysis; scales and secures DNS responses geographically to survive
DDoS attacks; delivers a complete, real-time DNSSEC solution; and
ensures global application high availability.

\sphinxstylestrong{Control and ensure app availability}

BIG-IP GTM helps you create a strong disaster recovery and business
continuity plan by ensuring that users are always connected to a site
where the application is available. In addition to performing
comprehensive health checking of the entire infrastructure, BIG-IP GTM
minimizes downtime and improves the user experience by determining
health at the application layer for every user.

\sphinxstylestrong{Improve application performance}

BIG-IP GTM enables you to send users to a site that will give them the
best application experience. It uses a range of different load balancing
methods and intelligent monitoring for each specific application and
user. Traffic is routed according to your business policies and current
network and user conditions. BIG-IP GTM includes an accurate, granular
geo-location database, giving you control of traffic distribution based
on the user’s location. By providing persistence for stateful
applications, BIG-IP GTM helps you eliminate broken sessions and
corrupted data.

\sphinxstylestrong{The purpose of the Global Traffic Manager is to ensure availability
and access to the applications in your environment by using
comprehensive health checks and load balancing methods to determine what
site the user should access to get the best application experience.}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{These products are also in TMOS version 11.4 but not mentioned in the blueprint}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com/pdf/products/big-ip-application-acceleration-manager-datasheet.pdf}{Link to Online Topic
Content}

\sphinxstylestrong{BIG-IP Application Acceleration Manager (AAM)}

F5 BIG-IP Application Acceleration Manager (AAM) overcomes network,
protocol, and application issues to help you meet application
performance, data replication, and disaster recovery requirements
presented by cloud, mobile applications, and video distribution. By
offloading your network and servers, BIG-IP AAM decreases the need for
additional bandwidth and hardware. Users get fast access to
applications, and you gain greater revenue and free up IT resources for
other strategic projects.

BIG-IP AAM can optimize a wide variety of protocols delivered to a
client browser, a desktop application, or another BIG-IP device,
depending on the deployment. Optimizations are divided into data center
optimizations, including server and network optimizations, transport
optimizations, and application delivery optimizations, including
application protocol and web performance optimizations.

\sphinxstylestrong{The purpose of the Application Acceleration Manager is to overcome
WAN latency, maximizes server capacity, and speeds application response
times. AAM decreases the need for additional bandwidth and hardware so
users get fast access to applications, while you gain greater revenue
and free up IT resources.}


\bigskip\hrule\bigskip


\sphinxhref{http://www.f5.com/pdf/products/big-ip-advanced-firewall-manager-datasheet.pdf}{Link to Online Topic
Content}

\sphinxstylestrong{BIG-IP Advanced Firewall Manager (AFM)}

F5 BIG-IP Advanced Firewall Manager (AFM) is a high-performance,
stateful, full-proxy network firewall designed to guard data centers
against incoming threats that enter the network on the most widely
deployed protocols—including HTTP/S, SMTP, DNS, and FTP. By aligning
firewall policies with the applications they protect, BIG-IP AFM
streamlines application deployment, security, and monitoring. With its
scalability, security, and simplicity, BIG-IP AFM forms the core of the
F5 application delivery firewall solution.

BIG-IP AFM is the core of the F5 application delivery firewall
solution—the first of its kind in the industry, which combines the
network firewall with traffic management, application security, user
access management, and DNS security. By consolidating the security
functions of several BIG-IP modules onto a single platform, the F5
application delivery firewall reduces management complexity and
overhead, while still maintaining superior performance and scalability.
Building upon BIG-IP Local Traffic Manager, the application delivery
firewall has deep application fluency in the most widely deployed
enterprise applications. This makes it ideal for protecting
Internet-facing data center applications, wherever they reside.

\sphinxstylestrong{The purpose of the Application Delivery Firewall is to combine the
network firewall with anti-DDoS, traffic management, application
security, user access management, and DNS security. By integrating these
core datacenter features, F5 application delivery firewall reduces
management complexity and overhead and is ideal for protecting
internet-facing data centers wherever they reside.}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.02 Explain the purpose, use, and advantages of iRules}
\label{\detokenize{class1/modules/module2:objective-2-02-explain-the-purpose-use-and-advantages-of-irules}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Explain the purpose of iRules}

\sphinxhref{https://devcentral.f5.com/wiki/iRules.HomePage.ashx}{Link to Online Topic Content}

\sphinxstylestrong{What is an iRule?}

An iRule is a script that you write if you want to make use of some of
the extended capabilities of the BIG-IP that are unavailable via the CLI
or GUI. iRules allow you to more directly interact with the traffic
passing through the device. Using iRules, you can send traffic not only
to pools, but also to individual pool members, ports, or URIs. And
directing traffic to a desired pool is only the beginning. You can parse
the entire header and payload of the data as it is being passed through
the BIG-IP and, at wire speed, execute an entire script of commands on
that traffic. The commands at your disposal range from logging to
redirecting traffic, from modifying the URI or port to actually
rewriting the payload itself.

The iRules you create can be simple or sophisticated, depending on your
content-switching needs. The following shows an example of a simple
iRule.

This iRule is triggered when a client-side connection has been accepted,
causing the LTM system to send the packet to the pool my\_pool, if the
client’s address matches 10.10.10.10.

Using a feature called the Universal Inspection Engine (UIE), you can
write an iRule that searches either a header of a packet, or actual
packet content, and then directs the packet based on the result of that
search. iRules can also direct packets based on the result of a client
authentication attempt.

iRules can direct traffic not only to specific pools, but also to
individual pool members, including port numbers and URI paths, either to
implement persistence or to meet specific load balancing requirements.

The syntax that you use to write iRules is based on the Tool Command
Language (Tcl) programming standard. Thus, you can use many of the
standard Tcl commands, plus a robust set of extensions that the LTM
system provides to help you further increase load balancing efficiency.

The advantage of iRules is that you extend the capabilities of the
BIG-IP that is not available through the CLI or the GUI.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Explain the advantages of iRules}

\sphinxhref{https://devcentral.f5.com/articles/-the101-irules-ndash-introduction-to-irules}{Link to Online Topic Content}

\sphinxstylestrong{How does an iRule work?}

To start at the beginning, as it were, an iRule is first and foremost a
configuration object, in F5 terms. This means that it is a part of your
general bigip.conf along with your pools, virtual servers, monitors,
etc. It is entered into the system either via the GUI or CLI, generally
speaking. There is also an iRules Editor available for download on
DevCentral that is a windows tool for editing and deploying/testing
iRules, which can be extremely useful. Unlike most configuration
objects, though, an iRule is completely user generated and customizable.
An iRule is a script, at its core after all. Regardless of how an iRule
gets there, be it UI, CLI or Editor, once an iRule is part of your
config, it is then compiled as soon as that configuration is saved.

One of the gross misconceptions about iRules is that, as with most
interpreted scripting languages such as TCL, and interpreter must be
instantiated every time an iRule is executed to parse the code and
process it. This is not true at all, because every time you save your
configuration all of your iRules are pre-compiled into what is referred
to as “byte code”. Byte code is mostly compiled and has the vast
majority of the interpreter tasks already performed, so that TMM can
directly interpret the remaining object. This makes for far higher
performance and as such increases scalability.

Now that the iRule is saved and pre-compiled, it must then be applied to
a virtual server before it can affect any traffic. An iRule that is not
applied to a virtual server is effectively disabled, for all intents and
purposes. Once you’ve applied an iRule to a given virtual server,
however, it will now technically be applied against all traffic passing
through that virtual server. Keep in mind though, that this does not
necessarily mean that all traffic passing through the virtual server in
question will be affected. IRules are most often very selective in which
traffic they affect, be it to modify, re-route or otherwise. This is
done through both logical constructs within the iRules, but also through
the use of events within the iRule itself.

Events are one of the ways in which iRules have been made to be network
aware, as a language. An event, which we’ll dig into in much more detail
in the next installment of this series, is a way of executing iRules
code at a given point in time within the flow of a networking session.
If I only want to execute a section of code once for each new connection
to the virtual server to which my iRule is applied, I could easily do so
by writing some simple code in the appropriate event. Events are also
important because they indicate at which point in the proxy chain
(sometimes referred to as a hud chain) an iRule executes. Given that
BIG-IP is a bidirectional proxy, it is important for iRules to execute
on not only the right side of the proxy, but at the right moment in the
network flow.

So now you have an iRule added to your configuration, it has been
automatically pre-compiled to byte code when the configuration was
saved, you have it applied to the appropriate virtual server, and the
code within the iRule calls out the desired event in which you want your
code to execute; now is when the magic happens, as it were. This is
where the massive collection of iRules commands comes into play. From
header modification to full on payload replacement to creating a socket
connection to an outside system and making a request before processing
traffic for your virtual, there are very few limitations to what can be
achieved when combining the appropriate series of iRules commands. Those
commands are then processed by TMM, which will affect whatever change(s)
it needs to the traffic it is processing for the given session,
depending on what you’ve designed your iRule to do. The true power of
iRules largely comes into play thanks to the massive array of custom
commands that we’ve built into the language, allowing you to leverage
your BIG-IP to the fullest.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Given a list of situations, determine which would be appropriate for the use of iRules}

\sphinxhref{https://devcentral.f5.com/articles/-the101-irules-ndash-introduction-to-irules}{Link to Online Topic Content}

\sphinxstylestrong{When would I use an iRule?}

The ideal time to use an iRule is when you’re looking to add some form
of functionality to your application or app deployment, at the network
layer, and that functionality is not already readily available via the
built in configuration options in your BIG-IP. Whether it’s looking to
perform some kind of custom redirect or logging specific information
about users’ sessions or a vast array of other possibilities, iRules can
add valuable business logic or even application functionality to your
deployment. iRules have a single point of management, your BIG-IP, as
opposed to being distributed to every server hosting whichever
application you’re trying to modify or affect. This can save valuable
management time, and can also be a large benefit in time to deployment.
It is often far easier to deploy an iRule or an iRule change than it is
to modify your application for a quick fix.

As an example, one of the most common uses of iRules when it was first
introduced was to redirect all traffic from HTTP (port 80) to HTTPS
(port 443) without affecting either the host or the requested URI for
the connection. (See example below) This was and still is a very simple
iRule, but it wasn’t at the time a feature available in the standard
configuration options for BIG-IP.

when HTTP\_REQUEST \{

\sphinxurl{HTTP::redirect} “\sphinxurl{https://{[}HTTP::host{]}{[}HTTP::uri}{]}”

\}

\sphinxstylestrong{When would I not use an iRule?}

The above example of an HTTP to HTTPS redirect iRule actually depicts
perfectly when to not use an iRule, because that functionality was so
popular that it has since been added as a profile option directly in the
BIG- IP configuration. As such, it is more appropriate and technically
higher performance, to use that feature in the profile as opposed to
writing an iRule to perform the same task. A general rule of thumb is:
Any time you can do something from within the standard config options,
profiles, GUI or CLI - do it there first. If you’re looking to perform a
task that can’t be accomplished via the “built-in” means of
configuration, then it is a perfect time to turn to iRules to expand the
possibilities.

The main reason for this is performance. iRules are extremely high
performance as a rule, if written properly. But there is always a slight
benefit in performance when you can run functionality directly from
built in, core features as opposed to a custom created script, even an
iRule. Also, though, it is easier to maintain a feature built into the
product through upgrades, rather than re-testing and managing an iRule
that could be easily replaced with a few configuration options.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.03 Explain the purpose, use, and advantages of iApps}
\label{\detokenize{class1/modules/module2:objective-2-03-explain-the-purpose-use-and-advantages-of-iapps}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Explain the purpose of iApps}

\sphinxhref{https://devcentral.f5.com/articles/managing-iapp-template-files-with-icontrol}{Link to Online Topic Content}

\sphinxstylestrong{What’s an iApp?}

An iApp is a user-customizable framework for deploying applications. It
consists of three components: Templates, Application Services, and
Analytics. An iApp Template is where the application is described and
the objects (required and optional) are defined through presentation and
implementation language. An iApp Application Service is the deployment
process of an iApp Template which bundles the entire configuration
options for a particular application together. You would have an iApp
Application Service for SharePoint, for example. iApp Analytics include
performance metrics on a per-application and location basis. Benefits of
using iApp:
\begin{itemize}
\item {} 
User-customizable

\item {} 
Easy editing of configurations and cleanup

\item {} 
Reentrancy

\item {} 
Configuration encapsulation

\item {} 
Cradle-to-grave configuration management

\item {} 
Strictness protects against accidental changes to the configuration

\item {} 
Operational tasks and health status for App objects displayed on
App-specific component view (see right)

\item {} 
Copy/Import/Export capability

\item {} 
Community support for DevCentral hosted templates

\end{itemize}

\noindent\sphinxincludegraphics{{1p19}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Explain the advantages of iApps}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip\_iapps\_developer\_11\_0\_0/2.html}{Link to Online Topic Content}

\sphinxstylestrong{About iApp Templates}

iApps templates create configuration-specific forms used by application
services to guide authorized users through complex system
configurations. The templates provide programmatic, visual layout and
help information. Each new application service uses one of the templates
to create a screen with fields and guide the user through the
configuration process and creates the configuration when finished.

The templates allow users to customize by either modifying an existing
template or creating one from scratch. Users can create scratch-built
templates using either the iApps Templates screen or any text-editing
software

The BIG-IP system comes with several system-supplied templates that you
can use as-is to create your application services. You can also use the
system-supplied templates as a starting point for your own templates, or
you can write templates from scratch using, variously, tmsh and TCL for
the back-end template implementation section.

\sphinxstylestrong{Template sections}

Templates have three sections; presentation, implementation, and help.
\begin{itemize}
\item {} 
The presentation section collects user entries.

\item {} 
The implementation section uses user entries to build a configuration
that will control traffic.

\item {} 
The help section documents the template and its presentation to users
when creating an application service.

\end{itemize}

\noindent\sphinxincludegraphics{{1p20}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Given a list of situations, determine which would be
appropriate for the use of iApps}

\sphinxhref{https://www.motiv.nl/documenten/whitepapers/f5-iapp-wp}{Link to Online Topic Content}

\sphinxstylestrong{When do you use an iApp?}

As organizations begin moving to more modular cloud and SaaS models,
managing applications becomes more important than building
infrastructure. Many of the benefits that come from moving to a more
agile model are not associated with managing the infrastructure; yet
managing application deployments, performance, and availability in cloud
and SaaS environments is often difficult because the application is
still tied to infrastructure. iApps bind application control,
visibility, and management to the infrastructure required to deliver
those applications and services beyond the data center.

iApps support the architecture that transforms a network from a static
resource comprising isolated components to a unified, flexible, and
resilient pool of resources directly associated with an application or
service. This enables rapid network deployment, integration, management,
and visibility at the application layer. iApps provide complete control
over the entire application delivery infrastructure by adapting the
network to the application. The resulting quick deployment and
single-point capabilities save operational costs. For the first time,
organizations can create a common and highly reusable catalogue for
security, acceleration, and availability services at a strategic point
of control to dramatically increase the organizational agility and
efficiency of F5 BIG-IP devices.

With iApps, F5 has created a paradigm shift in how administrators view
and manage the network by moving management responsibility from the
network components to the application. iApps increase IT agility and
efficiency by enabling organizations to manage the security,
optimization, availability, health, and performance of not only the ADN
devices in the network, but of the mission-critical applications running
the business. In this way, iApps create a truly unified Application
Delivery Network.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.04 Explain the purpose of and use cases for full proxy and packet forwarding/packet based architectures}
\label{\detokenize{class1/modules/module2:objective-2-04-explain-the-purpose-of-and-use-cases-for-full-proxy-and-packet-forwarding-packet-based-architectures}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Describe a full proxy architecture}

\sphinxhref{https://devcentral.f5.com/Portals/0/Cache/Pdfs/2807/the-concise-guide-to-proxies.pdf}{Link to Online Topic Content}

We often mention that the benefits derived from some application
delivery controllers are due to the nature of being a full proxy. And in
the same breath we might mention reverse, half, and forward proxies,
which makes the technology sound more like a description of the
positions on a sports team than an application delivery solution. So
what does these terms really mean? Here’s the lowdown on the different
kinds of proxies in one concise guide.

\sphinxstylestrong{Proxies}

Proxies (often called intermediaries in the SOA world) are hardware or
software solutions that sit between the client and the server and do
something to requests and sometimes responses. The most often heard use
of the term proxy is in conjunction with making Web surfing anonymous.
That’s because proxies sit between your browser and your desired
destination and proxy the connection; that is you talk to the proxy
while the proxy talks to the web server and neither you nor the web
server know about each other.

Proxies are not all the same. Some are half proxies, some are full
proxies; some are forward and some are reverse. Yes, that came
excruciatingly close to sounding like a Dr. Seuss book.

\sphinxstylestrong{Forward Proxies}

Forward proxies are probably the most well known of all proxies,
primarily because most folks have dealt with them either directly or
indirectly. Forward proxies are those proxies that sit between two
networks, usually a private internal network and the public Internet.
Large service providers have also traditionally employed forward proxies
as a bridge between their isolated network of subscribers and the public
Internet, such as CompuServe and AOL in days gone by. These are often
referred to as “mega-proxies” because they managed such high volumes of
traffic.

Forward proxies are generally HTTP (Web) proxies that provide a number
of services but primarily focus on web content filtering and caching
services. These forward proxies often include authentication and
authorization as a part of their product to provide more control over
access to public content. If you’ve ever gotten a web page that says
“Your request has been denied by blah blah. If you think this is an
error please contact the help desk/your administrator” then you’ve
probably used a forward proxy.

\noindent\sphinxincludegraphics{{1p21}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Reverse Proxies}

A reverse proxy is less well known, generally because we don’t use the
term anymore to describe products used as such. Load balancers
(application delivery controllers) and caches are good examples of
reverse proxies. Reverse proxies sit in front of web and application
servers and process requests for applications and content coming in from
the public Internet to the internal, private network. This is the
primary reason for the name “reverse” proxy to differentiate it from a
proxy that handles outbound requests.

Reverse proxies are also generally focused on HTTP but in recent years
have expanded to include a number of other protocols commonly used on
the web such as streaming audio (RTSP), file transfers (FTP), and
generally any application protocol capable of being delivered via UDP or
TCP.

\noindent\sphinxincludegraphics{{1p22}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Half Proxies}

Half-proxy is a description of the way in which a proxy, reverse or
forward, handles connections. There are two uses of the term half-proxy:
one describing a deployment configuration that affects the way
connections are handled and one that describes simply the difference
between a first and subsequent connections.

The deployment-focused definition of half-proxy is associated with a
direct server return (DSR) configuration. Requests are proxied by the
device, but the responses do not return through the device, but rather
are sent directly to the client. For some types of data, particularly
streaming protocols, this configuration results in improved performance.
This configuration is known as a half-proxy, because only half the
connection (incoming) is proxied while the other half, the response, is
not.

\noindent\sphinxincludegraphics{{1p23}.png}

The second use of the term “half-proxy” describes a solution in which
the proxy performs what is known as delayed binding in order to provide
additional functionality. This allows the proxy to examine the request
before determining where to send it. Once the proxy determines where to
route the request, the connection between the client and the server are
“stitched” together. This is referred to as a half-proxy because the
initial TCP handshaking and first requests are proxied by the solution,
but subsequently forwarded without interception.

\noindent\sphinxincludegraphics{{1p24}.png}

Half proxies can look at incoming requests in order to determine where
the connection should be sent and can even use techniques to perform
layer 7 inspection, but they are rarely capable of examining the
responses. Almost all half-proxies fall into the category of reverse
proxies.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Full Proxies}

Full proxy is also a description of the way in which a proxy, reverse or
forward, handles connections. A full proxy maintains two separate
connections - one between itself and the client and one between itself
and the destination server. A full proxy completely understands the
protocols, and is itself an endpoint and an originator for the
protocols. Full proxies are named because they completely proxy
connections - incoming and outgoing.

Because the full proxy is an actual protocol endpoint, it must fully
implement the protocols as both a client and a server (a packet-based
design does not). This also means the full proxy can have its own TCP
connection behavior, such as buffering, retransmits, and TCP options.
With a full proxy, each connection is unique; each can have its own TCP
connection behavior. This means that a client connecting to the full
proxy device would likely have different connection behavior than the
full proxy might use for communicating with servers. Full proxies can
look at incoming requests and outbound responses and can manipulate both
if the solution allows it.

Many reverse and forward proxies use a full proxy model today. There is
no guarantee that a given solution is a full proxy, so you should always
ask your solution provider if it is important to you that the solution
is a full proxy.

\noindent\sphinxincludegraphics{{1p25}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Describe a packet forwarding/packet based architecture}

\sphinxhref{https://en.wikipedia.org/wiki/Packet\_forwarding}{Link to Online Topic Content}

\sphinxstylestrong{Packet Forwarding}

Packet forwarding is the relaying of packets from one network segment to
another by nodes in a computer network. A unicast forwarding pattern,
typical of many networking technologies including the overwhelming
majority of Internet traffic a multicast-forwarding pattern, typical of
PIM

A broadcast forwarding pattern, typical of bridged Ethernet

The Network Layer of the OSI Layer is responsible for Packet Forwarding.
The simplest forwarding model—​unicasting—​involves a packet being
relayed from link to link along a chain leading from the packet’s source
to its destination. However, other forwarding strategies are commonly
used. Broadcasting requires a packet to be duplicated and copies sent on
multiple links with the goal of delivering a copy to every device on the
network. In practice, broadcast packets are not forwarded everywhere on
a network, but only to devices within a broadcast domain, making
broadcast a relative term. Less common than broadcasting, but perhaps of
greater utility and theoretical significance, is multicasting, where a
packet is selectively duplicated and copies delivered to each of a set
of recipients.

Networking technologies tend to naturally support certain forwarding
models. For example, fiber optics and copper cables run directly from
one machine to another to form a natural unicast media - data
transmitted at one end is received by only one machine at the other end.
However, as illustrated in the diagrams, nodes can forward packets to
create multicast or broadcast distributions from naturally unicast
media. Likewise, traditional Ethernet (10BASE5 and 10BASE2, but not the
more modern 10BASE-T) are natural broadcast media - all the nodes are
attached to a single long cable and a packet transmitted by one device
is seen by every other device attached to the cable. Ethernet nodes
implement unicast by ignoring packets not directly addressed to them. A
wireless network is naturally multicast - all devices within a reception
radius of a transmitter can receive its packets. Wireless nodes ignore
packets addressed to other devices, but require forwarding to reach
nodes outside their reception radius.

At nodes where multiple outgoing links are available, the choice of
which, all, or any to use for forwarding a given packet requires a
decision making process that, while simple in concept, is sometimes
bewilderingly complex. Since a forwarding decision must be made for
every packet handled by a node, the total time required for this can
become a major limiting factor in overall network performance. Much of
the design effort of high-speed routers and switches has been focused on
making rapid forwarding decisions for large numbers of packets.

The forwarding decision is generally made using one of two processes:
routing, which uses information encoded in a device’s address to infer
its location on the network, or bridging, which makes no assumptions
about where addresses are located and depends heavily on broadcasting to
locate unknown addresses. The heavy overhead of broadcasting has led to
the dominance of routing in large networks, particularly the Internet;
bridging is largely relegated to small networks where the overhead of
broadcasting is tolerable. However, since large networks are usually
composed of many smaller networks linked together, it would be
inaccurate to state that bridging has no use on the Internet; rather,
its use is localized.

A network can use one of two different methods to forward packets:
store-and-forward or cut through.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{https://f5.com/resources/white-papers/tmos-redefining-the-solution}{Link to Online Topic Content}

\sphinxstylestrong{Packet-based Design}

A network device with a packet-based (or packet-by-packet) design is
located in the middle of a stream of communications, but is not an
endpoint for those communications; it just passes the packets through.
Often a device that operates on a packet-by-packet basis does have some
knowledge of the protocols flowing through it, but is far from being a
real protocol endpoint. The speed of these devices is primarily based on
not having to understand the entire protocol stack, short-cutting the
amount of work needed to handle traffic. For example, with TCP/IP, this
type of device might only understand the protocols well enough to
rewrite the IP addresses and TCP ports; only about half of the entire
stack.

As networks became more complex and the need for intelligence increased,
more advanced packet-based designs began to emerge (including the BIG-IP
products from F5). These devices knew TCP/IP well enough to understand
both TCP connection setup and teardown, modify TCP/IP headers, and even
insert data into TCP streams. Because these systems could insert data
into TCP streams and modify the content of the stream, they also had to
rewrite the TCP sequence (SEQ) and acknowledgment (ACK) values for
packets going back and forth from the client and server. F5’s BIG-IP
products understood TCP/IP and HTTP well enough to identify individual
HTTP requests and could send different requests to different servers,
reusing connections the BIG-IP device already had open.

While all of this is possible using a very sophisticated
packet-by-packet architecture (BIG-IP devices are some of the most
sophisticated of such designs to date), it required a very complex state
tracking engine to understand the TCP/IP and HTTP protocols well enough
to rewrite header contents, insert data, and maintain its own
connections to clients and servers.

Despite this increasing complexity, packet-based designs are still less
complex and faster than traditional proxy-based designs, as they have
the advantage of only requiring a small percentage of the logic required
for a full proxy.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Given a list of situations, determine which is appropriate for
a full proxy architecture}

\sphinxhref{https://devcentral.f5.com/articles/the-full-proxy-data-center-architecture}{Link to Online Topic Content}

\sphinxstylestrong{Full proxy architecture - What do they mean?}

The reason there is a distinction made between “proxy” and “full-proxy”
stems from the handling of connections as they flow through the device.
All proxies sit between two entities - in the Internet age almost always
“client” and “server” - and mediate connections. While all full-proxies
are proxies, the converse is not true. Not all proxies are full-proxies
and it is this distinction that needs to be made when making decisions
that will impact the data center architecture.

A full-proxy maintains two separate session tables - one on the
client-side, one on the server-side. There is effectively an “air gap”
isolation layer between the two internal to the proxy, one that enables
focused profiles to be applied specifically to address issues peculiar
to each “side” of the proxy. Clients often experience higher latency
because of lower bandwidth connections while the servers are generally
low latency because they’re connected via a high-speed LAN. The
optimizations and acceleration techniques used on the client side are
far different than those on the LAN side because the issues that give
rise to performance and availability challenges are vastly different.

\noindent\sphinxincludegraphics[width=0.490\linewidth]{{1p26}.png}

\noindent\sphinxincludegraphics[width=0.490\linewidth]{{1p27}.png}

A full-proxy, with separate connection handling on either side of the
“air gap”, can address these challenges. A proxy, that may be a
full-proxy but more often than not simply uses a buffer-and-stitch
methodology to perform connection management, cannot optimally do so. A
typical proxy buffers a connection, often through the TCP handshake
process and potentially into the first few packets of application data,
but then “stitches” a connection to a given server on the back-end using
either layer 4 or layer 7 data, perhaps both. The connection is a single
flow from end-to-end and must choose which characteristics of the
connection to focus on - client or server - because it cannot
simultaneously optimize for both.

The second advantage of a full-proxy is its ability to perform more
tasks on the data being exchanged over the connection as it is flowing
through the component. Because specific action must be taken to “match
up” the connection as its flowing through the full-proxy, the component
can inspect, manipulate, and otherwise modify the data before sending it
on its way on the server-side. This is what enables termination of SSL,
enforcement of security policies, and performance-related services to be
applied on a per-client, per-application basis.

This capability translates to broader usage in data center architecture
by enabling the implementation of an application delivery tier in which
operational risk can be addressed through the enforcement of various
policies. In effect, we’re created a full-proxy data center architecture
in which the application delivery tier as a whole serves as the “full
proxy” that mediates between the clients and the applications.

\sphinxstylestrong{The full-proxy data center architecture}

A full-proxy data center architecture installs a digital “air gap”
between the client and applications by serving as the aggregation (and
conversely disaggregation) point for services. Because all communication
is funneled through virtualized applications and services at the
application delivery tier, it serves as a strategic point of control at
which delivery policies addressing operational risk (performance,
availability, security) can be enforced.

A full-proxy data center architecture further has the advantage of
isolating end-users from the volatility inherent in highly virtualized
and dynamic environments such as cloud computing. It enables solutions
such as those used to overcome limitations with virtualization
technology, such as those encountered with Pod architectural constraints
in VMware View deployments. Traditional access management technologies,
for example, are tightly coupled to host names and IP addresses. In a
highly virtualized or cloud computing environment, this constraint may
spell disaster for either performance or ability to function, or both.
By implementing access management in the application delivery tier - on
a full-proxy device - volatility is managed through virtualization of
the resources, allowing the application delivery controller to worry
about details such as IP address and VLAN segments, freeing the access
management solution to concern itself with determining whether this user
on this device from that location is allowed to access a given resource.

Basically, we’re taking the concept of a full-proxy and expanded it
outward to the architecture. Inserting an “application delivery tier”
allows for an agile, flexible architecture more supportive of the rapid
changes today’s IT organizations must deal with.

Such a tier also provides an effective means to combat modern attacks.
Because of its ability to isolate applications, services, and even
infrastructure resources, an application delivery tier improves an
organizations’ capability to withstand the onslaught of a concerted DDoS
attack. The magnitude of difference between the connection capacity of
an application delivery controller and most infrastructures (and all
servers) gives the entire architecture a higher resiliency in the face
of overwhelming connections. This ensures better availability and, when
coupled with virtual infrastructure that can scale on-demand when
necessary, can also maintain performance levels required by business
concerns.

A full-proxy data center architecture is an invaluable asset to IT
organizations in meeting the challenges of volatility both inside and
outside the data center.

\noindent\sphinxincludegraphics{{1p28}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Given a list of situations, determine which is appropriate for
a packet based architecture}

\sphinxhref{https://f5.com/resources/white-papers/tmos-redefining-the-solution}{Link to Online Topic Content}

\sphinxstylestrong{What is a packet-based design?}

A network device with a packet-based (or packet-by-packet) design is
located in the middle of a stream of communications, but is not an
endpoint for those communications; it just passes the packets through.
Often a device that operates on a packet-by-packet basis does have some
knowledge of the protocols flowing through it, but is far from being a
real protocol endpoint. The speed of these devices is primarily based
on not having to understand the entire protocol stack, shortcutting the
amount of work needed to handle traffic. For example, with TCP/IP, this
type of device might only understand the protocols well enough to
rewrite the IP addresses and TCP ports; only about half of the entire
stack.

As networks became more complex and the need for intelligence increased,
more advanced packet-based designs began to emerge (including the BIG-IP
products from F5). These devices knew TCP/IP well enough to understand
both TCP connection setup and teardown, how to modify TCP/IP headers,
and even insert data into TCP streams.

Because these systems could insert data into TCP streams and modify the
content of the stream, they also had to rewrite the TCP sequence (SEQ)
and acknowledgment (ACK) values for packets going back and forth from
the client and server. F5’s BIG-IP products understood TCP/IP and HTTP
well enough to identify individual HTTP requests and could send
different requests to different servers, reusing connections the BIG-IP
device already had open.

While all of this is possible using a very sophisticated
packet-by-packet architecture (BIG-IP devices are some of the most
sophisticated of such designs to date), it required a very complex state
tracking engine to understand the TCP/IP and HTTP protocols well enough
to rewrite header contents, insert data, and maintain its own
connections to clients and servers. Despite this increasing complexity,
packet-based designs are still less complex and faster than traditional
proxy-based designs, as they have the advantage of only requiring a
small percentage of the logic required for a full proxy.

\sphinxstylestrong{What is a proxy-based design (full proxy)?}

A full-proxy design is the opposite of a packet-by-packet design.
Instead of having a minimal understanding of the communications
streaming through the device, a full proxy completely understands the
protocols, and is itself an endpoint and an originator for the
protocols. The connection between a client and the full proxy is fully
independent of the connection between the full proxy and the server;
whereas in a packet-by-packet design, there is essentially a direct
communication channel between the client and the server (although the
device in the middle may manipulate the packets going back and forth).

Because the full proxy is an actual protocol endpoint, it must fully
implement the protocols as both a client and a server (a packet-based
design does not). This also means the full proxy can have its own TCP
connection behavior, such as buffering, retransmits, and TCP options.
With a full proxy, each connection is unique; each can have its own TCP
connection behavior. This means that a client connecting to the

full-proxy device would likely have different connection behavior than
the full proxy might use for communicating with the backend servers.

Therefore, a full proxy allows for the optimization of every connection
uniquely, regardless of the original source and the final destination.
Further, a full proxy understands and processes each protocol as a real
client or server would, using layers. Using HTTP as an example, first
the IP protocol is processed, then TCP, then HTTP; and each layer have
no knowledge of the lower layers.

\sphinxstylestrong{Redefining the Solution}

It is common knowledge that proxy-based solutions, or at least the
intelligence offered by them, were the ultimate solution. However, the
vastly superior performance of packet-by-packet designs more than made
up for their limited intelligence. For a while, this was an acceptable
trade-off for most enterprise networks. As the need for increased
intelligence grows, packet-based solutions are quickly experiencing the
same performance restrictions that proxy-based solutions have always
suffered from. And the development complexity of packet-based solutions
is quickly approaching that of proxy-based designs as well. Despite
dramatic increases in hardware and software power, packet-by-packet
designs are unable to keep up with the need for intelligence and
performance. It is no longer acceptable to have to choose between them.
While packet-based solutions had their time, that time is gone. It is
now readily apparent that shortcutting intelligence in lieu of
performance did not adequately provide a viable solution. The real
solution is to build a proxy-based solution with the performance of the
packet-based solution.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.05 Explain the advantages and configurations of high availability (HA)}
\label{\detokenize{class1/modules/module2:objective-2-05-explain-the-advantages-and-configurations-of-high-availability-ha}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - F5 High Availability concepts}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos\_management\_guide\_10\_0\_0/tmos\_high\_avail.html}{Link to Online Topic Content}

\sphinxstylestrong{Single device}

When you are running the BIG-IP system as a single device (as opposed to
a unit of a redundant system), high availability refers to core services
being up and running on that device, and VLANs being able to send and
receive traffic.

\sphinxstylestrong{Redundant devices}

When you are running the BIG-IP system as a unit of a redundant system
configuration, high availability refers to core system services being up
and running on one of the two BIG-IP systems in the configuration. High
availability also refers to a connection being available between the
BIG-IP system and a pool of routers, and VLANs on the system being able
to send and receive traffic.

A redundant system is a type of BIG-IP system configuration that allows
traffic processing to continue in the event that a BIG-IP system becomes
unavailable. A BIG-IP redundant system consists of two identically
configured BIG-IP units. When an event occurs that prevents one of the
BIG-IP units from processing network traffic, the peer unit in the
redundant system immediately begins processing that traffic, and users
experience no interruption in service.

\sphinxstylestrong{What is failover?}

Failover is a process that occurs when one system in a redundant system
becomes unavailable, thereby causing the peer unit to assume the
processing of traffic originally targeted for the unavailable unit. To
facilitate coordination of the failover process, each unit has a unit ID
(1 or 2).

An essential element to making failover successful is a feature called
configuration synchronization. Configuration synchronization, or
ConfigSync, is a process where you replicate one unit’s main
configuration file on the peer unit. Because data is shared in this way,
a unit can process the other unit’s traffic when failover occurs.

By default, the way that a BIG-IP unit monitors the status of its peer,
in order to detect that failover is required, is through a hard-wired
connection between the two BIG-IP units. With proper configuration,
however, you can cause each BIG-IP unit to monitor peer status by way of
a TCP/IP network connection instead.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain active/active}

\sphinxhref{https://support.f5.com/kb/en-us/solutions/public/15000/000/sol15002.html?sr=46848622}{Link to Online Topic Content}

\sphinxstylestrong{Understanding active-active redundancy}

Network device failures may occur for a wide variety of reasons,
resulting in unexpected interruptions to applications and/or services.
These unexpected outages may reduce customer satisfaction and
confidence, and as a result, may incur loss of revenue vital for most
organizations that conduct their businesses online. From this
perspective, avoiding outages is critical to these organizations and the
first step to ensure application and service availability is to deploy
devices in an HA configuration. High availability ensures that
applications fail over seamlessly and service continues uninterrupted.
You can also perform troubleshooting while the application or service is
still functioning.

You can deploy BIG-IP systems in an Active-Active configuration for an
HA deployment. Deploying BIG-IP systems in such a manner allows the
active devices in the same cluster to process traffic separately during
normal operations and the ability to failover to one another when
required. However, F5 does not recommend deploying BIG-IP systems in an
Active-Active configuration without a standby device in the cluster, due
to the potential loss of high availability. Consider the following
points:

If each BIG-IP system in the Active-Active configuration can process the
application or services adequately and with some additional resources in
reserve, a failover from one active device to another active device
should be seamless, which allows applications and/or services to
continue uninterrupted.

If each BIG-IP system in the Active-Active configuration is running at
half or greater capacity, a failover from one active device to another
active device may cause the device that is taking over to reach its
processing threshold. As a result, the device fails and interrupts the
applications and/or services. This condition could continue until both
devices are restored to their operational capability.

Starting in BIG-IP 11.0.0, the Device Service Clustering (DSC) feature
allows you to configure more than two BIG-IP systems in an HA
configuration. The DSC feature also allows you to configure multiple
devices as active and one or more devices as standby.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain active/standby}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-implementations-11-4-0/2.html}{Link to Online Topic Content}

\sphinxstylestrong{Understanding active-standby redundancy}

An active-standby pair is a pair of BIG-IP devices configured so that
one device is actively processing traffic while the other device remains
ready to take over if failover occurs. The two devices synchronize their
configuration data and can fail over to one another in the event that
one of the devices becomes unavailable.

First, you can run the Setup utility on each device to configure base
network components (that is, a management port, administrative
passwords, and the default VLANs and their associated self IP
addresses). Continue running it on each device to establish a trust
relationship between the two devices, and create a Sync-Failover type of
device group that contains two member devices.

After the Setup utility is run on both devices, each device contains the
default traffic group that the BIG-IP system automatically created
during setup. A traffic group represents a set of configuration objects
(such as floating self IP addresses and virtual IP addresses) that
process application traffic. This traffic group actively processes
traffic on one of the two devices, making that device the active device.
When failover occurs, the traffic group will become active on (that is,
float to) the peer BIG-IP device.

By default, the traffic group contains the floating self IP addresses of
the default VLANs. Whenever you create additional configuration objects
such as self IP addresses, virtual IP addresses, and SNATs, the system
automatically adds these objects to the default traffic group.

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Understanding failover in active/standby mode}

When a redundant system is in active/standby mode, one unit is active,
that is, accepting and processing connections on behalf of the redundant
system, while the other unit is idle (that is, in a standby state). When
failover occurs, the standby unit becomes active, and it normally stays
active until failover occurs again, or until you force it into a standby
state. Forcing the unit into a standby state automatically causes the
other system to become active again, if possible.

For example, you can configure unit 1 to process traffic for virtual
servers A and B. The standby unit monitors the active unit, and if
communications fail, the standby unit initiates a failover and becomes
the active unit. The newly-active unit then begins processing traffic
for both virtual servers. You can see an active/standby configuration,
first as it behaves normally, and then after failover has occurred, by
viewing the figure.

\noindent\sphinxincludegraphics{{1p29}.png}

As you can see in the figure, unit 1 is in an active state, and unit 2
is in a standby state. With this configuration, failover causes the
following to occur:
\begin{itemize}
\item {} 
Unit 2 switches to an active state.

\item {} 
Unit 2 begins processing the connections that would normally be
processed by its peer.

\end{itemize}

When the failed unit becomes available again, you can force a unit to
change its state from active to standby or from standby to active,
thereby initiating failback. Failback on an active/standby system causes
a unit to relinquish any processing that it is doing on behalf of its
peer, and return to a standby state. A redundant system in
active/standby mode is the most common type of redundant system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 3 - Load Balancing Essentials}
\label{\detokenize{class1/modules/module3:section-3-load-balancing-essentials}}\label{\detokenize{class1/modules/module3::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.01 Discuss the purpose of, use cases for, and key considerations related to load balancing}
\label{\detokenize{class1/modules/module3:objective-3-01-discuss-the-purpose-of-use-cases-for-and-key-considerations-related-to-load-balancing}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Explain the purpose of distribution of load across multiple servers}

\sphinxstylestrong{Distribution of Load}

The amount of connections and utilization that an application may have
coming in from its core base of users can often far exceed the
throughput capacity of a single server hosting the application. The need
for distributing the inbound requests and processing load of responses
across a group of servers running the same application or service is
self-evident. The trick to distributing the load is finding the right
load balancing solution and then implementing it in the most effective
manner. While making sure the functions of the applications are not
being broken as users are sent all across the servers in the group.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Given an environment, determine the appropriate load balancing algorithm that achieves a desired result}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html?sr=46848886}{Link to Online Topic Content}

\sphinxstylestrong{Local Traffic Manager load balancing methods}

There are several load balancing methods available within the BIG-IP
system for load balancing traffic to pool members.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{METHOD}
&
\sphinxstylestrong{DESCRIPTION}
&
\sphinxstylestrong{WHEN TO USE}
\\
\hline
Round Robin
&
This is the default load balancing method. Round Robin mode passes each new connection request to the next server in line, eventually distributing connections evenly across the array of machines being load balanced.
&
Round Robin mode works well in most configurations, especially if the equipment that you are load balancing is roughly equal in processing speed and memory.
\\
\hline
Ratio (member) Ratio (node)
&
Local Traffic Manager distributes connections among pool members or nodes in a static rotation according to ratio weights that you define. In this case, the number of connections that each system receives over time is proportionate to the ratio weight you defined for each pool member or node. You set a ratio weight when you create each pool member or node.
&
These are static load balancing methods, basing distribution on user-specified ratio weights that are proportional to the capacity of the servers.
\\
\hline
Dynamic Ratio (member) Dynamic Ratio (node)
&
The Dynamic Ratio methods select a server based on various aspects of real-time server performance analysis. These methods are similar to the Ratio methods, except that with Dynamic Ratio methods, the ratio weights are system-generated, and the values of the ratio weights are not static. These methods are based on continuous monitoring of the servers, and the ratio weights are therefore continually changing.

\sphinxstylestrong{*Note:} To implement Dynamic Ratio load balancing, you must first install and configure the necessary server software for these systems, and then install the appropriate performance monitor.*
&
The Dynamic Ratio methods are used specifically for load balancing traffic to RealNetworks RealSystem Server platforms, Windows platforms equipped with Windows Management Instrumentation (WMI), or any server equipped with an SNMP agent such as the UC Davis SNMP agent or Windows 2000 Server SNMP agent.
\\
\hline
Fastest (node) Fastest (application)
&
The Fastest methods select a server based on the least number of current sessions. These methods require that you assign both a Layer 7 and a TCP type of profile to the virtual server.

\sphinxstylestrong{*Note:} If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.*
&
The Fastest methods are useful in environments where nodes are distributed across separate logical networks.
\\
\hline
Least Connections (member) Least Connections (node)
&
The Least Connections methods are relatively simple in that Local Traffic Manager passes a new connection to the pool member or node that has the least number of active connections.

\sphinxstylestrong{*Note:} If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.*
&
The Least Connections methods function best in environments where the servers have similar capabilities. Otherwise, some amount of latency can occur. For example, consider the case where a pool has two servers of differing capacities, A and B. Server A has 95 active connections with a connection limit of 100, while server B has 96 active connections with a much larger connection limit of 500. In this case, the Least Connections method selects server A, the server with the lowest number of active connections, even though the server is close to reaching capacity. If you have servers with varying capacities, consider using the Weighted Least Connections methods instead.
\\
\hline
Weighted Least Connections (member) Weighted Least Connections (node)
&
Like the Least Connections methods, these load balancing methods select pool members or nodes based on the number of active connections. However, the Weighted Least Connections methods also base their selections on server capacity. The Weighted Least Connections (member) method specifies that the system uses the value you specify in Connection Limit to establish a proportional algorithm for each pool member. The system bases the load balancing decision on that proportion and the number of current connections to that pool member. For example, member\_a has 20 connections and its connection limit is 100, so it is at 20\% of capacity. Similarly, member\_b has 20 connections and its connection limit is 200, so it is at 10\% of capacity. In this case, the system select selects member\_b. This algorithm requires all pool members to have a non-zero connection limit specified. The Weighted Least Connections (node) method specifies that the system uses the value you specify in the node’s Connection Limit setting and the number of current connections to a node to establish a proportional algorithm. This algorithm requires all nodes used by pool members to have a non-zero connection limit specified. If all servers have equal capacity, these load balancing methods behave in the same way as the Least Connections methods.

\sphinxstylestrong{*Note:} If the OneConnect feature is enabled, the Weighted Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Weighted Least Connections methods use only active connections in their calculations.*
&
Weighted Least Connections methods work best in environments where the servers have differing capacities. For example, if two servers have the same number of active connections but one server has more capacity than the other, Local Traffic Manager calculates the percentage of capacity being used on each server and uses that percentage in its calculations.
\\
\hline
Observed (member) Observed (node)
&
With the Observed methods, nodes are ranked based on the number of connections. The Observed methods track the number of Layer 4 connections to each node over time and create a ratio for load balancing.
&
The need for the Observed methods is rare, and they are not recommended for large pools.
\\
\hline
Predictive (member) Predictive (node)
&
The Predictive methods use the ranking methods used by the Observed methods, where servers are rated according to the number of current connections. However, with the Predictive methods, Local Traffic Manager analyzes the trend of the ranking over time, determining whether a node’s performance is currently improving or declining. The servers with performance rankings that are currently improving, rather than declining, receive a higher proportion of the connections.
&
The need for the Predictive methods is rare, and they are not recommend for large pools.
\\
\hline
Least Sessions
&
The Least Sessions method selects the server that currently has the least number of entries in the persistence table. Use of this load balancing method requires that the virtual server reference a type of profile that tracks persistence connections, such as the Source Address Affinity or Universal profile type.

\sphinxstylestrong{*Note:} The Least Sessions methods are incompatible with cookie persistence.*
&
The Least Sessions method works best in environments where the servers or other equipment that you are load balancing have similar capabilities.
\\
\hline
Ratio Least Connections
&
The Ratio Least Connections methods cause the system to select the pool member according to the ratio of the number of connections that each pool member has active.
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Explain the concept of persistence}

\sphinxhref{https://devcentral.f5.com/articles/persistent-and-persistence-whats-the-difference}{Link to Online Topic Content}

\sphinxstylestrong{Persistent and Persistence, What’s the Difference?}

While the conceptual basis of persistence and persistent are essentially
the same, in reality they refer to two different technical concepts.

Both persistent and persistence relate to the handling of connections.
The former is often used as a general description of the behavior of
HTTP and, necessarily, TCP connections, though it is also used in the
context of database connections. The latter is most often related to
TCP/HTTP connection handling but almost exclusively in the context of
load balancing.

\sphinxstylestrong{Persistent}

Persistent connections are connections that are kept open and reused.
The most commonly implemented form of persistent connections is HTTP,
with database connections a close second.

Persistent HTTP connections were implemented as part of the HTTP 1.1
specification as a method of improving the efficiency of HTTP in
general. Before HTTP 1.1 a browser would generally open one connection
per object on a page in order to retrieve all the appropriate resources.
As the number of objects in a page grew, this became increasingly
inefficient and significantly reduced the capacity of web servers while
causing browsers to appear slow to retrieve data. HTTP 1.1 and the
Keep-Alive header in HTTP 1.0 were aimed at improving the performance of
HTTP by reusing TCP connections to retrieve objects. They made the
connections persistent such that they could be reused to send multiple
HTTP requests using the same TCP connection.

Similarly, this notion was implemented by proxy-based load-balancers as
a way to improve performance of web applications and increase capacity
on web servers. Persistent connections between a load-balancer and web
servers is usually referred to as TCP multiplexing. Just like browsers,
the load-balancer opens a few TCP connections to the servers and then
reuses them to send multiple HTTP requests.

Persistent connections, both in browsers and load-balancers, have
several advantages:
\begin{itemize}
\item {} 
Less network traffic due to less TCP setup/teardown. It requires no
less than 7 exchanges of data to set up and tear down a TCP
connection, thus each connection that can be reused reduces the
number of exchanges required resulting in less traffic.

\item {} 
Improved performance. Because subsequent requests do not need to
setup and tear down a TCP connection, requests arrive faster and
responses are returned quicker. TCP has built-in mechanisms, for
example window sizing, to address network congestion. Persistent
connections give TCP the time to adjust itself appropriately to
current network conditions, thus improving overall performance.
Non-persistent connections are not able to adjust because they are
open and almost immediately closed.

\item {} 
Less server overhead. Servers are able to increase the number of
concurrent users served because each user requires fewer connections
through which to complete requests.

\end{itemize}

\sphinxstylestrong{Persistence}

Persistence, on the other hand, is related to the ability of a
load-balancer or other traffic management solution to maintain a virtual
connection between a client and a specific server.

Persistence was often referred to in the application delivery networking
world as “stickiness” while in the web and application server demesne it
is called “server affinity”. Persistence ensures that once a client has
made a connection to a specific server that subsequent requests are sent
to the same server. This is very important to maintain state and
session-specific information in some application architectures and for
handling of SSL- enabled applications. When the first request is seen
by the load-balancer it chooses a server. On subsequent requests the
load balancer will automatically choose the same server to ensure
continuity of the application or, in the case of SSL, to avoid the
compute intensive process of renegotiation. This persistence is often
implemented using cookies but can be based on other identifying
attributes such as IP address. Load-balancers that have evolved into
application delivery controllers are capable of implementing persistence
based on any piece of data in the application message (payload),
headers, or at in the transport protocol (TCP) and network protocol (IP)
layers.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Some advantages of persistence are:
\begin{itemize}
\item {} 
Avoid renegotiation of SSL. By ensuring that SSL enabled connections
are directed to the same server throughout a session, it is possible
to avoid renegotiating the keys associated with the session, which is
compute and resource intensive. This improves performance and reduces
overhead on servers.

\item {} 
No need to rewrite applications. Applications developed without load
balancing in mind may break when deployed in a load-balanced
architecture because they depend on session data that is stored only
on the original server on which the session was initiated.
Load-balancers capable of session persistence ensure that those
applications do not break by always directing requests to the same
server, preserving the session data without requiring that
applications be rewritten.

\end{itemize}

\sphinxstylestrong{Summary}

So persistent connections are connections that are kept open so they can
be reused to send multiple requests, while persistence is the process of
ensuring that connections and subsequent requests are sent to the same
server through a load-balancer or other proxy device.

Both are important facets of communication between clients, servers, and
mediators like load-balancers, and increase the overall performance and
efficiency of the infrastructure as well as improving the end-user
experience.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.02 Differentiate between a client and server}
\label{\detokenize{class1/modules/module3:objective-3-02-differentiate-between-a-client-and-server}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Given a scenario, identify the client/server}

\sphinxhref{http://www.differencebetween.com/difference-between-client-and-server-systems/}{Link to Online Topic Content}

\sphinxstylestrong{Differences between Server and Client}

Computers are needed in businesses of different sizes. Large computer
setups that include networks and mainframes are used in large
businesses. A computer network used in these types of businesses has a
client- server architecture or two-tier architecture. The main purpose
of this architecture is the division of labor, which is required in
large organizations.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Explain the role of a client}

\sphinxhref{http://www.differencebetween.com/difference-between-client-and-server-systems/}{Link to Online Topic Content}

\sphinxstylestrong{Client}

In client- server architecture, the client acts a smaller computer that
is used by the employees of the organization in order to perform their
day-to-day activities. The employee uses the client computer in order to
access the data files or applications stored on the server machine.

The rights authorized to the client machine can be different. Some
employees have the access to data files of the organization while other
may only access the applications present on the server.

Apart from using the applications and data files, the client machine can
also utilize the processing power of the server. In this case, the
client computer is plugged-in to the server and the server machine
handles all the calculations. In this way, the large processing power of
the server can be utilized without any addition of hardware on the
client side.

The best example of client- server architecture is WWW or World Wide
Web. Here the client is the browser installed on each computer and the
information about different pages is stored on the server side from
which the client or the user can access it.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Explain the role of a server}

\sphinxhref{http://www.differencebetween.com/difference-between-client-and-server-systems/}{Link to Online Topic Content}

\sphinxstylestrong{Server}

In client-server environment, the server computer acts as the “brains”
of the business. A very large capacity computer is used as a server.
There can be a mainframe also as it stores a wide variety of
functionalities and data.

Generally, applications and data files are stored on the server
computer. Employee computers or workstations access these applications
and files across the network. For example, an employee can access
company’s data files stored on the server, from his/her client computer.

In some cases, employees may access only specific applications from
their client machine. Application server is the name given to this type
of server. The client-server architecture is fully utilized in this type
of environment as employees have to login from their client machine in
order to access the application stored on the server. For example, these
kinds of applications include graphic design programs, spreadsheets and
word processors. The client- server architecture is illustrated in each
case.

Apart from the storage medium, the server also acts as a processing
power source. The client machines get their processing power from this
server source. By doing so, no extra hardware for the client is needed
and it utilizes greater processing power of the server.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|}
\hline

Difference between client and server
• Client is a smaller computer through which the user accesses the information or application stored on the server whereas server is a powerful computer that stores the data files and applications.
• In some cases, the client may utilize the greater processing power of the server machine.
• In some cases, the client side may have a better graphical user interface or GUI as compared to the server side.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 4 - Security}
\label{\detokenize{class1/modules/module4:section-4-security}}\label{\detokenize{class1/modules/module4::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.01 Compare and contrast positive and negative security models}
\label{\detokenize{class1/modules/module4:objective-4-01-compare-and-contrast-positive-and-negative-security-models}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Describe the concept of a positive security model}

\sphinxhref{https://www.owasp.org/index.php/Positive\_security\_model}{Link to Online Topic Content}

\sphinxstylestrong{Positive Security Model}

A “positive” security model (also known as “whitelist”) is one that
defines what is allowed, and rejects everything else.

The positive security model can be applied to a number of different
application security areas. For example, when performing input
validation, the positive model dictates that you should specify the
characteristics of input that will be allowed, as opposed to trying to
filter out bad input. In the access control area, the positive model is
to deny access to everything, and only allow access to specific
authorized resources or functions. If you’ve ever had to deal with a
network firewall, then you’ve probably encountered this application of
the positive model.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Describe the concept of a negative security model}

\sphinxhref{http://www.xiom.com/waf-negative-model}{Link to Online Topic Content}

\sphinxstylestrong{Negative Security Model}

A “negative” (or “blacklist”) security model is one that defines what is
disallowed, while implicitly allowing everything else.

A negative security model (or misuse based detection) is based on a set
of rules that detect attacks rather than allow only valid traffic.

A negative security model is very common to Intrusion Detection and
Prevention systems (IDPS). Therefore it is very important to understand
what the differences are between the negative security model provided by
an IDPS and the negative security model provided by a WAF.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Describe the benefits of a positive security model}

\sphinxstylestrong{Benefits of a Positive Security Model}

The benefit of using a positive model is that 0-day attacks, will be
prevented as well as developer related shortcomings. However, the
positive model is susceptible to false positives in that if you don’t
account for everything that the application needs to function in the
policy you will block it. Also if the application changes you will need
to build a new custom policy to match the new changes.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Describe the benefits of a negative security model}

\sphinxstylestrong{Benefits of a Negative Security Model}

The benefit of a negative security model is that it can be deployed
rapidly. You do not have to worry with building a complicated policy
that has to deal with every transactional function of the application.
You are simply blocking any known bad attacks that could happen. You are
vulnerable to 0-day attacks of which the pattern of the attack is not
already known.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Security (Non-Blueprint)}

\sphinxhref{https://f5.com/resources/white-papers/applied-application-security-positive-and-negative}{Link to Online Topic Content}

\sphinxstylestrong{Positive \& Negative Security model}

After many years of purely negative security provided by anti-virus
scanners, IDS/IPS, and antispam engines, it’s refreshing to hear that
the positive security model—the basis for tried and true security
devices like network firewalls and ACLs—is coming back in vogue. Most
recently, this positive policy re-emergence has revolved around the Web
Application Firewall (WAF) and application security market. Yet with the
positive security positioning comeback carries with it a very
interesting point of detail: although many in the WAF space argue that
the positive model is preferable, nearly all application security
providers still rely on a partially negative solution. While
acknowledging that a positive security model is the preferable model to
secure web applications, many practitioners and vendors advocate a
bilateral approach of both positive and negative security.

As the application security market continues to evolve and define
itself, there continues to be diverging views on which security
methodology is the best option. In reality, enterprise security
decisions are highly dependent on many factors, most of which are more
business than technology oriented. Implementing an application security
solution that is both secure and practical—while still allowing for the
fluid nature of protecting dynamic applications—requires taking the best
pieces of technology and business analysis and synthesizing them into an
effective and efficient security solution.

\sphinxstylestrong{What Does “Good” Security Cost?}

In theory, the best security is impenetrable, but practical security
does not function as a control group. In a business environment,
security is a multivariate problem. What is the performance of the
security? How easy is it to deploy? What impact will adding security
have on the cost per transaction? Is it more expensive to build an
impenetrable security system or risk covering the cost of a public
breach? The quality of the security is always questioned as well, but
it’s never the only question. Many security-related questions come from
the balance sheets, not the security engineers. Approaching security
from a technical standpoint alone does not help the business; it hurts
it.

Businesses constantly analyze their economic model to generate better
operational efficiencies and a greater return on investment; the entire
business intelligence market exists for this purpose. The driving force
behind any IT security decision is an evaluation of a situation’s
potential risks versus the investment necessary to circumvent these
risks. In the same vein, a business’ security efforts should address a
business problem; namely, to increase operational efficiencies. Security
breaches can mar this efficiency, hurting a company’s value, either in
real dollars, operational downtime, or loss of customer trust. In truth,
the motivation behind every IT decision (including security decisions)
is a business decision. This has been stated and fully advocated by
Gartner as well:

Jay Heiser, a Gartner vice president, said the fundamental problem with
a purely technical approach is that IT security professionals have no
understanding of business. Speaking at {[}the{]} Gartner IT Security Summit
in London, Heiser said businesses must now mature and appoint
individuals who understand the complexities of business, rather than the
simplicities of security.

When IT decisions become business decisions, blurring the distinction
between secure value and business value, theoretical security and
applied, or practical, security begin to separate. The theoretical
approach places security on a singular plane, untouched by other
business factors; applied security is comprised of the measure and level
of actual security safeguards and implementations needed to accomplish
business goals.

For a security product to be a functional part of a business’ IT
infrastructure, the product’s applied security must be given more
attention than the product’s theoretical security. A solution that only
strives to provide ultimate security will almost always be replaced with
a solution designed to apply “good enough” security and increase
business efficiencies than one intending to recreate Fort Knox.
Theoretical security is a checkbox criteria, applied security becomes
more of a buy-and-use criteria. Applied security exists at an
equilibrium point between total security (theoretical security) and
total functionality (no security). The choice between these two—and what
to sacrifice—is made based on the most operationally efficient method
for achieving that prescribed balance. To better evaluate the root ROI
question when dealing with security products, the next logical question
becomes “Which model, positive or negative, provides this equilibrium in
the most operationally efficient manner?

\sphinxstylestrong{Positive vs. Negative Application Security}

The two approaches to security most often mentioned in the context of
application security—positive and negative are diametrically opposed in
all of their characteristic behaviors, but they are structured very
similarly. Both positive and negative security approaches operate
according to an established set of rules. Access Control Lists (ACLs)
and signatures are two implementation examples of positive and negative
security rules, respectively.

Positive security moves away from “blocked,” end of the spectrum,
following an “allow only what I know” methodology. Every rule added to a
positive security model increases what is classified as known behavior,
and thus allowed, and decreases what is blocked, or what is unknown.
Therefore, a positive security model with nothing defined should block
everything and relax (i.e., allow broader access) as the acceptable
content contexts are defined.

At the opposite end of the spectrum, negative security moves towards
“blocked what I know is bad,” meaning it denies access based on what has
previously identified as content to be blocked, running opposite to the
known/allowed positive model. Every rule added to the negative security
policy increases the blocking behavior, thereby decreasing what is both
unknown and allowed as the policy is tightened. Therefore, a negative
security policy with nothing defined would grant access to everything,
and be tightened as exploits are discovered. Although negative security
does retain some aspect of known data, negative security knowledge comes
from a list of very specific repositories of matching patterns. As data
is passed through a negative security policy, it is evaluated against
individual known “bad” patterns. If a known pattern is matched, the data
is rejected; if the data flowing through the policy is unidentifiable,
it is allowed to pass. Negative security policies do not take into
account how the application works, they only notice what accesses the
application and if that access violates any negative security patterns.

Discussions on preferred security methods typically spawn very polarized
debates. Tried and true security engineers might ardently argue the
merits of the positive security model because it originates from the
most “secure” place—“Only allow what I know and expect.” Many business
pundits would argue that the negative model is the best as it starts in
the most “functional” place—

“Block what I know is bad and let everything unknown through.” Both
groups are correct and yet both opinions become irrelevant when
projected onto applied security, because both positive and negative
security is theoretical. Applied security falls somewhere in the middle
of the spectrum, providing a practical balance. At some point, as the
negative approach is tightened, it will take on characteristics of a
more positive model, inching towards a more complete security approach.

Likewise, as a positive security model is loosened to accommodate new
application behaviors, it will take on some aspects of a more negative
approach, such as implementing data pattern matching, to block the more
predictable attacks. As a positive policy continues to relax, it will
move closer towards complete functionality. The point at which these two
opposing concepts begin to overlap is where applied security starts to
take shape.

\noindent\sphinxincludegraphics{{1p30}.png}

This “meet in the middle” idea suggests that from an applied security
standpoint, both models are capable of achieving the same delicate
balance between “security” and “functionality.” The difference between
these models stems from where each begins and where they collide. This
can be as simple as the number of rules required to meet the end goal.

It is clear then that, from an operational efficiency standpoint, the
undiluted concepts of neither the positive nor the negative approach
intrinsically provides more efficiency than the other. In some cases,
the positive approach generates the least number of rules while in other
cases the negative approach generates the least. It would also appear
that it is the nature of the applied policy and/or the content itself,
which might determine the best approach. What then, are the qualities of
the policy or content which makes one approach more efficient over the
other?

\sphinxstylestrong{Factors of an Effective Applied Security Model}

Implementing successful application security architecture is not as easy
as deciding how much negative security and how much positive security to
mix together into a hypothetical applied security blender. By design,
application security devices have to have some level of application
knowledge, such as the type of content delivered by the application,
which is accessing any point within the application, and how to map
specific policy criteria to this information. Very specific application
awareness of this nature is essential in building an efficient applied
security policy.

\sphinxstylestrong{The Effect of Content Variability}

Within the scope of application security, Content Variability is a
measure of the content that needs to be secured and includes a number of
different component pieces: the number of objects, the number of types
of content, frequency of content change, and the nature of the content.
A site that only has five specific objects is much less variable than a
site with 500 specific objects. Within those objects, the cohesiveness
of the content type is also a factor; if all 500 objects share a common
format, they are less variable than a site with where all 500 objects
are unique. Obviously, a site that changes only once a year is much less
variable than one that changes daily. Finally, the nature of that
content—for example, whether it is dynamically generated or static is a
contributing factor. Essentially, variability is a measure of the site
complexity. The idea of Content Variability is a single measurable value
based on all of these factors. The variability of the content dictates
the amount of effort needed to achieve the prescribed applied security
from the chosen model.

\noindent\sphinxincludegraphics{{1p31}.png}

As depicted in the diagram, the higher the variability of the content,
the easier it is to define a policy using the negative security model.
As the complexity of the known content increases, it is easier to
describe what isn’t allowed rather than what is. Conversely, the
opposite effect is true of the positive model; the more variable the
site content, more effort is required to define those elements that are
allowed. For example, let us assume that we have 10 different types of
content within our site out of a possible 100 different types of content
known. Because the site exhibits little variability, or is more
cohesive, it is much easier to define the 10 allowable types of content
than to define the 90 types of restricted content; a positive model is
much more appropriate in this case.

On the other hand, if the site is less cohesive, perhaps representing of
90 of the 100 different types, it now becomes more efficient to define
the 10 restricted content types than it is to define the 90 allowed
ones; thus a negative model is more efficient. Once again, both models
are equally successful at producing a desired level of security, but the
variability of the content determines which is more efficient in a given
scenario. And as we map the concept of content variability back to
applied security, it becomes obvious that we will take the necessary
aspects from the negative security model and couple those with what is
required from the positive model.

The most successful implementation will come from a joint applied
security policy, addressing both the security and the business needs at
same time.

\sphinxstylestrong{Rule Specificity}

As the content variability affects the ability to create and maintain a
security policy, the same is true of the specificity of rules used to
build that policy. Rule Specificity conveys the level of detail of the
protection mechanism implemented for any particular rule. For example, a
rule that blocks Unicode attacks may block them from any application on
one end of the spectrum all the way to only protecting Unicode directory
traversal attacks against IIS5 on the other end. Depending upon the
specificity of a rule, many things may be allowed with a single rule
(positive security) or disallowed with a single rule (negative
security). But as is the problem with theoretical security, Rule
Specificity itself is not an exact science.

A rule that is not specific enough may block too much, creating
unnecessary false positives (blocking access that shouldn’t be blocked);
a rule that is too specific may not block enough, creating false
negatives. Content variability also impacts the efficiency of a policy
by altering the level of specificity in the rules themselves. As the
variability of the content increases, the ability to specifically
stipulate what content is or isn’t allowed becomes more time consuming.
In an ideal world, every rule would be as specific as possible for the
particular application it was designed to protect, avoiding false
positives and false negatives. Similarly, the level of rule specificity
within an application security policy can vary greatly depending on the
content variability experienced by the application.

\sphinxstylestrong{Order of Precedence}

A third factor in implementing an efficient applied security policy is
the order of precedence: defining which parts of the security policy are
enacted before other parts of the policy. This concept is often seen in
programmatic search algorithms: “match first” or “match any.” Using a
combination of negative patterns and positive policy rules with varying
degrees of specificity is bound to create many conflicts. In order to
arbitrate these conflicts an order of precedence for all rules must be
defined and followed for the policy to remain coherent. This is a
critical decision point for application security, because the policy
must decide if it should implement a more funneled approach (parsing
through the policy to weed out what doesn’t match) or if it should look
for the most restrictive implementation first. Choosing the most
specific rule may solve this order of precedence, whether it is positive
or negative, and opening up access as data moves further through the
policy.

Alternately, the order may be based on implementing a given rule set,
for example, all traffic may be pattern matched first and if there are
any positive matches, the data is rejected, regardless of which specific
pattern was matched. No matter which method is chosen, if the policy is
implemented with an incorrect order of precedence, access to the
application could be blocked by a policy that tightens first. Likewise,
a policy that applies rules too loosely may allow unintended access to
the application.

And as precedence is factored into the applied security equation,
traffic volumes must also be taken into consideration. A two percent
false positive error rate may be an acceptable metric in an applied
security policy of an application that handles 100 connections/day, but
unacceptable for a 10 million connection/day application. Regardless of
the precedence methodology used it should be well defined and easy to
follow to make a policy easy to audit and manage.

\sphinxstylestrong{Conclusion - Best Practices}

The problem with a purely positive policy is simply that it’s merely the
most appropriate model for about half of the situations in which it’s
deployed. The other half are unnecessarily weighed down by the fact that
a negative model would be much more efficient. That is why, as a matter
of best practice, every security solution should support a weighted
balance of both the positive and negative methodologies. In the
strictest sense of the term, negative security provides the best applied
security out of the box due to the effort applied by the security vendor
before the product is shipped. Focusing on known security
vulnerabilities, this will block the most attacks, despite content
variability. However, this does not provide security against unknown
attacks or allow specific functions to be allowed. For that, positive
security is required. To lessen the amount of effort needed for a given
application, positive security templates should be provided by the
application vendors themselves to complement the negative security.

If the goal of applied security is to reach a pre-defined posture in the
most efficient manner, then the choice of model is directly related to
the variability of the content itself. Somewhere between total security
and total functionality is where the desired applied security level
exists, and—theoretically—either security model is capable of achieving
this goal. But as stated above, theoretical security can only exist in a
vacuum. Applied security is a business choice and concept that moves
security into real-world implementations to attain the most efficient,
functional method. Neither positive nor negative security models alone
can deliver the most economical solution in every situation or
environment. Applied together, however—and merged with the business
needs and requirements—a holistic view of both approaches can help
delineate between theoretical security and applied security, enabling
businesses to realize the greatest ROI from any security policy
implementation.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.02 Explain the purpose of cryptographic services}
\label{\detokenize{class1/modules/module4:objective-4-02-explain-the-purpose-of-cryptographic-services}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Describe the purpose of signing}

\sphinxhref{https://en.wikipedia.org/wiki/Digital\_signature}{Link to Online Topic Content}

\sphinxstylestrong{Purpose of Signing}

A digital signature is a mathematical scheme for demonstrating the
authenticity of a digital message or document. A valid digital signature
gives a recipient reason to believe that the message was created by a
known sender, that the sender cannot deny having sent the message
(authentication and non-repudiation), and that the message was not
altered in transit (integrity).

Digital signatures employ asymmetric cryptography. In many instances
they provide a layer of validation and security to messages sent through
a non-secure channel: Properly implemented, a digital signature gives
the receiver reason to believe the message was sent by the claimed
sender. Digital seals and signatures are equivalent to handwritten
signatures and stamped seals. Digital signatures are equivalent to
traditional handwritten signatures in many respects, but properly
implemented digital signatures are more difficult to forge than the
handwritten type. Digital signature schemes, in the sense used here, are
cryptographically based, and must be implemented properly to be
effective. Digital signatures can also provide non-repudiation, meaning
that the signer cannot successfully claim they did not sign a message,
while also claiming their private key remains secret; further, some
non-repudiation schemes offer a time stamp for the digital signature, so
that even if the private key is exposed, the signature is valid.
Digitally signed messages may be anything representable as a bitstring:
examples include electronic mail, contracts, or a message sent via some
other cryptographic protocol.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Describe the purpose of encryption}

\sphinxhref{http://www.garykessler.net/library/crypto.html\#purpose}{Link to Online Topic Content}

\sphinxstylestrong{Topic}

In data and telecommunications, cryptography is necessary when
communicating over any untrusted medium, which includes just about any
network, particularly the Internet.

Within the context of any application-to-application communication,
there are some specific security requirements, including:
\begin{itemize}
\item {} 
Authentication: The process of proving one’s identity. (The primary
forms of host-to-host authentication on the Internet today are
name-based or address-based, both of which are notoriously weak.)

\item {} 
Privacy/confidentiality: Ensuring that no one can read the message
except the intended receiver.

\item {} 
Integrity: Assuring the receiver that the received message has not
been altered in any way from the original.

\item {} 
Non-repudiation: A mechanism to prove that the sender really sent
this message.

\end{itemize}

Cryptography, then, not only protects data from theft or alteration, but
can also be used for user authentication. There are, in general, three
types of cryptographic schemes typically used to accomplish these goals:
secret key (or symmetric) cryptography, public-key (or asymmetric)
cryptography, and hash functions, each of which is described below. In
all cases, the initial unencrypted data is referred to as plaintext. It
is encrypted into ciphertext, which will in turn (usually) be decrypted
into usable plaintext.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Describe the purpose of certificates and the certificate
chains}

\sphinxhref{http://www.entrust.com/chain-certificates/}{Link to Online Topic Content}

\sphinxstylestrong{Certificates and Certificate Chains}

It all starts with something called a root certificate. The root
certificate is generated by a certification authority (CA) and is
embedded into software applications. You will find root certificates in
Microsoft Windows, Mozilla Firefox, Mac OS X, Adobe Reader, etc. The
purpose of the root certificate is to establish a digital chain of
trust. The root is the trust anchor.

The presumption is that the application developer has pre-screened the
CA, ensured it meets a minimum level of trust and has accepted the CA’s
root certificate for use. Many application developers, including Adobe,
Apple, Mozilla, Microsoft, Opera and Oracle, have root certificate
programs. Others rely on the roots provided by the underlying operating
system or developer toolkit.

One of the main functions of the root is to issue chain certificates to
issuing CAs who are the first link in the chain of trust. Your Web
browser will inherently trust all certificates that have been signed by
any root that has been embedded in the browser itself or in an operating
system on which it relies.

Why do you need an issuing CA? The purpose of the issuing CA is to
isolate certificate policy from the root. Issuing CAs can be used to
issue many different certificate types: SSL, EV SSL, Code Signing,
Secure Email, Adobe CDS, etc. These certificate types are subjected to
different requirements and risks, and as such have different certificate
policies. The certificates may have different assurance levels such as
high, medium and low. Issuing CAs may also be controlled by an
organization other than that which controls the root.

The last link of trust is that between the end entity certificate and
the issuing CA. In the case of an SSL certificate, the end entity
certificate represents the linkage between a website owner and the
website domain name. The SSL certificate is installed on the Web server
along with the chain certificate. When a user browses to the website
protected by the SSL certificate, the browser initiates the verification
of the certificate and follows the chain of trust back to the embedded
root.

In some cases, the CA may have chosen to issue end entity certificates
directly from the root CA. This is an outdated practice; issuing
directly from the root increases risk and limits how certificate policy
can be managed and enforced.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Distinguish between private/public keys}

\sphinxhref{http://www.tldp.org/REF/INTRO/SecuringData-INTRO/encryption.html}{Link to Online Topic Content}

\sphinxstylestrong{Private Key Encryption}

Private key encryption is the standard form. Both parties share an
encryption key, and the encryption key is also the one used to decrypt
the message. The difficulty is sharing the key before you start
encrypting the message - how do you safely transmit it?

Many private key encryption methods use public key encryption to
transmit the private key for each data transfer session.

If Bob and Alice want to use private key encryption to share a secret
message, they would each use a copy of the same key. Bob writes his
message to Alice and uses their shared private key to encrypt the
message. The message is then sent to Alice. Alice uses her copy of the
private key to decrypt the message. Private key encryption is like
making copies of a key. Anyone with a copy can open the lock. In the
case of Bob and Alice, their keys would be guarded closely because they
can both encrypt and decrypt messages.

\sphinxstylestrong{Public Key Encryption}

Public key encryption uses two keys - one to encrypt, and one to
decrypt. The sender asks the receiver for the encryption key, encrypts
the message, and sends the encrypted message to the receiver. Only the
receiver can then decrypt the message - even the sender cannot read the
encrypted message.

When Bob wants to share a secret with Alice using public key encryption,
he first asks Alice for her public key. Next, Bob uses Alice’s public
key to encrypt the message. In public key encryption, only Alice’s
private key can unlock the message encrypted with her public key. Bob
sends his message to Alice. Alice uses her private key to decrypt Bob’s
message.

The thing that makes public key encryption work is that Alice very
closely guards her private key and freely distributes her public key.
She knows that it will unlock any message encrypted with her public key.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Compare and contrast symmetric/asymmetric encryption}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Symmetric Encryption}

This system uses only private keys, which can be anything from a
numerical symbol to a string of random letters. These private keys are
used to encode a message, so that only the sender and the recipient of
the message who know what the secret key is can “unlock” it and decrypt
it. The system works pretty much like two best friends using a decoder
ring to send secret messages to each other. The symmetric system’s only
downside is the potentially unsafe private key transmission via the
Internet, where other people can “crack” it and decode the message.

\sphinxstylestrong{Asymmetric Encryption}

As a solution for the not completely safe Symmetric Encryption, there is
the Asymmetric Encryption system that uses a pair of keys for added
security: a private and a public key. The private key is for yourself
and the public key is published online for others to see.

The public key is used to access the encryption code that corresponds to
your private key. So, if you were sending an encrypted message to Susan,
which you do not want others to see, you would use her public key to
encrypt it. She will be able to decrypt it with her own corresponding
private key. Likewise, if she sends a message to you, she uses your
public key to encrypt the message and you would use your private key to
decrypt it.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.03 Describe the purpose and advantages of authentication}
\label{\detokenize{class1/modules/module4:objective-4-03-describe-the-purpose-and-advantages-of-authentication}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Explain the purpose of authentication}

\sphinxhref{http://www.authenticationworld.com}{Link to Online Topic Content}

\sphinxstylestrong{What Is Authentication?}

Authentication is the process of determining if a user or identity is
who they claim to be. Authentication is accomplished using something the
user knows (e.g. password), something the user has (e.g. security token)
or something of the user (e.g. biometric).

The authentication process is based on a measure of risk. High risk
systems, applications and information require different forms of
authentication that more accurately confirm the user’s digital identity
as being who they claim to be than would a low risk application, where
the confirmation of the digital identity is not as important from a risk
perspective. This is commonly referred to as “stronger authentication”.

Authentication processes are dependent upon identity verification and
registration processes. For example, when Jane Doe is hired at an
enterprise, she provides the enterprise with information and tokens of
who she is (e.g. name, address, driver’s license, birth certificate, a
SSN number, a passport, etc.). The enterprise may choose to immediately
accept this information or, it may instead chose to run background
checks on Jane to see if she is who she claims to be and determine if
she has any criminal record. When the checks come back favorably, the
enterprise will accept her identity and enter her into their systems.
The identity registration process will usually involve issuing Jane with
enterprise authentication mechanisms such as id and password, security
token, digital certificate and/or registering some of her biometrics.

The authentication process is totally dependents on the identity
validation and registration process used for Jane. If Jane presents
false tokens, which are accepted by the enterprise, then the person
acting as Jane will be positively authenticated every time, even though
she is not the real Jane Doe. Authentication security therefore is only
as good as the weakest link in the chain.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Explain the advantages of single sign on}

\sphinxhref{http://www.authenticationworld.com}{Link to Online Topic Content}

\sphinxstylestrong{Password Authentication}

Password authentication is the most common method of authentication. It
is also the least secure. Password authentication requires the identity
to input a user id and a password in order to login. Password length,
type of characters used and password duration are password management is
now critical concern in enterprises. The ability to easily crack
passwords has resulted in high levels of identity theft. As a result,
the high risk of passwords means most enterprises now deploy a layered
security strategy. A user enters in their id and password for initial
login to gain access to only low risk information and applications with
other forms of authentication required for higher risk information and
applications.

\sphinxstylestrong{Single Sign On Authentication}

Single Sign On (SSO), Reduced Sign On (RSO), or Enterprise Single Sign
On (ESSO) is the ability to reduce the number of id’s and passwords a
user has to remember. In most enterprises, a strong business case can be
made to implement single sign on by reducing the number of password
related help desk calls. SSO is also the architecture to require
stronger forms of authentication for higher risk information and
applications. Thus a user may login using their id and password to gain
general low risk access to an enterprise. The SSO software enables them
to not have to use multiple IDs and passwords. However, when the user
tries to access more sensitive information and applications, the single
sign on software will require the identity to input stronger
authentication such as a security token, a digital certificate and/or a
biometric.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Explain the concepts of multifactor authentication}

\sphinxhref{http://searchsecurity.techtarget.com/definition/multifactor-authentication-MFA}{Link to Online Topic Content}

\sphinxstylestrong{Multi-factor Authentication}

Multifactor authentication (MFA) is a security system in which more than
one form of authentication is implemented to verify the legitimacy of a
transaction. The goal of MFA is to create a layered defense and make it
more difficult for an unauthorized person to access a computer system or
network.

Multifactor authentication is achieved by combining two or three
independent credentials: what the user knows (knowledge-based
authentication), what the user has (security token or smart card) and
what the user is (biometric verification). Single-factor authentication
(SFA), in contrast, only requires knowledge the user possesses. Although
password-based authentication is well suited for website or application
access, it is not secure enough for online financial transactions.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Describe the role authentication plays in AAA}

\sphinxhref{http://searchsecurity.techtarget.com/definition/authentication-authorization-and-accounting}{Link to Online Topic Content}

\sphinxstylestrong{Authentication, Authorization, and Accounting (AAA)}

Authentication, authorization, and accounting (AAA) is a term for a
framework for intelligently controlling access to computer resources,
enforcing policies, auditing usage, and providing the information
necessary to bill for services. These combined processes are considered
important for effective network management and security.

As the first process, authentication provides a way of identifying a
user, typically by having the user enter a valid user name and valid
password before access is granted. The process of authentication is
based on each user having a unique set of criteria for gaining access.
The AAA server compares a user’s authentication credentials with other
user credentials stored in a database. If the credentials match, the
user is granted access to the network. If the credentials are at
variance, authentication fails and network access is denied.

Following authentication, a user must gain authorization for doing
certain tasks. After logging into a system, for instance, the user may
try to issue commands. The authorization process determines whether the
user has the authority to issue such commands. Simply put, authorization
is the process of enforcing policies: determining what types or
qualities of activities, resources, or services a user is permitted.
Usually, authorization occurs within the context of authentication. Once
you have authenticated a user, they may be authorized for different
types of access or activity.

The final plank in the AAA framework is accounting, which measures the
resources a user consumes during access. This can include the amount of
system time or the amount of data a user has sent and/or received during
a session. Accounting is carried out by logging of session statistics
and usage information and is used for authorization control, billing,
trend analysis, resource utilization, and capacity planning activities.

Authentication, authorization, and accounting services are often
provided by a dedicated AAA server, or a program that performs these
functions. A current standard by which network access servers interface
with the AAA server is the Remote Authentication Dial-In User Service
(RADIUS).


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - SAML Authentication Not on Blueprint}

\sphinxhref{https://www.skydesk.jp/en/help/portal/saml/SAML-Authentication.html}{Link to Online Topic Content}

\sphinxstylestrong{SAML Authentication - What is SAML?}

\sphinxstylestrong{SAML - Security Assertion Markup Language}

SAML, developed by the Security Services Technical Committee of
“Organization for the Advancement of Structured Information Standards”
(OASIS), is an XML-based framework for exchanging user authentication,
entitlement, and attribute information. SAML is a derivative of XML. The
purpose of SAML is to enable Single Sign-On for web applications across
various domains.

\sphinxstylestrong{Why SAML?}

There are four ‘drivers’ behind the creation of the SAML standard:

Limitations of Browser cookies: Most existing Single-Sign On products
use browser cookies to maintain state so that re-authentication is not
required. Browser cookies are not transferred between DNS domains. So,
if you obtain a cookie from www.abc.com, then that cookie will not be
sent in any HTTP messages to www.xyz.com. This could even apply within
an organization that has separate DNS domains. Therefore, to solve the
Cross-Domain SSO (CDSSO) problem requires the application of different
technology. All SSO products solve the CDSSO problem by different
techniques.

SSO Interoperability: How products implement SSO and CDSSO are
completely proprietary. If you have an organization and you want to
perform SSO across different DNS domains within the same organization or
you want to perform CDSSO to trading partners, then you will have to use
the same SSO product in all the domains.

Web Services: Security within Web Services is still being defined. Most
of the focus has been on how to provide confidentiality and
authentication/integrity services on an end-to-end basis. The SAML
standard provides the means by which authentication and authorization
assertions can exchanged between communicating parties.

Federation: The need to simplify identity management across
organizational boundaries, allowing users to consolidate many local
identities into a single (or at least a reduced set).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.04 Describe the purpose, advantages, and use cases of IPsec and SSL VPN}
\label{\detokenize{class1/modules/module4:objective-4-04-describe-the-purpose-advantages-and-use-cases-of-ipsec-and-ssl-vpn}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.04 - Explain the purpose, advantages, and challenges associated with IPsec}

\sphinxhref{https://en.wikipedia.org/wiki/IPsec}{Link to Online Topic Content}

\sphinxstylestrong{IPsec - IP Security}

Internet Protocol Security (IPsec) is a protocol suite for securing
Internet Protocol (IP) communications by authenticating and encrypting
each IP packet of a communication session. IPsec includes protocols for
establishing mutual authentication between agents at the beginning of
the session and negotiation of cryptographic keys to be used during the
session. IPsec can be used in protecting data flows between a pair of
hosts (host-to-host), between a pair of security gateways
(network-to-network), or between a security gateway and a host
(network-to-host).

Internet Protocol security (IPsec) uses cryptographic security services
to protect communications over Internet Protocol (IP) networks. IPsec
supports network-level peer authentication, data origin authentication,
data integrity, data confidentiality (encryption), and replay
protection.

IPsec is an end-to-end security scheme operating in the Internet Layer
of the Internet Protocol Suite, while some other Internet security
systems in widespread use, such as Transport Layer Security (TLS) and
Secure Shell (SSH), operate in the upper layers at Application layer.
Hence, only IPsec protects any application traffic over an IP network.
IPsec can automatically secure applications at the IP layer.point
environments.


\bigskip\hrule\bigskip


\sphinxhref{https://www.sonicwall.com/downloads/WP\_SSLVPN\_vs\_IPSec\_102907.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Why should you use IPsec?}

IPSec VPNs are best suited for point-to-point access. Open tunneling
protects data between two private networks or between IT-managed
machines and a private network. IPSec is a perfectly viable solution
when a permanent connection is required between two specific locations,
for example between a branch or remote office and a corporate
headquarters. It can also be used successfully to provide access to a
small finite number of remote workers using tightly controlled
corporate-issued laptops.

Many existing IPSec implementations can continue to work well for these
use cases for which they were originally deployed. IT might consider
keeping IPSec in these limited areas and extend remote access to other
areas, such as trusted partners or extranet users, via a parallel SSL
VPN solution. While a parallel VPN implementation is a viable choice for
some enterprises, transitioning all access use cases through a single
SSL VPN gateway might ultimately cost less and be easier to manage.

While many organizations still implement IPSec solutions today, however,
for secure remote access the momentum has clearly shifted to SSL VPNs.
Some organizations replace older versions of IPSec with newer versions
that better streamline the provisioning of agents, or provide elements
of end point control.

Nevertheless, these augmented IPSec VPNs still may not be as flexible or
robust as SSL VPN solutions.

With increased access from unmanaged end point devices, end point
control becomes a key risk factor. For managed devices, some IPSec
solution providers suggest keeping IPSec and adding a network access
control (NAC) solution. However, this greatly adds to the costs and
complexity of administering and maintaining a separate appliance to
achieve end point control, and still does not provide granular access
controls down to the application layer, essentially allowing the remote
device to be a node on the network.

\sphinxstylestrong{Replacing IPsec}

The ascendancy of IPSec technology as an innovative remote access
solution peaked nearly a decade ago. IPSec VPNs are no longer an
effective remote access solution when comparing costs of IT overhead and
the desire for granular access controls for highly portal devices with
the current demands of an increasingly mobile workforce. With early
IPSec implementations, the considerable overhead involved in
provisioning, maintaining and supporting dedicated IPSec clients was
tolerated because IPSec access tended to be restricted only to
relatively few managed-device use cases. In recent years, however, since
broadband has become widespread and laptops have become cheaper, there
has been greater incentive for IT to deploy more laptops and other
mobile devices to more users across the enterprise, increasing the
overhead needed to support distributed-client IPSec VPNs. While these
devices are more likely to be transported beyond the physical office to
be used at home or other remote sites, IPSec still views them as nodes
on the network, regardless of location.

Workers are also now accessing corporate resources from more end point
devices that are not directly managed by IT, such as home computers,
WiFi-enabled laptops, PDAs, smartphones and public kiosks.

While most workers today are not full-time teleworkers, many commonly
perform teleworking functions, such as sending and receiving e-mail and
attachments from home before or after work hours, on weekends, while on
the road or while on vacation. In addition, business partners need
limited access to specific network resources, which introduces
additional remote access challenges to the IT department in today’s
world of outsourced supply chains. By providing employees and business
partners with wider access to business tools and information, the
proliferation of unmanaged end point devices has directly resulted in
increased productivity. But it has also greatly increased the complexity
for IT in controlling remote access, thereby minimizing the viability of
distributed-client IPSec VPNs as an efficient remote access solution.

\sphinxstyleemphasis{But still IPsec tunnels are still commonly used in site-to-site communications.}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.04 - Explain the purpose, advantages, and challenges associated with SSL VPN}

\sphinxhref{https://www.sonicwall.com/downloads/WP\_SSLVPN\_vs\_IPSec\_102907.pdf}{Link to Online Topic Content}

\sphinxstylestrong{SSL VPN}

SSL is the standard protocol for managing the security of message
transmission on the Internet. SSL is a higher-layer security protocol
than IPSec, working at the application layer rather than at the network
layer. By operating at the application layer, SSL can provide the highly
granular policy and access control required for secure remote access.
Because SSL is included in all modern browsers, SSL VPNs can empower
today’s mobile workforce with clientless remote access—while saving IT
departments the headache of installing and managing the complexity of
IPSec clients. By extending the workplace to home PCs, kiosks,

SSL VPN solutions increase workforce productivity, for users with PDAs,
and other unmanaged devices, resulting in a greater return on
investment. And by eliminating the need to deploy and support “fat”
clients, SSL VPN reduces IT overhead, resulting in a lower total cost of
ownership.

An SSL VPN uses SSL to provide end users with authorized and secure
access for Web, client/server and file share resources. SSL VPNs deliver
user-level authentication, ensuring that only authorized users have
access to the specific resources allowed by the company’s security
policy. SSL VPNs start with providing access via a Web browser, removing
the need for IT to provision clients to the end point device. For
advanced access, agents may be required but SSL VPNs allow IT to have
agents provisioned and activated within the context of the Web browser
where Active X or Java based “thin” clients are transparently pushed
through the browser, Alternatively, most SSL VPNs allow IT to
pre-provision the agents directly to a user’s device, allowing the user
to directly access the SSL VPN without having to open a Web browser.

Potential Benefits of Transitioning to an SSL VPN:
\begin{itemize}
\item {} 
Increased productivity: SSL VPNs work in more places, including home
PCs, kiosks, PDAs and unmanaged devices over wired and wireless
networks.

\item {} 
Lower costs: SSL VPNs are clientless or use lightweight Web-delivered
clients rather than “fat” IPSec clients, reducing management and
support calls.

\item {} 
Broadened security: SSL VPNs provide granular access and end point
control to managed and non-managed devices

\end{itemize}

\sphinxstylestrong{Why you should transition to SSL VPN}

Today’s modern mobile workforce demands more secure access to more
resources from more remote devices and platforms than ever before.
Corporate boundaries are blurring, with partners, vendors and
consultants playing as vital a role in daily operations as employees do.
These changes suggest the need for an inverted model for the corporate
network, evolving from the traditional enclosed-perimeter model to a
distributed global network that connects employees, partners and
customers over multiple Internet, intranet and VoIP channels. IT
managers must now assume that any user and device is a potential risk
point, whether the user is accessing remotely or plugged directly into
the LAN. Disaster recovery and business continuity initiatives pose
additional incentive to provide remote access from any end point
location. Policy based granular access control becomes imperative.

Securing inverted networks with granular access control is an ideal use
case for SSL VPN technology. SSL based access control appliances are the
key to achieving application access control. SSL VPN solutions can
detect what is running on the end point device, protect applications
with granular access control based on user identity and device integrity
and connect users securely and easily to applications on any device.

Because SSL is part of any Web browser, SSL VPN solutions provide
clientless and Web-delivered thin client access that significantly
increases the number of points from which employees, partners and
customers can access network data. SSL VPN solutions greatly simplify
the connection process for mobile 7 users, seamlessly traversing NAT,
firewalls and proxy servers. SSL VPN solutions reduce IT support costs,
lowering total cost of ownership. SSL VPN clientless access minimizes
the IT overhead involved in provisioning, configuring and maintaining an
enterprise remote access solution. Alternatively, certain SSL

VPN tunnel solutions provide a complete “in-office” experience by
deploying an auto-updating, Web delivered thin client, eliminating the
need for direct IT intervention. SSL VPN solutions also streamline
administration costs by controlling all access to enterprise resources
via a single, centralized gateway.

SSL VPN solutions also provide greater security compared to IPSec. Since
SSL is an application layer protocol, an SSL VPN is inherently better
suited for securing application-based remote access. SSL VPN solutions
provide secure, granular access controls, ensuring that users gain
access only to the designated resources or applications specific to
their needs and according to security policy.

With SSL VPN solutions, end-user access to any given resource is
restricted unless authorized. As a result, SSL VPN technology provides
the granular access control that requires all users, regardless of
location, to be granted explicit permission to access specific network
resources. With SSL VPN technology, access control to applications and
networks can be as general or specific as required to meet regulatory
compliance and corporate security mandates.

\noindent\sphinxincludegraphics{{1p32}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.04 - Given a list of environments/situations, determine which is
appropriate for an IPsec solution and which is appropriate for an SSL
VPN solution}

\sphinxstylestrong{SSL VPN vs IPSec}

When presented with scenario-based questions on which solution is more
appropriate IPSec or SSL VPN. Just remember that SSL VPN is the best
solution for remote users to access business resources remotely and
IPSec is the best solution for tunneling traffic between two business
locations.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 5 - Application Delivery Platforms}
\label{\detokenize{class1/modules/module5:section-5-application-delivery-platforms}}\label{\detokenize{class1/modules/module5::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.01 Describe the purpose, advantages, use cases, and challenges associated with hardware based application delivery platforms and virtual machines}
\label{\detokenize{class1/modules/module5:objective-5-01-describe-the-purpose-advantages-use-cases-and-challenges-associated-with-hardware-based-application-delivery-platforms-and-virtual-machines}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Explain when a hardware based application deliver platform
solution is appropriate and when a virtual machine solution is
appropriate}

\sphinxstylestrong{Hardware vs. Software}

Different situations call for the BIG-IP Virtual Edition and the
physical BIG-IP hardware.

The Virtual Edition should be used for discrete workloads on commodity
hardware. It also provides flexible and quick deployment options and
failure isolation. Virtual Editions can also give you the flexibility to
run in proprietary computing environments like Amazon Web Services (AWS)
and other public cloud offerings.

Physical hardware provides a number of important benefits and is
necessary in many situations. F5 hardware is purposefully built to
provide high performance for application delivery. Using an F5 physical
platform also offers a single-vendor solution. If a customer is running
an F5 Virtual Edition on an HP server and an issue arises,
troubleshooting between vendors is more difficult. When F5 hardware runs
F5 software, this is avoided.

Additionally, a BIG-IP physical device can run all BIG-IP modules and
perform hardware SSL offload and compression. It provides customers with
all other features that may be important to their deployment, such as
always-on management, certifications, special-purpose FPGAs, and
improved security.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Explain the purpose, advantages, and challenges associated with
hardware based application deliver platform solutions}

\sphinxhref{http://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Hardware}

BIG-IP ADC appliances can help you simplify your network by offloading
servers and consolidating devices, saving management costs as well as
power, space, and cooling in the data center.

With the massive performance and scalability of the BIG-IP platform, you
can reduce the number of Application Delivery Controllers you need to
deliver even the most demanding applications. By offloading
computationally intense processes, you can significantly reduce the
number of application servers needed.

BIG-IP hardware includes:
\begin{itemize}
\item {} 
SSL hardware acceleration—Offload costly SSL processing and
accelerate key exchange and bulk encryption with best-in-market SSL
performance.

\item {} 
Hardware compression*—Cost-effectively offload traffic compression
processing from your servers to improve page load times and reduce
bandwidth utilization.

\item {} 
OneConnect connection pooling—Aggregate millions of TCP requests into
hundreds of server-side connections. Increase server capacity and
ensure requests are handled efficiently.

\item {} 
Embedded Packet Velocity Acceleration (ePVA)*—Provide specific
application delivery optimizations, support for low latency and
tunneling protocols, and denial-of-service (DoS) protection. ePVA
uses field-programmable gate array (FPGA) technology tightly
integrated with TMOS and software to deliver:

\item {} 
High performance interconnects between Ethernet ports and processors.

\item {} 
L4 offload, enabling leading throughput and reduced load on software.

\item {} 
Hardware-accelerated SYN flood protection.

\item {} 
More than 65 types of DoS attacks detected and mitigated in hardware.

\item {} 
Native Financial Information eXchange (FIX) support for message
routing and tag substitution while maintaining low latency
requirements.

\end{itemize}

\sphinxstylestrong{Advantages}

The Advantages of F5 BIG-IP Technology

Unique architecture and patented hardware and software innovations from
F5 offer unmatched capabilities, including:

F5 ScaleN architecture

ScaleN enables you to scale performance on demand, virtualize, or
horizontally cluster multiple BIG-IP devices, creating an elastic
Application Delivery Networking infrastructure that can efficiently
adapt as your business needs change.
\begin{itemize}
\item {} 
On-demand scaling—Increase capacity and performance with on-demand
scaling, where you can simply add more power to your existing
infrastructure instead of adding more devices. The latest BIG-IP
appliance models can be upgraded to the higher performance model
within each series through on-demand software licensing. On- demand
licensing enables organizations to right-size application delivery
services and support growth without requiring new hardware.

\item {} 
Operational scaling—F5 can virtualize ADC services with a
multi-tenant architecture that supports a variety of BIG-IP versions
and product modules on a single device. Multi- tenant device
virtualization is provided by F5’s unique Virtual Clustered
Multiprocessing (vCMP) technology, which enables select hardware
platforms to run multiple BIG-IP guest instances. Each BIG-IP guest
instance looks and acts like a physical BIG-IP device, with a
dedicated allocation of CPU, memory, and other resources.
\begin{itemize}
\item {} 
You can further divide each vCMP guest using multi-tenant features such as partitions and route domains, which can isolate configuration and networks on a per-virtual-domain basis. Within each virtual domain, you can further isolate and secure configuration and policies by using a role-based access system for greater administrative control. When combining both route domains/partitions with vCMP guests, F5 provides the highest density multi-tenant virtualization solution that can scale to thousands of virtual ADC (vADC) instances.

\item {} 
This ability to virtualize BIG-IP ADC services means service providers and enterprise users can isolate based on BIG-IP version, enabling departmental or project-based tenancy as well as performance guarantees, while benefiting from managing a single, consolidated application delivery platform and increased utilization.

\end{itemize}

\item {} 
Application scaling—Increase capacity by adding BIG-IP resources
through an all-active approach. With application scaling, you can
scale beyond the traditional device pair to eliminate the need for
idle and costly standby resources. Application scaling achieves this
through two forms of horizontal scale: Application Service
Clustering, which focuses on application scalability and high
availability, and Device Service Clustering, designed to efficiently
and seamlessly scale BIG-IP application delivery services.
\begin{itemize}
\item {} 
Application Service Clustering delivers sub-second failover and comprehensive connection mirroring for a highly available cluster of up to eight devices at the application layer, providing highly available multi-tenant deployments. Workloads can be moved across a cluster of devices or virtual instances without interrupting other services and can be scaled to meet the business demand.

\item {} 
Device Service Clustering can synchronize full device configurations in an all-active deployment model, enabling consistent policy deployment and enforcement across devices—up to 32 active nodes. This ensures a consistent device configuration that simplifies operations.

\end{itemize}

\end{itemize}

\sphinxstylestrong{Challenges}

Some of the only challenges with hardware are that it can take longer to
acquire for implementations, which can add to time lines in projects,
and some public cloud environments do not let you run your own hardware,
since it is a strictly virtualized environment.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Explain the purpose, advantages, and challenges associated with virtual machines}

\sphinxhref{http://www.f5.com}{Link to Online Topic Content}

\sphinxstylestrong{Virtual Hardware}

Virtualization is critical to maintaining an adaptable network and
accomplishing the scale, consolidation, and business continuity demanded
by today’s advanced application infrastructures.

F5 BIG-IP virtual editions (VEs) are virtual application delivery
controllers (vADCs) that can be deployed on all leading hypervisors and
cloud platforms running on commodity servers. BIG-IP VEs deliver all the
same market-leading Software-Defined Application Services
(SDAS)—including advanced traffic management, acceleration, DNS,
firewall, and access management—that run on F5 purpose-built hardware.
VE software images are downloadable and portable between on-premises
virtualized data centers, public, and hybrid cloud environments. With
BIG-IP virtual editions and F5 BIG-IQ management solutions, you can
rapidly provision consistent application services across the data center
and into the cloud.

\sphinxstylestrong{Advantages}

Deploy with increased agility
\begin{itemize}
\item {} 
Quickly and easily spin up, spin down, or migrate application
delivery services in and across the data center and public cloud,
using instant deployment options as needed.

\end{itemize}

Achieve automation and orchestration in cloud architectures
\begin{itemize}
\item {} 
Automate deployment and configuration or integrate with leading
orchestration frameworks—in cloud or software-defined networking
(SDN) environments through application level templates, REST APIs,
and granular programmability.

\end{itemize}

Optimize application services more efficiently
\begin{itemize}
\item {} 
Rapidly provision and consolidate application services on your
existing servers, unlocking the broadest feature density through
flexible licensing models that align to your business needs.

\end{itemize}

Provide the ultimate in flexibility
\begin{itemize}
\item {} 
Get the most flexible deployment options in the industry, with
support across all major virtualization platforms for both private
and public cloud environments.

\end{itemize}

\sphinxstylestrong{Challenges}

Some of the only challenges with have to do with performance when
compared to what dedicated hardware can do. Throughput speeds and
volumetric processing of SSL transactions per second does not compare
with anything above a 4000 series in hardware.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Explain the advantages of dedicated hardware (SSL card,
compression card)}

The charts below tell the story of Hardware vs. Software, especially in
relation to SSL offload with hardware or software.

\sphinxhref{http://www.f5.com/pdf/products/big-ip-virtual-editions-datasheet.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Virtual Editions}

Available in a range of performance options, F5 virtual editions can be
sized and configured to suit the application services required. Maximum
performance is based on applicable VE licensed performance ranges and
resources (number of CPU cores/memory) allocated.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Performance
&\sphinxstyletheadfamily 
Starting
&\sphinxstyletheadfamily 
Maximum*
\\
\hline
L7 requests per second
&
3,000
&
450,000
\\
\hline
L4 connections per second
&
2,000
&
135,000
\\
\hline
Throughput
&
25 Mbps
&
10 Gbps**
\\
\hline
Maximum connections
&
1 million
&
10 million
\\
\hline
SSL
&&\\
\hline
Maximum SSL TPS (1K keys/2K keys)
&
900/900
&
12,000/3,550
\\
\hline
SSL throughput
&
23 Mbps
&
4 Gbps
\\
\hline
Software compression
&&\\
\hline
Maximum software compression throughput
&
20 Mbps
&
4 Gbps
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Appliance Hardware Editions}

Available in a range of performance options, F5 hardware appliances can
be sized and configured to suit the application services required.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Performance
&\sphinxstyletheadfamily 
2000s Model
&\sphinxstyletheadfamily 
12250v Model
\\
\hline
L7 requests per second
&
212,000
&
4 million
\\
\hline
L4 connections per second
&
75,000
&
1.5 million
\\
\hline
Throughput
&
5 Gbps L4/L7
&
84 Gbps/40 Gbps L4/L7
\\
\hline
Maximum connections
&
5 million
&
10 million
\\
\hline
SSL
&&\\
\hline
Maximum SSL TPS (2K keys)
&
2,000
&
240,000
\\
\hline
SSL throughput
&
4 Gbps*
&
40 Gbps*
\\
\hline
Hardware compression
&&\\
\hline
Maximum compression throughput
&
N/A
&
40 Gbps
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{http://www.f5.com/pdf/products/viprion-overview-ds.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Viprion Hardware Editions}

Available in a range of performance options, F5 hardware blades for
chassis platforms can be sized and configured to suit the application
services required.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Performance
&\sphinxstyletheadfamily 
2150 blades
&\sphinxstyletheadfamily 
4340N blades
\\
\hline
L7 requests per second
&
1 million
&
2.5 million
\\
\hline
L4 connections per second
&
400,000
&
1.4 million
\\
\hline
Throughput
&
40Gbps/18Gbps L4/L7
&
80 Gbps/40 Gbps L4/L7
\\
\hline
Maximum connections
&
24 million
&
72 million
\\
\hline
SSL
&&\\
\hline
Maximum SSL TPS (2K keys)
&
10,000
&
30,000
\\
\hline
SSL throughput
&
4 Gbps*
&
20 Gbps*
\\
\hline
Hardware compression
&&\\
\hline
Maximum compression throughput
&
10 Gbps
&
20 Gbps
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.02 Describe the purpose of the various types of advanced acceleration techniques}
\label{\detokenize{class1/modules/module5:objective-5-02-describe-the-purpose-of-the-various-types-of-advanced-acceleration-techniques}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.02 - Describe the purpose of TCP optimization}

\sphinxhref{http://www.f5.com/pdf/analyst-reports/acceleration-101-wp.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Optimizing TCP}

Although TCP is ubiquitous today, the protocol has undergone many
updates to help overcome limitations that existed in earlier versions.
An acceleration device can help optimize TCP by implementing features
that may not be present in either a client or server’s TCP
implementation.

An acceleration device can also decrease the number of server-side TCP
connections required to service client requests. Additionally, it can
help accelerate HTTP traffic by increasing the number of simultaneous
client-side TCP connections a browser can open while downloading a web
page.

\sphinxstylestrong{General TCP Optimizations}

Because it operates as a proxy, an acceleration device may be able to
implement features missing from a client or server that can help speed
application delivery. The acceleration device may be able to leverage
optimizations natively supported by particular client or server
operating systems and is likely to be able to implement optimizations
that are not operating-system specific. The benefit of high speed, high
latency WAN connections are that the acceleration device can perform TCP
window scaling to improve performance. To overcome packet loss, the
acceleration device can implement selective TCP acknowledgements (SACK)
and advanced congestion control algorithms to prevent TCP from reducing
throughput.

These are only two examples. Some acceleration devices implement
hundreds of improvements to TCP in order to help it perform better.

\sphinxstylestrong{Decreasing Server-side TCP Connections}

Reducing server-side connection processing can dramatically improve
application performance and reduce the number of servers required to
host an application. TCP connection setup and teardown requires
significant overhead, particularly for servers. As the number of open
server connections increases, maintaining the open connections while
simultaneously opening new connections can severely degrade server
performance and therefore, user response time.

Although multiple transactions (for example, file transfers) can occur
within a single TCP connection, a connection is generally between one
client and one server. Normally, a connection closes either when a
server reaches a defined transaction limit or when a client has
transferred all needed files from that server. Because an acceleration
device operates as a proxy, it can aggregate, or “pool,” TCP server-side
connections by combining many separate transactions, potentially from
many users, through fewer (or one) TCP connections. The acceleration
device opens new server-side connections only when necessary, and
instead reuses existing connections for requests from other users
whenever possible.

\sphinxstylestrong{Increasing Client-side TCP Connections}

By default, most web browsers limit the maximum number of simultaneous
HTTP/HTTPS connections that the browser can open to one URL. For
example, Microsoft Internet Explorer v7 and below limit the maximum
number of simultaneous connections to two per domain. Earlier versions
of Firefox limit the browser to eight connections per domain. Given that
a web page can contain dozens of objects, this limitation can greatly
slow page-loading times.

For example, suppose a user running Internet Explorer v7 requests a page
from a web server that returns a response containing a list of the 30
objects that make up the web page. Further assume that that all objects
are accessed through the domain, www.example.com. The browser opens two
connections to www.example.com, requests one object at a time per
connection (the limit imposed by TCP), and then reuses the two
connections until all files have been downloaded or the connection
reaches the server’s transaction limit. If the connection suffers high
latency, round trip time is high and download speed can be greatly
reduced.

If the server terminates the connection after reaching a pre-defined
transaction limit, the browser opens another connection to that URL.
This process continues until the page downloads completely. Operating
this way needlessly increases the page load time.

Some acceleration devices can “spoof” a browser by modifying the URLs in
an HTTP response to speed page downloading. The modified URLs must first
be defined in DNS to point to the same IP address. When examining the
server response, the modified names appear to the browser to be
different servers, so the web browser opens parallel connections to
these altered URLs rather than serially downloading the objects from one
URL.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.02 - Describe the purpose of HTTP Keep-alives, caching, compression, and pipelining}

\sphinxhref{http://www.f5.com/pdf/analyst-reports/acceleration-101-wp.pdf}{Link to Online Topic Content}

\sphinxstylestrong{HTTP Protocol and Web Application Optimizations}

HTTP protocol optimizations maintain high user performance levels by
optimally tuning each HTTP session. For example, some web applications
are unable to return an HTTP 304 status code (Not Modified) in response
to a client request rather than returning the entire object. Because an
acceleration device proxies connections and caches content, it may be
able to note when there is no change to a requested object and return
the 304 response instead. This enables the browser to load the content
from its own cache, even in conditions where the web application is
hard-coded to re-send the object.

Some acceleration devices can additionally examine and change server
responses to provide better browser and server performance. For example,
some off-the-shelf and custom applications add a no-cache header to some
objects, which directs a browser not to cache an object, rather to
download the object from the origin web server every time. The purpose
of the no-cache header is to ensure a browser always downloads dynamic
(changing) data.

However, applications in some cases mark static data like a company logo
as being non-cacheable. Some acceleration devices can re-write the
server response to mark the object as being cacheable and supply a more
realistic expiration date. This feature can help remedy problems with
off-the-shelf or custom-developed applications where code cannot easily
be modified.

\sphinxstylestrong{Caching}

Caching involves storing data close to users and re-using the data
during subsequent requests. Caching usually takes one of three forms.
The first is the classic approach taken by web browsers and web
applications. In this case, the web application code running on a server
instructs a browser to cache an object marked as static for a specific
time period. During that time period, the browser reads the object from
cache when building a web page until the content expires. The client
then reloads the content. Caching prevents the browser from having to
waste time and bandwidth by always accessing data from a central site.
This is the most common form of caching in use today.

The second form involves deploying an acceleration device in a data
center to offload requests for web application content from web servers.
This method operates asymmetrically, with the acceleration device
caching objects from web servers and delivering them directly to users.
Some acceleration devices cache static content only, while some
additionally can process HTTP responses, include objects referenced in a
response, and send the included objects as a single object to a browser.
This not only offloads web server processing but also offloads web
browser processing too. A side benefit to this approach is that as the
acceleration device is typically in the data center and connected to
higher-speed connections, the acceleration device can both assemble the
objects from instructions in the HTTP response and deliver them using
fewer objects and with fewer transactions.

Operating in this manner, caching can dramatically reduce server TCP and
application processing, improve web page loading time, and hence reduce
the need to regularly expand the number of web servers required to
service an application.

The third form of caching involves using symmetric acceleration devices
to cache and serve content to users at the remote site. The remote
acceleration device serves content locally whenever possible, which
reduces both response time and network utilization. This form of caching
can be deployed not only for HTTP, but also for other protocols as well.

Caching has its limitations. First, if the client-side acceleration
device serves content regardless of whether it is in contact with its
remote peer, the client side device must implement access control to
prevent unauthorized access to an object. Second, the client-side device
may serve older, stale versions of content that change after the
connection between the devices is broken. While this typically is not an
issue with static web content, it can have significant impact on files
that regularly change. When both issues are addressed, remote caching
can greatly improve application performance, especially for web
applications and static files used with other applications.

\sphinxstylestrong{Compression}

Compression is one of the oldest acceleration techniques, having been
around for decades. GZIP, the most common compression algorithm, is
implemented in virtually every web browser and server. Compression
algorithms such as GZIP are good at finding small, repeating patterns
and reducing the characters required to send them. Besides web servers
and browsers, acceleration devices implement compression. This is done
for two reasons: first to offload compression overhead from web servers
and second, to enable the acceleration device to perform other
optimizations that improve performance for an HTTP/HTTPS stream.

Compression can be computationally expensive, especially for algorithms
that provide high compression levels. These algorithms are of limited
use with high-speed communication, where delays must be minimized to
maintain rapid user response times. More effective compression
algorithms are therefore limited to low- speed communications where more
time is available to perform compression processing without degrading
user throughput and hence, response times. Fortunately, compression
hardware assist is now available in some acceleration devices that can
achieve compression rates in excess of 1 Gbps.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{https://devcentral.f5.com/Portals/0/Cache/Pdfs/2807/http-pipelining-a-security-risk-without-real-performance-benefits.pdf}{Link to Online Topic Content}

\sphinxstylestrong{Pipelining}

Everyone wants web sites and applications to load faster, and there’s no
shortage of folks out there looking for ways to do just that. But all
that glitters are not gold and not all acceleration techniques actually
do all that much to accelerate the delivery of web sites and
applications. Worse, some actual incur risk in the form of leaving
servers open to exploitation.

\sphinxstylestrong{A brief history}

Back in the day when HTTP was still evolving, someone came up with the
concept of persistent connections. See, in ancient times - when
administrators still wore togas in the data center - HTTP 1.0 required
one TCP connection for every object on a page. That was okay, until
pages started comprising ten, twenty, and more objects. So someone added
an HTTP header, Keep-Alive, which basically told the server not to close
the TCP connection until (a) the browser told it to or (b) it didn’t
hear from the browser for X number of seconds (a time out). This
eventually became the default behavior when HTTP 1.1 was written and
became a standard.

\sphinxstylestrong{I told you it was a brief history.}

This capability is known as a persistent connection, because the
connection persists across multiple requests. This is not the same as
pipelining, though the two are closely related. Pipelining takes the
concept of persistent connections and then ignores the traditional
request - reply relationship inherent in HTTP and throws it out the
window.

\noindent\sphinxincludegraphics{{1p33}.png}

The general line of thought goes like this:

“Whoa. What if we just shoved all the requests from a page at the server
and then waited for them all to come back rather than doing it one at a
time? We could make things even faster!”

\sphinxstylestrong{HTTP pipelining}

In technical terms, the browser initiates HTTP pipelining by opening a
connection to the server and then sending multiple requests to the
server without waiting for a response. Once the requests are all sent
then the browser starts listening for responses. The reason this is
considered an acceleration technique is that by shoving all the requests
at the server at once you essentially save the RTT (Round Trip Time) on
the connection waiting for a response after each request is sent.

\noindent\sphinxincludegraphics{{1p34}.png}

\sphinxstylestrong{Why it just doesn’t matter anymore (and maybe never did)}

Unfortunately, pipelining was conceived of and implemented before
broadband connections were widely utilized as a method of accessing the
Internet. Back then, the RTT was significant enough to have a negative
impact on application and web site performance and the overall
user-experience was improved by the use of pipelining. Today, however,
most folks have a comfortable speed at which they access the Internet
and the RTT impact on most web application’s performance, despite the
increasing number of objects per page, is relatively low.

There is no arguing, however, that some reduction in time to load is
better than none. Too, anyone who’s had to access the Internet via high
latency links can tell you anything that makes that experience faster
has got to be a Good Thing. So what’s the problem?

The problem is that pipelining isn’t actually treated any differently on
the server than regular old persistent connections. In fact, the HTTP
1.1 specification requires that a “server MUST send its responses to
those requests in the same order that the requests were received.” In
other words, the requests are return in serial, despite the fact that
some web servers may actually process those requests in parallel.
Because the server MUST return responses to requests in order that the
server has to do some extra processing to ensure compliance with this
part of the HTTP 1.1 specification. It has to queue up the responses and
make certain responses are returned properly, which essentially negates
the performance gained by reducing the number of round trips using
pipelining.

Depending on the order in which requests are sent, if a request
requiring particularly lengthy processing - say a database query - were
sent relatively early in the pipeline, this could actually cause a
degradation in performance because all the other responses have to wait
for the lengthy one to finish before the others can be sent back.

Application intermediaries such as proxies, application delivery
controllers, and general load-balancers can and do support pipelining,
but they, too, will adhere to the protocol specification and return
responses in the proper order according to how the requests were
received. This limitation on the server side actually inhibits a
potentially significant boost in performance because we know that
processing dynamic requests takes longer than processing a request for
static content. If this limitation were removed it is possible that the
server would become more efficient and the user would experience
non-trivial improvements in performance. Or, if intermediaries were
smart enough to rearrange requests such a way that their execution were
optimized then we’d maintain the performance benefits gained by
pipelining. But that would require an understanding of the application
that goes far beyond what even today’s most intelligent application
delivery controllers are capable of providing.

\sphinxstylestrong{The silver lining}

At this point it may be fairly disappointing to learn that HTTP
pipelining today does not result in as significant a performance gain as
it might at first seem to offer (except over high latency links like
satellite or dial-up, which are rapidly dwindling in usage). But that
may very well be a good thing.

As miscreants have become smarter and more intelligent about exploiting
protocols and not just application code, they’ve learned to take
advantage of the protocol to “trick” servers into believing their
requests are legitimate, even though the desired result is usually
malicious. In the case of pipelining, it would be a simple thing to
exploit the capability to enact a layer 7 DoS attack on the server in
question. Because pipelining assumes that requests will be sent one
after the other and that the client is not waiting for the response
until the end, it would have a difficult time distinguishing between
someone attempting to consume resources and a legitimate request.

Consider that the server has no understanding of a “page”. It
understands individual requests. It has no way of knowing that a “page”
consists of only 50 objects, and therefore a client pipelining requests
for the maximum allowed - by default 100 for Apache - may not be seen as
out of the ordinary. Several clients opening connections and pipelining
hundreds or thousands of requests every second without caring if they
receive any of the responses could quickly consume the server’s
resources or available bandwidth and result in a denial of service to
legitimate users.

So perhaps the fact that pipelining is not really all that useful to
most folks is a good thing, as server administrators can disable the
feature without too much concern and thereby mitigate the risk of the
feature being leveraged as an attack method against them.

Pipelining as it is specified and implemented today is more of a
security risk than it is a performance enhancement. There are, however,
tweaks to the specification that could be made in the future that might
make it more useful. Those tweaks do not address the potential security
risk, however, so perhaps given that there are so many other
optimizations and acceleration techniques that can be used to improve
performance that incur no measurable security risk that we simply let
sleeping dogs lie.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Conclusion}
\label{\detokenize{class1/modules/module5:conclusion}}
This document is intended as a study guide for the F5 101 - Application
Delivery Fundamentals exam. This study guide is not an all-inclusive
document that will guarantee a passing grade on the exam. It is intended
to be a living doc and any feedback or material that you feel should be
included, to help exam takers better prepare, can be sent to
\sphinxhref{mailto:F5CertGuides@f5.com}{F5CertGuides@f5.com}.

Thank you for using this study guide to prepare the 101 - Application
Delivery Fundamentals exam and good luck with your certification goals.

Thanks

\sphinxstylestrong{Eric Mitchell}

Sr. Systems Engineer - Global SI


\chapter{F5 201 - TMOS Administration Study Guide 11/01/19}
\label{\detokenize{class2/class2:f5-201-tmos-administration-study-guide-11-01-19}}\label{\detokenize{class2/class2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview  201 - TMOS Administration}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Welcome to the TMOS Administration compiled Study Guide. The purpose of this
guide is to help you prepare for the F5 201 - TMOS Administration exam. The
contents of this document are based on the 201 - TMOS Administration Exam
Blueprint for TMOS v11.4.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

Hands on experience with the Big-IP platform will reinforce many of the topics
contained in the TMOS Administration exam. F5 has created a virtual lab
environment that can be run on a laptop with VMware Workstation (Fusion for
Mac) or in a lab with an ESXi server. The f5 vLabs can help by providing access
to a lab environment in which your knowledge of the Big-IP platform can grow.
For access to the vLab guides and virtual machines please contact your local
F5 Sales Engineer.

This study guide is a collection of information and therefore not a completely
original work. The information was found mostly in F5 resources. All of the
information locations are referenced at each topic instead of in an Appendix
of this document. This was done to help the reader access the reference the
linked information easier without having to search through a formal appendix.

The F5 101 - Application Delivery Fundamentals exam is a pre-requisite
to this exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Reading = Knowledge = Power}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Printed References}

These referenced books are important and should be considered basic reading
material for this exam.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Section 1 - Troubleshoot basic virtual server Connectivity issues}
\label{\detokenize{class2/modules/module1:section-1-troubleshoot-basic-virtual-server-connectivity-issues}}\label{\detokenize{class2/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.01 - Given a connectivity troubleshooting situation, consider the packet and virtual server processing order}
\label{\detokenize{class2/modules/module1:objective-1-01-given-a-connectivity-troubleshooting-situation-consider-the-packet-and-virtual-server-processing-order}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Virtual Server Intro:}

Before we get into the study points of this section, there is some basic
information you should know about virtual servers and the BIG-IP
platform.

\sphinxhref{https://techdocs.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/1.html\#conceptid}{TMOS Concepts 11-5-0 (the 11-4-0 Docs no longer exist but concepts are the same)}

\sphinxhref{https://techdocs.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/2.html\#conceptid}{Virtual Server Intro}

A BIG-IP platform is a default deny device. This means that the device
will not accept traffic and process it unless you have configured it to
do so.

A virtual server is a traffic-management object on the BIG-IP system
that is represented by an IP address and a service (port number).
Clients on an external network can send application traffic to a virtual
server, which then directs the traffic according to your configuration
instructions. The main purpose of a virtual server is often to balance
traffic load across a pool of servers on an internal network. Virtual
servers increase the availability of resources for processing client
requests.

Not only do virtual servers distribute traffic across multiple servers,
they also treat varying types of traffic differently, depending on your
traffic-management needs. For example, a virtual server can enable
compression on HTTP request data as it passes through the BIG-IP system,
or decrypt and re-encrypt SSL connections and verify SSL certificates.
For each type of traffic, such as TCP, UDP, HTTP, SSL, SIP, and FTP, a
virtual server can apply an entire group of settings, to affect the way
that Local Traffic Manager manages that traffic type.

A virtual server can also enable session persistence for a specific
traffic type. Through a virtual server, you can set up session
persistence for HTTP, SSL, SIP, and MSRDP sessions, to name a few.

Finally, a virtual server can apply an iRule, which is a user-written
script designed to inspect and direct individual connections in specific
ways. For example, you can create an iRule that searches the content of
a TCP connection for a specific string and, if found, directs the
virtual server to send the connection to a specific pool or pool member.

To summarize, a virtual server can do the following:
\begin{itemize}
\item {} 
Distribute client requests across multiple servers to balance server
load

\item {} 
Apply various behavioral settings to a specific type of traffic

\item {} 
Enable persistence for a specific type of traffic

\item {} 
Direct traffic according to user-written iRules

\end{itemize}

You can use virtual servers in any of several distinct ways:

\sphinxstylestrong{Directing traffic to a load balancing pool}

A Standard virtual server (also known as a load balancing virtual
server) directs client traffic to a load balancing pool and is the most
basic type of virtual server. When you first create the virtual server,
you assign an existing default pool to it. From then on, the virtual
server automatically directs traffic to that default pool.

\sphinxstylestrong{Sharing an IP address with a VLAN node}

You can set up a Forwarding (Layer 2) virtual server to share the same
IP address as a node in an associated VLAN. To do this, you must perform
some additional configuration tasks. These tasks consist of: creating a
VLAN group that includes the VLAN in which the node resides, assigning a
self-IP address to the VLAN group, and disabling the virtual server on
the relevant VLAN.

\sphinxstylestrong{Forwarding traffic to a specific destination IP address}

A Forwarding (IP) virtual server is just like other virtual servers,
except that a forwarding virtual server has no pool members to load
balance. The virtual server simply forwards the packet directly to the
destination IP address specified in the client request. When you use a
forwarding virtual server to direct a request to its originally
specified destination IP address, Local Traffic Manager adds, tracks,
and reaps these connections just as with other virtual servers. You can
also view statistics for a forwarding virtual server.

\sphinxstylestrong{Increasing the speed of processing HTTP traffic}

A Performance (HTTP) virtual server is a virtual server with which you
associate a Fast HTTP profile. Together, the virtual server and profile
increase the speed at which the virtual server processes HTTP requests.

\sphinxstylestrong{Increasing the speed of processing Layer 4 traffic}

A Performance (Layer 4) virtual server is a virtual server with which
you associate a Fast L4 profile. Together, the virtual server and
profile increase the speed at which the virtual server processes Layer 4
requests.

\sphinxstylestrong{Relaying DHCP traffic}

You can create a type of virtual server that relays Dynamic Host Control
Protocol (DHCP) messages between clients and servers residing on
different IP networks. Known as a DHCP relay agent, a BIG-IP system with
a DHCP Relay type of virtual server listens for DHCP client messages
being broadcast on the subnet and then relays those messages to the DHCP
server. The DHCP server then uses the BIG-IP system to send the
responses back to the DHCP client. Configuring a DHCP Relay virtual
server on the BIG-IP system relieves you of the tasks of installing and
running a separate DHCP server on each subnet.

When you create a virtual server, you specify the pool or pools that you
want to serve as the destination for any traffic coming from that
virtual server. You also configure its general properties, some
configuration options, and other resources you want to assign to it,
such as iRules or session persistence types.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Explain how a packet is processed once it arrives on the device}

In version 4.x, which was just prior to version 9.x (when TMOS was
created), the BIG-IP system used a virtual server precedence to define
the order in which it routes a packet to a specific virtual server in
the event that the packet matches multiple virtual server definitions.

The order of virtual server precedence was (from the highest precedence
to the lowest precedence) as follows:
\begin{itemize}
\item {} 
ip:port

\item {} 
ip:any

\item {} 
network:port

\item {} 
any:port

\item {} 
network:any

\item {} 
vlan:port

\item {} 
vlan:any

\item {} 
any:any

\end{itemize}

Many things have changed since then.

In Version 9.x through 11.2.1, (\sphinxstyleemphasis{which is not a part of this exam
version, but is a building block for the current exam version}) the
BIG-IP system determines the order of precedence applied to new inbound
connections using an algorithm that places a higher precedence on the
address netmask and a lesser emphasis on the port. BIG-IP LTM sets
virtual server precedence according to the following criteria:
\begin{itemize}
\item {} 
The first precedent of the algorithm chooses the virtual server that
has the longest subnet match for the incoming connection.

\item {} 
If the number of bits in the subnet mask match, the algorithm chooses
the virtual server that has a port match.

\item {} 
If no port match is found, the algorithm uses the wildcard server (if
a wildcard virtual server is defined).

\item {} 
A wildcard address has a netmask length of zero; thus, it has a lower
precedence than any matching virtual server with a defined address.

\end{itemize}

This algorithm results in the following order of precedence:
\begin{itemize}
\item {} 
\textless{}address\textgreater{}:\textless{}port\textgreater{}

\item {} 
\textless{}address\textgreater{}:*

\item {} 
\textless{}network\textgreater{}:\textless{}port\textgreater{}

\item {} 
\textless{}network\textgreater{}:*

\item {} 
*:\textless{}port\textgreater{}

\item {} 
*:*

\end{itemize}

Example of VIP precedence behavior

For example, for a BIG-IP system with the following VIPs configured on
the inbound VLAN:

10.0.0.0/8:80

10.10.0.0/16:80

10.10.10.10/32:80

20.0.0.0/8:*

20.0.0.0/8:80

*:80 (alternatively noted as 0.0.0.0/0:80)

*:* (alternatively noted as any:any, 0.0.0.0/0:any)

The following table illustrates how inbound destination addresses map to
the configured VIPs:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Inbound destination address
&
VIP
\\
\hline
10.10.10.10:80
&
10.10.10.10/32:80 - address match and port match
\\
\hline
10.10.10.11:80
&
10.10.0.0/16:80 - most specific address match and port match
\\
\hline
10.1.10.10:80
&
10.0.0.0/8:80 - most specific address match and port match
\\
\hline
20.0.0.0:80
&
20.0.0.0/8:80 - most specific address match and port match
\\
\hline
20.0.0.0:443
&
20.0.0.0/8:* - most specific address match with wildcard port
\\
\hline
1.1.1.1:443
&
*:* - wildcard address and wildcard port
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Changes in the order of precedence applied to new inbound connections
are in Version 11.3 and later (which covers the material of this exam).
Complete details can be found at the following location:

\sphinxhref{http://support.f5.com/kb/en-us/solutions/public/14000/800/sol14800.html}{SOL14800: Order of precedence for virtual server matching (11.3.0 and
later)}

Starting in BIG-IP 11.3.0, you can configure source addresses from which
virtual servers accept traffic. The BIG-IP system uses the destination
address, source address, and service port configuration to determine the
order of precedence applied to new inbound connections. When a
connection matches multiple virtual servers, the BIG-IP system uses an
algorithm that places virtual server precedence in the following order:
\begin{itemize}
\item {} 
Destination address

\item {} 
Source address

\item {} 
Service port

\end{itemize}

This algorithm uses the following order of precedence:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline

\sphinxstylestrong{Order}
&
\sphinxstylestrong{Destination}
&
\sphinxstylestrong{Source}
&
\sphinxstylestrong{Service port}
\\
\hline
\sphinxstyleemphasis{1}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{2}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{3}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{4}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{5}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{6}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{7}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{8}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{9}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{10}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{11}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{12}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{13}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{14}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}host address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{15}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{16}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}network address\textgreater{}}
&
\sphinxstyleemphasis{*}
\\
\hline
\sphinxstyleemphasis{17}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{\textless{}port\textgreater{}}
\\
\hline
\sphinxstyleemphasis{18}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{*}
&
\sphinxstyleemphasis{*}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

With the addition of the Source Address matching on the virtual server,
you can now have more than one virtual server listening on the same
IP:port combination, as long as the source IP filter is different on
each listener. There is a good example in the linked SOL for this
section.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Explain how a virtual server processes a request}

\sphinxhref{http://support.f5.com/kb/en-us/solutions/public/8000/000/sol8082.html}{SOL8082: Overview of TCP connection setup for BIG-IP LTM virtual server types}

\sphinxstylestrong{Standard virtual server}

The BIG-IP LTM TMOS operating system implements ”full proxy”
architecture for virtual servers configured with a TCP profile. By
assigning a custom TCP profile to the virtual server, you can configure
the BIG-IP LTM to maintain compatibility to disparate server operating
systems in the data center. At the same time, the BIG-IP LTM can
leverage its TCP/IP stack on the client side of the connection to
provide independent and optimized TCP connections to client systems.

In a full proxy architecture, the BIG-IP LTM appears as a TCP peer to
both the client and the server by associating two independent TCP
connections with the end-to-end session. Although certain client
information such as the source IP address or source TCP port, may be
re-used on the server side of the connection; the BIG-IP LTM system
manages the two sessions independently, making itself transparent to the
client and server.

The Standard virtual server requires a TCP or UDP profile, and may
optionally be configured with HTTP, FTP, or SSL profiles if Layer 7 or
SSL processing is required.

The TCP connection setup behavior for a Standard virtual server varies
depending on whether a TCP profile or a TCP and Layer 7 profile, such as
HTTP, is associated with the virtual server.

Standard virtual server with a TCP profile

The TCP connection setup behavior for a Standard virtual server operates
as follows: the three-way TCP handshake occurs on the client side of the
connection before the BIG-IP LTM initiates the TCP handshake on the
server side of the connection.

A Standard virtual server processes connections using the full proxy
architecture. The following TCP flow diagram illustrates the TCP
handshake for a Standard virtual server with a TCP profile:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p1}.jpeg}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Given a specific connectivity issue, isolate where the problem might be according to the processing order}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

In general, all trouble shooting should be done in an order that allows
for narrowing of the possible issue. When there is an issue with
connectivity to a virtual server, there can be many reasons. Gather what
you know. When you or the client tried to connect to the virtual server,
how was it done? Was it through a browser or another application? What
was the path that was used? (ie \sphinxurl{https://www.yoursite.com})

Starting out with checking to see if you have IP connectivity to the
virtual server is a good place to start. This is a sort of “divide and
conquer” approach to solve the issue. Can you reach the virtual servers
IP address from your location on the network? Start with a ping of the
virtual server address. If you can ping the IP we know that the F5 is
listening. Now are you connecting to the port number the virtual server
is listening on?

If you were browsing to \sphinxurl{https://www.yoursite.com}, does the DNS name of
www.yoursite.com resolve to the IP the address the virtual server is
configured on? If not, is it the NAT address of the firewall that
translates to the virtual server address?

If all the network connectivity looks good, is the virtual server
configured correctly for the type of traffic that is trying to pass?
Perhaps the administrator has applied a profile to the virtual server
telling it to process http traffic when the virtual server is set to
listen on 443. Without terminating the SSL traffic the virtual server
cannot process http traffic and the virtual server will not work
correctly.

These are just a few of the scenarios that you can be faced with trying
to figure out why a connection to an application may not be working.
Spending time on the vLabs and getting comfortable with interface and
configuring virtual servers will help you understand how the BIG-IP LTM
works.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.02 - Identify the reason a virtual server is not working as expected}
\label{\detokenize{class2/modules/module1:objective-1-02-identify-the-reason-a-virtual-server-is-not-working-as-expected}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine the state of a virtual server (offline, enabled, etc.)}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/2.html}

At any time, you can determine the status of a virtual server or virtual
address, using the Configuration utility. You can find this information
by displaying the list of virtual servers or virtual addresses and
viewing the Status column, or by viewing the \sphinxstyleemphasis{Availability} property
of the object.

The Configuration utility indicates status by displaying one of several
icons, distinguished by shape and color:
\begin{itemize}
\item {} 
The shape of the icon indicates the status that the monitor has
reported for that node.

\item {} 
The color of the icon indicates the actual status of the node.

\end{itemize}

To understand these icons with respect to status, see the table below.

Explanation of status icons for virtual servers and virtual addresses


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Status indicator
&
Explanation
\\
\hline
\noindent\sphinxincludegraphics{{p2}.png}
&
The virtual server or virtual address is \sphinxstylestrong{enabled} and able to receive traffic.
\\
\hline
\noindent\sphinxincludegraphics{{p3}.png}
&
The virtual server or virtual address is enabled but is \sphinxstylestrong{currently unavailable}. However, the virtual server or virtual address might become available later, with no user action required.

An example of a virtual server or virtual address showing this status is when the objects connection limit has been exceeded. When the number of connections falls below the configured limit, the virtual server or virtual address becomes available again.
\\
\hline
\noindent\sphinxincludegraphics{{p4}.png}
&
The virtual server or virtual address is enabled but \sphinxstylestrong{offline} because an associated object has marked the virtual server or virtual address as unavailable. To change the status so that the virtual server or virtual address can receive traffic, you must actively enable the virtual server or
virtual address.
\\
\hline
\noindent\sphinxincludegraphics{{p5}.png}
&
The virtual server or virtual address is operational but set to \sphinxstylestrong{Disabled}. To resume normal operation, you must manually enable the virtual server or virtual address.
\\
\hline
\noindent\sphinxincludegraphics{{p6}.png}
&
The status of the virtual server or virtual address is \sphinxstylestrong{unknown}.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine if a virtual server is configured with the proper ip address configuration}

\sphinxstylestrong{GUI Study in the vLabs}

\sphinxhref{http://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-1-0/ltm\_virtual.html}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/2.html}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

A virtual address is the IP address with which you associate a virtual
server. For example, if a virtual server’s IP address and service are
10.10.10.2:80, then the IP address 10.10.10.2 is a virtual address.

You can create a many-to-one relationship between virtual servers and a
virtual address. For example, you can create the three virtual servers
10.10.10.2:80, 10.10.10.2:443, and 10.10.10.2:161 for the same virtual
address of 10.10.10.2.

You can enable and disable a virtual address. When you disable a virtual
address, none of the virtual servers associated with that address will
receive incoming network traffic.

You create a virtual address indirectly when you create a virtual
server. When this happens, Local Traffic Manager internally associates
the virtual address with a MAC address. This in turn causes the BIG-IP
system to respond to Address Resolution Protocol (ARP) requests for the
virtual address, and to send gratuitous ARP requests and responses with
respect to the virtual address.

If the address you entered is not the correct address that your clients
are attempting to connect to, the symptom will seem as if the BIG-IP is
not working. This is a very common issue when DNS entries that resolve a
name to the virtual server IP address do not correlate. If your clients
are connecting to a DNS name make sure that it resolves to the intended
virtual server IP address or NAT address on the firewall that maps to
the virtual server IP address.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine if a virtual server is configured for the proper listening port}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

When you configure a virtual server and define the virtual address and
service port; this is how the virtual server is listening on the
network. If the service port you have configured is not the appropriate
port number for the type of connection that your clients are attempting
to make, the connection will likely fail. Understanding how your clients
intend to connect to the virtual server is usually a good sanity check
on the configuration.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine if the virtual server is configured with the appropriate profiles}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/2.html}

A virtual server has a number of properties and settings that you can
configure to affect the way that a virtual server manages traffic. You
can also assign certain resources to a virtual server, such as a load
balancing pool and a persistence profile. Together, these properties,
settings, and resources represent the definition of a virtual server,
and most have default values. When you create a virtual server, you can
either retain the default values or adjust them to suit your needs.
Profiles are one of the settings you can assign to a Virtual server to
control how the virtual server will behave.

Profiles are a configuration tool that you can use to affect the
behavior of certain types of network traffic. More specifically, a
profile is an object that contains settings with values, for controlling
the behavior of a particular type of network traffic, such as HTTP
connections. Profiles also provide a way for you to enable connection
and session persistence, and to manage client application
authentication.

By default, Local Traffic Manager provides you with a set of profiles
that you can use as is. These default profiles contain various settings
with default values that define the behavior of different types of
traffic. If you want to change those values to better suit the needs of
your network environment, you can create a custom profile. A custom
profile is a profile derived from a default profile and contains values
that you specify.

You can use profiles in the following ways:
\begin{itemize}
\item {} 
You can use the default profiles, which means that you do not need to
actively configure any profile settings. Local Traffic Manager uses
them to automatically direct the corresponding traffic types
according to the values specified in the those profiles.

\item {} 
You can create a custom profile, using the default profile as the
parent profile, modifying some or all of the values defined in that
profile.

\item {} 
You can create a custom profile to use as a parent profile for other
custom profiles.

\end{itemize}

After configuring a profile, you associate the profile with a virtual
server. The virtual server then processes traffic according to the
values specified in the profile. Using profiles enhances your control
over managing network traffic, and makes traffic-management tasks easier
and more efficient.

You can associate multiple profiles with a single virtual server. For
example, you can associate a TCP profile, an SSL profile, and an HTTP
profile with the same virtual server.


\bigskip\hrule\bigskip


How profiles are assigned to the virtual server can affect the virtual
servers ability to process the traffic that is passing through it. For
instance if you create a virtual server that is listening on
10.10.10.2:443, and you also assign an http profile to process the http
traffic according to your needs. The virtual server will not respond to
connections as expected. The virtual server settings say to take in
encrypted traffic on port 443 and then process and possible manipulate
the http headers. This is impossible without first terminating the
encrypted traffic with a clientside SSL profile to make the encrypted
traffic clear text for the BIG-IP to then apply the http profile. If you
apply a visual map of the OSI model to the functional parts of the
virtual server’s configuration it is easier to see what may be needed or
may be conflicting with each other. This is covered in depth in the F5
Certified Training course.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine if the pool configuration has an effect on virtual server state}

\sphinxstylestrong{GUI Study in the vLabs}

If all pool members are offline or misconfigured the virtual server’s
state can be affected. All heath status information trickles up to the
virtual server.

This means that if a node is not online due to a monitor marking the
node offline, any pool member using that node will be marked offline as
well. And if all members of a pool are marked offline by a failing
health monitor the virtual server will have no available resources so it
will be marked offline as well.

To see if a virtual server is not available due to a lack of resources
look in the GUI under Local Traffic and click on the Network Map/Show
Map and search for the virtual server in question. If it is down you can
see in the same pane if the resources are also offline.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine which tools to use in order to diagnose the issue}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

There are multiple tools you can use to check to see if a server behind
the BIG-IP is working as expected.

If you have a workstation on the local server subnet you can make a
direct connection to the server to see the response. Or if you have a
route to the server’s IP subnet from your current network location you
can try to connect to the server directly. If it is responding then look
to see if the pool member is configured to match how you just connected
to the server (IP:port).

You can see if the BIG-IP has connectivity to the IP address of the
server using the ping command from the command line interface of the
BIG-IP.

If there is IP connectivity then you can try to use the CURL command to
see if the BIG-IP can connect to the website on the server or FTP if the
server is listening for FTP traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain the difference between the virtual servers status definitions}

\sphinxstylestrong{GUI Study in the vLabs}

A virtual servers status icon is a quick way to see the high level
status of the virtual server. The five different status levels are
Enabled, Offline, Currently Unavailable, Unknown and Disabled. Each of
theses levels are pretty self explanatory.
\begin{itemize}
\item {} 
Enabled means that the virtual server is up and available for traffic
(monitors are succeeding) and is represented by a green circle icon.

\item {} 
Offline means that the resource for the virtual server is not
available (likely a failing monitor) and is represented by a red
diamond icon.

\item {} 
Currently Unavailable means that the virtual server or all of it’s
resources have reached a restricting connection limit that has been
set by the administrator and the virtual server currently has no
further capacity for traffic until the current connections fall below
the connection limit settings. A yellow triangle icon represents the
Currently Unavailable status.

\item {} 
Unknown means that there is not any monitors set for the resources of
the virtual server, so there is no status to show and is represented
by a blue square icon. This status does not mean that the virtual
server will not respond to traffic. A virtual server with an Unknown
status will take in traffic and send it on to the resources even if
they are not online.

\item {} 
Disabled means that the administrator has marked the virtual server
down so that it will not process traffic. The status icon will be a
shape that represents the current monitor status of the virtual
server but will always be colored black. Examples of this status icon
would be; if the virtual server has succeeding monitors but is
disabled the icon would be a black circle, or if the virtual server
has failing monitors but is disabled the icon would be a black
diamond or if the virtual server has no monitors but is disabled the
icon would be a black square.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.03 - Identify the reason a pool member has been marked down by health monitors}
\label{\detokenize{class2/modules/module1:objective-1-03-identify-the-reason-a-pool-member-has-been-marked-down-by-health-monitors}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Pool Intro:}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#conceptid}

In a typical client-server scenario, a client request goes to the
destination IP address specified in the header of the request. For sites
with a large amount of incoming traffic, the destination server can
quickly become overloaded as it tries to service a large number of
requests. To solve this problem, BIG-IP Local Traffic Manager
distributes client requests to multiple servers instead of to the
specified destination IP address only. You configure Local Traffic
Manager to do this when you create a load balancing pool.

You can enable or disable individual pool members. When you enable or
disable a pool member, you indirectly set the value of the pool members
State property, in the following way:
\begin{itemize}
\item {} 
Enable - Sets the State property of the pool member to Enabled.

\item {} 
Disable - Sets the State property of the pool member to Disabled.

\end{itemize}

Note that the difference between a disabled pool member, and a pool
member that a monitor reports as down, is that a disabled pool member
continues to process persistent and active connections. Conversely, a
pool member reported as down processes no connections whatsoever.

The status icons on the pool-member list screen and properties screen
indicate whether a pool member is currently enabled or disabled.

\sphinxstylestrong{Pool status}

An important part of managing pools and pool members is viewing and
understanding the status of a pool or pool member at any given time. The
Configuration utility indicates status by displaying one of several
icons, distinguished by shape and color, for each pool or pool member:

The shape of the icon indicates the status that the monitor has reported
for that pool or pool member. For example, a circle-shaped icon
indicates that the monitor has reported the pool member as being up,
whereas a diamond-shaped icon indicates that the monitor has reported
the pool member as being down.

The color of the icon indicates the actual status of the node itself.
For example, a green shape indicates that the node is up, whereas a red
shape indicates that the node is down. A black shape indicates that
user-intervention is required.

At any time, you can determine the status of a pool. The status of a
pool is based solely on the status of its members. Using the
Configuration utility, you can find this information by viewing the
Availability property of the pool. You can also find this information by
displaying the list of pools and checking the Status column.

The Configuration utility indicates pool status by displaying one of
several icons, distinguished by shape and color. To understand these
icons, see table below.

Explanation of status indicators for pools


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Status indicator
&
Explanation
\\
\hline
\noindent\sphinxincludegraphics{{p2}.png}
&
At least one pool member is available for processing traffic.
\\
\hline
\noindent\sphinxincludegraphics{{p3}.png}
&
No pool members are currently available but any one of them could become available later, with no user action required. An example of an unavailable pool member becoming available automatically is when the number of concurrent connections to the pool member no longer exceeds the value defined in the pool members Connection Limit setting.
\\
\hline
\noindent\sphinxincludegraphics{{p4}.png}
&
All pool members are unavailable and therefore cannot accept traffic. A reason for a pool member being unavailable is that an associated EAV monitor has detected that the pool member is unavailable. When pool status is red, user action is usually required.
\\
\hline
\noindent\sphinxincludegraphics{{p5}.png}
&
The status of at least one pool member is unknown, and no other pool members are available. Sample reasons for unknown pool-member status are:

One or more pool members has no associated monitor.

Monitor results are not available yet.

The pool members IP address is misconfigured.

The parent node has been disconnected from the network.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Discuss the effects of health monitors on the status of pool members/nodes}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#conceptid}

Health monitors are a key feature of Local Traffic Manager. Health
monitors help to ensure that a server is in an up state and able to
receive traffic. When you want to associate a monitor with an entire
pool of servers, you do not need to explicitly associate that monitor
with each individual server. Instead, you can simply assign the monitor
to the pool itself. Local Traffic Manager then automatically monitors
each member of the pool.

Local Traffic Manager contains many different pre-configured monitors
that you can associate with pools, depending on the type of traffic you
want to monitor. You can also create your own custom monitors and
associate them with pools. The only monitor types that are not available
for associating with pools are monitors that are specifically designed
to monitor nodes and not pools or pool members. That is, the destination
address in the monitor specifies an IP address only, rather than an IP
address and a service port. These monitor types are:
\begin{itemize}
\item {} 
ICMP

\item {} 
TCP Echo

\item {} 
Real Server

\item {} 
SNMP DCA

\item {} 
SNMP DCA Base

\item {} 
WMI

\end{itemize}

With Local Traffic Manager, you can configure your monitor associations
in many useful ways:

You can associate a health monitor with an entire pool instead of an
individual server. In this case, Local Traffic Manager automatically
associates that monitor with all pool members, including those that you
add later. Similarly, when you remove a member from a pool, Local
Traffic Manager no longer monitors that server.

When a server that is designated as a pool member allows multiple
processes to exist on the same IP address and port, you can check the
health or status of each process. To do this, you can add the server to
multiple pools, and then within each pool, associate a monitor with that
server. The monitor you associate with each server checks the health of
the process running on that server.

When associating a monitor with an entire pool, you can exclude an
individual pool member from being associated with that monitor. In this
case, you can associate a different monitor for that particular pool
member, or you can exclude that pool member from health monitoring
altogether. For example, you can associate pool members A, B, and D with
the http monitor, while you associate pool member C with the https
monitor.

You can associate multiple monitors with the same pool. For instance,
you can associate both the http and https monitors with the same pool.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Determine the state and availability of the pool member/node in question}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#conceptid}

Table 4.5 Explanation of status icons for pool members


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Status indicator
&
Explanation
&
State property is set to…
\\
\hline
\noindent\sphinxincludegraphics{{p2}.png}
&
The pool member is set to Enabled, the parent node is up, and a monitor has marked the pool member as up.
&
Enabled (All Traffic Allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p3}.png}
&
The pool member is unavailable, but could become available later with no user interaction required. This status occurs when the number of concurrent connections has exceeded the limit defined in the pool members Connection Limit setting.
&
Enabled (All Traffic Allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p4}.png}
&
The pool member is unavailable because either the parent node is down, a monitor has marked the pool member as down, or a user has disabled the pool member.
&
Enabled (All Traffic Allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p5}.png}
&
The pool member is set to Disabled, although a monitor has marked the pool member as up. To resume normal operation, you must manually enable the pool member.
&
Disabled (Only persistent or active connections allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p5}.png}
&
The pool member is set to Disabled and is offline because the parent node is down. To resume normal operation, you must manually enable the pool member.
&
Forced Offline (Only active connections allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p7}.png}
&
The pool member is set to Disabled and is offline because a user disabled it. To resume normal operation, you must manually enable the pool member.
&
Disabled (Only persistent or active connections allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p7}.png}
&
The pool member is set to Disabled and is offline because either the parent node is down, or a monitor has marked the pool member as down. To resume normal operation, you must manually enable the pool member.
&
Forced Offline (Only active connections allowed)
\\
\hline
\noindent\sphinxincludegraphics{{p6}.png}
&
The pool member or node has no monitor associated with it, or no monitor results are available yet
&
Enabled (All Traffic Allowed)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Verify the pool member/node Ratio configuration}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#conceptid}

\sphinxstylestrong{Ratio weights for pool members}

When using a ratio-based load balancing method for distributing traffic
to servers within a pool, you can assign a ratio weight to the
corresponding pool members. The ratio weight is used by the Local
Traffic Manager to distribute connections among pool members or nodes in
a static rotation. The number of connections that each system receives
over time is proportionate to the ratio weight you defined for each pool
member or node.

The ratio-based load balancing methods are: Ratio (node, member, and
sessions), Dynamic Ratio (node and member), and Ratio Least Connections
(node and member).


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Verify the pool member/node connection configuration and count}

You can configure a virtual server, pool member, or node to prevent an
excessive number of connection requests during events such as a Denial
of Service (DoS) attack or a planned, high-demand traffic event. To
ensure the availability of a virtual server, pool member, or node, you
can use the BIG-IP Local Traffic Manager to manage the total number of
connections and the rate at which connections are made.

When you specify a connection limit, the system prevents the total
number of concurrent connections to the virtual server, pool member, or
node from exceeding the specified number.

When you specify a connection rate limit, the system controls the number
of allowed new connections per second, thus providing a manageable
increase in connections without compromising availability.

After configuring connection limits and connection rate limits on a
virtual server, or after configuring these limits on a pool member or
node associated with a virtual server, the system controls the total
number of concurrent connections and the rate of new connections to the
virtual server, pool member, or node.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.04 - Identify a pool member not in the active priority group}
\label{\detokenize{class2/modules/module1:objective-1-04-identify-a-pool-member-not-in-the-active-priority-group}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify a pool member not in the active priority group}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html?sr=52980886}

About priority-based member activation

Priority-based member activation is a feature that allows you to
categorize pool members into priority groups, so that pool members in
higher priority groups accept traffic before pool members in lower
priority groups. The priority-based member activation feature has two
configuration settings:

\sphinxstylestrong{Priority group activation}

For the priority group activation setting, you specify the minimum
number of members that must remain available in each priority group in
order for traffic to remain confined to that group. The allowed value
for this setting ranges from 0 to 65535. Setting this value to 0
disables the feature (equivalent to using the default value of
Disabled).

\sphinxstylestrong{Priority group}

When you enable priority group activation, you also specify a priority
group for each member when you add that member to the pool. Retaining
the default priority group value of 0 for a pool member means that the
pool member is in the lowest priority group and only receives traffic
when all pool members in higher priority groups are unavailable.

If the number of available members assigned to the highest priority
group drops below the number that you specify, the BIG-IP system
distributes traffic to the next highest priority group, and so on.

For example, this configuration has three priority groups, 3, 2, and 1,
with the priority group activation value (shown here as min active
members) set to 2.

pool my\_pool \{

lb\_mode fastest

min active members 2

member 10.12.10.7:80 priority 3

member 10.12.10.8:80 priority 3

member 10.12.10.9:80 priority 3

member 10.12.10.4:80 priority 2

member 10.12.10.5:80 priority 2

member 10.12.10.6:80 priority 2

member 10.12.10.1:80 priority 1

member 10.12.10.2:80 priority 1

member 10.12.10.3:80 priority 1

\}

Connections are first distributed to all pool members with priority 3
(the highest priority group). If fewer than two priority 3 members are
available, traffic is directed to the priority 2 members as well. If
both the priority 3 group and the priority 2 group have fewer than two
members available, traffic is directed to the priority 1 group. The
BIG-IP system continuously monitors the priority groups, and whenever a
higher priority group once again has the minimum number of available
members, the BIG-IP system limits traffic to that group.

To see which pool members are not receiving traffic you can look at
Statistics in the GUI or on console.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Previous Exam Objective - 1.05 - Persistence}
\label{\detokenize{class2/modules/module1:previous-exam-objective-1-05-persistence}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

Due to the 201 Exam Blueprint having an obvious mistake with layout or
objectives I have added this section.

\sphinxstylestrong{Previous Exam Topic 1.05 - Explain the concept of “persistence”}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/10.html\#unique\_1009994785}

Using BIG-IP Local Traffic Manager, you can configure session
persistence. When you configure session persistence Local Traffic
Manager tracks and stores session data, such as the specific pool member
that serviced a client request. The primary reason for tracking and
storing session data is to ensure that client requests are directed to
the same pool member throughout the life of a session or during
subsequent sessions when an application requires it to be so.

In addition, session persistence can track and store other types of
information, such as user preferences or a user name and password.

Local Traffic Manager offers several types of session persistence, each
one designed to accommodate a specific type of storage requirement for
session data. The type of persistence that you implement depends on
where and how you want to store client-specific information, such as
items in a shopping cart or airline ticket reservations.

For example, you might store airline ticket reservation information in a
back-end database that all servers can access, or on the specific server
to which the client originally connected, or in a cookie on the client’s
machine. When you enable persistence, returning connections will not be
load balancing and instead will be sent to the server to which they last
connected in order to access application again.

Local Traffic Manager keeps session data for a period of time that you
specify.

The primary tool for configuring session persistence is to configure a
persistence profile and assign it to a virtual server. If you want to
enable persistence for specific types of traffic only, as opposed to all
traffic passing through the virtual server, you can write an iRule.

To configure and manage persistence profiles, log in to the BIG-IP
Configuration utility, and on the Main tab, expand Local Traffic, and
click Persistence.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Previous Exam Topic 1.05 - Verify the type of persistence profile assigned to the virtual server in question}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/10.html\#unique\_1009994785}

A persistence profile is a pre-configured object that automatically
enables persistence when you assign the profile to a virtual server. By
using a persistence profile, you avoid having to write a program to
implement a type of persistence.

Each type of persistence that Local Traffic Manager offers includes a
corresponding default persistence profile. These persistence profiles
each contain settings and setting values that define the behavior of the
BIG-IP system for that type of persistence. You can either use the
default profile or create a custom profile based on the default.

\sphinxstylestrong{Persistence profile types:}

You can configure persistence profile settings to set up session
persistence on the BIG-IP system. You can configure these settings when
you create a profile or after profile creation by modifying the profiles
settings.

The persistence types that you can enable using a persistence profile
are:

\sphinxstylestrong{Cookie persistence}

Cookie persistence uses an HTTP cookie stored on a clients computer to
allow the client to reconnect to the same server previously visited at a
web site.

\sphinxstylestrong{Destination address affinity persistence}

Also known as sticky persistence, destination address affinity
persistence supports TCP and UDP protocols, and directs session requests
to the same server based solely on the destination IP address of a
packet.

\sphinxstylestrong{Hash persistence}

Hash persistence allows you to create a persistence hash based on an
existing iRule.

\sphinxstylestrong{Microsoft Remote Desktop Protocol persistence}

Microsoft Remote Desktop Protocol (MSRDP) persistence tracks sessions
between clients and servers running the Microsoft Remote Desktop
Protocol (RDP) service.

\sphinxstylestrong{SIP persistence}

SIP persistence is a type of persistence used for servers that receive
Session Initiation Protocol (SIP) messages sent through UDP, SCTP, or
TCP.

\sphinxstylestrong{Source address affinity persistence}

Also known as simple persistence, source address affinity persistence
supports TCP and UDP protocols, and directs session requests to the same
server based solely on the source IP address of a packet.

\sphinxstylestrong{SSL persistence}

SSL persistence is a type of persistence that tracks non-terminated SSL
sessions, using the SSL session ID. Even when the clients IP address
changes, Local Traffic Manager still recognizes the connection as being
persistent based on the session ID. Note that the term non-terminated
SSL sessions refer to sessions in which Local Traffic Manager does not
perform the tasks of SSL certificate authentication and
encryption/re-encryption.

\sphinxstylestrong{Universal persistence}

Universal persistence allows you to write an expression that defines
what to persist on in a packet. The expression, written using the same
expression syntax that you use in iRules, defines some sequence of bytes
to use as a session identifier.

You can see the type of persistence assigned to a virtual server by
going to \sphinxstylestrong{Local Traffic \textgreater{} Virtual Servers} in the GUI and selecting
the virtual server from the list you wish to inspect. Click on the
Resources tab and look at the settings for the Default Persistence
Profile setting and the Fallback Persistence Profile setting. To change
the setting you can select the name of the profile you created or wish
to use, such as \sphinxstylestrong{cookie}. This implements cookie persistence, using
the default cookie persistence profile.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p8}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Previous Exam Topic 1.05 - Differentiate between fallback and primary persistence}

\sphinxstylestrong{GUI Study in the vLabs}

The administrator of a BIG-IP can set a primary persistence type for a
virtual server as shown in the previous section. A fallback persistence
type can also be set. Only IP address based persistence types are
allowed as fallback. This means that along with honoring the primary
persistence method there is a second record being kept that can be used
to persist the client’s transaction to the resource of the virtual
server as well. For example if cookie persistence is set with a fallback
of sourceaddr, as a client makes their second connection to the virtual
server the cookie from the first connection will be used to determine
the server in the pool to send the connection to. But at the same time
as the first connection was made to the virtual server a source address
persistence record was also created. And if the client did not have the
cookie any longer the record matching their IP address would still exist
(if it had not timed out) and could be used to get them back to their
original pool member.

However this also means that if a source address persistence profile is
used as a fallback that has a wider subnet in the configuration such as
a 255.255.255.0, and a second client from the same class C network as
the first client made their first connection to the virtual server. They
would be persisted to the same pool member as the first client since
they would match the source IP record of the first client even though
they did not have a cookie when they connected.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Previous Exam Topic 1.05 - Validate the expected persistence behavior}

\sphinxstylestrong{GUI Study in the vLabs - Module 8 Exercises}

As you connect to an application through the virtual server of the
BIG-IP platform the first connection is load balanced to the best
available resource according to the load-balancing algorithm. With
persistence enabled the following connections from the same client will
be sent to the same resource as their first initial load balanced
connection.

Checking to see if the client is being persisted is simple in a test
scenario where a single client connects to the virtual server and the
statistics on the system show the connections only going to the same
resource in the pool.

However in regular production volume it will be hard to see the
individual client connections hitting the same resource when there are
hundreds or thousands of connections coming in all the time. An easy way
to see that the client is connecting to the same server resource is to
have watermarks on the application webpages. These watermarks will show
a unique mark on the web page identifying it to the individual server,
much like we use in the vLabs on the load-balanced sites. Not all
developers will take the time or effort to do this water marking. If you
do not have the ability to add a watermark to your page then there needs
to be another method.

In the BIG-IP platform you have the ability to show the active
connection table and use filters to show the data you want to see. So to
show a client’s current connection in the connection table you can type
the following command:

In version 9.X and 10.X:

\sphinxstyleemphasis{bigpipe conn show \textbar{} grep “client IP”}

In version 11.x:

\sphinxstyleemphasis{tmsh show sys conn cs-client-addr “client IP”}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Previous Exam Topic 1.05 - Use the appropriate tool to troubleshoot persistence}

\sphinxstylestrong{GUI Study in the vLabs}

If the persistence method you are using is not tracked locally by the
BIG-IP system, such as Cookie persistence; then there are no local
records on the BIG-IP to review. This is due to the fact that the cookie
containing the pool member info is passed to the client system from the
BIG-IP, and when the client makes the next connection it will include
the cookie from the previous in the request for the BIG-IP system to use
for the persistence info. Allowing the BIG-IP to simply read the cookie
and not have to locally store the info. An administrator can find the
cookie on the client’s workstation. It is stored where the client’s
local browser would normally store cookies. This location will vary by
browser type and OS type.

If the persistence method you are using is tracked by the BIG-IP system
locally, such as Source Address Affinity persistence, then you can look
at the records that are stored on the local system using the following
methods:
\begin{itemize}
\item {} 
Source Address persistence records can be found in the Configuration
Utility, open the Statistics \textgreater{} Module Statistics \textgreater{} Local Traffic page
and select Persistence Records from the Statistics Type list.

\item {} 
In version 11.X command line do: tmsh show /ltm persistence
persist-records

\end{itemize}

In version 9.X and 10.X command line do: B persist show all

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.05 - Identify traffic diverted due to persistence record}
\label{\detokenize{class2/modules/module1:objective-1-05-identify-traffic-diverted-due-to-persistence-record}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Identify traffic diverted due to persistence record}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#unique\_1112226001}

When traffic matches an existing persistence record the load balancing
decision is not made for that traffic. The decision of which server to
send it to has been made for that traffic by first inbound connection to
the virtual server that created the record and now the matching traffic
will use that decision until the persistence record expires.

You can see the existing persistence records for methods that are kept
on the system by typing the following command:

root@(bigipD1)(tmos)\# show ltm persistence persist-records

Or by going to Overview \textgreater{} Module Statistics and choosing Persistence
records in the Statistics Type field.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p9}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.06 - Identify the current configured state of the pool member}
\label{\detokenize{class2/modules/module1:objective-1-06-identify-the-current-configured-state-of-the-pool-member}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Identify the current configured state of the pool member}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#unique\_1112226001}

\sphinxstylestrong{About pool member state}

You can enable or disable individual pool members. When you enable or
disable a pool member, you indirectly set the value of the pool member’s
State property, in the following way:

Enable sets the State property of the pool member to Enabled.

Disable sets the State property of the pool member to Disabled.

Note that the difference between a disabled pool member and a pool
member that a monitor reports as down is that a disabled pool member
continues to process persistent and active connections. Conversely, a
pool member reported as down processes no connections whatsoever.

The status icons on the pool-member list screen and properties screen
indicate whether a pool member is currently enabled or disabled.

\sphinxstylestrong{Pool and pool member status}

An important part of managing pools and pool members is viewing and
understanding the status of a pool or pool member at any given time. The
Configuration utility indicates status by displaying one of several
icons, distinguished by shape and color, for each pool or pool member:

The shape of the icon indicates the status that the monitor has reported
for that pool or pool member. For example, a circle-shaped icon
indicates that the monitor has reported the pool member as being up,
whereas a diamond-shaped icon indicates that the monitor has reported
the pool member as being down.

The color of the icon indicates the actual status of the node itself.
For example, a green shape indicates that the node is up, whereas a red
shape indicates that the node is down. A black shape indicates that
user-intervention is required.

At any time, you can determine the status of a pool. The status of a
pool is based solely on the status of its members. Using the
Configuration utility, you can find this information by viewing the
Availability property of the pool. You can also find this information by
displaying the list of pools and checking the Status column.

You can see the Status of a pool member in the GUI by going to Local
Trafic \textgreater{} Pools and clicking on the pool you want to see. Navigate to the
Members tab to view each pool member’s status. You can click on the pool
member to see which monitor may have changed the status of the pool
member.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p10}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.07 - Identify a persistence issue}
\label{\detokenize{class2/modules/module1:objective-1-07-identify-a-persistence-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Identify a persistence issue}

\sphinxstylestrong{General Network Study and vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

When there is a persistence issue a user’s session state data will not
be available to the user’s session and it could result in many different
issues. If they are connecting to an application that requires a login
and they are load balanced to a different server after they have logged
in on their first connection, they may be presented with the login
screen for next server. If they are using a website filling out an
on-line form or filling up their shopping cart with items and they are
load balanced to a different server, their form data or cart contents
may not be available to that next server’s session. A simple fix for
most session state issues is to turn on persistence on the BIG-IP
platform and not load balance every session only a user’s first
connection. However even though we can generally fix the issue the real
problem lies with the application not sharing session state between the
servers. If the necessary information is shared between the application
servers, we would be able to load balance every connection to the most
available server. Most of time cost is the issue because it can be
expensive to run a session state database or to rewrite the application
to handle it.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 2 - Troubleshoot basic hardware issues}
\label{\detokenize{class2/modules/module2:section-2-troubleshoot-basic-hardware-issues}}\label{\detokenize{class2/modules/module2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.01 Perform an End User Diagnostic per F5 documentation and collect the output}
\label{\detokenize{class2/modules/module2:objective-2-01-perform-an-end-user-diagnostic-per-f5-documentation-and-collect-the-output}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Reboot an F5 platform into the EUD}

\sphinxurl{http://support.f5.com/kb/en-us/products/big-ip\_ltm/releasenotes/related/EUD\_11\_4.html}

You can run the EUD only from a console connected to the BIG-IP system.
You can start the EUD using the following methods:
\begin{itemize}
\item {} 
Attach a USB CDROM drive containing the bootable system CD. As the
system boots up, the EUD starts.

\item {} 
Attach a USB mass storage device drive with the EUD boot image
loaded. As the system boots up, the EUD starts.

\item {} 
While the system is booting, select the End User Diagnostics option
from the boot menu.

\end{itemize}

You can then run the tests that are necessary.

After you have completed the tests you want to run, use option 21 to
exit the EUD and reboot the system. You must use this option to exit the
EUD. Using other methods, such as rebooting or using the command menu,
can destabilize the system.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Download output from the unit an EUD was run on}

\sphinxurl{http://support.f5.com/kb/en-us/products/big-ip\_ltm/releasenotes/related/EUD\_11\_4.html}

An End User Diagnostic or EUD report log is stored as a text file named
eud.log in the /shared/log/ directory on the host file system.

If you have run an EUD Test on the system it will be available in this
location. You can connect to the console IP address of the BIG-IP system
and use and SCP tool to get the file off of the system, to upload to the
F5 Support case.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Interpret the output from an EUD and determine if the test
passed or failed}

\sphinxurl{http://support.f5.com/kb/en-us/products/big-ip\_ltm/releasenotes/related/EUD\_11\_4.html}

When all tests complete correctly, the following message displays:

\sphinxstyleemphasis{Completed test with 0 errors}.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.02 Interpret the LCD Warning Messages}
\label{\detokenize{class2/modules/module2:objective-2-02-interpret-the-lcd-warning-messages}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Locate the LCD on an F5 Platform}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/platform-b5000/2.html\#c\_reuse\_about\_lcd\_panel}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/platform-b5000/2.html
-
c\_reuse\_about\_lcd\_panel}

On the front of the platform, you can reset the unit using the LCD
control buttons. You can also use the front-panel LEDs to assess the
condition of the platform. On the back, you can power off the unit.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p11}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Front view of the 5000 platform
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Management 10/100/1000 Ethernet port

\item {} 
USB ports

\item {} 
Console serial port

\item {} 
Serial (hard-wired) failover port

\item {} 
10/100/1000 interfaces

\item {} 
1G/10G optical ports

\item {} 
Indicator LEDs

\item {} 
LCD display

\item {} 
LCD control buttons

\end{enumerate}

The liquid crystal display, or LCD panel, provides the ability to
control the unit without attaching a console or network cable.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p12}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

The LCD panel is located on the front of all F5 hardware except for the
Viprion 2400 Series Chassis. A separate USB attachable LCD panel is
available for the Viprion 2400 Series Chassis.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Correlate the LCD message to message in the corresponding log
file}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/4000/200/sol4263.html}

Alert conditions

Alerts that affect the behavior of the Alarm LED indicator are defined
in the /etc/alertd/alert.conf file. The lcdwarn function of an alert
definition defines which alerts will modify the Alarm LED indicator.

As an example, the default alertd process conditions in BIG-IP version
9.2 are defined in the following table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Description
&
Alert Level
&
LED behavior
\\
\hline
CPU Temp too high
&
3 - Critical
&
Solid Red
\\
\hline
CPU fan too slow
&
3 - Critical
&
Solid Red
\\
\hline
CPU fan bad
&
3 - Critical
&
Solid Red
\\
\hline
Chassis Temp too high
&
3 - Critical
&
Solid Red
\\
\hline
Chassis Fan bad
&
3 - Critical
&
Solid Red
\\
\hline
Power Supply bad
&
4 - Emergency
&
Blink Red
\\
\hline
Unit going standby
&
0 - Warning
&
Solid Yellow
\\
\hline
Unit going Active
&
0 - Warning
&
Solid Yellow
\\
\hline
The license validation failed
&
2 - Alert
&
Solid Red
\\
\hline
The license has expired
&
2 - Alert
&
Solid Red
\\
\hline
Blocking DoS attack
&
2 - Alert
&
Solid Red
\\
\hline
Hard disk is failing
&
4 - Emergency
&
Blink Red
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The events that trigger LCD screen events and lights are written to log
files. You may want to look up more information on the logged events.
For example, the BIG-IP system may generate an error messages to the
/var/log/ltm file that contains the following event:
\begin{itemize}
\item {} 
emerg system\_check{[}11277{]}: 010d0010:0: Power supply \#2 fan-1: fan
speed (0) is too low.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Identify which tasks the buttons on the LCD perform}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/pg-10200v/2.html\#c\_reuse\_about\_lcd\_panel}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/pg-10200v/2.html - c\_reuse\_about\_lcd\_panel}

Pressing the X button puts the LCD panel in Menu. The buttons Left
Arrow, Right Arrow, Up Arrow, and Down Arrow are only functional when
the LCD is in Menu mode for navigation. The \(\pmb{\checkmark}\) check button is used to
select and confirm selections.

Please refer to the Hyperlink to review the menu options available on
the LCD Panel

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.03 Identify a possible hardware issue within the log files}
\label{\detokenize{class2/modules/module2:objective-2-03-identify-a-possible-hardware-issue-within-the-log-files}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Indicate which logs would contain debugging information}

\sphinxurl{http://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/11.html}

If you are using the Syslog utility for local logging, whether or not
you are using the high-speed logging mechanism you can view and manage
the log messages, using the BIG-IP Configuration utility.

The local Syslog logs that the BIG-IP system can generate include
several types of information. For example, some logs show a timestamp,
host name, and service for each event. Moreover, logs sometimes include
a status code, while the audit log shows a user name and a transaction
ID corresponding to each configuration change. All logs contain a
one-line description of each event.

For local log messages that the BIG-IP system stores in the local Syslog
data base, the BIG-IP system automatically stores and displays log
messages in these categories:
\begin{itemize}
\item {} 
System messages

\item {} 
Packet filter messages

\item {} 
Local Traffic messages

\item {} 
Global Traffic messages

\item {} 
BIG-IP system configuration (audit) messages

\end{itemize}

Each type of event is stored locally in a separate log file, and the
information stored in each log file varies depending on the event type.
All log files for these event types are in the directory /var/log.

The product specific logs like /var/log/ltm, var/log/gtm, etc will
contain debug info relative to that product. If you are logging from an
irule you can define what log file you want to write your debug info
into by specifying the local facility you chose.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Given a log file, determine the nature of a hardware issue}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/11.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/11.html
-
conceptid}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

You may look in the logs and see there are may events. Perhaps you
notice an event like this:

Mon Feb 14 o4:36:06 PST 2005 bigip2 bcm56xxd(785) 00010012 Link 2.5 is up

This could have been caused by the administrator turning up a new
interface or because the interface lost connectivity to the upstream
switch. Some events can be self-explanatory while others may be more
cryptic and need some deciphering.

\sphinxstylestrong{Understanding log content}

The logs that the BIG-IP system generates include several types of
information. For example, some logs show a timestamp, host name, and
service for each event. Moreover, logs sometimes include a status code,
while the audit log shows a user name and a transaction ID corresponding
to each configuration change. All logs contain a 1-line description of
each event.

The table below lists the categories of information contained in the
logs and the specific logs in which the information is displayed.

Log information categories and their descriptions


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Information Type
&
Explanation
&
Log Type
\\
\hline
Timestamp
&
The time and date that the system logged the event message.
&
System

Packet Filter

Local Traffic

Audit
\\
\hline
Host name
&
The host name of the system that logged the event message. Because this is typically the host name of the local machine, the appearance of a remote host name could be of interest.
&
System

Packet Filter

Local Traffic
\\
\hline
Service
&
The service that generated the event.
&
System

Packet Filter

Local Traffic
\\
\hline
Status code
&
The status code associated with the event. Note that only events logged by BIG-IP system components, and not Linux system services, have status codes.
&
Packet Filter

Local Traffic
\\
\hline
Description
&
The description of the event that caused the system to log the message.
&
System

Packet Filter

Local Traffic
\\
\hline
User Name
&
The name of the user who made the configuration change.
&
Audit
\\
\hline
Transaction ID
&
The identification number of the configuration change.
&
Audit
\\
\hline
Event
&
A description of the configuration change that caused the system to log the message.
&
Audit
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Given a possible issue, determine which log file entries to review}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/11.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/11.html - conceptid}

Viewing and managing log messages are an important part of maintaining a
BIG-IP system. Log messages inform you on a regular basis of the events
that are happening on the system. Some of these events pertain to
general events happening within the operating system, while other events
are specific to the BIG-IP system, such as the stopping and starting of
BIG-IP system services.

The mechanism that the BIG-IP system uses to log events is the Linux
utility syslog-ng. The syslog-ng utility is an enhanced version of the
standard UNIX and Linux logging utility syslog.

The types of events that the BIG-IP system logs are:

\sphinxstylestrong{System events}

System event messages are based on Linux events, and are not specific to
the BIG-IP system.

\sphinxstylestrong{Packet filter events}

Packet filter messages are those that result from the implementation of
packet filters and packet-filter rules.

\sphinxstylestrong{Local traffic events}

Local-traffic event messages pertain specifically to the local traffic
management system.

\sphinxstylestrong{Audit events}

Audit event messages are those that the BIG-IP system logs as a result
of changes to the BIG-IP system configuration. Logging audit events is
optional.

To configure and manage event logging, log in to the BIG-IP
Configuration utility, and on the Main tab, expand System, and click
Logs.

As described in Introducing BIG-IP system logging, the BIG-IP system
automatically logs four main event types: system, packet filter, local
traffic, and configuration changes (audit). Each type of event is stored
in a separate log file, and the information stored in each log file
varies depending on the event type. All log files for these event types
are in the directory /var/log.

\sphinxstylestrong{Logging system events}

Many events that occur on the BIG-IP system are Linux-related events,
and do not specifically apply to the BIG-IP system.

Using the Configuration utility, you can display these system messages.
The table below shows some sample system log entries.

Sample system log entries


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline

Timestamp
&
Host
&
Service
&
Event
\\
\hline
Mon Feb 14 03:34:45 PST 2005
&
bigip3
&
syslog-ng{[}5494{]}
&
new configuration initialized
\\
\hline
Mon Feb 14 03:35:06 PST 2005
&
bigip3
&
syslog-ng{[}5494{]}
&
kjournald starting. Commit interval 5 seconds.
\\
\hline
Mon Feb 14 04:38:06 PST 2005
&
bigip3
&
EXT3-fs
&
mounted filesystem with ordered data mode.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Logging packet filter events}

Some of the events that the BIG-IP system logs are related to packet
filtering. The system logs the messages for these events in the file
/var/log/pktfilter.

Using the Configuration utility, you can display these packet filter
messages.

\sphinxstylestrong{Logging local traffic events}

Many of the events that the BIG-IP system logs are related to local area
traffic passing through the BIG-IP system. The BIG-IP system logs the
messages for these events in the file /var/log/ltm.

Using the Configuration utility, you can display these local-traffic
messages. The table below shows some sample local-traffic log entries.

Sample local-traffic log entries


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

Timestamp
&
Host
&
Service
&
Status Code
&
Event
\\
\hline
Mon Feb 14 03:34:45 PST 2005
&
bigip2
&
bcm56xxd(785)
&
00010013
&
Starting packet registry event timer
\\
\hline
Mon Feb 14 03:35:06 PST 2005
&
bigip2
&
bcm56xxd(785)
&
00010013
&
Starting HA heartbeat timer tick
\\
\hline
Mon Feb 14 04:38:06 PST 2005
&
bigip2
&
bcm56xxd(785)
&
00010013
&
Successful start. Entering main message loop
\\
\hline
Mon Feb 14 o4:36:06 PST 2005
&
bigip2
&
bcm56xxd(785)
&
00010012
&
Link 2.5 is up
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Some of the specific types of events that the BIG-IP system displays on the Local Traffic logging screen are:}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{1}{\X{1}{1}|}}
\hline
\begin{itemize}
\item {} 
Address Resolution Protocol (ARP) packet and ARP cache events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
bigdb database events (such as populating and persisting bigdb variables)

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
HTTP protocol events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
HTTP compression events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
IP packet discard events due to exceptional circumstances or invalid parameters (such as a bad checksum)

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
Layer 4 events (events related to TCP, UDP, and Fast L4 processing)

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
MCP/TMM configuration events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
Monitor configuration events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
Network events (Layers 1 and 2)

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
Packet Velocity ASIC (PVA) configuration events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
iRule events related to run-time iRule processing

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
SSL traffic processing events

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
General TMM events such as TMM startup and shutdown

\end{itemize}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.04 Force an active unit to standby under the appropriate circumstances}
\label{\detokenize{class2/modules/module2:objective-2-04-force-an-active-unit-to-standby-under-the-appropriate-circumstances}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Force an active unit to standby under the appropriate
circumstances}

\sphinxstylestrong{General Network Study and vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

For example:

If the BIG-IP HA pair is synchronized then the configurations are the
same on both systems. If the active system is having an issue and you
can’t find an issue with the other systems in the environment (Client or
Server). The issue may have something to do with the LTM. You could try
a fail over of the Active system to the standby system. If the problem
resolves then you are likely faced with an issue in the first system and
since they were in sync it may be hardware. That hardware issue may be
in the LTM or in the network systems that it is connected to. If the
fail over did not solve the issue the problem is like a configuration
issue and hardware has been eliminated.

Since a failover of an HA pair can interrupt current connections of
clients and depending on the type of connection they may have made their
connection may not recover from the termination of the connection (if
connection mirroring is not properly configured for long lived
connections), using failover as a troubleshooting step should be done as
a last measure. How ever it can help to narrow down if there is an issue
with hardware.

For a failover between systems in an HA pair, to be transparent to the
clients currently connected to the active unit, the state of the active
connections need to be known by the standby system. If the connection
states are not know by the standby system when the failover occurs,
connections that were being persisted, connections that were being
SNAT’d or any active connection state know by the active unit will not
survive the failover. To create a stateful failover environment the
systems must be configured to mirror the current connection table,
persistence records and SNAT table to the standby unit.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.05 Understand the relationship between interfaces, trunks, VLANs and their status/statistics}
\label{\detokenize{class2/modules/module2:objective-2-05-understand-the-relationship-between-interfaces-trunks-vlans-and-their-status-statistics}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Understand the relationship between interfaces, trunks, VLANs
and their status/statistics}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/12.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/12.html - conceptid}

\sphinxstylestrong{Introduction to BIG-IP system interfaces}

A key task of the BIG-IP system configuration is the configuration of
BIG-IP system interfaces. The interfaces on a BIG-IP system are the
physical ports that you use to connect the BIG-IP system to other
devices on the network. These other devices can be next-hop routers,
Layer 2 devices, destination servers, and so on. Through its interfaces,
the BIG-IP system can forward traffic to or from other network devices.

\sphinxstyleemphasis{Note: The term interface refers to the physical ports on the BIG-IP
system.}

Every BIG-IP system includes multiple interfaces. The exact number of
interfaces that you have on the BIG-IP system depends on the platform
type.

A BIG-IP system has two types of interfaces:

\sphinxstylestrong{A management interface}

The management interface is a special interface dedicated to performing
a specific set of system management functions.

\sphinxstylestrong{TMM switch interfaces}

TMM switch interfaces are those interfaces that the BIG-IP system uses
to send or receive application traffic, that is, traffic slated for
application delivery.

Each of the interfaces on the BIG-IP system has unique properties, such
as the MAC address, media speed, duplex mode, and support for Link Layer
Discovery Protocol (LLDP).

In addition to configuring interface properties, you can implement a
feature known as interface mirroring, which you can use to duplicate
traffic from one or more interfaces to another. You can also view
statistics about the traffic on each interface.

Once you have configured the properties of each interface, you can
configure several other features of the BIG-IP system that control the
way that interfaces operate. For example, by creating a virtual local
area network (VLAN) and assigning interfaces to it, the BIG-IP system
can insert a VLAN ID, or tag, into frames passing through those
interfaces. In this way, a single interface can forward traffic for
multiple VLANs.

\sphinxstylestrong{Introduction to virtual LANs}

A VLAN is a logical subset of hosts on a local area network (LAN) that
operate in the same IP address space. Grouping hosts together in a VLAN
has distinct advantages. For example, with VLANs, you can:

Reduce the size of broadcast domains, thereby enhancing overall network
performance.

Reduce system and network maintenance tasks substantially.
Functionally-related hosts no longer need to physically reside together
to achieve optimal network performance.

Enhance security on your network by segmenting hosts that must transmit
sensitive data.

The way that you group hosts into VLANs is by using the Configuration
utility to create a VLAN and associate physical interfaces with that
VLAN. In this way, any host that sends traffic to a BIG-IP system
interface is logically a member of the VLAN or VLANs to which that
interface belongs.

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/18.html\#unique\_599320773}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/18.html - unique\_599320773}

\sphinxstylestrong{VLANs on a BIG-IP system}

The BIG-IP system is a port-based switch that includes multilayer
processing capabilities. These capabilities enhance standard VLAN
behavior, in these ways:

You can associate physical interfaces on the BIG-IP system directly with
VLANs. In this way, you can associate multiple interfaces with a single
VLAN, or you can associate a single interface with multiple VLANs.

You do not need physical routers to establish communication between
separate VLANs. Instead, the BIG-IP system can process messages between
VLANs.

You can incorporate a BIG-IP system into existing, multi-vendor switched
environments, due to the BIG-IP system’s compliance with the IEEE 802.1q
VLAN standard.

You can combine two or more VLANs into an object known as a VLAN group.
With a VLAN group, a host in one VLAN can communicate with a host in
another VLAN using a combination of Layer 2 forwarding and IP routing.
This offers both performance and reliability benefits.

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/17.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/17.html - conceptid}

\sphinxstylestrong{Introduction to trunks}

A trunk is a logical grouping of interfaces on the BIG-IP system. When
you create a trunk, this logical group of interfaces functions as a
single interface. The BIG-IP system uses a trunk to distribute traffic
across multiple links, in a process known as link aggregation. With link
aggregation, a trunk increases the bandwidth of a link by adding the
bandwidth of multiple links together. For example, four fast Ethernet
(100 Mbps) links, if aggregated, create a single 400 Mbps link.

With one trunk, you can aggregate a maximum of eight links. For optimal
performance, you should aggregate links in powers of two. Thus, you
ideally aggregate two, four, or eight links.

The purpose of a trunk is two-fold:

To increase bandwidth without upgrading hardware

To provide link failover if a member link becomes unavailable

You can use trunks to transmit traffic from a BIG-IP system to another
vendor switch. Two systems that use trunks to exchange frames are known
as peer systems.

How do trunks work?

In a typical configuration where trunks are configured, the member links
of the trunk are connected through Ethernet cables to corresponding
links on a peer system.

This figure shows an example of a typical trunk configuration with two
peers and three member links on each peer:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p13}.jpeg}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

A primary goal of the trunks feature is to ensure that frames exchanged
between peer systems are never sent out of order or duplicated on the
receiving end. The BIG-IP system is able to maintain frame order by
using the source and destination addresses in each frame to calculate a
hash value, and then transmitting all frames with that hash value on the
same member link.

The BIG-IP system automatically assigns a unique MAC address to a trunk.
However, by default, the MAC address that the system uses as the source
and destination address for frames that the system transmits and
receives (respectively), is the MAC address of the lowest-numbered
interface of the trunk.

The BIG-IP system also uses the lowest-numbered interface of a trunk as
a reference link. The BIG-IP system uses the reference link to take
certain aggregation actions, such as implementing the automatic link
selection policy. For frames coming into the reference link, the BIG-IP
system load balances the frames across all member links that the BIG-IP
system knows to be available. For frames going from any link in the
trunk to a destination host, the BIG-IP system treats those frames as if
they came from the reference link.

Finally, the BIG-IP system uses the MAC address of an individual member
link as the source address for any LACP control frames.

\sphinxstylestrong{Overview of LACP}

A key aspect of trunks is Link Aggregation Control Protocol, or LACP.
Defined by IEEE standard 802.3ad, LACP is a protocol that detects error
conditions on member links and redistributes traffic to other member
links, thus preventing any loss of traffic on the failed link. On a
BIG-IP system, LACP is an optional feature that you can configure.

You can also customize LACP behavior. For example, you can specify the
way that LACP communicates its control messages from the BIG-IP system
to a peer system. You can also specify the rate at which the peer system
sends LACP packets to the BIG-IP system. If you want to affect the way
that the BIG-IP system chooses links for link aggregation, you can
specify a link control policy.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 3 - Troubleshoot basic performance issues}
\label{\detokenize{class2/modules/module3:section-3-troubleshoot-basic-performance-issues}}\label{\detokenize{class2/modules/module3::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.01 Recognize when a packet capture is needed within the context of a performance issue}
\label{\detokenize{class2/modules/module3:objective-3-01-recognize-when-a-packet-capture-is-needed-within-the-context-of-a-performance-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

A packet capture can be one of the most powerful tools that an
administrator has at there command. If you are not use to doing packet
captures or have never done one, you should do them in your vLabs as
soon as possible to start becoming proficient.

\sphinxstylestrong{Running tcpdump on a busy system}

\sphinxstylestrong{Important:} The BIG-IP system is designed as an application delivery
network platform and not as a packet capture device. If you intend to
capture traffic under high load conditions, F5 recommends mirroring
traffic to a dedicated sniffing device.

Running tcpdump on a BIG-IP system is considered best effort, as it will
place more load on the CPU and may result in inaccuracies in the tcpdump
output, such as missed packets or packet timestamp irregularities. If
you run tcpdump on a heavily loaded BIG-IP system, the packet capture
process may not capture all matching traffic, and the statistical values
reported by tcpdump may be inaccurate.

If you run tcpdump on a heavily loaded system, F5 recommends using
tcpdump filter expressions to mitigate the potential for missed packets.

\sphinxstylestrong{Determine an appropriate location to take the capture}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/6000/500/sol6546.html}

An administrator can also do a capture from their workstation. The will
gather traffic between the destination and their workstation, which in
most cases is between the virtual server on the LTM and their
workstation. Captures can also be done locally on the F5 BIG-IP
platform. Doing a capture on the BIG-IP LTM is very strategic since you
have the ability to capture both sides of the proxied conversation
between the workstation and the back end server resources. Understanding
which networks the resources are on for both sides of the conversation
will also allow you to narrow the capture using filters in the tcpdump.

F5 recommends that you run tcpdump on a VLAN when you intend to capture
traffic for in-depth troubleshooting on the BIG-IP system. When the VLAN
is specified in the tcpdump syntax, tcpdump can read packets processed
by TMM.

\sphinxstylestrong{Determine the appropriate time to take capture}

\sphinxstylestrong{Command Line Study in the vLabs}

The right time to do a capture can be a catch 22. You need to capture
the issue; so a capture needs to be done while the problem is occurring.
Of course sometimes the problem may only be occurring under peak load.
So doing a capture during peak load may be ineffective due to issues
mentioned in the opening of this section. However most of the time you
can do the capture when the problem is occurring and tightening up the
amount of data you capture by using filters will help with overhead.

\sphinxstylestrong{Given a scenario, determine whether a packet capture is appropriate}

\sphinxstylestrong{Command Line Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

There may be times that determining the source of an issue will not
require the administrator to do a capture. When a problem arises look
first to the status of the BIG-IP and the configuration. If all of the
settings and statistics look fine, you can then check the client
settings and client access restrictions before moving on to a capture of
the network traffic.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.02 Use BIG-IP tools in order to identify potential performance issues}
\label{\detokenize{class2/modules/module3:objective-3-02-use-big-ip-tools-in-order-to-identify-potential-performance-issues}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Differentiate between performance issue types (i.e. Latency, Congestion, broken content)}

\sphinxstylestrong{General Network Study}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

\sphinxstylestrong{Latency}

Latency is the largest cause of slow Web applications over the WAN or
Internet. Latency describes the time delay experienced while a data
packet moves from one point to another, usually caused by physical
distance and high round-trip times. Latency can also be introduced by
compute-intensive processing such as SSL handshaking, bulk
encryption/decryption, and TCP session management. Latency can have a
profound effect on application performance, even over networks with
abundant bandwidth.

\sphinxstylestrong{Congestion}

Network congestion occurs a node or network is processing so much data
that its level of service deteriorates. The BIG-IP platform has some
built in optimizations to help with network congestion. The TCP profile
has a setting to enable Nagles algorithm. Nagles algorithm attempts to
reduce network congestion by aggregating smaller TCP packets into larger
ones.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Establish the frequency of a given issue (random, continuous, isolated, intermittent, repetitive intervals)}

\sphinxstylestrong{General Network Study}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Tracking how often issues occur or for how long an issue is impacting a
function can be a telltale sign to what may be happening. This can be
done through the use of logs, statistics, network captures and
observation.

For instance an administrator wants to load balance a server that is
already functioning in their DMZ. They spin up a second instance of the
server and place both the new and old server behind an LTM pair off of
the DMZ. They use the server’s address on the DMZ network for the
virtual server address on the LTM and place the servers on a new network
behind the LTM, with the LTM acting as the servers default gateway. The
firewall administrators add the new server IP addresses to the rule sets
allowing all the same server traffic to get to the servers on the new
network.

When the servers are brought on-line the users immediately notice a
delay in the transactions to the server. It seems to be taking about 30
seconds longer than before and is consistent on every transaction. In
thinking through the change in architecture, you would not expect that
the F5 platform introduced a 30 delay with each connection. The time it
takes for a DNS query to timeout in many systems is around 30 seconds.
On a deeper look into the logs on the server, it was doing a DNS reverse
lookup and it was timing out. The firewall admin had not added the new
network to the DNS rule on the firewall rule set to allow the network
nodes to query their DNS servers.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Explain how to get performance statistics in addition to the
those shown in the dashboard (Overview - Performance)}

\sphinxstylestrong{GUI Study in the vLabs}

To see additional platform performance information, use the following
steps:

In version 11.x of the BIG-IP Configuration Utility:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Click Statistics.

\item {} 
Click Performance.

\end{enumerate}

In version 10.x of the BIG-IP Configuration Utility:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Click Overview.

\item {} 
Click Performance.

\end{enumerate}

All categories are shown under the \sphinxstylestrong{All} tab or you can see the break
outs of \sphinxstylestrong{System}, \sphinxstylestrong{Connections}, \sphinxstylestrong{Throughput} and \sphinxstylestrong{Cache}.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 4 - Troubleshoot basic device management connectivity issues}
\label{\detokenize{class2/modules/module4:section-4-troubleshoot-basic-device-management-connectivity-issues}}\label{\detokenize{class2/modules/module4::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.01 Verify remote connectivity to the box in order to determine the cause of a management connectivity issue}
\label{\detokenize{class2/modules/module4:objective-4-01-verify-remote-connectivity-to-the-box-in-order-to-determine-the-cause-of-a-management-connectivity-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Isolate potential causes of basic network connectivity issues,
given scenarios related to: client configuration, client network access,
device network access, and network topologies}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

A general knowledge of how devices communicate on IP based networks and
basic configuration settings that are necessary on the client as well as
the server environments are critical to being able to support an ADN
environment. An understanding of how networks are designed and where
devices are connected in a network topology are also critical to
supporting an ADN environment.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Apply connectivity troubleshooting tools (i.e. ping,
traceroute, http/https availability, remote shell access, network based
console access) in the appropriate situation}

\sphinxstylestrong{General Network Study and vLabs Practice}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Understanding of each of these tools functions and when you should use
them to do troubleshooting of issues is key to administration of any
network. An understanding of ways to connect to systems via console to
test connectivity from the remote device on the network is critical as
well.

\sphinxstylestrong{Ping}

Ping is a computer network administration utility used to test the
reachability of a host on an Internet Protocol (IP) network and to
measure the round-trip time for messages sent from the originating host
to a destination computer. Ping operates by sending Internet Control
Message Protocol (ICMP) echo request packets to the target host and
waiting for an ICMP response.

\sphinxstylestrong{Traceroute}

Traceroute is a computer network diagnostic tool for displaying the
route (path) and measuring transit delays of packets across an Internet
Protocol (IP) network. The history of the route is recorded as the
round-trip times of the packets received from each successive host
(remote node) in the route (path); the sum of the mean times in each hop
indicates the total time spent to establish the connection. Traceroute
proceeds unless all (three) sent packets are lost more than twice, then
the connection is lost and the route cannot be evaluated. Traceroute
sends a sequence of three Internet Control Message Protocol (ICMP) Echo
Request packets addressed to a destination host.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.02 Check and interpret port lockdown settings and packet filters in order to determine the cause of a management connectivity issue to a Self-IP}
\label{\detokenize{class2/modules/module4:objective-4-02-check-and-interpret-port-lockdown-settings-and-packet-filters-in-order-to-determine-the-cause-of-a-management-connectivity-issue-to-a-self-ip}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Given a scenario, review port lockdown settings on the Self-IP
to determine the cause of the issue}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/13000/200/sol13250.html}

Port lockdown is a BIG-IP security feature that allows you to specify
particular protocols and services from which the self-IP address defined
on the BIG-IP system can accept traffic.

The port lockdown feature allows you to secure the BIG-IP system from
unwanted connection attempts by controlling the level of access to each
self-IP address defined on the system. Each port lockdown list setting
specifies the protocols and services from which a self-IP can accept
connections. The system refuses traffic and connections made to a
service or protocol port that is not on the list.

\sphinxstylestrong{Port lockdown setting definitions:}

\sphinxstylestrong{Allow Default}

This option allows access for a pre-defined set of network protocols and
services that are typically required in a BIG-IP deployment.

The Allow Default setting specifies that connections to the self-IP
addresses are allowed from the following protocols and services:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Allowed protocol
&
Service
&
Service definition
\\
\hline
OSPF
&
N/A
&
N/A
\\
\hline
TCP
&
4353
&
iQuery
\\
\hline
UDP
&
4353
&
iQuery
\\
\hline
TCP
&
443
&
HTTPS
\\
\hline
TCP
&
161
&
SNMP
\\
\hline
UDP
&
161
&
SNMP
\\
\hline
TCP
&
22
&
SSH
\\
\hline
TCP
&
53
&
DNS
\\
\hline
UDP
&
53
&
DNS
\\
\hline
UDP
&
520
&
RIP
\\
\hline
UDP
&
1026
&
network failover
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

You can also determine the default supported protocols and services
using the following command: \sphinxstyleemphasis{tmsh list net self-allow}

The output will appear similar to the following example:

net self-allow \{
\begin{quote}

defaults \{
\begin{quote}

ospf:any

\sphinxurl{tcp:domain}

\sphinxurl{tcp:f5query}

\sphinxurl{tcp:https}

\sphinxurl{tcp:snmp}

\sphinxurl{tcp:ssh}

udp:520

udp:cap

udp:domain

udp:f5-iquery

udp:snmp
\end{quote}

\}
\end{quote}

\}

\sphinxstylestrong{Allow All}

This option specifies that all connections to the self-IP address are
allowed, regardless of protocol or service.

\sphinxstylestrong{Allow None}

This option specifies that no connections are allowed on the self IP
address, regardless of protocol or service. However, ICMP traffic is
always allowed, and if the BIG-IP systems are configured in a redundant
pair, ports that are listed as exceptions are always allowed from the
peer system.

\sphinxstylestrong{Allow Custom}

This option allows you to specify the protocols and services for which
connections are allowed on the self-IP address. However, ICMP traffic is
always allowed, and if the BIG-IP systems are configured in a redundant
pair, ports that are listed as exceptions are always allowed from the
peer system.

\sphinxstylestrong{Default port lockdown setting}

When creating a self-IP address, the default port lockdown setting in
BIG-IP 10.x is Allow Default. In BIG-IP 11.x, the default port lockdown
setting is \sphinxstylestrong{None}.

Modifying port lockdown settings for a specific self IP using the
Configuration utility
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Click Network.

\item {} 
Click Self-IPs.

\item {} 
Click the relevant self-IP address.

\item {} 
Select the desired setting from the Port Lockdown box.

\item {} 
Click Update.

\end{enumerate}

\sphinxstylestrong{Modifying port lockdown settings using the tmsh utility}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Traffic Management Shell (tmsh) by entering the
following command:\sphinxstyleemphasis{tmsh}  NOTE:If you are currently logged in to the tmsh
shell, you can skip this step.

\item {} 
To modify the port lockdown settings for a self IP address, use the
following command syntax:\sphinxstyleemphasis{modify /net self \textless{}self\_ip\textgreater{} allow-service
\textless{}option\textgreater{}} For example, to change the port lockdown setting for self IP
address 10.10.10.1 to default, you would type the following
command:modify /net self 10.10.10.1 allow-service default

\item {} 
Save the change by typing the following command:
\begin{itemize}
\item {} 
BIG-IP 10.1.0 and later:save sys config

\item {} 
BIG-IP 10.0.x:save config

\end{itemize}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Describe appropriate use cases for the use of port lockdown}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/13000/200/sol13250.html}

For optimal security, F5 recommends using the port lockdown feature to
allow only the protocols or services required for a self-IP address.

If you are managing the BIG-IP platform from one of the Self-IP
addresses rather than using the out of band management interface, you
run the risk of users having access to the Self-IP address on a port
that will allow administration of the BIG-IP platform. All external
facing Self-IP addresses should be restricted to only necessary ports
for the BIG-IP platform to communicate to other necessary BIG-IP
platforms or other necessary network functions such as DNS servers, etc.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.03 Given the use of a remote authentication server, verify proper DNS and NTP settings in order to diagnose a connectivity issue}
\label{\detokenize{class2/modules/module4:objective-4-03-given-the-use-of-a-remote-authentication-server-verify-proper-dns-and-ntp-settings-in-order-to-diagnose-a-connectivity-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Given the use of a remote authentication server, verify proper
DNS and NTP settings in order to diagnose a connectivity issue}

Due to the 201 Exam Blueprint having an obvious mistake with layout or
objectives I have modified this section’s Example Points to reflect the
Objectives from the last blueprint.

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/14.html\#unique\_1887226478}

\sphinxstylestrong{Remote Authentication Intro:}

A significant feature of BIG-IP Local Traffic Manager is its ability to
support Pluggable Authentication Module (PAM) technology. PAM technology
allows you to choose from a number of different authentication and
authorization schemes to use to authenticate or authorize network
traffic.

The goal of PAM technology is to separate an application, such as the
BIG-IP system, from its underlying authentication technology. This means
that you can dictate the particular authentication/authorization
technology that you want the BIG-IP system to use to authenticate
application traffic coming into the BIG-IP system.

To this end, Local Traffic Manager offers several authentication
schemes, known as authentication modules. These authentication modules
allow you to use a remote system to authenticate or authorize
application requests that pass through the BIG-IP system.

The BIG-IP system normally routes remote authentication traffic through
a Traffic Management Microkernel (TMM) switch interface (that is, an
interface associated with a VLAN and a self IP address), rather than
through the management interface. Therefore, if the TMM service is
stopped for any reason, remote authentication is not available until the
service is running again.

\sphinxstylestrong{BIG-IP system authentication modules}

Local Traffic Manager authentication modules that you can implement for
remote authentication are:

\sphinxstylestrong{Lightweight Directory Access Protocol (LDAP)}

Local Traffic Manager can authenticate or authorize network traffic
using data stored on a remote LDAP server or a Microsoft Windows Active
Directory server. Client credentials are based on basic HTTP
authentication (user name and password).

\sphinxstylestrong{Remote Authentication Dial-In User Service (RADIUS)}

Local Traffic Manager can authenticate network traffic using data stored
on a remote RADIUS server. Client credentials are based on basic HTTP
authentication (user name and password).

\sphinxstylestrong{TACACS+}

Local Traffic Manager can authenticate network traffic using data stored
on a remote TACACS+ server. Client credentials are based on basic HTTP
authentication (user name and password).

\sphinxstylestrong{SSL client certificate LDAP}

Local Traffic Manager can authorize network traffic using data stored on
a remote LDAP server. Client credentials are based on SSL certificates,
as well as defined user groups and roles.

\sphinxstylestrong{Online Certificate Status Protocol (OCSP)}

Local Traffic Manager can check on the revocation status of a client
certificate using data stored on a remote OCSP server. Client
credentials are based on SSL certificates.

\sphinxstylestrong{Certificate Revocation List Distribution Point (CRLDP)}

Local Traffic Manager can use CRL distribution points to determine
revocation status.

\sphinxstylestrong{Kerberos Delegation}

Local Traffic Manager can authenticate application traffic when you are
using Microsoft Windows Integrated Authentication.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Given a suspected DNS issue, use appropriate tools to verify proper settings}

\sphinxstylestrong{GUI Study in the vLabs}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/13000/200/sol13205.html}

For the BIG-IP platform to connect to a node by name or to get to any
system for any reason by the server’s DNS name, a DNS server must be
configured on BIG-IP’s settings. The BIG-IP system uses two sources of
information to resolve host names: the hosts file and DNS. The BIG-IP
system first refers to the local /etc/hosts file. If the host name is
not found in the /etc/hosts file, the BIG-IP system uses DNS if
configured to do so. The following procedures help you configure the
BIG-IP system to use DNS.

Using the BIG-IP Configuration utility is the preferred method of
configuring a DNS remote lookup server.

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the BIG-IP Configuration utility.

\item {} 
Click System.

\item {} 
Click Configuration.

\item {} 
Click Device.

\item {} 
Click DNS.

\item {} 
In the DNS Lookup Server List section, type the IP address of your
remote DNS lookup server.

\item {} 
Click Add.

\item {} 
Complete the change by clicking Update.

\end{enumerate}

This same procedure can be used to modify the BIND Forwarder Server List
or DNS Search Domain List. If this setting is not configured then
resolving a DNS name from the BIG-IP platform will fail, including
resolving the name of the remote authentication server for remote
authentication.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Given a suspected DNS issue, use appropriate tools to verify DNS response}

\sphinxstylestrong{GUI Study in the vLabs}

If the DNS issue is related to the BIG-IP platform connecting to a DNS
name you can check to make sure that the system is able to resolve
names. From the command prompt you can do a NSLOOKUP of a server name,
or you can DIG the server name. Both of these tools are found on the
BIG-IP platform.

\sphinxstyleemphasis{nslookup example:}

nslookup www.stonegreyband.com**Server: 192.168.69.1 Address:
192.168.69.1\#53 Non-authoritative answer: www.stonegreyband.com
canonical name = stonegreyband.com. Name:stonegreyband.com
Address: 71.251.96.82

\sphinxstyleemphasis{Dig Example:}

dig www.stonegreyband.com**; \textless{}\textless{}\textgreater{}\textgreater{} DiG 9.8.3-P1 \textless{}\textless{}\textgreater{}\textgreater{}
www.stonegreyband.com;; global options: +cmd;; Got answer:;;
-\textgreater{}\textgreater{}HEADER\textless{}\textless{}- opcode: QUERY, status: NOERROR, id: 24965;; flags: qr rd
ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION
SECTION:;www.stonegreyband.com. IN A;; ANSWER
SECTION:www.stonegreyband.com. 3495 IN CNAME stonegreyband.com.
stonegreyband.com. 495 IN A 71.251.96.82 ;; Query time: 4 msec;;
SERVER: 192.168.69.1\#53(192.168.69.1) ;; WHEN: Thu Jan 9 22:41:06
2014;; MSG SIZE rcvd: 69

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 5 - Open a support ticket with F5}
\label{\detokenize{class2/modules/module5:section-5-open-a-support-ticket-with-f5}}\label{\detokenize{class2/modules/module5::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.01 Identify the appropriate supporting components and severity levels for an F5 support ticket}
\label{\detokenize{class2/modules/module5:objective-5-01-identify-the-appropriate-supporting-components-and-severity-levels-for-an-f5-support-ticket}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Identify the necessary components for all support cases (Qkview
uploaded to iHealth/ or attached to case, serial number of device,
problem description, other supporting data)}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/0000/100/sol135.html}

F5 Technical Support can help resolve issues more quickly when you
provide a full description of the issue and the details of your
configuration. To help you gather all the required information, use the
following guidelines to prepare for opening a case:

\sphinxstylestrong{General Information}

Provide the following information when you open a case with F5 Technical
Support:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
\sphinxstylestrong{A full description of the issue, including the following details:}

\end{enumerate}
\begin{itemize}
\item {} 
The symptoms of the issue

\item {} 
The approximate time the issue first occurred

\item {} 
The number of times the issue has recurred

\item {} 
Any error output provided by the system

\item {} 
Steps to reproduce the issue

\item {} 
Any changes you made to the system before the issue first occurred

\item {} 
Any steps you have attempted to resolve the issue

\end{itemize}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\setcounter{enumi}{1}
\item {} 
\sphinxstylestrong{A description of the impact the issue is having on your site, using
the following definitions:}

\end{enumerate}
\begin{itemize}
\item {} 
Site Down - All network traffic has ceased, causing a critical impact
to your business.

\item {} 
Site at Risk - Primary unit has failed resulting in no redundancy.
Site is at risk of going down.

\item {} 
Performance Degraded - Network traffic is partially functional
causing some applications to be unreachable.

\end{itemize}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\setcounter{enumi}{2}
\item {} 
\sphinxstylestrong{The hours that you are available to work on the issue and any
alternative contacts that can work on the issue if you are not
available.}

\item {} 
\sphinxstylestrong{Remote access information, if possible.}

\end{enumerate}
\begin{itemize}
\item {} 
Remote access to your network environment is important, because it is
the most effective method for collecting information and
troubleshooting technical issues. If you cannot provide remote
access, F5 Technical Support will work directly with you to resolve
the issue over the phone; however, this method can often be more time
consuming and may require file transfers, replication, and additional
testing.

\end{itemize}

Collect the following information from the affected systems and provide
the information when you open the case.

\sphinxstylestrong{qkview or “tech.out” file}
\begin{quote}

The qkview utility is a BIG-IP program that an administrator can use
to automatically collect configuration and diagnostic information
from BIG-IP and Enterprise Manager systems.

Starting in BIG-IP 10.0.0, the qkview utility is an executable
program that generates machine-readable (XML) diagnostic data from
the BIG-IP or Enterprise Manager system and combines the data into a
single compressed tar file. The diagnostic file can then be uploaded
to BIG-IP iHealth, or given to F5 Technical Support to aid in
troubleshooting.

\sphinxstyleemphasis{Note: If you are running BIG-IP version 10.x or later, you can use
BIG-IP iHealth to diagnose a qkview file. BIG-IP iHealth diagnoses
the health and proper operation of your BIG-IP system when you
upload the qkview file to the BIG-IP iHealth website. For more
information, refer to the BIG-IP iHealth website.}
\end{quote}

\sphinxstylestrong{Log files}
\begin{quote}

\sphinxstyleemphasis{Note: The qkview utility automatically gathers 5MB of log files and
includes them with qkview in a .tar output.}

If the systems logs are heavy and more of the logs are needed,
provide all the log files on the system by performing the following
procedure:

Log in to the command line.

Create a tar archive named logfiles.tar.gz in the /var/tmp directory
which contains all the files in the /var/log directory, by typing
the following command:

tar -czpf /var/tmp/logfiles.tar.gz /var/log/*
\end{quote}

\sphinxstylestrong{Packet traces}
\begin{quote}

If the issue involves the network, perform a packet trace while the
issue is occurring and provide the packet trace when you open the
case.

\sphinxstyleemphasis{Note: For more information about performing packet traces with
tcpdump, refer to SOL4714: Performing a packet trace and providing
the results to F5 Technical Support.}
\end{quote}

\sphinxstylestrong{UCS archive}
\begin{quote}

If you cannot give F5 Technical Support remote access to your
system, you may need to provide a UCS archive of the current
configuration. For more information, refer to SOL4423: Overview of
UCS archives.
\end{quote}

\sphinxstylestrong{Core files}
\begin{quote}

Core files contain the contents of the system memory at the time a
crash occurred. If the system has been configured to save core
files, they will be located in the /var/savecore directory (BIG-IP
versions 9.0 through 9.2.5) or /var/core directory (BIG-IP versions
9.3 and later). Provide any existing core files when you open the
case.

\sphinxstyleemphasis{Note: For information about requirements when submitting core files
to F5, refer to SOL10062: Submitting core files for analysis to F5
Technical Support.}
\end{quote}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Identify severity levels and the associated response times}

\sphinxurl{https://www.f5.com/pdf/customer-support/guidelines-and-policies-ds.pdf}

All F5 Network Support Centers uphold the following case severity
definitions and target response times to ensure that the appropriate
resources are used to resolve all technical issues as efficiently as
possible. F5 will endeavor to respond to Severity 1 and Severity 2
issues within one hour. Understanding that unforeseen events could delay
attempts, F5 expects that the majority of Severity 1 and Severity 2
issues will be responded to within this service level. Initial response
is defined as the time from when the F5 case was created to when a
Network Support Engineer first attempts to contact the case contact for
troubleshooting and updates the case log reflecting this action.

\sphinxstylestrong{SEVERITY 1}
\begin{quote}

1-hour response - Software or hardware conditions on your F5 device
are preventing the execution of critical business activities. The
device will not power up or is not passing traffic.
\end{quote}

\sphinxstylestrong{SEVERITY 2}
\begin{quote}

1-hour response - Software or hardware conditions on your F5 device
are preventing or significantly impairing high-level commerce or
business activities.
\end{quote}

\sphinxstylestrong{SEVERITY 3}
\begin{quote}

4-business hour response - Software or hardware conditions on your
F5 device are creating degradation of service or functionality in
normal business or commerce activities.
\end{quote}

\sphinxstylestrong{SEVERITY 4}
\begin{quote}

24-hour response - Questions regarding configurations (“how to”),
troubleshooting non-critical issues, or requests for product
functionality that is not part of the current product feature set.
\end{quote}

When a case is logged as Severity 1, F5 Network Support Managers are
immediately notified to ensure the case is assigned within the
appropriate timeframe to an appropriately skilled Network Support
Engineer.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.02 Given an issue, determine the appropriate severity according to F5 guidelines}
\label{\detokenize{class2/modules/module5:objective-5-02-given-an-issue-determine-the-appropriate-severity-according-to-f5-guidelines}}
\sphinxurl{https://www.f5.com/pdf/customer-support/guidelines-and-policies-ds.pdf}

\sphinxstylestrong{SEVERITY 1}
\begin{quote}

Software or hardware conditions on your F5 device are preventing the
execution of critical business activities. The device will not power
up or is not passing traffic.
\end{quote}

\sphinxstylestrong{SEVERITY 2}
\begin{quote}

Software or hardware conditions on your F5 device are preventing or
significantly impairing high-level commerce or business activities.
\end{quote}

\sphinxstylestrong{SEVERITY 3}
\begin{quote}

Software or hardware conditions on your F5 device are creating
degradation of service or functionality in normal business or
commerce activities.
\end{quote}

\sphinxstylestrong{SEVERITY 4}
\begin{quote}

Questions regarding configurations (“how to”), troubleshooting
non-critical issues, or requests for product functionality that is
not part of the current product feature set.
\end{quote}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.03 Provide quantitative and relevant information appropriate for a given issue}
\label{\detokenize{class2/modules/module5:objective-5-03-provide-quantitative-and-relevant-information-appropriate-for-a-given-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.03 - Distinguish between qualitative/quantitative statements in
order to assemble an accurate problem description}

\sphinxstylestrong{General Network Study}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Quantitative observations are observations that can be precisely
measured. (i.e. There is taking an additional 20 seconds per connection
over the connection times this morning.)

Qualitative observations have more to do with characteristics of what is
being observed. (i.e. It seems to be taking longer to connect than it
did this morning.)


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.03 - Distinguish between relevant/irrelevant information in order to
assemble an accurate problem description}

\sphinxstylestrong{General Network Study}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Is the information that you are gathering relative to the issue you are
experiencing? Troubleshooting can lead to many rat holes where you can
get lost from the real issues.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 6 - Identify and report current device status}
\label{\detokenize{class2/modules/module6:section-6-identify-and-report-current-device-status}}\label{\detokenize{class2/modules/module6::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 6.01 Review the network map in order to determine the status of objects}
\label{\detokenize{class2/modules/module6:objective-6-01-review-the-network-map-in-order-to-determine-the-status-of-objects}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.01 - Explain the status icons of objects on the map}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/1.html\#unique\_1250686602}

The Configuration utility includes a feature known as the network map.
The network map shows a summary of local traffic objects, as well as a
visual map of the virtual servers, pools, and pool members on the BIG-IP
system. For both the local traffic summary and the network map, you can
customize the display using a search mechanism that filters the
information that you want to display, according to criteria that you
specify. The system highlights in blue all matches from a search
operation.

Object summary

When you first open the Network Map screen, the screen displays a
summary of local traffic objects. This summary includes the type of
objects specified with the search mechanism, the number of each type of
object, and, for each object type, the number of objects with a given
status.

The summary displays data for these object types:
\begin{itemize}
\item {} 
Virtual servers

\item {} 
Pools

\item {} 
Pool members

\item {} 
Nodes

\item {} 
iRules

\end{itemize}

\sphinxstyleemphasis{Note: A local traffic summary includes only those objects that are
referenced by a virtual server. For example, if you have configured a
pool on the system but there is no virtual server that references that
pool, the local traffic summary does not include that pool, its members,
or the associated nodes in the summary.}

The diagram below shows an example of a network map screen that
summarizes local traffic objects on the system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p14}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

For each object type listed in the summary, the system shows the number
of objects with each type of status. Table 1.3 shows the various status
indicators that the summary screen can display for a local traffic
object.

Table 1.3 Explanation of status icons in a local traffic summary


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Status indicator
&
Explanation
\\
\hline
\noindent\sphinxincludegraphics{{p2}.png}
&
The objects are enabled and available (able to receive traffic).
\\
\hline
\noindent\sphinxincludegraphics{{p3}.png}
&
The objects are enabled but are currently unavailable. However, the objects might become available later, with no user action required.

An example of an object showing this status is a virtual server whose connection limit has been exceeded. When the number of connections falls below the configured limit, the virtual server becomes available again.
\\
\hline
\noindent\sphinxincludegraphics{{p4}.png}
&
The objects are enabled but offline because an associated object has marked the object as unavailable. To change the status so that the object can receive traffic, you must actively enable the object.
\\
\hline
\noindent\sphinxincludegraphics{{p6}.png}
&
The status of the objects is unknown.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{The network map display}

The network map presents a visual hierarchy of the names and status of
virtual servers, pools, pool members, nodes, and iRules defined on the
system. The map shows all objects in context, starting with the virtual
servers at the top. The Status, Type, and Search settings at the top of
the screen determine the objects that the map includes.

When you position the cursor over an object on the map, the system
presents hover text containing information about the object. When you
position the cursor over the status icon accompanying an object, the
system presents hover text containing information about the object’s
status, text which also appears on the pool’s Properties screen. The
system arranges objects in alphabetic order, and organizes the dependent
objects in a hierarchy. Due to the way that a network map presents
objects in context, the updated screen also shows objects of other
statuses, types, and names that relate to those objects. This is because
a network map always shows objects in context with the objects that
depend on them, and the objects they depend on.

For example, if you have an available virtual server with an available
pool and two pool members, one available and one offline, then selecting
Offline from the Status list causes the system to show the offline pool
member in context with the available virtual server and the available
pool. This is because the available virtual server and the available
pool depend on the offline pool member.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p15}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.01 - Explain what virtual servers, pools, nodes and pool members are}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/2.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/2.html - conceptid}

\sphinxstylestrong{Virtual Server}

A virtual server is a traffic-management object on the BIG-IP system
that is represented by an IP address and a service. Clients on an
external network can send application traffic to a virtual server, which
then directs the traffic according to your configuration instructions.
The main purpose of a virtual server is often to balance traffic load
across a pool of servers on an internal network. Virtual servers
increase the availability of resources for processing client requests.

Not only do virtual servers distribute traffic across multiple servers,
they also treat varying types of traffic differently, depending on your
traffic-management needs. For example, a virtual server can enable
compression on HTTP request data as it passes through the BIG-IP system,
or decrypt and re-encrypt SSL connections and verify SSL certificates.
For each type of traffic, such as TCP, UDP, HTTP, SSL, SIP, and FTP, a
virtual server can apply an entire group of settings, to affect the way
that Local Traffic Manager manages that traffic type.

A virtual server can also enable session persistence for a specific
traffic type. Through a virtual server, you can set up session
persistence for HTTP, SSL, SIP, and MSRDP sessions, to name a few.

Finally, a virtual server can apply an iRule, which is a user-written
script designed to inspect and direct individual connections in specific
ways. For example, you can create an iRule that searches the content of
a TCP connection for a specific string and, if found, directs the
virtual server to send the connection to a specific pool or pool member.

To summarize, a virtual server can do the following:
\begin{itemize}
\item {} 
Distribute client requests across multiple servers to balance server
load

\item {} 
Apply various behavioral settings to a specific type of traffic

\item {} 
Enable persistence for a specific type of traffic

\item {} 
Direct traffic according to user-written iRules

\end{itemize}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/5.html - conceptid}

\sphinxstylestrong{Pool and Pool Members}

A load balancing pool is a logical set of devices, such as web servers,
that you group together to receive and process traffic. Instead of
sending client traffic to the destination IP address specified in the
client request, Local Traffic Manager sends the request to any of the
servers that are members of that pool. This helps to efficiently
distribute the load on your server resources.

When you create a pool, you assign pool members to the pool. A pool
member is a logical object that represents a physical node (server), on
the network. You then associate the pool with a virtual server on the
BIG-IP system. Once you have assigned a pool to a virtual server, Local
Traffic Manager directs traffic coming into the virtual server to a
member of that pool. An individual pool member can belong to one or
multiple pools, depending on how you want to manage your network
traffic.

The specific pool member that the Local Traffic Manager chooses to send
the request to is determined by the load balancing method that you have
assigned to the pool. A load balancing method is an algorithm that Local
Traffic Manager uses to select a pool member for processing a request.
For example, the default load balancing method is Round Robin, which
causes Local Traffic Manager to send each incoming request to the next
available member of the pool, thereby distributing requests evenly
across the servers in the pool.

To configure and manage pools, log in to the BIG-IP Configuration
utility, and on the Main tab, expand Local Traffic, and click Pools.

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/4.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-4-0/4.html - conceptid}

\sphinxstylestrong{Nodes}

A node is a logical object on the BIG-IP Local Traffic Manager system
that identifies the IP address of a physical resource on the network.
You can explicitly create a node, or you can instruct Local Traffic
Manager to automatically create one when you add a pool member to a load
balancing pool.

The difference between a node and a pool member is that a node is
designated by the devices IP address only (10.10.10.10), while
designation of a pool member includes an IP address and a service (such
as 10.10.10:80).

A primary feature of nodes is their association with health monitors.
Like pool members, nodes can be associated with health monitors as a way
to determine server status. However, a health monitor for a pool member
reports the status of a service running on the device, whereas a health
monitor associated with a node reports status of the device itself.

For example, if an ICMP health monitor is associated with node
10.10.10.10, which corresponds to pool member 10.10.10.10:80, and the
monitor reports the node as being in a down state, then the monitor also
reports the pool member as being down. Conversely, if the monitor
reports the node as being in an up state, then the monitor reports the
pool member as being either up or down, depending on the status of the
service running on it.

Nodes are the basis for creating a load balancing pool. For any server
that you want to be part of a load balancing pool, you must first create
a node, that is, designate that server as a node. After designating the
server as node, you can add the node to a pool as a pool member. You can
also associate a health monitor with the node, to report the status of
that server.

To configure and manage nodes, log in to the BIG-IP Configuration
utility, and on the Main tab, expand Local Traffic, and click Nodes.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 6.02 Use the dashboard to gauge the current running status of the system}
\label{\detokenize{class2/modules/module6:objective-6-02-use-the-dashboard-to-gauge-the-current-running-status-of-the-system}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.02 - Interpret each of the statistic types displayed by the dashboard}

\sphinxstylestrong{GUI Study in the vLabs}

The main Dashboard screen is of the system overview. This screen
displays a graphical representation of CPU utilization, Memory
utilization, Connections and Throughput of the system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p16}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.02 - Given a situation, predict the appropriate dashboard statistics}

\sphinxstylestrong{GUI Study in the vLabs}

Understand what situations and which configurations will affect the
different areas of the Dashboard statistics. For example, the more
features that are provisioned on the BIG-IP platform the higher the base
Memory utilization will be. Also, if ASM is running on the BIG-IP the
CPU utilization my get higher as additional policies are added to the
configuration under load.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 6.03 Review log files and identify possible events}
\label{\detokenize{class2/modules/module6:objective-6-03-review-log-files-and-identify-possible-events}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.03 - Given log file snippets, describe an event sequence}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Get familiar with looking at the event logs on the BIG-IP and learn to
reconstruct what has happened recently based on the events in the logs.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.03 - Given log file snippets, identify critical events}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Get familiar with looking at the event logs on the BIG-IP and be able to
identify critical events. This may be hard to do in the lab unless you
are cresting your own system errors. Possible do the opposite and get
used to seeing what is there when all is good and then the errors will
stand out.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 6.04 Use iApps Analytics to gauge the current running status of application services}
\label{\detokenize{class2/modules/module6:objective-6-04-use-iapps-analytics-to-gauge-the-current-running-status-of-application-services}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.04 - Explain the purpose of iApps Analytics}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-4-0/1.html?sr=54633323}

\sphinxstylestrong{What is Analytics?}

Analytics (also called Application Visibility and Reporting) is a module
on the BIG-IP system that lets you analyze performance of web
applications. It provides detailed metrics such as transactions per
second, server and client latency, request and response throughput, and
sessions. You can view metrics for applications, virtual servers, pool
members, URLs, specific countries, and additional detailed statistics
about application traffic running through the BIG-IP system.

Transaction counters for response codes, user agents, HTTP methods,
countries, and IP addresses provide statistical analysis of the traffic
that is going through the system. You can capture traffic for
examination and have the system send alerts so you can troubleshoot
problems and immediately react to sudden changes.

The Analytics module also provides remote logging capabilities so that
your company can consolidate statistics gathered from multiple BIG-IP
appliances onto syslog servers or SIEM devices, such as Splunk.

\sphinxstylestrong{About Analytics profiles}

An Analytics profile is a set of definitions that determines the
circumstances under which the system gathers, logs, notifies, and
graphically displays information regarding traffic to an application.
The Analytics module requires that you select an Analytics profile for
each application you want to monitor. You associate the Analytics
profile with one or more virtual servers used by the application, or
with an iApps application service. Each virtual server can have only one
Analytics profile associated with it.

In the Analytics profile, you customize:
\begin{itemize}
\item {} 
What statistics to collect

\item {} 
Where to collect data (locally, remotely, or both)

\item {} 
Whether to capture the traffic itself

\item {} 
Whether to send notifications

\end{itemize}

The BIG-IP system includes a default Analytics profile called analytics.
It is a minimal profile that internally logs application statistics for
server latency, throughput, response codes, and methods. You can create
custom Analytics profiles for each application if you want to track
different data for each one.

Charts shown in the Overview \textgreater{} Statistics \textgreater{} Analytics screen display the
application data saved for all Analytics profiles associated with iApps
application services or virtual servers on the system. You can filter
the information, for example, by application or URL. You can also drill
down into the specifics on the charts, and click the tabs to further
refine the information in the charts.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.04 - Describe how to capture application statistics}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-4-0/1.html?sr=54633323}

You can examine the statistics on the Analytics charts when Application
Visibility and Reporting (AVR) is provisioned. The system recalculates
the Analytics statistics and updates the charts every five minutes.

Before you can look at the application statistics, you need to have
created an Analytics profile so that the system is capturing the
application statistics internally on the BIG-IP system. You must
associate the Analytics profile with one or more virtual servers (in the
Analytics profile or in the virtual server). If you created an iApp
application service, the template provided allows you to associate the
virtual server. To view Analytics statistics properly, Adobe Flash
Player must be installed on the computer where you plan to view them.

The task summary of how to set up the BIG-IP system to collect
application performance statistics can be found in the “Setting up local
application statistics collection” section of the hyperlinked site.

The system can collect application statistics locally, remotely, or
both. You use these statistics for troubleshooting and improving
application performance.

You can collect application statistics for one or more virtual servers
or for an iApps application service. If virtual servers are already
configured, you can specify them when setting up statistics collection.
If you want to collect statistics for an iApps application service, you
should first set up statistics collection, creating an Analytics
profile, and then create the application service.

The system can send alerts regarding the statistics when thresholds are
exceeded, and when they cross back into the normal range. You can
customize the threshold values for transactions per second, latency,
page load time, and throughput.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{6.04 - Given a current running status, recognize significant statistics}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

Get familiar with looking at the status information in \sphinxstylestrong{Statistics -
Module Statistics - Local Traffic} under the different \sphinxstylestrong{Statistics
Types} drop menu on the BIG-IP and be able to identify significant
statistic levels. This may be hard to do in the lab unless you are
pushing load through the unit. Get used to how the reports look and how
to read them.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 7 - Maintain system configuration}
\label{\detokenize{class2/modules/module7:section-7-maintain-system-configuration}}\label{\detokenize{class2/modules/module7::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.01 Create and restore a UCS archive under the appropriate circumstances}
\label{\detokenize{class2/modules/module7:objective-7-01-create-and-restore-a-ucs-archive-under-the-appropriate-circumstances}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.01 - Discuss scenarios in which restoring a UCS archive is appropriate}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/6.html\#conceptid}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/6.html - conceptid}

Once you have created the configuration data for the BIG-IP system, you
can replicate all of this set of data in a separate file. You can then
use this replicated data later, for these reasons:
\begin{itemize}
\item {} 
As an archive for disaster recovery

\end{itemize}

Using the Archives feature, you can back up the current configuration
data, and if necessary, restore the data at a later time. We highly
recommend that you use this feature to mitigate the potential loss of
BIG- IP system configuration data. To create an archive, you can use the
Configuration utility, which stores the configuration data in a special
file known as a user configuration set, or UCS file. You can then use
the UCS file to recover from any loss of data, in the unlikely event
that you need to do so.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.01 - Discuss the tasks involved in successfully restoring a UCS archive}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/100/sol13132.html?sr=34127482\#restoreui}

There are a few different ways to do a UCS restore on a BIG-IP platform.

\sphinxstylestrong{Restoring configuration data by using the Configuration utility}

Impact of procedure: The BIG-IP system replaces any existing
configuration with the UCS archive file configuration.

If you are restoring a UCS archive on a BIG-IP 6400, 6800, 8400, or 8800
hardware platform other than the system from which the backup was
created, such as when replacing an RMA system, you must perform the
procedure in the “Restoring configuration data from the command line by
using the tmsh utility” section of this article to restore the
configuration.

To restore a configuration in a UCS archive by using the Configuration
utility, review the considerations described in the Considerations for
restoring configuration data section of this article before performing
the following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Click System.

\item {} 
Click Archives.

\item {} 
Click the name of the UCS archive you want to restore.

\item {} 
If the UCS archive is encrypted, type the passphrase for the
encrypted UCS archive file in the Restore Passphrase field. If the
UCS archive is not encrypted, you can skip this step.

\item {} 
To initiate the UCS archive restore process, click Restore.

\item {} 
When the restore process is completed, examine the status page for
any reported errors before proceeding to the next step.

\item {} 
To return to the Archive List page, click OK.

\end{enumerate}

If you restored the UCS archive on a different device and received the
errors noted in the “Considerations for restoring configuration data”
section of this article, you must reactivate the BIG-IP system license.

After relicensing the system, restart the system to ensure that the
configuration is fully loaded. To restart the system, navigate to System
\textgreater{} Configuration, and then click Reboot.

If the system you restored contains the FIPS 140 HSM, you must configure
the FIPS 140 HSM Security World after completing steps 1 through 9. For
additional information about recovering FIPS information after a system
recovery, refer to the Configuring and Maintaining a FIPS Security
Domain chapter in the Platform Guide: 6900 and 8900.

\sphinxstylestrong{Restoring configuration data from the command line by using the tmsh utility}

Impact of procedure: The BIG-IP system replaces any existing
configuration with the UCS archive file configuration.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Log in to tmsh by typing the following command:

\end{enumerate}

\sphinxstyleemphasis{tmsh}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Restore the UCS archive file by using the following command syntax.
Replace \textless{}path/to/UCS\textgreater{} with the full path of the UCS archive file you
want to restore: \sphinxstyleemphasis{load /sys ucs \textless{}path/to/UCS\textgreater{}}

\end{enumerate}

If you do not specify the path, the BIG-IP system performs as if the UCS
archive file is located in the default /var/local/ucs directory.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
If the UCS archive file was encrypted with a passphrase during the
backup, you are prompted to enter the passphrase for the archive
file.

\item {} 
If you are running BIG-IP on a 6400, 6800, 8400, or 8800 hardware
platform, type the following command to switch to the bash shell:

\end{enumerate}

\sphinxstyleemphasis{run /util bash}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Type the following command to verify that the new or replaced secure
shell (SSH) keys from the UCS file are synchronized between the
BIG-IP system and the Switch Card Control Processor (SCCP):

\end{enumerate}

\sphinxstyleemphasis{keyswap.sh sccp}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Type the following command to switch back to tmsh:

\end{enumerate}

\sphinxstyleemphasis{exit}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Restart the system by typing the following command:

\end{enumerate}

\sphinxstyleemphasis{reboot}

If you installed the UCS archive on the same device on which the backup
was created, it loads the restored configuration after the system
restarts. If you restored the backup on a different device and received
the first error noted in the Considerations for restoring configuration
data section of this article, you must reactivate the BIG-IP system
license. Alternatively, you can replace the /config/bigip.license file
with the original bigip.license file that you backed up from the target
system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
If the system you restored contains the FIPS 140 HSM, you must
configure the FIPS 140 HSM Security World after completing steps 1
through 5. For additional information about recovering FIPS
information after a system recovery, refer to the Configuring and
Maintaining a FIPS Security Domain chapter in the Platform Guide:
6900 and 8900.

\end{enumerate}

\sphinxstylestrong{Restoring configuration data on a replacement RMA unit}

F5 recommends that you use the following procedure when you restore the
archive on a different device than the system on which the backup was
created, such as an RMA system. If you do not use this procedure when
restoring the archive on a different device, the configuration load may
fail and the mcpd process generates an error message that appears
similar to the following example to both stdout and the /var/log/ltm
file:

mcpd{[}2395{]}: 01070608:0: License is not operational(expired or digital
signature does not match contents)

F5 expects this message, and you can correct the issue by re-licensing
the system, which is discussed later in the procedure.

Impact of procedure: The BIG-IP system replaces any existing
configuration with the UCS archive file configuration.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Activate the license on the unit according to the steps detailed in
SOL7752: Overview of licensing the BIG-IP system.

\item {} 
Log in to tmsh by typing the following command:

\end{enumerate}

\sphinxstyleemphasis{tmsh}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Restore the UCS archive file by using the following command syntax.
Replace \textless{}path/to/UCS\textgreater{} with the full path of the UCS archive file you
want to restore:

\end{enumerate}

\sphinxstyleemphasis{load /sys ucs \textless{}path/to/UCS\textgreater{} no-license}

If you do not specify the path, the BIG-IP system performs as if the UCS
archive file is located in the default /var/local/ucs directory.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
If the UCS archive file was encrypted with a passphrase during the
backup, you are prompted to enter the passphrase for the archive
file.

\item {} 
If you are running the BIG-IP system on a 6400, 6800, 8400, or 8800
hardware platform, switch to the bash utility by entering the
following command:

\end{enumerate}

run /util bash
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
To verify that the new or replaced SSH keys from the UCS file are
synchronized between the BIG-IP and the SCCP, enter the following
command:

\end{enumerate}

\sphinxstyleemphasis{keyswap.sh sccp}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
To switch back to tmsh, type the following command:

\end{enumerate}

\sphinxstyleemphasis{exit}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Restart the system by typing the following command:

\end{enumerate}

\sphinxstyleemphasis{reboot}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
If the system you restored contains the FIPS 140 HSM, you must
configure the FIPS 140 HSM Security World after completing steps 1
through 5. For additional information about recovering FIPS
information after a system recovery, refer to the Configuring and
Maintaining a FIPS Security Domain chapter in the Platform Guide:
6900 and 8900.

\end{enumerate}

\sphinxstylestrong{Restoring UCS archives on BIG-IP systems running later software versions}

Impact of procedure: The BIG-IP system replaces any existing
configuration with the UCS archive file configuration.

F5 recommends that the BIG-IP system run the same version of the BIG-IP
software from which it was backed up. However, in some cases, it is
possible to restore a UCS archive that was obtained from an earlier
software version on a target BIG-IP system running a later software
version. For example, if you saved a UCS archive on a system running
BIG-IP 10.2.3, it is possible to restore the version BIG-IP 10.2.3
archive file on a BIG-IP system running 11.x. To restore a UCS archive
on a BIG-IP system running a later software version, perform the
following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Verify that a supported upgrade path exists between the software
version from which the UCS archive was obtained and the software
version running on the target system.

\end{enumerate}

For example, there is a supported upgrade path between BIG-IP 10.x and
BIG-IP 11.x. As a result, you can successfully restore a BIG-IP 10.x UCS
archive file on a BIG-IP system running 11.x. However, there is no
supported upgrade path between BIG-IP 9.x and BIG-IP 11.x. As a result,
you cannot restore a BIG-IP 9.x UCS archive file on a BIG-IP system
running 11.x.

For information about supported upgrade paths, refer to the product
release notes for your specific software version.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Review the previous section, Considerations for restoring
configuration data.

\item {} 
Manually copy the UCS archive file to the /var/local/ucs/ directory
on the target system.

\item {} 
Restore the UCS archive on the BIG-IP system:

\end{enumerate}
\begin{itemize}
\item {} 
If you are restoring the archive on a different device than the
system on which the backup was created, follow the “Restoring
configuration data on a replacement RMA unit” procedure.

\item {} 
If you are restoring the archive on a different device than the
system on which the backup was created, follow the “Restoring
configuration data from the command line by using the tmsh utility”
procedure.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.01 - Given a scenario, discuss when it is appropriate to create a
UCS archive}

\sphinxstylestrong{GUI Study in the vLabs}

Any time the system administrator makes changes to the configuration of
the system a UCS archive should be taken prior to the change and after
the change. This will allow for a restore to the point prior to the
change and also provides a backup of the new current state. This should
be done on both the Active and stand by systems in an HA pair.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.02 Identify which high-level tasks can be automated using BIG-IQ}
\label{\detokenize{class2/modules/module7:objective-7-02-identify-which-high-level-tasks-can-be-automated-using-big-iq}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.02 - Identify which high-level tasks can be automated using BIG-IQ}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-iq-adc/manuals/product/bigiq-adc-administration-4-5-0/1.html\#unique\_1381791279}{https://support.f5.com/kb/en-us/products/big-iq-adc/manuals/product/bigiq-adc-administration-4-5-0/1.html - unique\_1381791279}

BIG-IQ Application Delivery Controller (ADC) makes it possible for you
to monitor and manage the Local Traffic Manager (LTM) configuration on
BIG-IP devices. This module helps the user:
\begin{itemize}
\item {} 
Create efficient work flows to view the LTM configurations in a
relational and dynamic user interface.

\item {} 
Control access to configuration objects using fine-grained,
role-based access control (RBAC). This allows administrators to
delegate frequently performed operations (for example, enabling or
disabling pool members) to the correct team member.

\item {} 
Maintain ultimate control of the LTM configuration by providing a
staging option. Delegated team members make all relevant changes,
then the administrator can apply them after a quick review.

\end{itemize}

BIG-IQ ADC has two primary interfaces; Configuration and Deployment.
\begin{itemize}
\item {} 
Use the Configuration interface to work with the settings for the
devices the BIG-IQ device manages. The Configuration interface has
two interactive modes: On BIG-IQ and On BIG-IP.

\item {} 
When BIG-IP is selected, the settings that display for the managed
devices are from the most recent sync. You cannot make changes to
these settings when BIG-IP is selected.

\item {} 
When On BIG-IQ is selected, the settings that display for the managed
devices still include the most recent sync settings, but also include
any revisions you have made.

\item {} 
Use the Deployment interface to apply configuration changes, that
were made on the BIG-IQ device, to the managed devices.

\end{itemize}

To get familiar with BIG-IQ for the exam you should download the VE of
BIG-IQ and set it up in your vLAB environment.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.03 Manage software images}
\label{\detokenize{class2/modules/module7:objective-7-03-manage-software-images}}
\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/k/34/sol34745165.html?sr=54637095}

The BIG-IP system allows you to install and delete additional software
images on separate boot locations, also called volumes. You can then
boot the BIG-IP system to a specific volume and begin processing traffic
using that specific software version. By default, the BIG-IP system has
three volumes that appear similar to the following example:


\bigskip\hrule\bigskip


Sys::Software Status

Volume Product Version Build Active Status


\bigskip\hrule\bigskip


HD1.1 BIG-IP 11.5.2 0.0.141 no complete

HD1.2 BIG-IP 11.5.3 0.0.163 yes complete

HD1.3 none none none no complete

You can find the step-by-step instructions on loading software onto the
BIG-IP in this sections hyperlink.

\sphinxstylestrong{Potential impact of booting a device into another volume}

Booting the BIG-IP platform into another volume may put the system in an
inaccessible state if the circumstances are right. Just because there is
an OS loaded onto a volume does not mean there is any configuration
other than the default configuration on the volume. The out of band
management may still be set to the default IP address and you could lose
your management connection the unit. Or if this was a volume that was
used in the past it will likely be in the state it was in when the
system was booted into another volume. This could mean that it is
running some older configuration that is not the same as the current
configuration in the current volume, or the system could even be
licensed differently leaving some functions of the OS not even enabled.

The \sphinxstylestrong{cpcfg} command allows you to copy a configuration from a
specified source boot location to a specified target boot location. If
the specified target boot location is an earlier version than the source
boot location, the command fails with an error message. If the specified
target boot location is the active boot location, the command fails with
an error message.

\sphinxstylestrong{Common issues related to the migration of a device to a new software version}

\sphinxurl{http://support.f5.com/kb/en-us/solutions/public/13000/100/sol13123.html}

If the device you are migrating, to a new version of software, is not an
HA pair. The upgrade will cause an outage so plan accordingly.

When dealing with an HA pair of devices, upgrades should be done on the
units in the standby state to minimize outages. A hotfix to an existing
software version is normally non-impactful to the operation of the unit,
however it is still a best practice to upgrade the standby unit first,
confirm the upgrade, failover the pair and proceed with upgrading the
now standby unit.

Always follow the F5 Solutions or SOLs for installing the software.

Some common issues that can be impactful to an environment when doing
software upgrades are know issues with the release, iRule compatibility
with the newer version and older version configurations migrating
forward successfully.

Before upgrading to the next desired version of OS the administrator
should read all the release notes to make sure that the known issues on
that release will not impact with the configurations currently running.

iRules are compiled scripts running on the system’s current version of
code. Changes in the OS can change how the iRule functions (or functions
at all) between versions. Testing the OS upgrade in a lab environment is
the best way to make sure there are no failing iRules after an upgrade.
Also reading through the DevCentral reference on Commands and Events by
version is a good plae to start.
\sphinxurl{https://devcentral.f5.com/wiki/iRules.BIGIP\_Commands\_by\_Version.ashx}

When migrating from older releases to a newer major release of OS, there
can be issues with configuration migration to the newer release. You
should always read the release notes and follow the recommended
migration path for the version on the Ask F5 site.
\sphinxurl{http://support.f5.com/kb/en-us.html}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.04 Given an HA pair, describe the appropriate strategy for deploying a new software image}
\label{\detokenize{class2/modules/module7:objective-7-04-given-an-ha-pair-describe-the-appropriate-strategy-for-deploying-a-new-software-image}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.04 - Given an HA pair, describe the appropriate strategy for deploying a new software image}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-upgrade-active-standby-11-4-0/1.html\#unique\_305366860}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-upgrade-active-standby-11-4-0/1.html - unique\_305366860}

The upgrade process involves preparation of the two BIG-IP devices
(Device A and Device B) configured in an active-standby implementation,
followed by the installation and verification of version 11.0 on each
device. When you upgrade each device, you perform several tasks.
Completing these tasks results in a successful upgrade to version 11.0
on both BIG-IP devices, with a traffic group configured properly for an
active-standby implementation.

In a properly configured HA pair of BIG-IP devices, a software upgrade
should always be done on the standby unit in the pair. This allows the
upgrade to be hitless to the extent of nothing greater than a failover
between functioning units in the HA pair.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.05 Understand the processes of licensing, license reactivation, and license modification (add-ons)}
\label{\detokenize{class2/modules/module7:objective-7-05-understand-the-processes-of-licensing-license-reactivation-and-license-modification-add-ons}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.05 - Understand the processes of licensing, license reactivation,
and license modification (add-ons)}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/7000/700/sol7752.html?sr=54637267}

Before you can configure and use the BIG-IP system, you must activate a
valid license on the system. To license the BIG-IP system, you must
perform the following procedures:

Obtaining a registration key

Obtaining a dossier

Activating the license

\sphinxstylestrong{Obtaining a registration key}

Before you can activate the license for the BIG-IP system, you must
obtain a base registration key. The base registration key is a
27-character string that instructs the license server which F5 products
you can license. The base registration key is pre-installed on new
BIG-IP systems. When you connect to the Configuration utility, the
Licensing screen opens and displays the registration key.

\sphinxstylestrong{Obtaining a dossier}

The dossier is an encrypted list of key characteristics used to identify
the platform, which you can obtain from the BIG-IP software. The dossier
is generated by your F5 product after you choose a license activation
method.

\sphinxstylestrong{Activating the license}

If your BIG-IP system is not yet licensed and you connect to the
Configuration utility, you are prompted to enter the base registration
key. Certain systems may require you to enter keys for additional
modules in the Add-On Registration Key List box.

To activate the license on the BIG-IP system using the Configuration
utility, you can use either the automatic activation method or the
manual activation method. The activation method specifies the method by
which you want the system to communicate with the F5 License Server. The
license activation date is unique to the device that the dossier is
derived from.

For step-by-step procedures please review the content via the hyperlink.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.06 Identify which modules are licensed and/or provisioned}
\label{\detokenize{class2/modules/module7:objective-7-06-identify-which-modules-are-licensed-and-or-provisioned}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.06 - Identify which modules are licensed and/or provisioned}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/12000/100/sol12111.html?sr=54657583}

Using the Configuration utility, you can easily display the licensed
software and see which of the software modules are provisioned to run on
the platform. Simply go to System \textgreater{} Resource Provisioning to see the
current configuration.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p17}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.07 Explain how to create a user}
\label{\detokenize{class2/modules/module7:objective-7-07-explain-how-to-create-a-user}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.07 - Explain how to create a user}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/10.html?sr=54654799}

An important part of managing the BIG-IP system is creating and managing
user accounts for BIG-IP system administrators. By creating user
accounts for system administrators, you provide additional layers of
security. User accounts ensure that the system:
\begin{itemize}
\item {} 
Verifies the identity of users logging into the system
(authentication)

\item {} 
Controls user access to system resources (authorization)

\end{itemize}

To enable user authentication and authorization, you assign passwords
and user roles to your user accounts. Passwords allow you to
authenticate your users when they attempt to log in to the BIG-IP
system. User roles allow you to control user access to BIG-IP system
resources.

You can create and store BIG-IP administrative accounts either locally
on the BIG-IP system, or remotely on a separate authentication server.
If you want your user accounts to reside locally on the BIG-IP system,
you create those user accounts on the BIG-IP system and assign user
roles to them.

If you want your user accounts to reside remotely on a separate
authentication server, you do not use the BIG-IP system to create the
accounts. Instead, you use the mechanism provided by the server vendor,
and you use the BIG-IP system strictly to assign user roles to those
remote accounts and to maintain those user role assignments over time.
The types of servers that you can use to remotely store BIG-IP system
user accounts are:
\begin{itemize}
\item {} 
Lightweight Directory Access Protocol (LDAP) servers

\item {} 
Active Directory servers

\item {} 
Remote Authentication Dial-in User Service (RADIUS) servers

\end{itemize}

User account types

There are two types of user accounts on the BIG-IP system: The system
maintenance account and a set of standard user accounts.

The system maintenance account

The system maintenance account is a user account that you maintain using
the Setup utility. The name of the system maintenance account is root.
This account resides locally on the BIG-IP system and grants full access
to BIG-IP system resources. You configure and maintain this account
using the Setup utility and the Configuration utility, respectively.

Standard user accounts

Standard user accounts are user accounts that you create for other
BIG-IP system administrators to use. Standard user accounts can reside
either locally on the BIG-IP system, or remotely on a remote
authentication server. You create and maintain these accounts using the
browser-based Configuration utility or the command line interface.
Creating standard user accounts allows you to assign various user roles
to those accounts as a way to control system administrator access to
BIG-IP system resources. A special standard user account is the admin
account, which automatically exists on any BIG-IP system.

You are not required to have any user accounts other than the root and
admin accounts, but F5 recommends that you create other user
accounts, as a way to intelligently control administrator access to
system resources.

Administrative partitions

When you create configurable objects for the BIG-IP system, you have the
option of putting those objects into administrative partitions. An
administrative partition is a logical container of BIG-IP system objects
such as virtual servers, pools, and monitors. When you first install the
BIG-IP system, a default partition already exists named Common.

By putting objects into partitions, you establish a finer granularity of
access control. Rather than having control over all resources on the
BIG-IP system or no resources whatsoever, users with certain permissions
can control resources within a designated partition only. For example,
users with the role of Operator can mark nodes up or down, but can only
mark those nodes that reside within their designated partition.

User accounts are another type of object that you can put into a
partition. You put user accounts into administrative partitions strictly
for the purpose of giving other users administrative access to those
accounts. For example, you can put user accounts into partition B, and
then assign a set of permissions (known as a user role) to user Jane so
that she is allowed to modify user accounts in partition B.

Each user account on the BIG-IP system has a property known as Partition
Access. The Partition Access property defines the partitions that the
user can access. A user account can have access to either one partition
or all partitions. Access to all partitions is known as universal
access.

This figure shows how partition access can differ for different user
accounts on the BIG-IP system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p18}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

In this example, the BIG-IP system objects reside in multiple
partitions. Note that user accounts are also a type of BIG-IP system
object, and as such, reside in a partition named Users. (Although you
are not required to group user accounts together in a separate
partition, for security purposes F5 highly recommends that you
do so.)

To continue with the example, each user account in partition Users has
access to specific, but different, partitions. Note that user accounts
sjones, cjohnson, and gnelson can access one partition only, while the
tbrown account has universal access.

To summarize, an administrative partition defines a set of objects,
including user accounts, that other administrative users can potentially
manage. This gives computing organizations greater control over user
access to specific objects on the BIG-IP system.

\sphinxstylestrong{What are user roles?}

User roles are a means of controlling user access to BIG-IP system
resources. You assign a user role to each administrative user, and in so
doing, you grant the user a set of permissions for accessing BIG-IP
system resources.

The BIG-IP system offers several different user roles that you can
choose from when assigning a role to an administrative user. A user role
is a property of a user account. Each user role grants a different set
of permissions. More specifically, a user role defines:

The resources that a user can manage

User roles define the types of resources, or objects, that a user can
manage. For example, a user with the role of Operator can enable or
disable nodes and pool members only. By contrast, a user with the Guest
role cannot manage any BIG-IP system resources.

The tasks that a user can perform

For example, a user with the role of Operator can enable or disable
nodes and pool members, but cannot create, modify, or delete them.
Conversely, a user with the Manager role can perform all tasks related
to partitioned objects (except for user accounts), including nodes and
pool members.

Important: A role defines the type of objects that a user can manage and
the tasks that a user can perform on those object types. A role does not
define the set of specific, existing objects that the user can access.

\sphinxstylestrong{User roles on the BIG-IP system}

\sphinxstylestrong{Administrator:} This role grants users complete access to all
partitioned and non-partitioned objects on the system. In addition,
accounts with the Administrator role can change their own passwords.

\sphinxstylestrong{Resource Administrator}: This role grants users complete access to
all partitioned and non-partitioned objects on the system, except user
account objects. In addition, accounts with the Resource Administrator
role can change their own passwords.

\sphinxstylestrong{User Manager}: Users with the User Manager role that have access to
all partitions can create, modify, delete, and view all user accounts
except those that are assigned the Administrator role, or the User
Manager role with different partition access. Accounts with the User
Manager role that have access to all partitions can also change their
own passwords.

Users with the User Manager role that have access only to a single
partition can create, modify, delete, and view only those user accounts
that are in that partition and that have access to that partition only.
For example, if your user account has a User Manager role and has access
to Partition A only, then you can manage only those user accounts that
both reside in and have access to Partition A only.

User accounts with the User Manager role can change their own passwords.

\sphinxstylestrong{Manager}: This role grants users permission to create, modify, and
delete virtual servers, pools, pool members, nodes, custom profiles,
custom monitors, and iRules. These users can view all objects on the
system and change their own passwords.

\sphinxstylestrong{Certificate Manager:} This role grants users permission to manage
device certificates and keys, as well as perform Federal Information
Processing Standard (FIPS) operations.

iRule Manager: This role grants users permission to create, modify, and
delete iRules. Users with this role cannot affect the way that an iRule
is deployed. For example, a user with this role can create an iRule but
cannot assign it to a virtual server or move the iRule from one virtual
server to another. A user with this role can be assigned universal
access to administrative partitions.

\sphinxstylestrong{Application Editor}: This role grants users permission to modify
nodes, pools, pool members, and monitors. These users can view all
objects on the system and change their own passwords.

\sphinxstylestrong{Acceleration Policy Editor}: This role allows users to view, create,
modify, and delete all WebAccelerator policy objects in all
administrative partitions. Users can also view, create, update, and
delete Web Acceleration profiles.

\sphinxstylestrong{Application Security Administrator}: This role grants a user access
to all Application Security Manager security policy objects on the
BIG-IP system. These users have read-only permission for these profile
types: HTTP, FTP, and SMTP. These users have no access to other LTM
objects, nor to any TMOS objects. They can, however, change their own
passwords. With respect to security policy objects, this role is similar
to the Administrator role. You can assign this role only when the BIG-IP
system includes the BIG-IP Application Security Manager component.

\sphinxstylestrong{Web Application Security Editor:} This role allows a user to
configure or view most parts of the Application Security Manager
component, in a specified administrative partition only. Specifically,
these users have limited access to LTM objects, namely read-only
permission for these profile types: HTTP, FTP, and SMTP.

These users have no access to other LTM objects, nor to any TMOS
objects. They can, however, change their own passwords.

You can assign this role only when the BIG-IP system includes the
Application Security Manager component.

\sphinxstylestrong{Operator}: This role grants users permission to enable or disable
nodes and pool members. These users can view all objects and change
their own passwords.

\sphinxstylestrong{Auditor}: This role grants users permission to view all configuration
data on the system, including logs and archives. Users with this role
cannot create, modify, or delete any data, nor can they view SSL keys or
user passwords.

\sphinxstylestrong{Guest}: This role grants users permission to view all objects on the
system except for sensitive data such as logs and archives. Users with
this role can change their own passwords.

\sphinxstylestrong{No Access}: This role prevents users from accessing the system.

\sphinxstylestrong{Local user account creation}

You can create a new user in the GUI as well as tmsh. To create a user
in the GUI, go to System \textgreater{} Users and then click Create.

When you create a local user account, you must give the account a name
and a password. You must also set the user role, either by retaining the
default user role or by assigning a new one. The default user role for
local, non-system maintenance accounts is No Access.

Only users who have been granted the Administrator or User Manager role
can create user accounts. If the user role assigned to your account is
Administrator, you can create a user account in any partition on the
system. If the user role assigned to your account is User Manager, you
can create a user account in any partition to which you have access.

\sphinxstylestrong{Properties of a local BIG-IP system user account}

\sphinxstylestrong{User Name:} Specifies the name of the user account. The BIG-IP system
is case-sensitive, which means that names such as JONES and Jones are
treated as separate user accounts. No default value

\sphinxstylestrong{Partition:} When viewing the properties of an existing user account,
displays the name of the partition in which the user account resides.
All partitionable BIG-IP system objects (including user account objects)
have the Partition property. Note that you cannot edit the value of this
setting. No default value

\sphinxstylestrong{Password}: Specifies a password that the user will use to log in to
the BIG-IP system. No default value

\sphinxstylestrong{Role}: Specifies the user role that you want to assign to the user
account. Default Value No Access

\sphinxstylestrong{Partition Access}: Specifies the partition to which the user has
access when logged on to the BIG-IP system. If you have permission to do
so, you can assign this value to a new user account, or change this
value on an existing user account. This setting appears only when the
user role for the account is not Administrator. (Accounts with the
Administrator role always have universal partition access, that is,
access to all partitions.) Default Value All

\sphinxstylestrong{Terminal Access}: Specifies the level of access to the BIG-IP system
command line interface. Possible values are: Disabled and Advanced
shell. Users with the Administrator or Resource Administrator role
assigned to their accounts can have advanced shell access, that is,
permission to use all BIG-IP system command line utilities, as well as
any Linux commands. Default Value Disabled

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 7.08 Explain how to modify user properties}
\label{\detokenize{class2/modules/module7:objective-7-08-explain-how-to-modify-user-properties}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{7.08 - Explain how to modify user properties}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-4-0/10.html?sr=54654799}

Using the Configuration utility, you can easily display a list of
existing local user accounts and view the properties of an individual
account. Only users who have been granted the Administrator or User
Manager roles can view the settings of other user accounts.

If the user role assigned to your account is Administrator, you can view
any user account on the BIG-IP system, in any partition. If the user
role assigned to your account is User Manager, you can view any user
account in any partition to which you have access on the BIG-IP system.

To summarize, depending on their own partition access, users with a User
Manager role can do some or all of the following:
\begin{itemize}
\item {} 
Change another user’s password

\item {} 
Change another user’s user role

\item {} 
Change the partition in which the user can access objects (applies
only to users who have both a User Manager role and access to all
partitions)

\item {} 
Enable or disable terminal access

\end{itemize}

\sphinxstylestrong{Local user account modification}

You use the Configuration utility to modify the properties of any
existing local user account, other than the root account. When modifying
user accounts, consider the following:
\begin{itemize}
\item {} 
Only users who have been granted either the Administrator or User
Manager role can modify user accounts other than their own account.

\item {} 
A user with the User Manager role can modify only those accounts that
reside in the partition to which that user has access. For example,
if user nelson has a User Manager role and has access to partition B
only, he can modify only those user accounts that reside in partition
B. Even in this case, however, for user accounts in partition B, user
nelson cannot modify a user’s Partition Access property. If, however,
user nelson has a User Manager role and has access to all partitions,
he can modify all user accounts on the system. This includes changing
another user’s Partition Access property.

\item {} 
Users with any role but No Access can modify their own user accounts
to change the password. These users cannot modify any other
properties of their own user accounts. \sphinxstyleemphasis{Note: When a user changes his
own password, the system automatically logs the user off of the
Configuration utility. The system then requires the user to use the new
password for subsequent logins. This behavior applies even when the new
password matches the old password.}

\item {} 
Users with the role of User Manager can modify all of the properties
of their own user accounts, except their user role and partition
access.

\end{itemize}

If you have an Administrator user role, you can also change some
properties of the root account. Specifically, you can change the
password of the root account, and you can enable or disable access to
the BIG-IP system through SSH.

\sphinxstyleemphasis{Warning: The Administrator user role provides access to the BIG-IP
system prompt. If a user with the Administrator user role is currently
logged on to the system, and you change the user role to a role other
than Administrator or Resource Administrator, the user can still run
commands at the BIG-IP system prompt until he or she logs off of the
system.}

\sphinxstylestrong{Delete local user accounts}

If the account you are using has the Administrator or User Manager user
role, you can delete other local user accounts. A user with the
Administrator role can delete any user account on the BIG-IP system in
any partition. A user with the User Manager role can delete user
accounts on the BIG-IP system in only those partitions to which she has
access.

When you delete a local user account, you remove it permanently from the
local user-account database on the BIG-IP system.

\sphinxstyleemphasis{Note: You cannot delete the admin user account, nor can you delete the
user account with which you are logged in.}

\sphinxstyleemphasis{Warning: The Administrator user role provides access to the BIG-IP
system prompt. If a user with the Administrator user role is currently
logged in to the system and you delete the user account, the user can
still run commands at the BIG-IP system prompt until he or she logs off
of the system.}

\sphinxstylestrong{Remote user account management}

Rather than store user accounts locally on the BIG-IP system, you can
store them on a remote authentication server. In this case, you create
all of your standard user accounts (including user names and passwords)
on that remote server, using the mechanism supplied by that server’s
vendor.

Once you have created each user account on the remote server, you can
then use the BIG-IP system to assign authorization properties (user
role, partition access, and terminal access) for each account, for the
purpose of controlling user access to BIG-IP system resources.

\sphinxstyleemphasis{Important: You can assign authorization properties to remotely-stored
user accounts on a group basis. You can then use the single
configuration file (SCF) feature to propagate those properties to other
BIG-IP devices on the network.}

The Configuration utility stores all local and remote access control
information in the BIG-IP system’s local user-account database. When a
user whose account information is stored remotely logs into the BIG-IP
system and is granted authentication, the BIG-IP system then checks its
local database to determine the access control properties that you
assigned to that user.

\sphinxstyleemphasis{Note: The Configuration utility refers to remote user accounts as
external users. An external user is any user account that is stored on a
remote authentication server.}

\sphinxstyleemphasis{Important: Only users with the role of Administrator can manage user
roles for remote user accounts. Also, if a user with a local user
account is logged on to the BIG-IP system, and you subsequently switch
the system from local authentication to remote authentication, the local
user remains authenticated until the user’s login session terminates.}

\sphinxstylestrong{Remote user-account server specification}

One of the tasks you perform with the Configuration utility is to
specify the type of remote user-account server that currently stores
your remote user accounts. The available server types that you can
specify are:
\begin{itemize}
\item {} 
Active Directory or Lightweight Directory Access Protocol (LDAP)

\item {} 
Remote Authentication Dial-In User Service (RADIUS)

\item {} 
Terminal Access Controller Access-Control System Plus (TACACS+)

\end{itemize}

When you specify the type of remote server, you can also configure some
server settings. For example, you can specify the user role you would
like the BIG-IP system to assign to a remote account if you do not
explicitly assign one.

Once you have configured the remote server, if you want any of the
remote accounts to have a non-default user role, you can explicitly
assign a user role to those accounts.

If the remote authentication server is an Active Directory or LDAP
server and is set up to authenticate SSL traffic, there is an additional
feature that you can enable. You can configure the BIG-IP system to
perform the server-side SSL handshake that the remote server would
normally perform when authenticating client traffic. In this case, there
are some preliminary steps you must perform to prepare for remote
authentication using SSL.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 8 - Manage existing system and application services}
\label{\detokenize{class2/modules/module8:section-8-manage-existing-system-and-application-services}}\label{\detokenize{class2/modules/module8::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 8.01 Modify and manage virtual servers}
\label{\detokenize{class2/modules/module8:objective-8-01-modify-and-manage-virtual-servers}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.01 - Given a proposed virtual server configuration change, outline
the scope of the change and for which connections those changes will
affect (active connections, new connections, persisted sessions)}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

This topic would be an example of an existing virtual server
configuration that is being modified. If you were to add a profile or an
iRule to a virtual server what would be the impact to the existing or
new client connections.

Build out a basic virtual server on the LTM and see what different
profile changes do to client connections.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.01 - Given a description of an application, identify the correct
virtual server configured for it (HTTP/HTTPS, TCP/UDP, VLANs enabled,
route-domain)}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

With a description of an application can you tell how a virtual server
will need to be configured? For example if you had an SSL protected
virtual server and needed to do cookie insert persistence. How would
this be configured at a high level? The virtual server would have to
terminate the SSL traffic with a Clientside SSL profile, to be able to
apply the http profile, so that you can process the http traffic to
insert a cookie into the header.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.01 - Given a situation where a virtual server configuration change
did not appear to immediately take effect, determine why}

\sphinxstylestrong{GUI Study in the vLabs}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. For most questions like these you must have
exposure to supporting the BIG-IP platform in a production environment
or understand many of the different issues that may arise around the
topic and the best practice method of solving the issue. Hands-on study
is the best way to master these types of topics.

This topic has to do with recognizing that changing settings on a
virtual server may not immediately look as if anything changed. The
scope of the change and behavior of the type of change will define who
and how the clients will be affected.

Some changes do not affect existing connections only the new connections
after the change is made will be affected.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 8.02 Modify and manage pools}
\label{\detokenize{class2/modules/module8:objective-8-02-modify-and-manage-pools}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.02 - Distinguish between disabling a member and forcing it down}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/300/sol13310.html}

The BIG-IP system designates two terms for network devices to which a
BIG-IP system load balances traffic: nodes and pool members. A node is
identified as the network device’s IP address, such as 10.10.10.10. A
pool member is identified as the network device’s IP address, the
service port on which the pool member is listening, and the name of the
pool to which it belongs. For example: myPool:10.10.10.10:80.

You can set the node and pool members to a Disabled or Forced Offline
state. When you interrupt access to a network device for maintenance,
you should change the state of the node to Disabled or Forced Offline.
If the node is set to Disabled or Forced Offline, any pool member in the
BIG-IP configuration that uses that same IP address is also set to
Disabled or Forced Offline. Alternatively, when you disrupt only some
services on a device, you should change the state of the affected pool
members to Disabled or Forced Offline. For example, if you want to
change the state of the HTTP, HTTPS, and FTP pool members using the
server IP 10.0.0.10, you should disable or force the 10.0.0.10 node
offline. If you want to only change the state of the HTTP pool members
running on address 10.0.0.10 and port 80, you should disable or force
all 10.0.0.10:80 pool members offline.

When set to Disabled, a node or pool member continues to process
persistent and active connections. It can accept new connections only if
the connections belong to an existing persistence session.

When set to Forced Offline, a node or pool member allows existing
connections to time out, but no new connections are allowed.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.02 - Determine use cases for disabling a member}

\sphinxstylestrong{GUI Study in the vLabs}

If the administrator needs to make changes, such as configuration
maintenance, to a server, that is the resource of a pool, but wants to
gracefully allow users to finish what they are doing, Then they should
sett the pool resource to Disabled.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.02 - Determine use cases for forcing down a member}

\sphinxstylestrong{GUI Study in the vLabs}

If the administrator needs take a resource out of a pool immediately due
to a critical misconfiguration or system error that is impacting
business, they can set the resource to Forced Offline.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.02 - Given a situation where a pool member has been disabled but
still appears to be receiving traffic, determine the cause}

\sphinxstylestrong{GUI Study in the vLabs}

Setting the pool resource to Disabled will allow the current users to
finish their sessions but not start new connections to this resource
unless the virtual server is using persistence. If the virtual server is
using persistence then the persistence record will be honored until it
expires. Thus the administrator could disable a pool member and that
member can still receive new connections from the existing persisted
clients.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{8.02 - Articulate the characteristics of a pool member that has been
disabled or forced offline (Such as for new connections, persisted
connections, etc.)}

\sphinxstylestrong{GUI Study in the vLabs}

Setting the pool resource to Disabled will allow the current users to
finish their sessions but not start new connections to this resource
unless the virtual server is using persistence. Setting the pool
resource to Forced Offline will allow current connections to finish but
will not allow any new connections to the even if persistence is
configured on the virtual server. If the Administrator needs to stop all
connections immediately from a pool resource with out any completion of
the current connections. Then removing the pool member from the pool
will kill all connections immediately. This is not recommended for
day-to-day maintenance but is an option for emergencies.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Conclusion}
\label{\detokenize{class2/modules/module8:conclusion}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

This document is intended as a study guide for the F5 201 - TMOS
Administration exam. This study guide is not an all-inclusive document
that will guarantee a passing grade on the exam. It is intended
to be a living doc and any feedback or material that you feel should be
included, to help exam takers better prepare, can be sent to
\sphinxhref{mailto:F5CertGuides@f5.com}{F5CertGuides@f5.com}.

Thank you for using this study guide to prepare the F5 201 - TMOS
Administration exam and good luck with your certification goals.

Thanks

\sphinxstylestrong{Eric Mitchell}

Sr. Systems Engineer - Global SI


\chapter{F5 201 - TMOS Administration Labs 08/11/2020}
\label{\detokenize{class3/class3:f5-201-tmos-administration-labs-08-11-2020}}\label{\detokenize{class3/class3::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

These exercises are design to reinforced the concepts outlined in the \sphinxstylestrong{TMOS Administration} exam blueprint.  F5 certification exams are designed to required hands-on experience to pass the test and these exercises will help you deal with exam questions requiring you to interpret configuration and other outputs from the BIG-IP.

Exam blueprints can be found on the F5 Support site at:
\sphinxurl{https://support.f5.com/csp/article/K29900360\#301a}

This class covers the following topics:
\begin{itemize}
\item {} 
Packet Processing and Virtual Server Processing Order

\item {} 
Virtual Server and Pool Behavior and Status

\item {} 
Administrative Troubleshooting of the BIG-IP

\item {} 
Support, Analytics and iApps

\item {} 
Managing the BIG-IP

\item {} 
Modifying and Managing Pools and Virtual Servers

\end{itemize}

Expected time to complete: \sphinxstylestrong{4 hours}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Lab 1 \textendash{} Accessing the Lab, Networking and BIG-IP Traffic Flow}
\label{\detokenize{class3/module1/module1:lab-1-accessing-the-lab-networking-and-big-ip-traffic-flow}}\label{\detokenize{class3/module1/module1::doc}}
In this module you will access the configure networking, packet filters and virtual servers to help you understand how BIG-IP processes traffic.  You will pass traffic through the BIG-IP and observe which objects
items process or block the traffic under various circumstances.
\begin{description}
\item[{Overview of the lab environment}] \leavevmode\begin{itemize}
\item {} 
Logging on to UDF

\item {} 
Lab layout

\item {} 
Accessing the images

\end{itemize}

\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.01}] \leavevmode\begin{itemize}
\item {} 
Explain the relationship between interfaces, trunks, VLANs, self-IPs, routes and their status/statistics

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{1.02}] \leavevmode\begin{itemize}
\item {} 
Determine expected traffic behavior based on configuration

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Accessing the Lab Environment}
\label{\detokenize{class3/module1/lab1:accessing-the-lab-environment}}\label{\detokenize{class3/module1/lab1::doc}}

\subsubsection{Accessing the UDF labs}
\label{\detokenize{class3/module1/lab1:accessing-the-udf-labs}}
You will be access the labs using the F5 Unified Demo Framework (UDF).  Chrome is the preferred browser for access.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Open your browser, preferably Chrome and navigate to F5 UDF \sphinxurl{https://udf.f5.com/courses}
\begin{itemize}
\item {} 
Select the \sphinxstylestrong{Non-F5 Users} option and log in using you UDF credentials.

\end{itemize}

\end{enumerate}

\begin{sphinxadmonition}{important}{Important:}
You should retain these credentials, as they will be required to any access future F5 UDF courses you attend in the F5 UDF environment
\end{sphinxadmonition}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
You should see the event(s) under \sphinxstylestrong{Happening now}. Find the NGINX 101 Workshop event and click on the \sphinxstylestrong{Launch} link at the far right.

\item {} 
Click the \sphinxstylestrong{Join} button.  \sphinxstyleemphasis{Manage SSH Keys should not be required. (change this?)}

\item {} 
At the top you will see \sphinxstylestrong{Documentation} and \sphinxstylestrong{Deployment}.
- In the \sphinxstylestrong{Documentation} section you can elect to leave the session, see how long the session will last and other documentation
- Click on the \sphinxstylestrong{Deployment} tab. The VM instances will take a minute to provision and will be ready when you have a green arrow.

\item {} 
To access an instance, click the “Access” link and select the type of access you want from the drop-down menu

\item {} 
\sphinxstylestrong{NOTE}: To paste into the web shell use \sphinxstylestrong{ctrl-shift-v}

\end{enumerate}


\subsubsection{Lab Environment}
\label{\detokenize{class3/module1/lab1:lab-environment}}
\begin{sphinxadmonition}{important}{Important:}
The F5 201 lab guide is written with the assumption that the lab jumpbox will be used as the client for testing and accessing the BIG-IPs.  Although you are welcome to use the direct access links provided for configuring and viewing the BIG-IPs.
\end{sphinxadmonition}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

\sphinxstylestrong{Components}
&
** Mgmt IP **
&
\sphinxstylestrong{Access}
&
\sphinxstylestrong{Username}
&
\sphinxstylestrong{Password}
\\
\hline
bigip01
&
10.1.1.4
&
GUI
&
admin
&
f5UDFrocks!
\\
\hline&&
SSH
&
admin
&
f5UDFrocks!
\\
\hline
bigip02
&
10.1.1.5
&
GUI
&
admin
&
f5UDFrocks!
\\
\hline&&
SSH
&
admin
&
f5UDFrocks!
\\
\hline
ubu-jumpbox
&&
RDP
&
f5studen
&
f5UDFrocks!
\\
\hline
NGLAMP
&
10.1.1.7
&
SSH
&
f5student
&
f5UDFrocks!
\\
\hline&
10.1.1.7
&
webmin
&
f5student
&
f5UDFrocks!
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Accessing the Jumpbox BIG-IP VE System Configuration}
\label{\detokenize{class3/module1/lab1:accessing-the-jumpbox-big-ip-ve-system-configuration}}
Go to the \sphinxstylestrong{Components} tab and select the \sphinxstylestrong{Access} drop down menu and select \sphinxstylestrong{XRDP}.  Log on with the credentials in the table above.

\noindent\sphinxincludegraphics{{lab-jumpbox-access}.png}

Access your BIG-IP and verify it is configured properly.

From the jumpbox open a new Web browser and access \sphinxurl{https://10.1.1.4}. Log into the BIG-IP VE
system using the following credentials:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Username: admin
Password: f5UDFrocks
\end{sphinxVerbatim}

Check the upper left-hand corner and ensure you are on the active device
the status should be \sphinxstylestrong{ONLINE (ACTIVE)}. Most deployments are
active-standby and either device could be the active device.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Virtual Servers} and verify your virtual
server states. They should match the image below.

\noindent\sphinxincludegraphics{{201ex211t1-virtuals}.png}

\begin{sphinxadmonition}{note}{Note:}
This BIG-IP has been pre-configured and the \sphinxstylestrong{purple\_vs}
virtual server is down on purpose.
\end{sphinxadmonition}

If everything is in order go on to the \sphinxstylestrong{Networking the BIG-IP lab}.


\subsection{Networking the BIG-IP}
\label{\detokenize{class3/module1/lab2:networking-the-big-ip}}\label{\detokenize{class3/module1/lab2::doc}}
You should be familiar with networking on the BIG-IP.  BIG-IP has a L3 switching architecture built in to the appliances and VEs.  For the 201 certification test you should understand how, interfaces, trunks, VLANs (tagged and untagged) and self IPs work together on a BIG-IP.

In this lab you will review the interfaces, create a tagged VLAN and add a self IP to the VLAN to give you a feel for how these object are configured.  You will configure the objects using TMUI (BIG-IP GUI interface), but you will also see the TMSH commands.


\subsubsection{Review the BIG-IP Interfaces}
\label{\detokenize{class3/module1/lab2:review-the-big-ip-interfaces}}
On the sidebar expand the \sphinxstylestrong{Network} tab.  Here you will see all the networking selections for the BIG-IP.

Click on \sphinxstylestrong{Interfaces} or click on \sphinxstylestrong{Interface List} on the pop out menu.  Here you will see the status and configuration of the interfaces.  For statistical information you would click on the \sphinxstylestrong{Statistics} tab on the top bar.


\subsubsection{Create a Tagged VLAN}
\label{\detokenize{class3/module1/lab2:create-a-tagged-vlan}}
VLANs on the BIG-IP can be tagged (802.1q) or untagged.  VLANs are required to have an interface assigned to them and a tag (if the Interfaces is Tagged).

On the \sphinxstylestrong{Network} sidebar click on \sphinxstylestrong{VLANs} or select \sphinxstylestrong{VLAN List} from the pop out menu.  Here you will see a list of the currently configured VLANs and the interfaces assigned to them.
\begin{itemize}
\item {} 
Create a new VLAN by selecting the \sphinxstylestrong{Create} to the upper right of the list.

\item {} 
Give the new VLAN a name:   \sphinxstylestrong{test-vlan}

\item {} 
Assign the VLAN a tag:      \sphinxstylestrong{40}

\item {} 
In the Resources section select the Interface: \sphinxstylestrong{1.3}

\item {} 
In the Resources section select the Tagging: \sphinxstylestrong{Tagged}

\item {} 
\sphinxstylestrong{Add} the interface.

\item {} 
Hit \sphinxstylestrong{Finished} at the bottom.

\end{itemize}

\begin{sphinxadmonition}{note}{TMSH}

tmsh create net vlan test\_vlan tag 40 interfaces add \{ 1.3 \{ tagged \} \}
\end{sphinxadmonition}

Once complete you should see the following:

\noindent\sphinxincludegraphics{{vlan-list}.png}


\subsubsection{Assign a Self IP to a VLAN}
\label{\detokenize{class3/module1/lab2:assign-a-self-ip-to-a-vlan}}
Self IPs are assign to VLANs to define L3 broadcast domains.  By default, Self IP addresses will respond only to ICMP traffic (port lockdown set to None).  Self IPs are defined as non-floating and floating.  Non-floating self IPs fail when the BIG-IP system fails. Floating self IPs will fail over to other BIG-IPs in the device service cluster and send out a gratuitous ARP to change L2 MAC address tables of the switching architecture.

To assign a self IP, go to \sphinxstylestrong{Network \textgreater{}\textgreater{} Self IPs \textgreater{}\textgreater{} Self IP List} from the sidebar and select \sphinxstylestrong{Create}.
\begin{itemize}
\item {} 
You will name your self IP:  \sphinxstylestrong{test\_selfIP}

\item {} 
You will give your self IP the following address: \sphinxstylestrong{10.1.30.245}

\item {} 
With a netmask of: \sphinxstylestrong{255.255.255.0}

\item {} 
Assign the self IP to the VLAN you just created:  \sphinxstylestrong{test\_vlan}

\item {} 
Note the \sphinxstylestrong{Port Lockdown} setting and the \sphinxstylestrong{Traffic Group}

\item {} 
Select \sphinxstylestrong{Finished} when you are done.

\end{itemize}

\begin{sphinxadmonition}{note}{TMSH}

tmsh create net self test\_selfIP address 10.1.30.245/24 vlan test\_vlan
\end{sphinxadmonition}

Once complete you should see the following:

\noindent\sphinxincludegraphics{{selfip_list}.png}

\sphinxstyleemphasis{Q1. What will happen to the IP addresses if the BIG-IP goes down?}


\subsection{Packet Processing Lab}
\label{\detokenize{class3/module1/lab2b:packet-processing-lab}}\label{\detokenize{class3/module1/lab2b::doc}}

\subsubsection{Open BIG-IP TMSH and TCPDump session}
\label{\detokenize{class3/module1/lab2b:open-big-ip-tmsh-and-tcpdump-session}}
In this task, you will open two SSH sessions to the BIG-IP. One for TMSH
commands and the other for a tcpdump of the client-side network.

Open a terminal window (window1) from the shortcut bar at the
bottom of the jumpbox.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ssh root@10.1.1.4
password: default
\end{sphinxVerbatim}

Use tcpdump to monitor traffic from the client (10.1.10.51) destined to
\sphinxstylestrong{ftp\_vs} (10.1.10.100)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}nni client\PYGZus{}vlan host \PYG{l+m}{10}.1.10.7 and \PYG{l+m}{10}.1.10.100
\end{sphinxVerbatim}

Open another terminal window (window2) and use \sphinxstylestrong{tmsh} to display the
connection table.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ssh root@10.1.1.4
password: default
\end{sphinxVerbatim}

At the TMOS prompt \sphinxstylestrong{(tmos)\#}

\begin{sphinxadmonition}{note}{TMSH}

show sys connection
\end{sphinxadmonition}

Do you see any connections from the jumpbox 10.1.1.7 to 10.1.1.245:22 in the connection table?

\sphinxstyleemphasis{Q1. Why are the ssh management sessions not displayed in connection
table?}


\subsubsection{Establish ftp connection}
\label{\detokenize{class3/module1/lab2b:establish-ftp-connection}}
In this task you will open a third terminal window and establish an FTP
session through the \sphinxstylestrong{ftp\_vs} virtual server. With the connection
remaining open you will view the results in window1 (tcpdump) and
window2 (tmsh).

Open a third command/terminal window (window3).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ftp \PYG{l+m}{10}.1.10.100
\end{sphinxVerbatim}

In the first terminal window ( window1) you should see something similar to the tcpdump captured
below.

\noindent\sphinxincludegraphics{{201ex211t2a-tcpdump}.png}

\sphinxstyleemphasis{Q1. In the tcpdump above, what is client IP address and port and the
server IP address port?}

In window2 (tmsh) run the \sphinxstylestrong{show sys conn} again, but strain out the
noise of other connections (mirrored and selfIP) by just looking at
connections from your jumpbox.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
show sys conn cs\PYGZhy{}client\PYGZhy{}addr \PYG{l+m}{10}.1.10.7
\end{sphinxVerbatim}

The connection table on window2 will show the client-side and
server-side connection similar to below:

\noindent\sphinxincludegraphics{{201ex211t2b-shsysconn}.png}

\sphinxstyleemphasis{Q2. What is source ip and port as seen by ftp server in the example
above?}

\sphinxstyleemphasis{Q3. What happened to the original client IP address and where did
10.1.20.249 come from?}

\begin{sphinxadmonition}{hint}{Hint:}
You will have to review the configuration of \sphinxstylestrong{ftp\_vs} to  determine the answer to question 3.
\end{sphinxadmonition}


\subsection{Packet Filter Lab}
\label{\detokenize{class3/module1/lab3:packet-filter-lab}}\label{\detokenize{class3/module1/lab3::doc}}
You are going to test how packet filters impact packet processing by
creating a packet filter to block ftp connections to 10.1.10.100.


\subsubsection{Create a packet filter}
\label{\detokenize{class3/module1/lab3:create-a-packet-filter}}
Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} Rules} and \sphinxstylestrong{Create} a filter using
the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Name}
&
Block\_ftp
\\
\hline
\sphinxstylestrong{Order}
&
First
\\
\hline
\sphinxstylestrong{Action}
&
Discard
\\
\hline
\sphinxstylestrong{Destination Hosts and Networks}
&
10.1.10.100
\\
\hline
\sphinxstylestrong{Destination Port List}
&
21 (FTP)
\\
\hline
\sphinxstylestrong{Logging}
&
Enabled
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Make sure you select \sphinxstylestrong{Add} after entering a host/network or a port.


\subsubsection{Test the FTP packet filter}
\label{\detokenize{class3/module1/lab3:test-the-ftp-packet-filter}}
Ensure ftp connection is currently established to \sphinxstylestrong{10.1.10.100}.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} General} and select \sphinxstylestrong{Enable} and
then \sphinxstylestrong{Update}.

\sphinxstyleemphasis{Q1. Was the existing ftp connection in the connection table affected?   Why?}

Quit ftp and clear virtual server statistics by going to \sphinxstylestrong{Local Traffic
\textgreater{} Virtual Servers \textgreater{} Statistic}, select the virtual server and hit
\sphinxstylestrong{Reset}.

Attempt to establish an ftp connection to 10.1.10.100.
Watch tcpdump capture you built in window1.

\sphinxstyleemphasis{Q2. Was ftp connection successful? Why?}

\sphinxstyleemphasis{Q3. What did tcpdump reveal? Did the connection timeout or reset?}

\sphinxstyleemphasis{Q4. What did virtual server statistics for} \sphinxstylestrong{ftp\_vs} \sphinxstyleemphasis{reveal? Why are
counters not incrementing?}

\sphinxstyleemphasis{Q5. Prioritize the packet processing order below from 1-7:}

Virtual Server\_\_\_ SNAT\_\_\_ AFM/Pkt Filter\_\_\_ NAT\_\_\_ Existing
Connections\_\_\_ Self IP\_\_\_ Drop \_\_\_

Review the Packet Filter Logs and Packet Filter Statistics, then disable
the Packet Filters.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} Statistics} and review the
information.

Go to \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Packet Filters} and review the information.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} General} and select \sphinxstylestrong{Disable} and
then \sphinxstylestrong{Update}


\subsection{Virtual Server Packet Processing}
\label{\detokenize{class3/module1/lab4:virtual-server-packet-processing}}\label{\detokenize{class3/module1/lab4::doc}}

\subsubsection{Create additional Virtual Servers}
\label{\detokenize{class3/module1/lab4:create-additional-virtual-servers}}
Create a wildcard virtual server and pool, test and observe various
traffic under different configurations to determine how virtual servers
process new inbound connections. You will be using tcpdump from window1,
virtual server statistics, as well as a browser to determine behavior.

Create \sphinxstylestrong{wildcard\_vs} \sphinxstylestrong{10.1.10.100:*} with a \sphinxstylestrong{TCP} profile, \sphinxstylestrong{Automap} and a
pool named \sphinxstylestrong{wildcard\_pool} with the following member \sphinxstylestrong{10.1.20.11:*}

To create the wildcard pool, go to \sphinxstylestrong{Local Traffic \textgreater{} Pools \textgreater{} Pool List}
and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Name}
&
wildcard\_pool
\\
\hline
\sphinxstylestrong{Address}
&
10.1.20.11
\\
\hline
\sphinxstylestrong{Port}
&
*
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{sphinxadmonition}{hint}{Hint:}
Don’t forget to \sphinxstylestrong{Add} the pool member to the \sphinxstylestrong{New Members} box
before you hit \sphinxstylestrong{Finished.}
\end{sphinxadmonition}

To create the wildcard virtual server, go to \sphinxstylestrong{Local Traffic \textgreater{} Virtual
Server} and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
\sphinxstylestrong{wildcard\_vs}
\\
\hline
\sphinxstylestrong{Destination}
&
10.1.10.100
\\
\hline
\sphinxstylestrong{Service Port}
&
*
\\
\hline
\sphinxstylestrong{Source Address Translation}
&
Automap
\\
\hline
\sphinxstylestrong{Default Pool}
&
wildcard\_pool
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Don’t forget to hit \sphinxstylestrong{Finished.}

You didn’t need to enter the source addresses allowed. Go to your new virtual
server and look at the \sphinxstylestrong{Source} to see what the default default is source addresses
allowed.


\subsubsection{Testing Virtual Server Packet Processing Behavior}
\label{\detokenize{class3/module1/lab4:testing-virtual-server-packet-processing-behavior}}
Many of your virtual servers have the same virtual address. You will now
test various behaviors.

Clear virtual server stats.

Observe connection statistics (VS stats) after each of the following tasks.

Browse to \sphinxurl{http://10.1.10.100:8080}

\sphinxstyleemphasis{Q1. Which VS is used for web traffic over port 8080?}

FTP to 10.1.10.100

\sphinxstyleemphasis{Q2. Which VS is used for FTP traffic?}

Browse to \sphinxurl{http://10.1.10.100}

\sphinxstyleemphasis{Q3. Which VS is used for this web traffic the default HTTP port? What
port was used?}

Clear virtual server stats.

Modify the \sphinxstylestrong{wildcard\_vs} to only allow connections from a \sphinxstylestrong{Source}
of 10.1.10.0/24.

\begin{sphinxadmonition}{note}{Note:}
The source address your jumpbox shoud be connecting from is 10.1.10.51
\end{sphinxadmonition}

Browse to \sphinxurl{http://10.1.10.100}

Observe connection statistics (VS stats)

\sphinxstyleemphasis{Q4. Which VS is used for web traffic?}

Clean up your modifications

Clear virtual server stats.

Modify \sphinxstylestrong{wildcard\_vs} to include the default \sphinxstylestrong{Source} of 0.0.0.0/0.


\section{Lab 2 \textendash{} Virtual Server and Pool Status and Behavior}
\label{\detokenize{class3/module2/module2:lab-2-virtual-server-and-pool-status-and-behavior}}\label{\detokenize{class3/module2/module2::doc}}
You are the administrator of a pair of BIG-IPs with a number of virtual
servers pre-configured. In this lab you will determine how traffic is
processed and take a look at various virtual server states and some
reasons a virtual server may not be working.
\begin{description}
\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.02-1.06}] \leavevmode\begin{itemize}
\item {} 
Identify the reason a virtual server is not working as expected

\item {} 
Identify the reason a pool member has been marked down by health monitors

\item {} 
Identify a pool member not in the active priority group

\item {} 
Identify traffic diverted due to persistence record

\item {} 
Identify the current configured state of the pool member

\item {} 
Identify a persistence issue

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Virtual Server Status}
\label{\detokenize{class3/module2/lab1:virtual-server-status}}\label{\detokenize{class3/module2/lab1::doc}}

\subsubsection{Test Disabled Virtual Servers}
\label{\detokenize{class3/module2/lab1:test-disabled-virtual-servers}}
In this task, you will disable and enable various virtual servers and
note the behavior.

Disable \sphinxstylestrong{www\_vs} from the \sphinxstylestrong{Virtual Server List} or from within the
\sphinxstylestrong{www\_vs} GUI interface.

Open \sphinxstylestrong{Local} \sphinxstylestrong{Traffic \textgreater{} Virtual Servers} and hover over status icons.

From window2 (TMSH) type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{show} \PYG{n}{ltm} \PYG{n}{virtual}
\PYG{n}{show} \PYG{n}{ltm} \PYG{n}{virtual} \PYG{n}{www\PYGZus{}vs}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q1. What is the Availability of} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{? What is the state?}

\sphinxstyleemphasis{Q2. What symbol is used to represent} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{status?}

\sphinxstyleemphasis{Q3. Would you expect browsing to} \sphinxstylestrong{http://10.1.10.100} \sphinxstyleemphasis{to work?}

\sphinxstyleemphasis{Q4. Can you ping the virtual IP?}

Clear virtual server stats and browse to \sphinxstylestrong{http://10.1.10.100}

Observe the tcpdump (window1) and connection statistics in the Virtual
Server statics GUI interface.

\sphinxstyleemphasis{Q5. Did the site work? What did the tcpdump show?}

\sphinxstyleemphasis{Q6. Did statistics counters for any virtual increment?}

\sphinxstyleemphasis{Q7. Why do you think the} \sphinxstylestrong{wildcard\_vs} \sphinxstyleemphasis{didn’t pick up the packets?}

Disable \sphinxstylestrong{wildcard\_vs} and note the State and Availability of the
virtual servers.

\sphinxstyleemphasis{Q8. What symbol is used to represent} \sphinxstylestrong{wildcard\_vs}?   \sphinxstyleemphasis{Why is the
symbol a square?}

\sphinxstyleemphasis{Q9. What is the Reason given for current state?}

Establish ftp connection to 10.1.10.100 and ensure successful login:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{root}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{default}
\end{sphinxVerbatim}

Disable \sphinxstylestrong{ftp\_vs}.

\sphinxstyleemphasis{Q10. Does ftp session still work?   Why?}

Open another window and establish ftp connection to 10.1.10.100.

\sphinxstyleemphasis{Q11. Did new ftp session establish connection?   Why not?}

\begin{sphinxadmonition}{important}{Important:}
Make sure all virtual servers are \sphinxstylestrong{Enabled} before continuing.
\end{sphinxadmonition}


\subsubsection{Virtual Server Connection Limits and Status}
\label{\detokenize{class3/module2/lab1:virtual-server-connection-limits-and-status}}
In this task, you will set the connection limit for the FTP virtual
server to 1 and note the status and behavior of different connection
scenarios.

Modify \sphinxstylestrong{ftp\_vs} for connection limit of 1. The \sphinxstylestrong{Connection Limit}
option can be found under the \sphinxstylestrong{Advanced} virtual server menus.

Establish ftp connection to \sphinxstylestrong{10.1.10.100} and hold the logon open.

\sphinxstyleemphasis{Q1. Does FTP session work?}

\sphinxstyleemphasis{Q2. What is the virtual server symbol and status of} \sphinxstylestrong{ftp\_vs}\sphinxstyleemphasis{?}

Open another window and establish a second ftp connection to
\sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q3. Did new ftp session establish connection? Why not?}

\sphinxstyleemphasis{Q4. Did tcpdump capture a connection reset?}

\sphinxstyleemphasis{Q5. Quit all FTP sessions and note} \sphinxstylestrong{ftp\_vs} \sphinxstyleemphasis{status.}


\subsection{Pool Member and Virtual Servers}
\label{\detokenize{class3/module2/lab2:pool-member-and-virtual-servers}}\label{\detokenize{class3/module2/lab2::doc}}
In this exercise, you will determine the effects of monitors, and on the status of pools members and virtual servers.  You will also review the hierarchal effects of changes in status of various configuration objects.


\subsubsection{Create a new monitor}
\label{\detokenize{class3/module2/lab2:create-a-new-monitor}}
Create \sphinxstylestrong{mysql} monitor for testing.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Monitors} and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Name}
&
mysql\_monitor
\\
\hline
\sphinxstylestrong{Parent Monitor}
&
mysql
\\
\hline
\sphinxstylestrong{Interval}
&
15
\\
\hline
\sphinxstylestrong{Timeout}
&
46
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Effects of Monitors on Members, Pools and Virtual Servers}
\label{\detokenize{class3/module2/lab2:effects-of-monitors-on-members-pools-and-virtual-servers}}
Go to \sphinxstylestrong{Local Traffic \textgreater{} Pools \textgreater{} www\_pool} and assign ths
\sphinxstylestrong{mysql\_monitor} to the pool.

Observe availability status of \sphinxstylestrong{www\_pool.} The pool status
momentarily changes to \sphinxstylestrong{Unknown}.

\sphinxstyleemphasis{Q1. Since the} \sphinxstylestrong{mysql\_monitor} \sphinxstyleemphasis{will fail, how long will it take to
mark the pool offline?}

Go to \sphinxstylestrong{Local Traffic \textgreater{} Pool \textgreater{} www\_pool} and then \sphinxstylestrong{Member} from the
top bar and open member \sphinxstylestrong{10.1.20.13:80} and note the status of the
monitors.

Open \sphinxstylestrong{Local Traffic -\textgreater{} Network Map -\textgreater{} Show Map}

\sphinxstyleemphasis{Q2. What is the icon and status of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

\sphinxstyleemphasis{Q3. What is the icon and status of} \sphinxstylestrong{www\_pool}\sphinxstyleemphasis{?}

\sphinxstyleemphasis{Q4. What is the icon and status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members?}

\sphinxstyleemphasis{Q5. How does the status of the pool configuration effect the virtual
server status?}

Clear the virtual server statistics.

Browse to \sphinxstylestrong{http://10.1.10.100} and note the browser results,
statistics and tcpdump.

Disable \sphinxstylestrong{www\_vs} and clear the statistics and ping the virtual
server.

\sphinxstyleemphasis{Q6. What is the icon and status of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

Browse to \sphinxstylestrong{http://10.1.10.100} and note the browser results,
statistics and tcpdump..

\sphinxstyleemphasis{Q7. Did traffic counters increment for} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

Q8. What is the difference in the tcpdumps between Offline (Disabled) vs
Offliine (Enabled)?

\begin{sphinxadmonition}{important}{Important:}
Make sure all virtual servers are \sphinxstylestrong{Enabled} before continuing.
\end{sphinxadmonition}


\subsubsection{More on status and member specific monitors}
\label{\detokenize{class3/module2/lab2:more-on-status-and-member-specific-monitors}}
Go to \sphinxstylestrong{Local Traffic \textgreater{} Pool \textgreater{} www\_pool} and then \sphinxstylestrong{Member} from the
top bar and open member \sphinxstylestrong{10.1.20.13:80.} Enable the \sphinxstylestrong{Configuration:
Advanced} menus.

\sphinxstyleemphasis{Q1. What is the status of the Pool Member and the monitors assigned to
it?}

In \sphinxstylestrong{Health Monitors} select \sphinxstylestrong{Member Specific} and assign the
\sphinxstylestrong{http} monitor and \sphinxstylestrong{Update.}

Go to the \sphinxstylestrong{Network Map}.

\sphinxstyleemphasis{Q2. What is the status of} \sphinxstylestrong{www\_vs}, \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and the pool
members?   Why?}

Browse to \sphinxstylestrong{http://10.1.10.100} and note results of browser and
tcpdump.

\sphinxstyleemphasis{Q3. Did the site work?}

\sphinxstyleemphasis{Q4. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

\begin{sphinxadmonition}{important}{Important:}
After completing this task remove \sphinxstylestrong{mysql\_monitor} from the
\sphinxstylestrong{www\_pool} health monitors
\end{sphinxadmonition}


\subsection{Load Balancing}
\label{\detokenize{class3/module2/lab3:load-balancing}}\label{\detokenize{class3/module2/lab3::doc}}

\subsubsection{Static Load Balancing}
\label{\detokenize{class3/module2/lab3:static-load-balancing}}
In the task, you will look and the various effects of different load
balancing configurations.

Open the \sphinxstylestrong{www\_pool Members} tab.

Note the load balancing method on the pool and the \sphinxstylestrong{Ratio} and
\sphinxstylestrong{Priority} settings on the members. Select each member and update them
to the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Member}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Ratio}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Priority}
\\
\hline
10.1.20.11
&
5
&
10
\\
\hline
10.1.20.12
&
1
&
10
\\
\hline
10.1.20.13
&
1
&
5
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Go to Local \sphinxstylestrong{Traffic \textgreater{} Pools \textgreater{} Statistics} and clear the \sphinxstylestrong{www\_pool}
statistics.

Browse to \sphinxstylestrong{http://10.1.10.100} and refresh or \sphinxstylestrong{\textless{}ctrl\textgreater{} F5} several
times.

\sphinxstyleemphasis{Q1. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

\sphinxstyleemphasis{Q2. Did member} \sphinxstylestrong{10.1.20.11} \sphinxstyleemphasis{receive the most traffic?   Why not?}

Under the \sphinxstylestrong{Members} tab change \sphinxstylestrong{Load Balancing Method} to \sphinxstylestrong{Ratio
(member)} then \sphinxstylestrong{Update}.

Clear stats for \sphinxstylestrong{www\_pool} and browse \sphinxstylestrong{http://10.1.10.100} several
times.

\sphinxstyleemphasis{Q3. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

\sphinxstyleemphasis{Q4. Did member} \sphinxstylestrong{10.1.20.11} \sphinxstyleemphasis{receive the most traffic?}


\subsubsection{Priority Group Activation}
\label{\detokenize{class3/module2/lab3:priority-group-activation}}
Change \sphinxstylestrong{Priority Group Activation} to less than 2 and \sphinxstylestrong{Update}.

Clear stats for \sphinxstylestrong{www\_pool} and browse to \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q1. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

On the pool statistics page, select member \sphinxstylestrong{10.1.20.11:80} and change
the \sphinxstylestrong{State} to \sphinxstylestrong{Disable.}

Clear the statistics for the \sphinxstylestrong{www\_pool} and browse to
\sphinxstylestrong{http://10.1.10.100} several times.

\sphinxstyleemphasis{Q2. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?  Why?}

\sphinxstyleemphasis{Q3. Would the results have been different if 10.1.20.11:80 had been
marked offline or marked with a yellow triangle?}

\begin{sphinxadmonition}{important}{Important:}
Once you have complete the lab, change then \sphinxstylestrong{Load
Balancing Method} to \sphinxstylestrong{Round Robin}, \sphinxstylestrong{Priority Group} to
\sphinxstylestrong{Disabled}, and \sphinxstylestrong{Enable} pool member \sphinxstylestrong{10.1.20.11:80}
\end{sphinxadmonition}


\subsubsection{Effects of Persistence on Load Balancing}
\label{\detokenize{class3/module2/lab3:effects-of-persistence-on-load-balancing}}
In this task, you will enable persistence on the \sphinxstylestrong{www\_vs} and see the
effects of persistence on load balancing. You will also see where to
view persistence records that are maintain by the BIG-IP

Enable a \sphinxstylestrong{Persistence Profile} on \sphinxstylestrong{www\_vs} by opening the virtual
server and selecting the \sphinxstylestrong{Resources} tab.

Assign the following persistence profiles:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Default} \PYG{n}{Persistence} \PYG{n}{Profile}\PYG{p}{:}  \PYG{n}{cookie}
\PYG{n}{Fallback} \PYG{n}{Persistance\PYGZus{}Profile}\PYG{p}{:} \PYG{n}{source\PYGZus{}addr}
\end{sphinxVerbatim}

Did you see an error requiring an HTTP profile? Correct the error by assigning the HTTP profile to the virtual server.

\sphinxstyleemphasis{Q1. Why was a http profile required?}

Clear stats for \sphinxstylestrong{www\_pool} and browse to \sphinxstylestrong{http://10.1.10.100}

\sphinxstyleemphasis{Q2. Was traffic evenly distributed to all} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members? Why
not?}

In the web page under \sphinxstylestrong{HTTP Request and Response Information} is
the \sphinxstylestrong{Display Cookie} link. Select the \sphinxstylestrong{Display Cookie} link to view the cookie created by the BIG-IP.

\begin{sphinxadmonition}{note}{Note:}
You may have to scroll down the web page to find the link.
\end{sphinxadmonition}

Open \sphinxstylestrong{Statistic \textgreater{} Module Statistics \textgreater{} Local Traffic \textgreater{} Persistence
Records}

Click on pool member displayed on persistence record and \sphinxstylestrong{Disable} the
pool member.

Browse to \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q3. Did you persist to the Disabled member?  Why?}

Change status of persisted pool member to \sphinxstylestrong{Forced Offline}

The cookie persisted records should still exist.  Browse to \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q4. Does traffic continue to persist to the member Forced Offline?}

\sphinxstyleemphasis{Q5. If cookies were disable on your browser would persistence still
work?  Why?}

\begin{sphinxadmonition}{note}{TMSH}

An Alternate method to display persistence is:

\sphinxstylestrong{tmsh show ltm persistence persist-records}
\end{sphinxadmonition}


\section{Lab 3 \textendash{} Troubleshooting the BIG-IP}
\label{\detokenize{class3/module3/module3:lab-3-troubleshooting-the-big-ip}}\label{\detokenize{class3/module3/module3::doc}}
You are the administrator of a pair of BIG-IPs with a number of virtual
servers pre-configured. In this lab you will look at troubleshooting methodologies
for various issues.
\begin{description}
\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{2.01-2.05}] \leavevmode\begin{itemize}
\item {} 
Perform an End User Diagnostic per F5 documentation and collect the output

\item {} 
Interpret the LCD Warning Messages

\item {} 
Identify a possible hardware issue within the log files

\item {} 
Force an active unit to standby under the appropriate circumstances

\item {} 
Understand the relationship between interfaces, trunks, VLANs and
their status/statistics

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{3.01-3.02}] \leavevmode\begin{itemize}
\item {} 
Perform a packet capture within the context of a performance issue

\item {} 
Use BIG-IP tools in order to identify potential performance issues

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{4.01-4.03}] \leavevmode\begin{itemize}
\item {} 
Verify remote connectivity to the box in order to determine the cause of a management connectivity issue

\item {} 
Check and interpret port lockdown settings and packet filters in order to determine the cause of a management connectivity issue

\item {} 
Given the use of a remote authentication server, verify proper DNS and NTP settings in order to diagnose a connectivity issue

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{20 minutes}


\subsection{Trouble-shooting Hardware}
\label{\detokenize{class3/module3/lab1:trouble-shooting-hardware}}\label{\detokenize{class3/module3/lab1::doc}}
Review what you have learned about troubleshooting hardware.

\begin{sphinxadmonition}{note}{Note:}
If you are doing the labs during a class you can skip Exercise 3.1 as it does not require the lab environment.  These are review questions only.
\end{sphinxadmonition}


\subsubsection{End User Diagnostics}
\label{\detokenize{class3/module3/lab1:end-user-diagnostics}}
\sphinxstyleemphasis{Q1. What three methods are available for running EUD on F5 Hardware?}

\sphinxstyleemphasis{Q2. How do you determine EUD version?}

\sphinxstyleemphasis{Q3. What is the filename and location of the EUD output?}


\subsubsection{LCD Panel}
\label{\detokenize{class3/module3/lab1:lcd-panel}}
\sphinxstyleemphasis{Q1. How do you halt the unit via the LCD panel?}

\sphinxstyleemphasis{Q2. Holding the} \sphinxstylestrong{X} \sphinxstyleemphasis{for 4 seconds does what?}

\sphinxstyleemphasis{Q3. Holding the Check button for 4 seconds does what?}


\subsubsection{Hardware Log Files}
\label{\detokenize{class3/module3/lab1:hardware-log-files}}
\sphinxstyleemphasis{Q1. What is the filename and location of the logs for LTM?}

\sphinxstyleemphasis{Q2. Where will power supply, fan and hard disk related issues be logged?}


\subsubsection{HA and Failover}
\label{\detokenize{class3/module3/lab1:ha-and-failover}}
\sphinxstyleemphasis{Q1. Is failover sometimes used to determine issues related to hardware
or software?}

\sphinxstyleemphasis{Q2. How do you initiate failover to standby unit?}

\sphinxstyleemphasis{Q3. What persistence profile cannot be mirrored?}

\sphinxstyleemphasis{Q4. What two connections types are re-mirrored after failback?}

\sphinxstyleemphasis{Q5. When would you recommend using connection mirroring?}

\sphinxstyleemphasis{Q6. Where is connection mirroring configured?}

\sphinxstyleemphasis{Q7. Where is persistence mirroring configured?}

\sphinxstyleemphasis{Q8. What tmsh command is used to view mirrored connections?}

\sphinxstyleemphasis{Q9. What tmsh command is used to view mirrored persistence?}

\sphinxstyleemphasis{Q10. What can be the cause of primary unit returning to active state
after initiating failover to standby?}


\subsection{tcpdump Packet Capture}
\label{\detokenize{class3/module3/lab2:tcpdump-packet-capture}}\label{\detokenize{class3/module3/lab2::doc}}
In this exercise are going to perform \sphinxstylestrong{tcpdump} packet captures and
review the results.


\subsubsection{Packet Captures of multiple interfaces simultaneously}
\label{\detokenize{class3/module3/lab2:packet-captures-of-multiple-interfaces-simultaneously}}
Open SSH session window1, and enter on one line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{ni} \PYG{n}{client\PYGZus{}vlan} \PYG{o}{\PYGZhy{}}\PYG{n}{eXs} \PYG{l+m+mi}{0} \PYG{o}{\PYGZhy{}}\PYG{n}{w} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{dump}\PYG{o}{.}\PYG{n}{cap} \PYG{o}{\PYGZam{}} \PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{ni}
\PYG{n}{server\PYGZus{}vlan} \PYG{o}{\PYGZhy{}}\PYG{n}{eXs} \PYG{l+m+mi}{0} \PYG{o}{\PYGZhy{}}\PYG{n}{w} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{dump2}\PYG{o}{.}\PYG{n}{cap} \PYG{o}{\PYGZam{}}
\end{sphinxVerbatim}

This starts two tcpdumps, one on the \sphinxstylestrong{client\_vlan} and one on the \sphinxstylestrong{server\_vlan}

Browse to \sphinxstylestrong{http://10.1.10.100}.

Type \sphinxstylestrong{fg} then \sphinxstylestrong{\textless{}cr\textgreater{}} then \sphinxstylestrong{\textless{}crtl\textgreater{} c}.

Again, type \sphinxstylestrong{fg} then \sphinxstylestrong{\textless{}cr\textgreater{}} then \sphinxstylestrong{\textless{}crtl\textgreater{} c} then:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{r} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{dump}\PYG{o}{.}\PYG{n}{cap} \PYG{o}{\PYGZam{}} \PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{r} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{dump2}\PYG{o}{.}\PYG{n}{cap}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q1. What is the alternate method for capturing two interfaces
simultaneously?}

\sphinxstyleemphasis{Q2. What interface does 0.0 represent?}

\sphinxstyleemphasis{Q3. What interface typically represents the management interface?}

\sphinxstyleemphasis{Q4. What is recommended method for packet captures on high load system?}

\sphinxstyleemphasis{Q5. Will tcpdump capture PVA accelerated traffic?}


\subsection{Performance Statistics}
\label{\detokenize{class3/module3/lab3:performance-statistics}}\label{\detokenize{class3/module3/lab3::doc}}

\subsubsection{Observing performance statistics}
\label{\detokenize{class3/module3/lab3:observing-performance-statistics}}
Open \sphinxstylestrong{Statistics \textgreater{}\textgreater{} Performance} page

\begin{sphinxadmonition}{note}{Note:}
Stats are available for System, Connections, Throughput and Cache
\end{sphinxadmonition}

\sphinxstyleemphasis{Q1. What is the longest time interval available for performance
statistics?}


\subsection{Connectivity Troubleshooting}
\label{\detokenize{class3/module3/lab4:connectivity-troubleshooting}}\label{\detokenize{class3/module3/lab4::doc}}

\subsubsection{Connectivity troubleshooting tools}
\label{\detokenize{class3/module3/lab4:connectivity-troubleshooting-tools}}
Disable all virtual servers with the \sphinxstylestrong{10.1.10.100} virtual address and
clear stats. Ping \sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q1. Was echo response received?}

\sphinxstyleemphasis{Q2. What is the status of the virtual servers?}

Enable all virtual servers with the \sphinxstylestrong{10.1.10.100} virtual address.

The \sphinxstylestrong{purple\_vs} is currently Offline (Enabled). Ping the virtual at
\sphinxstylestrong{10.1.10.105}.

\sphinxstyleemphasis{Q3. Was echo response received?}


\subsection{Self IP Port Lockdown and more}
\label{\detokenize{class3/module3/lab5:self-ip-port-lockdown-and-more}}\label{\detokenize{class3/module3/lab5::doc}}

\subsubsection{Effects of Port Lockdown}
\label{\detokenize{class3/module3/lab5:effects-of-port-lockdown}}
Ping \sphinxstylestrong{10.1.10.245}

\sphinxstyleemphasis{Q1. Was echo response received?}

SSH to \sphinxstylestrong{10.1.10.245}

\sphinxstyleemphasis{Q2. Was ssh successful? Why not?}

Open \sphinxstylestrong{Network \textgreater{} Self IPs \textgreater{} 10.1.10.245} and change \sphinxstylestrong{Port Lockdown}
to \sphinxstylestrong{Allow Defaults}

SSH to \sphinxstylestrong{10.1.10.245}

Browse to \sphinxstylestrong{https://10.1.10.245}

\sphinxstyleemphasis{Q1. Did SSH work? Did browsing work?}

\sphinxstyleemphasis{Q2. What other ports are opened when you select Allow Defaults.}

Open \sphinxstylestrong{Network \textgreater{} Self IPs \textgreater{} 10.1.10.245} and change \sphinxstylestrong{Port Lockdown} to
\sphinxstylestrong{Allow Custom} and add \sphinxstylestrong{Port 22}

SSH to \sphinxstylestrong{10.1.10.245}

Browse to \sphinxstylestrong{https://10.1.10.245}

\sphinxstyleemphasis{Q3. Did SSH work? Did browsing work?}

Open \sphinxstylestrong{System \textgreater{} Platform}

On \sphinxstylestrong{SSH IP Allow} \textgreater{} \sphinxstylestrong{Specify Range} of \sphinxstylestrong{10.1.1.10-20}

\sphinxstyleemphasis{Q4. Does existing SSH window still work?}

Open new SSH session to \sphinxstylestrong{10.1.1.245}

\sphinxstyleemphasis{Q5. Was new ssh session established?}


\subsubsection{Check DNS and NTP are configured properly}
\label{\detokenize{class3/module3/lab5:check-dns-and-ntp-are-configured-properly}}
Verify the DNS and NTP configuration and test DNS.

Go to \sphinxstylestrong{System \textgreater{} Configuration \textgreater{} Device \textgreater{} General} and review the
DNS and NTP setting

In BIG-IP command line terminal window (window2) test DNS from the CLI or TMSH enter:

CLI:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dig} \PYG{n}{pool}\PYG{o}{.}\PYG{n}{ntp}\PYG{o}{.}\PYG{n}{org}
\end{sphinxVerbatim}

TMSH:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{run} \PYG{n}{util} \PYG{n}{dig} \PYG{n}{pool}\PYG{o}{.}\PYG{n}{ntp}\PYG{o}{.}\PYG{n}{org}
\end{sphinxVerbatim}


\section{Lab 4 \textendash{} Support and Analytics}
\label{\detokenize{class3/module4/module4:lab-4-support-and-analytics}}\label{\detokenize{class3/module4/module4::doc}}
In this section you will retrieve information that is necessary to open support cases and is useful in troubleshooting you BIG-IP.  You will also take a look at BIG-IP analytics capabilities, also known as, Application Visibility and Reporting (AVR).
\begin{description}
\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{5.01}] \leavevmode\begin{itemize}
\item {} 
Identify the appropriate supporting components and severity levels for an F5 support ticket

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{6.01-6.04}] \leavevmode\begin{itemize}
\item {} 
Review the network map in order to determine the status of objects

\item {} 
Use the dashboard to gauge the current running status of the system

\item {} 
Review log files and identify possible events

\item {} 
Use iApps Analytics to gauge the current running status of application services

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Support, Status and Logs}
\label{\detokenize{class3/module4/lab1:support-status-and-logs}}\label{\detokenize{class3/module4/lab1::doc}}

\subsubsection{Qkview and iHealth}
\label{\detokenize{class3/module4/lab1:qkview-and-ihealth}}
Open \sphinxstylestrong{System \textgreater{} Support} page.

Ensure \sphinxstylestrong{QKView} is selected then click \sphinxstylestrong{Start}.

Download the snapshot file and upload it to \sphinxstylestrong{https://ihealth.f5.com}

\begin{sphinxadmonition}{note}{Note:}
A login account is required to access iHealth.  If you do not have an account, now would be a good time to create one.   It may take one or two days for your account to activate.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q1. Are logs associated with qkview?}

From ssh window run qkview

\sphinxstyleemphasis{Q2. Where is default filename and location of qkview output?}

\sphinxstyleemphasis{Q3. Where is the default filename and location of core dump?}

\sphinxstyleemphasis{Q4. What is Severity and Condition for unit failure in active/standby
pair?}

\sphinxstyleemphasis{Q5. If support case was opened online with Severity 4 and no call has
been received in a week. What should you do?}

\sphinxstyleemphasis{Q6. What is the procedure to escalate support case?}


\subsubsection{Network Map}
\label{\detokenize{class3/module4/lab1:network-map}}
You should be able to explain status icons of objects on network map.

Open \sphinxstylestrong{Local Traffic \textgreater{} Network Map} and hover over icons and observe
status info.

Ensure all icons are green. If an icon is red determine the reason why.

Note the top-down status relationship between VS, pools, pool members
and nodes.

\sphinxstyleemphasis{Q1. What is a node?}

Open \sphinxstylestrong{Local Traffic \textgreater{} Nodes} and disable node \sphinxstylestrong{10.1.20.11}

\sphinxstyleemphasis{Q2. What icon is reflected for 10.1.20.11 on the Network map?}

\sphinxstyleemphasis{Q3. What is the color of the icon for pool members based on 10.1.20.11?  Why?}

\sphinxstyleemphasis{Q4. Does} \sphinxstylestrong{ftp\_vs} \sphinxstyleemphasis{still work as expected?}

Select \sphinxstylestrong{www\_vs} from the Network Map. Select \sphinxstylestrong{Resources \textgreater{} Manage irules}

Enable \sphinxstylestrong{\_sys\_https\_redirect} irule and click \sphinxstylestrong{Finished}.

\sphinxstyleemphasis{Q5. Where is irule reflected on Network Map?}


\subsubsection{Dashboard}
\label{\detokenize{class3/module4/lab1:dashboard}}
Observe Dashboard statistics

Log on to the BIG-IP GUI using and go to \sphinxstylestrong{Statistics
\textgreater{} Dashboard}

\begin{sphinxadmonition}{warning}{Warning:}
Adobe Flash is required to view the dashboard.  If you are using the Ravello lab environment with the Xubuntu jumpbox you need to use Firefox to view the BIG-IP dashboard via the BIG-IP GUI.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q1. What is longest duration available for reporting?}

\sphinxstyleemphasis{Q2. How can report be exported?}


\subsubsection{Log files}
\label{\detokenize{class3/module4/lab1:log-files}}
Interpret the LTM log file

Open ssh window1 and enter the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tail} \PYG{o}{\PYGZhy{}}\PYG{n}{f} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{log}\PYG{o}{/}\PYG{n}{ltm}
\end{sphinxVerbatim}

Disable \sphinxstylestrong{ftp\_vs}

\sphinxstyleemphasis{Q1. Was alert logged?}

Go to \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Local Traffic}

\sphinxstyleemphasis{Q2. Was the alert logged here?}

From ssh window1 enter \sphinxstylestrong{\textless{}CTRL\textgreater{} c} and at the CLI prompt enter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{grep} \PYG{n}{alert} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{log}\PYG{o}{/}\PYG{n}{ltm}
\PYG{n}{grep} \PYG{n}{www\PYGZus{}pool}\PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{log}\PYG{o}{/}\PYG{n}{ltm}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q3. What command is needed to find all instances of err in /var/log/ltm?}


\subsection{iApps and Analytics}
\label{\detokenize{class3/module4/lab2:iapps-and-analytics}}\label{\detokenize{class3/module4/lab2::doc}}

\subsubsection{Create and iApps and add Analytics}
\label{\detokenize{class3/module4/lab2:create-and-iapps-and-add-analytics}}
As you saw in the first lab, Application Visibility and Reporting has
already been provisioned. You are going to create an analytics profile
and attach it to an HTTP iApp application you will create.

Open \sphinxstylestrong{Local Traffic \textgreater{} Profiles \textgreater{} Analytics} page.

Create an analytics profile checking the following boxes to obtain the
desired information, and then click \sphinxstylestrong{Finished}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Profile Name}
&\sphinxstyletheadfamily 
custom\_analytics
\\
\hline
\sphinxstylestrong{Collected Metrics}
&
Max TPS

Throughput

Page Load Time
\\
\hline
\sphinxstylestrong{Collected Entities}
&
URLs

Countries

Client IP Addresses

Client Subnets

Response Codes

User Agents

Methods
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Go to \sphinxstylestrong{iApps \textgreater{} Application Services} and select \sphinxstylestrong{Create}.

Select the \sphinxstylestrong{f5.http} template, name it \sphinxstylestrong{iapp\_lab} and review the
\sphinxstylestrong{Basic} selections.

In the \sphinxstylestrong{Template Options} section set the configuration mode to
\sphinxstylestrong{Advanced - Configure advanced options}.

Build the iApp using the following information:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Virtual Server IP}
&\sphinxstyletheadfamily 
10.1.10.110
\\
\hline
\sphinxstylestrong{Virtual Server Port}
&
80
\\
\hline
\sphinxstylestrong{FQDN}
&
iapp.f5demo.com
\\
\hline
\sphinxstylestrong{Pool member 1}
&
10.1.20.14:80
\\
\hline
\sphinxstylestrong{Pool member 2}
&
10.1.20.15:80
\\
\hline
\sphinxstylestrong{Analytics Profile}
&
custom\_analytics
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Review the status and components built by the iApp.

From both the Chromium and Firefox browsers go to \sphinxstylestrong{http://10.1.10.110}
and refresh the page several times and the select the following links
from the page on each browser.

\sphinxstylestrong{Request and Response Headers Allowed} \sphinxstyleemphasis{(review the request and
response headers)}

\sphinxstylestrong{HTTP Compress Example}

\sphinxstylestrong{Multiple Stream Example}

\sphinxstyleemphasis{Q1. Did both pool members respond? Why?}

Go to \sphinxstylestrong{Statistics \textgreater{} Analytics \textgreater{} HTTP} and review the information.

\begin{sphinxadmonition}{note}{Note:}
It may take up to 10 minutes for Analytic statistics to be available.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q2. Can you determine which page took the longest to load?}

Go to \sphinxstylestrong{Local Traffic \textgreater{} Pools} and attempt to add \sphinxstylestrong{10.1.20.13:80} to
the \sphinxstylestrong{iapp\_lab\_pool}.

\sphinxstyleemphasis{O3. Could you add the pool member? Why?}

\sphinxstyleemphasis{Q4. Can you add the custom\_analytics profile to the ftp\_vs? Why?}


\section{Lab 5 \textendash{} Managing the BIG-IP}
\label{\detokenize{class3/module5/module5:lab-5-managing-the-big-ip}}\label{\detokenize{class3/module5/module5::doc}}
In this module you’ll review basic BIG-IP management tasks and get a look at BIG-IQ.
\begin{description}
\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{7.01-7.08}] \leavevmode\begin{itemize}
\item {} 
Create and restore a UCS archive under the appropriate
circumstances

\item {} 
Identify which high-level tasks can be automated using BIG-IQ

\item {} 
Manage software images

\item {} 
Given an HA pair, describe the appropriate strategy for deploying
a new software image

\item {} 
Understand the processes of licensing, license reactivation,
license modification and add-ons

\item {} 
Identify which modules are licensed and/or provisioned

\item {} 
Explain how to create a user

\item {} 
Explain how to modify user properties

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{UCS, BIG-IP Archive}
\label{\detokenize{class3/module5/lab1:ucs-big-ip-archive}}\label{\detokenize{class3/module5/lab1::doc}}

\subsubsection{Create UCS Archive Files}
\label{\detokenize{class3/module5/lab1:create-ucs-archive-files}}
Open \sphinxstylestrong{System \textgreater{} Archives} page.

Create new archive named \sphinxstylestrong{backup\_labs\_1\_to\_4}

\begin{sphinxadmonition}{note}{TMSH}

You can also create backups via TMSH:
\sphinxstylestrong{sav sys ucs \textless{}filename\textgreater{}}
\end{sphinxadmonition}

\sphinxstyleemphasis{Q1. What extension must an archive have?}

\sphinxstyleemphasis{Q2. What is the default location for ucs files?}

\sphinxstyleemphasis{Q3. What is command for loading ucs file?}

\sphinxstyleemphasis{Q4. What issues will occur by restoring ucs file on RMA device?}


\subsection{Upgrading a BIG-IP Device Service Clusters (DSC)}
\label{\detokenize{class3/module5/lab2:upgrading-a-big-ip-device-service-clusters-dsc}}\label{\detokenize{class3/module5/lab2::doc}}

\subsection{Upgrading software}
\label{\detokenize{class3/module5/lab2:upgrading-software}}
Prior to any upgrade, you would want to backup your device and then
synchronize your changes. In the upper left corner, you should see
\sphinxstylestrong{Changes Pending} due to the changes you have made to
\sphinxstylestrong{bigip01.f5demo.com}.

Click on \sphinxstylestrong{Changes Pending} or go to \sphinxstylestrong{Device Management \textgreater{} Overview}
and select \sphinxstylestrong{bigip01.}

The \sphinxstylestrong{Sync Device to Group} button should already be selected. Hit the
\sphinxstylestrong{Sync} button at the bottom.

Sometime incremental sync get slightly off, if your sync fails select \sphinxstylestrong{Overwrite
Configuration} and try again.  This will do a full sync to the DSC members.

\sphinxstyleemphasis{Q1. You are about to start your upgrade to 12.1, which device will you
upgrade first?}

On the appropriate device go to \sphinxstylestrong{System \textgreater{} Software Management}

Select the \sphinxstylestrong{v12.1.2} image and hit \sphinxstylestrong{Install.}

In the \sphinxstylestrong{Volume set name} selection enter \sphinxstylestrong{upgrade}.

\begin{sphinxadmonition}{note}{Note:}
You could also have picked a volume, but for the lab you are creating a
new one to see how it’s done.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q2. True or false? Once the install is complete, the BIG-IP will
automatically reboot to the new volume.}

\sphinxstyleemphasis{Q3. What steps would be required to complete the upgrade?}


\subsection{BIG-IQ}
\label{\detokenize{class3/module5/lab3:big-iq}}\label{\detokenize{class3/module5/lab3::doc}}

\subsubsection{Peruse BIG-IQ}
\label{\detokenize{class3/module5/lab3:peruse-big-iq}}
In this lab you will talk a short walk through the BIG-IQ interface and
perform a few tasks.
\begin{description}
\item[{Logon to the BIG-IQ at \sphinxstylestrong{https://10.1.1.235}::}] \leavevmode
Username: admin
Password: admin

\end{description}

Go to \sphinxstylestrong{BIG-IQ \textgreater{} Device \textgreater{} Configuration \textgreater{} Overview} view the
various panes.

\sphinxstyleemphasis{Q1. What BIG-IPs are being managed?}

Select the Backups pane, select (\sphinxstylestrong{+}) and the \sphinxstylestrong{Add Backup}

\noindent\sphinxincludegraphics{{201bigiq}.png}

Back up \sphinxstylestrong{bigip01.f5demo.com}.

Go to \sphinxstylestrong{BIG-IQ \textgreater{} ADC} and review the information in the panels.

\sphinxstyleemphasis{Q2. Where are configurations currently being display from?}

\sphinxstyleemphasis{Q3. What is the difference between displaying from BIG-IQ and displaying
from BIG-IP?}

Select \sphinxstylestrong{bigip02} and the hover the mouse over the \sphinxstylestrong{Nodes} title.

Now select the \sphinxstylestrong{BIG-IQ} radio button from above, select \sphinxstylestrong{bigip02},
and then hover over the \sphinxstylestrong{Nodes} title.

\sphinxstyleemphasis{Q4. What now appears in the} \sphinxstylestrong{Nodes} \sphinxstyleemphasis{title when you hover the mouse
over it?}


\subsubsection{Make a modification via the BIG-IQ}
\label{\detokenize{class3/module5/lab3:make-a-modification-via-the-big-iq}}
With, \sphinxstylestrong{BIG-IQ} and \sphinxstylestrong{bigip02} selected hover over \sphinxstylestrong{Nodes} and hit
the plus sign (\sphinxstylestrong{+}) and add a new node to \sphinxstylestrong{bigip02} named
\sphinxstylestrong{new\_node} with an IP address of \sphinxstylestrong{10.1.20.252.}

\sphinxstyleemphasis{Q1. Was new\_node added to bigip02?}

Let’s have BIG-IQ deploy the change. Select \sphinxstylestrong{Deployment} next to
\sphinxstylestrong{ADC} on the top bar.

Next to \sphinxstylestrong{Deployments}, select the plus sign (\sphinxstylestrong{+}) and \sphinxstylestrong{Deploy
Configuration Changes}. Select the \sphinxstylestrong{review Pending Changes} link.

\sphinxstyleemphasis{Q2. What is being added? What is in the New Version window.?}

Name deployment \sphinxstylestrong{deploy\_new\_node}, select the \sphinxstylestrong{bigip02} device and
click on \sphinxstylestrong{Deploy} in the upper left.

\sphinxstyleemphasis{Q3. Check bigip02, was new\_node created?}


\section{Lab 6 \textendash{} Modify and Manage Pools and Virtual Servers}
\label{\detokenize{class3/module6/module6:lab-6-modify-and-manage-pools-and-virtual-servers}}\label{\detokenize{class3/module6/module6::doc}}
In the module you will put your BIG-IP knowledge to work making modificatons and resolving issues with little or no guidance.
\begin{description}
\item[{201 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{8.01-8.02}] \leavevmode\begin{itemize}
\item {} 
Modify and manage virtual servers

\item {} 
Modify and manage software images

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{A lot of minutes}


\subsection{Modify and Troubleshoot Virtual Servers}
\label{\detokenize{class3/module6/lab1:modify-and-troubleshoot-virtual-servers}}\label{\detokenize{class3/module6/lab1::doc}}

\subsubsection{Troubleshooting virtual servers}
\label{\detokenize{class3/module6/lab1:troubleshooting-virtual-servers}}
By now, I am sure you are dying to know what’s up with the
\sphinxstylestrong{purple\_vs}. Here’s a chance to find out. You are going to some
troubleshooting with a little guidance.

Go to \sphinxstylestrong{Network Maps} and take a look at the status of the
\sphinxstylestrong{purple\_vs} and its components.

It is obvious that all pool members are offline which could be anything,
a network issue, a server issue, a BIG-IP configuration issue.

\sphinxstyleemphasis{Q1. Where would you start?}

SSH to \sphinxstylestrong{bigip01} at 10.1.1.245.

\sphinxstyleemphasis{Q2. Attempt to ping he pool members. Does it work? What does this tell
you?}

\sphinxstyleemphasis{Q3. Attempt a} \sphinxstylestrong{curl -i} \sphinxstyleemphasis{against the pool members. Does it work? What
does this tell you?}

\sphinxstyleemphasis{Q4. Since the problem affects all pool members, what would you suspect
as a possible issue?}

Find the issue with the pool members and correct the issue.

\sphinxstyleemphasis{Q5. Did you correct the issue?}

\begin{sphinxadmonition}{hint}{Hint:}
If not go to \sphinxstylestrong{Appendix I - Answer Key} and see how the issue was fixed.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q6. Now the pool is working and purple\_vs is available can you access
the page through the virtual?}

\sphinxstyleemphasis{Q7. What is your next step in debugging? Is the virtual server
processing traffic?}

You need to watch traffic from your PC to the BIG-IP virtual server and
from the BIG-IP to the pool.

\sphinxstyleemphasis{Q8. What command(s) could you use to watch traffic hit the virtual
server and leave toward the pool?}

\begin{sphinxadmonition}{hint}{Hint:}
Try to figure it out, if you need help go to \sphinxstylestrong{Appendix I - Answer Key} and one version of the commands
\end{sphinxadmonition}

\sphinxstyleemphasis{Q9. Did you see traffic hit the virtual server? Did you see BIG-IP send
traffic to a pool member?}

\sphinxstyleemphasis{Q10. Did you see the return traffic? If there was no response, what is
your step?}

Remember the server’s default gateway is 10.1.20.240, which is an \sphinxstylestrong{unused} IP
address on the 10.1.20.0/24 network.

There were two ways to resolve the virtual server issue. Your purple\_vs
should now be available.


\subsubsection{Working with profiles}
\label{\detokenize{class3/module6/lab1:working-with-profiles}}
Create new virtual server \sphinxstylestrong{secure\_vs 10.1.10.100:443} with \sphinxstylestrong{TCP} profile,
use SNAT and the \sphinxstylestrong{www\_pool}. Open tcpdumps to view traffic on both sides of the proxy. Browse to \sphinxstylestrong{https://10.1.10.100} and view the tcpdumps.

\sphinxstyleemphasis{Q1. Did site work? Why not?}

Change SSL Profile to include clientssl then update Browse to
\sphinxstylestrong{https://10.1.10.100} and observe tcpdumps.

\sphinxstyleemphasis{Q2. Did site work?}

Enable cookies Default Persistence Profile and update? Note error and
troubleshoot to fix.

\sphinxstyleemphasis{Q3. What was needed to add cookie persistence?}

Browse to \sphinxstylestrong{https://10.1.10.100/index.php} and select \sphinxstylestrong{Display Cookie} on
bottom of page.

\sphinxstyleemphasis{Q4. What is the name of the cookie inserted begin with?}

Create new pool \sphinxstylestrong{secure\_pool} with members of \sphinxstylestrong{10.1.20.11:443},
\sphinxstylestrong{10.1.20.12:443} and \sphinxstylestrong{10.1.20.13:443} and assign it to \sphinxstylestrong{secure\_vs}. Browse to
\sphinxstylestrong{https://10.1.10.100}

\sphinxstyleemphasis{Q5. Did site work?}

Troubleshoot and fix.

\sphinxstyleemphasis{Q6. What profile was needed to correct the error?}


\section{Appendix I - Answer Key}
\label{\detokenize{class3/module7/module7:appendix-i-answer-key}}\label{\detokenize{class3/module7/module7::doc}}
The answers to all of your questions.  Literally.

\begin{sphinxadmonition}{note}{Note:}
In this appendix the third digit in the section (ie. 2.7.**X**) represents the module number and the fourth digit (ie. 2.7.X.**Y**) the task/lab number.
\end{sphinxadmonition}


\subsection{Module 1 - Packet Processing and Virtual Servers}
\label{\detokenize{class3/module7/lab1:module-1-packet-processing-and-virtual-servers}}\label{\detokenize{class3/module7/lab1::doc}}

\subsubsection{Lab Preparation and Packet Processing}
\label{\detokenize{class3/module7/lab1:lab-preparation-and-packet-processing}}

\paragraph{Open BIG-IP TMSH and TCPDump session}
\label{\detokenize{class3/module7/lab1:open-big-ip-tmsh-and-tcpdump-session}}
\sphinxstyleemphasis{Q1. Why are ssh sessions not displayed in connection table?}

\sphinxstylestrong{tmsh show sys connections} displays connections on the TMOS data plane.
SSH connections are established to out-of-band management interface and
thus not seen.


\paragraph{Establish ftp connection}
\label{\detokenize{class3/module7/lab1:establish-ftp-connection}}
\sphinxstyleemphasis{Q1. In the tcpdump above, what is client IP address and port and the
server IP address port?}

10.1.10.1:60603 and 10.1.10.20:21 (FTP)

\begin{sphinxadmonition}{note}{Note:}
60603 is an ephemeral port and BIG-IP will attempt to use the same
client port on the server-side connection
\end{sphinxadmonition}

\sphinxstyleemphasis{Q2. What is source ip and port as seen by ftp server in the example
above?}

Source IP: 10.1.20.249 Source IP: 61236

\sphinxstyleemphasis{Q3. What happened to the original client IP address and where did
10.1.20.249 come from?}

The virtual server was configured to do source address translation using
the SNAT Pool, SNAT249\_pool. Reviewing the configuration of
SNAT249\_pool shows it was configured with IP address 10.1.20.249.


\subsubsection{Packet Filters}
\label{\detokenize{class3/module7/lab1:packet-filters}}

\paragraph{Test the FTP packet filter}
\label{\detokenize{class3/module7/lab1:test-the-ftp-packet-filter}}
\sphinxstyleemphasis{Q1. Was the existing ftp connection in the connection table affected?
Why?}

The FTP connection is not affected because adding packet filter does not
impact established connections.

\sphinxstyleemphasis{Q2. Was ftp connection successful? If yes, why?}

The attempt to establish a new FTP connection was blocked, because the
packet filter rule applies to all new connection attempts

\sphinxstyleemphasis{Q3. What did tcpdump reveal? Connection timeout or reset?}

Tcpdump revealed multiple \sphinxstylestrong{S} (syn) attempts without receiving ack. This
is indicating a connection timeout.

\sphinxstyleemphasis{Q4. What did virtual server statistics for ftp20\_vs reveal? Why are
counters not incrementing?}

VS stats shows no new connection attempts because Filter is applied
before VS in order of processing

\sphinxstyleemphasis{Q5. Prioritize the packet processing order:}

Virtual Server \sphinxstylestrong{3} SNAT \sphinxstylestrong{4} AFM/Pkt Filter \sphinxstylestrong{2} NAT \sphinxstylestrong{5} Existing
Connections \sphinxstylestrong{1} Self IP \sphinxstylestrong{6} Drop \sphinxstylestrong{7}


\subsubsection{Virtual Server Packet Processing}
\label{\detokenize{class3/module7/lab1:virtual-server-packet-processing}}

\paragraph{Testing Virtual Server Packet Processing Behavior}
\label{\detokenize{class3/module7/lab1:testing-virtual-server-packet-processing-behavior}}
\sphinxstyleemphasis{Q1. Which VS is used for web traffic over port 8080?}

wildcard\_vs

\sphinxstyleemphasis{Q2. Which VS is used for ftp traffic?}

ftp\_vs

\sphinxstyleemphasis{Q3. Which VS is used for web traffic over the default HTTP port? Which
port was used?}

www\_vs port 80

Q4. Which VS is used for web traffic?

wildcard\_vs


\subsection{Module 2 - Virtual Server and Pool Behavior and Status}
\label{\detokenize{class3/module7/lab2:module-2-virtual-server-and-pool-behavior-and-status}}\label{\detokenize{class3/module7/lab2::doc}}

\subsubsection{Virtual Server Status}
\label{\detokenize{class3/module7/lab2:virtual-server-status}}

\paragraph{Test Disabled Virtual Server}
\label{\detokenize{class3/module7/lab2:test-disabled-virtual-server}}
\sphinxstyleemphasis{Q1. What is the Availability of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{? What is the State?}

Availability: available, State: disabled

\sphinxstyleemphasis{Q2. What symbol is used to represent} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{status?}

Black Circle

\sphinxstyleemphasis{Q3. Would you expect browsing to http://10.1.10.100 to work?}

No

\sphinxstyleemphasis{Q4. Can you ping the virtual IP?}

Yes, the virtual address still responds to pings

\sphinxstyleemphasis{Q5. Did the site work? What did the tcpdump show?}

No, the tcpdump showed the virtual server 10.1.10.100:80 responding to
SYNs with Resets

\sphinxstyleemphasis{Q6. Did statistics counters for any virtual increment?}

No

\sphinxstyleemphasis{Q7. Why do you think the} \sphinxstylestrong{wildcard\_vs} \sphinxstyleemphasis{didn’t pick up the packets?}

www\_vs was the most specific virtual server so it responded. Because the www\_vs was disabled the response was to reset the connection.  This make sense if you think about it.  What good would it do to disable a virtual server just to have another virtual server pick up the traffic either process incorrectly or send it to servers you just tried to prevent traffic from going too.

\sphinxstyleemphasis{Q8. What symbol is used to represent} \sphinxstylestrong{wildcard\_vs}\sphinxstyleemphasis{? Why is symbol a
square?}

The status symbol is a black square. Black because the virtual server
was administratively disabled and square because there is no monitor and
the state is Unknown

\sphinxstyleemphasis{Q9. What is the reason given for current state?}

The children pool member(s) either don’t have service checking enabled,
or service check results are not available yet. Availability: unknown
State: disabled

\sphinxstyleemphasis{Q10. Does ftp session still work? Why?}

Disabling a configuration item (node, pool or virtual server) does not
affect existing connections.

\sphinxstyleemphasis{Q11. Did new ftp session establish connection? Why not?}

No, a disabled virtual server will not process new connections.


\paragraph{Virtual Server Connection Limits and Status}
\label{\detokenize{class3/module7/lab2:virtual-server-connection-limits-and-status}}
\sphinxstyleemphasis{Q1. Does ftp session work?}

Yes

\sphinxstyleemphasis{Q2. What is the virtual server status of ftp\_vs?}

Yellow Triangle - Availability: unavailable - State: enabled

\sphinxstyleemphasis{Q3. Did new ftp session establish connection? Why not?}

No, the virtual server’s connection limit has been reached.

\sphinxstyleemphasis{Q4. Did tcpdump capture show a connection reset?}

Yes, tcpdump revealed \sphinxstylestrong{R} TCP reset the connection.


\subsubsection{Pool Member and Virtual Servers}
\label{\detokenize{class3/module7/lab2:pool-member-and-virtual-servers}}

\paragraph{Effects of Monitors on Members, Pools and Virtual Servers}
\label{\detokenize{class3/module7/lab2:effects-of-monitors-on-members-pools-and-virtual-servers}}
\sphinxstyleemphasis{Q1. Since the} \sphinxstylestrong{mysql\_monitor} \sphinxstyleemphasis{will fail, how long will it take to
mark the pool offline?}

60 seconds, the monitor will have to fail 4 times at 15 second intervals
before it exceeds the 46 second timeout value.

\sphinxstyleemphasis{Q2. What is the icon and status of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

Red Diamond - Availability: offline - State: enabled - The children pool
member(s) are down

\sphinxstyleemphasis{Q3. What is the icon and status of} \sphinxstylestrong{www\_pool}\sphinxstyleemphasis{?}

Red Diamond - Availability: offline - State: enabled - The children pool
member(s) are down

\sphinxstyleemphasis{Q4. What is the icon and status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members?}

Red Diamond - Availability: offline - State: enabled - Pool member has
been marked down by a monitor

\sphinxstyleemphasis{Q5. Does pool configuration have an effect on virtual server status?}

Yes, the status of the pool members can affect the status of the virtual
server.

\sphinxstyleemphasis{Q6. What is the icon and status of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

Black Diamond - Availability: offline - State: disabled - The children
pool member(s) are down

\sphinxstyleemphasis{Q7. Did traffic counters increment for} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{?}

No

\sphinxstyleemphasis{Q8. What is the difference in the tcpdumps between Offline (Disabled) vs
Offline (Enabled)?}

Offline (Disabled) - immediate connection reset, you will see no virtual
server statistics.

Offline (Enabled) - initial connection accepted then reset, the virtual server stats are
incremented


\paragraph{More on status and member specific monitors}
\label{\detokenize{class3/module7/lab2:more-on-status-and-member-specific-monitors}}
\sphinxstyleemphasis{Q1. What is the status of the Pool Member and the monitors assigned to
it?}

Red Diamond - Red Diamond - Availability: offline - State: enabled -
Pool member has been marked down by a monitor

http - Green Circle, mysql\_monitor - Red Diamond

\sphinxstyleemphasis{Q2. What is the status of} \sphinxstylestrong{www\_vs}, \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and the pool
members? Why?}

Green, Green, Red, Red, Green. One pool member available, marks the pool
available and since the pool is available, the virtual server is
available

\sphinxstyleemphasis{Q3. Did the site work?}

Yes

\sphinxstyleemphasis{Q4. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

Traffic was distributed to availble pool members.


\subsubsection{Load Balancing}
\label{\detokenize{class3/module7/lab2:load-balancing}}

\paragraph{Load Balancing}
\label{\detokenize{class3/module7/lab2:id1}}
\sphinxstyleemphasis{Q1. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

Traffic was distributed to 10.1.20.12 and 10.1.20.13

\sphinxstyleemphasis{Q2. Did member 10.1.20.12 receive the most traffic? Why not?}

No, because LB method is Round Robin, Ratio and Priority Group
configurations on pool members do not apply.

\sphinxstyleemphasis{Q3. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

Traffic was distributed to 10.1.20.12 and 10.1.20.13

\sphinxstyleemphasis{Q4. Did member 10.1.20.12 receive the most traffic?}

10.1.20.12 received 5x more traffic than 10.1.20.12


\paragraph{Priority Group Activation}
\label{\detokenize{class3/module7/lab2:priority-group-activation}}
\sphinxstyleemphasis{Q1. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent} to?

Traffic was distributed to 10.1.20.11 and 10.1.20.12

\sphinxstyleemphasis{Q2. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to? Why?}

Traffic was distributed to 10.1.20.12 and 10.1.20.13. Pool member
availability dropped below 2 available members in the highest priority
group and the next lowest priority group was activated.

\sphinxstyleemphasis{Q3. Would the results have been different if 10.1.20.11:80 had been
marked offline or marked with a yellow triangle?}

No, both mark the member as Unavailable, dropping the Available members
below 2.


\paragraph{The Effects of Persistence on Load Balancing}
\label{\detokenize{class3/module7/lab2:the-effects-of-persistence-on-load-balancing}}
\sphinxstyleemphasis{Q1. Why was a http profile required?}

The http profile was required to tell the BIG-IP to parse the http
request/response sequence for the virtual server so it could insert and
read cookies in the http headers.

\sphinxstyleemphasis{Q2. Was traffic evenly distributed to all} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members? Why
not?}

Traffic went to only on pool member because of persistence,

\sphinxstyleemphasis{Q3. Did you persist to the Disabled member? Why?}

Yes, a Disable pool member will still receive new connections if a
persistence record points to it.

\sphinxstyleemphasis{Q4. Does traffic continue to persist to the member Forced Offline?}

No, another available member was selected and a new persistence record
was created

\sphinxstyleemphasis{Q5. If cookies were disable on your browser would persistence still
work? Why?}

Yes, source address persistence would be used to persist to a pool
member


\subsection{Module 3 - Trouble-shooting the BIG-IP}
\label{\detokenize{class3/module7/lab3:module-3-trouble-shooting-the-big-ip}}\label{\detokenize{class3/module7/lab3::doc}}

\subsubsection{Trouble-shooting Hardware}
\label{\detokenize{class3/module7/lab3:trouble-shooting-hardware}}

\paragraph{End User Diagnostics}
\label{\detokenize{class3/module7/lab3:end-user-diagnostics}}
\sphinxstyleemphasis{Q1. What three methods are available for running EUD on F5 Hardware?}

USB CDROM, USB Bootable Drive, Hardware Boot Menu

\sphinxstyleemphasis{Q2. How do you determine EUD version?}

EUD image downloaded or eud\_info

\sphinxstyleemphasis{Q3. What is the filename and location of the EUD output?}

/shared/log/eud.log


\paragraph{LCD Panel}
\label{\detokenize{class3/module7/lab3:lcd-panel}}
\sphinxstyleemphasis{Q1. How do you halt the unit via the LCD panel?}

Press X, select system menu, press check, select halt, press check to
confirm

\sphinxstyleemphasis{Q2. Holding the X for 4 seconds does what?}

Powers down unit

\sphinxstyleemphasis{Q3. Holding the Check button for 4 seconds does what?}

Reboots the unit


\paragraph{Hardware Log Files}
\label{\detokenize{class3/module7/lab3:hardware-log-files}}
\sphinxstyleemphasis{Q1. What is the filename and location of the logs for LTM?}

/var/log/ltm

\sphinxstyleemphasis{Q2. Where will power supply, fan and hard disk related issues be logged?}

/var/log/ltm


\paragraph{HA and Failover}
\label{\detokenize{class3/module7/lab3:ha-and-failover}}
\sphinxstyleemphasis{Q1. Is failover sometimes used to determine issues related to hardware or software?}

hardware

\sphinxstyleemphasis{Q2. How do you initiate failover to standby unit?}

From Active unit select Network \textgreater{} Traffic Groups, select traffic group, select Force to Standby

\sphinxstyleemphasis{Q3. What persistence profile cannot be mirrored?}

Cookie persistence is not mirrored

\sphinxstyleemphasis{Q4. What two connections types are re-mirrored after failback?}

Only FastL4 and SNAT connections are re- mirrored after failback

\sphinxstyleemphasis{Q5. When would you recommend using connection mirroring?}

Long lived connections

\sphinxstyleemphasis{Q6. Where is connection mirroring configured?}

You can configure connection mirroring at VS and SNAT

\sphinxstyleemphasis{Q7. Where is persistence mirroring configured?}

You can configure persistence mirroring at Persistence

\sphinxstyleemphasis{Q8. What tmsh command is used to view mirrored connections?}

show /ltm persistence persist-records

\sphinxstyleemphasis{Q9. What tmsh command is used to view mirrored persistence?.}

show /ltm persistence persist-records

\sphinxstyleemphasis{Q10. What can be the cause of primary unit returning to active state after initiating failover to standby?}

Show /sys connection all-properties


\subsubsection{tcpdump Packet Capture}
\label{\detokenize{class3/module7/lab3:tcpdump-packet-capture}}

\paragraph{Packet Captures of multiple interfaces simultaneously}
\label{\detokenize{class3/module7/lab3:packet-captures-of-multiple-interfaces-simultaneously}}
\sphinxstyleemphasis{Q1. What is the alternate method for capturing two interfaces
simultaneously?}

tcpdump -ni eth1 -w /var/tmp/dump1.cap \sphinxstylestrong{\&} tcpdump -ni eth2 -w
/var/tmp/dump2.cap

\sphinxstyleemphasis{Q2. What interface does 0.0 represent?}

All interfaces

\sphinxstyleemphasis{Q3. What interface typically represents the management interface?}

eth0

\sphinxstyleemphasis{Q4. What is recommended method for packet captures on high load system?}

F5 recommends that you mirror traffic to a dedicated sniffing device

\sphinxstyleemphasis{Q5. Will tcpdump capture PVA accelerated traffic?}

No, you must disable PVA to capture traffic


\subsubsection{Performance Statistics}
\label{\detokenize{class3/module7/lab3:performance-statistics}}

\paragraph{Observing performance statistics}
\label{\detokenize{class3/module7/lab3:observing-performance-statistics}}
\sphinxstyleemphasis{Q1. What is the longest time interval available for performance
statistics?}

30 Days


\subsubsection{Connectivity Troubleshooting}
\label{\detokenize{class3/module7/lab3:connectivity-troubleshooting}}

\paragraph{Connectivity troubleshooting tools}
\label{\detokenize{class3/module7/lab3:connectivity-troubleshooting-tools}}
\sphinxstyleemphasis{Q1. Was echo response received?}

Ping reply was successful

\sphinxstyleemphasis{Q2. What is the status of the virtual servers?}

ftp\_vs and www\_vs available, disabled - wildcard\_vs unknown, disabled

\sphinxstyleemphasis{Q3. Was echo response received?}

Ping reply successful


\subsubsection{Self IP Port Lockdown}
\label{\detokenize{class3/module7/lab3:self-ip-port-lockdown}}

\paragraph{Effects of Port Lockdown}
\label{\detokenize{class3/module7/lab3:effects-of-port-lockdown}}
\sphinxstyleemphasis{Q1. Was echo response received?}

Ping reply successful

\sphinxstyleemphasis{Q2. Was ssh successful? Why not?}

No. Port lockdown set to \sphinxstylestrong{Allow None} by default

\sphinxstyleemphasis{Q3. Was ssh successful?}

Yes

\sphinxstyleemphasis{Q4. Does existing ssh window still work?}

No

\sphinxstyleemphasis{Q5. Was new ssh session established?}

No


\subsection{Module 4 - Support and Analytics}
\label{\detokenize{class3/module7/lab4:module-4-support-and-analytics}}\label{\detokenize{class3/module7/lab4::doc}}

\subsubsection{Support, Status and Logs}
\label{\detokenize{class3/module7/lab4:support-status-and-logs}}

\paragraph{Qkview and iHealth}
\label{\detokenize{class3/module7/lab4:qkview-and-ihealth}}
\sphinxstyleemphasis{Q1. Are logs associated with qkview?}

Yes

\sphinxstyleemphasis{Q2. Where is default filename and location of qkview output?}

/var/tmp/hostname.qkview

\sphinxstyleemphasis{Q3. Where is the default filename and location of core dump?}

/var/core/

\sphinxstyleemphasis{Q4. What is Severity and Condition for unit failure in active/standby
pair?}

Severity 2, Site at Risk

\sphinxstyleemphasis{Q5. If support case was opened online with Severity 4 and no call has
been received in a week. What should you do?}

Call support, reference open case and ask to escalate. This may require
Duty Manager approval.

\sphinxstyleemphasis{Q6. What is the procedure to escalate support case?}

Call support, reference open case and ask to escalate. This may require
Duty Manager approval.


\paragraph{Network Map}
\label{\detokenize{class3/module7/lab4:network-map}}
\sphinxstyleemphasis{Q1. What is a node?}

IP Address of Pool Member

\sphinxstyleemphasis{Q2. What icon is reflected for 10.1.20.11 on the Network map?}

Black

\sphinxstyleemphasis{Q3. What is the color of the icon for pool members based on 10.1.20.11?  Why?}

Grey Circle

\sphinxstyleemphasis{Q4. Does ftp\_vs still work as expected?}

No

\sphinxstyleemphasis{Q5. Where is irule reflected on Network Map?}

iRule is displayed between the Virtual Server and Pool


\paragraph{Dashboard}
\label{\detokenize{class3/module7/lab4:dashboard}}
\sphinxstyleemphasis{Q1. What is longest duration available for reporting?}

1 Month

\sphinxstyleemphasis{Q2. How can report be exported?}

Reports may be exported as csv files.


\paragraph{Log files}
\label{\detokenize{class3/module7/lab4:log-files}}
\sphinxstyleemphasis{Q1. Was an alert logged?}

Yes

\sphinxstyleemphasis{Q2. Was the alert logged here?}

Yes

\sphinxstyleemphasis{Q3. What command is needed to find all instances of err in /var/log/ltm?}

grep err /var/log/ltm


\subsubsection{iApps and Analytics}
\label{\detokenize{class3/module7/lab4:iapps-and-analytics}}

\paragraph{Create iApps Analytics}
\label{\detokenize{class3/module7/lab4:create-iapps-analytics}}
\sphinxstyleemphasis{Q1. Did both pool members respond? Why?}

No, only one responded because cookie persistence was built using the
iApp

\sphinxstyleemphasis{Q2. Can you determine which page took the longest to load?}

If you select Latency \textgreater{} Page Load Time from the top bar you will find
/bigtext.html took longest.

\sphinxstyleemphasis{O3. Could you add the pool member? Why?}

No, because iApp strictness is on by default and the application can
only be changed by going to the iApp application and selecting
Reconfigure from the top bar

\sphinxstyleemphasis{Q4. Can you add the custom\_analytics profile to the ftp\_vs? Why?}

No, analytics in v11.5 can only be done on HTTP and DNS virtual servers
with a HTTP or DNS profile attached.


\subsection{Module 5 - Managing the BIG-IP}
\label{\detokenize{class3/module7/lab5:module-5-managing-the-big-ip}}\label{\detokenize{class3/module7/lab5::doc}}

\subsubsection{UCS, BIG-IP Archive}
\label{\detokenize{class3/module7/lab5:ucs-big-ip-archive}}

\paragraph{Create UCS Archive Files}
\label{\detokenize{class3/module7/lab5:create-ucs-archive-files}}
\sphinxstyleemphasis{Q1. What extension must Archive have?}

.ucs

\sphinxstyleemphasis{Q2. What is the default location for ucs files?}

/var/local/ucs

\sphinxstyleemphasis{Q3. What is command for loading ucs file?}

load /sys ucs \textless{}path to UCS\textgreater{}

load /sys ucs \textless{}path to UCS\textgreater{} no-license - This will not restore the license
file

\sphinxstyleemphasis{Q4. What issues will occur by restoring ucs file on RMA device?}

Licensing and device cert keys must be updated.


\subsubsection{Upgrading a BIG-IP Device Service Clusters (DSC)}
\label{\detokenize{class3/module7/lab5:upgrading-a-big-ip-device-service-clusters-dsc}}

\paragraph{Upgrading software}
\label{\detokenize{class3/module7/lab5:upgrading-software}}
\sphinxstyleemphasis{Q1. You are about to start your upgrade to 12.1, which device will you
upgrade first?}

You would begin the upgrade on the standby device, in this case that
should be bigip02.

\sphinxstyleemphasis{Q2. True or false? Once the install is complete, the BIG-IP will
automatically reboot to the new volume.}

False, you will have to set the new volume as the Active volume and then
reboot the BIG-IP

\sphinxstyleemphasis{Q3. What steps would be required to complete the upgrade?}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Set the new volume to the active volume

\item {} 
Reboot the BIG-IP

\item {} 
Confirm the reboot was successful and the BIG-IP is running

\item {} 
Force the BIG-IP with the old software to Standby, making virtual
servers, and other listeners active on the upgraded BIG-IP

\item {} 
Test that traffic is passing correctly.

\item {} 
Upgrade the BIG-IP with the older software.

\end{enumerate}


\subsubsection{BIG-IQ}
\label{\detokenize{class3/module7/lab5:big-iq}}

\paragraph{Peruse BIG-IQ}
\label{\detokenize{class3/module7/lab5:peruse-big-iq}}
\sphinxstyleemphasis{Q1. What BIG-IPs are being managed?}

bigip01.f5demo.com and bigip02.f5demo.com

\sphinxstyleemphasis{Q2. Where are configurations currently being display from?}

The configuration displayed was retrieved from the BIG-IP

\sphinxstyleemphasis{Q3. What is the difference between displaying from BIG-IQ and displaying
from BIG-IP?}

If you are displaying configuration from BIG-IP the configuration is
maintained and updated on that BIG-IP. If you are displaying
configuration from the BIG-IQ, then BIG-IQ owns the configuration and
can push changes out to the BIG-IP, no change should be made to the
BIG-IP directly.

\sphinxstyleemphasis{Q4. What now appears in the Nodes title when you hover the mouse over
it?}

A (\sphinxstylestrong{+}) appears in the title area because you can now modify the device
via the BIG\_IQ.


\paragraph{Make a modification via the BIG-IQ}
\label{\detokenize{class3/module7/lab5:make-a-modification-via-the-big-iq}}
\sphinxstyleemphasis{Q1. Was new\_node added to bigip02?}

No, it was not.

\sphinxstyleemphasis{Q2. What is being added? What is in the New Version window.?}

new\_node is being added and the REST commands to do that are show in
the New Version window.

\sphinxstyleemphasis{Q3. Check bigip02, was new\_node created?}

Yes


\subsection{Module 6 - Modify and Troubleshoot Pools and Virtual Servers}
\label{\detokenize{class3/module7/lab6:module-6-modify-and-troubleshoot-pools-and-virtual-servers}}\label{\detokenize{class3/module7/lab6::doc}}

\subsubsection{Modify and Troubleshoot Virtual Servers}
\label{\detokenize{class3/module7/lab6:modify-and-troubleshoot-virtual-servers}}

\paragraph{Troubleshooting virtual servers}
\label{\detokenize{class3/module7/lab6:troubleshooting-virtual-servers}}
\sphinxstyleemphasis{Q1. Where would you start?}

I would go on the BIG-IP and test connectivity from the BIG-IP to the
pool members.

\sphinxstyleemphasis{Q2. Attempt to ping one of the pool members. Does it work? What does
this tell you?}

The ping should be successful. This means the server IP is up and I have
basic connectivity.

\sphinxstyleemphasis{Q3. Attempt a} \sphinxstylestrong{curl -i} \sphinxstyleemphasis{against a pool member. Does it work? What does
this tell you?}

The curl should be successful and you should see the request come back.
The application is running.

\sphinxstyleemphasis{Q4. Since the problem affects all pool members, what would you suspect
as a possible issue?}

Since I can see all pool members are functioning I would suspect the
monitor is the issue. You could start debugging the monitor directly, or
you could put the default HTTP monitor and see if the pool members
come up. If they do, then the monitor is the issue and needs correction.
In the case, you would check the Send and Receive strings. I would use a
curl -i (to include the header and response codes) to look for the
receive string. In this case it’s obvious, we are looking for a 200 OK
(successful reponse), but have fat-finger 020 OK in the Receive box.
Correct the receive string and reapply the monitor. The pool should come
up Available (Green).

\begin{sphinxadmonition}{note}{Note:}
The default HTTP monitor usually, but does not always, work on an HTTP application.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q5. Did you correct the issue?}

Yes

\sphinxstyleemphasis{Q6. Now the pool is working and purple\_vs is available can you access
the page through the virtual?}

No

\sphinxstyleemphasis{Q7. What do you think would be the next step in debugging the issue
would be?}

I would clear the virtual server statistics and try again and see if the
traffic is hitting purple\_vs. The virtual server statistics should show
traffic being processed.

\sphinxstyleemphasis{Q8. What command(s) could you use to watch traffic hit the virtual
server and leave toward the pool?}

I would create two tcpdumps one on the client-side and the other on the
server-side. I would want to limit the captures to watch for my PC IP
address 10.1.10.51. You will need two terminal windows.

Terminal Window 1 (Client to BIG-IP)

\sphinxstylestrong{tcpdump -i client\_vlan -X -s0 host 10.1.10.51 and 10.1.10.105}

(This command will only watch client-side traffic between the PC and
virtual server. The -s0 command will dump the entire packet -X command
will dump hex and ascii code of the packet. You will be able to see the
HTTP request and response in the dump)

Terminal Window 2 (BIG-IP to Pool)

\sphinxstylestrong{tcpdump -i server\_vlan -X -s0 host 10.1.10.51}

(This command will only watch server-side traffic from the PC and to the
pool. The -s0 command will dump the entire packet -X command will dump
hex and ascii code of the packet. You will be able to see the HTTP
request and response in the dump)

\sphinxstyleemphasis{Q9. Did you see traffic hit the virtual server? Did you see BIG-IP send
traffic to a pool member?}

You should have seen traffic hit the virtual server in Window 1 and in
Window 2 BIG-IP should have picked a pool member and sent traffic to it.

\sphinxstyleemphasis{Q10. Did you see the return traffic? If there was no response, what is
your step?}

No, you should not have received a response. Because the BIG-IP is not
the default gateway, so the response went someplace else.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
You can add and SNAT Pool or do SNAT Automap on the virtual server.

\item {} 
You can add 10.1.20.240 as a self IP address on the BIG-IP. This
should be a floating IP in traffic\_group\_1 so that the default
gateway for the servers is still available upon failover.

\end{enumerate}


\paragraph{Working with profiles}
\label{\detokenize{class3/module7/lab6:working-with-profiles}}
\sphinxstyleemphasis{Q1. Did site work? Why not?}

SSL connection error

\sphinxstyleemphasis{Q2. Did site work?}

Yes

\sphinxstyleemphasis{Q3. What was needed to add cookie persistence?}

http profile

\sphinxstyleemphasis{Q4. What is the name of the cookie inserted begin with?}

BIGipServerwww\_pool

\sphinxstyleemphasis{Q5. Did site work?}

No

\sphinxstyleemphasis{Q6. What profile was needed to correct the error?}

Server side ssl profile


\chapter{F5 202 - Pre-Sales Fundamentals Study Guide 11/01/19}
\label{\detokenize{class4/class4:f5-202-pre-sales-fundamentals-study-guide-11-01-19}}\label{\detokenize{class4/class4::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview  202 - Pre-Sales Fundamentals}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Welcome to the F5 202 - Pre-Sales Fundamentals Study Guide. The purpose
of this guide is to help you prepare for the F5 202 - Pre-Sales
Fundamentals exam. The contents of this document are based on the F5 202
- Pre-Sales Fundamentals Exam Blueprint for TMOS v13.1.

\sphinxstylestrong{This study guide provides students with some of the basic
foundational knowledge required to pass the exam.}

\sphinxstylestrong{This study guide is a collection of information and therefore not a
completely original work.}

I would like to give recognition to a group of people that helped with this
document. A special thank you goes out to Mickey Woods with Ingram Micro,
Ed Rabago with F5, Leif Rasmussen with F5, Orlando Santiago with F5,
Patrick Oswalt from F5, Greg Godar with F5 and Mark Diminico with F5.

The majority of the information is compiled from F5 sources that are
located on the Internet. All of the information locations are referenced
at the top of each topic instead of in an appendix of this document.
This was done to help the reader access the referenced information
easier without having to search through a formal appendix.

The F5 101 - App Delivery Fundamentals exam, stands as a pre-requisite
to this exam.

This guide was prepared by an F5 employee but is not an official F5
document and is \sphinxstyleemphasis{not} supported by F5.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Reading = Knowledge = Power}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{F5 202 Introduction}
\label{\detokenize{class4/modules/module1:f5-202-introduction}}\label{\detokenize{class4/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{The 202 Pre-Sales Fundamentals Exam}

The F5 Pre-Sales Fundamentals Exam is focused on assessing a Sales
Architect/Engineer’s knowledge of sales motions and sales positioning of
F5 products.

This exam identifies individuals who have the skills and understanding
necessary for technical selling of F5 solutions. They will likely be a
sales engineer with a proven track record of successfully selling F5
solutions and typically have two years of sales experience. The Sales
Professional should have a working understanding of F5 solutions and the
ability to articulate its value to customers and prospective customers.
The majority of the content is found on the site links of the sections.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 1 - Discovery}
\label{\detokenize{class4/modules/module1:section-1-discovery}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.01 - Research the Company and Customer}
\label{\detokenize{class4/modules/module1:objective-1-01-research-the-company-and-customer}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

Understanding the customer’s company direction and initiatives can help
you understand their high-level IT infrastructure drivers. You can
gather this type of information from many different sources and a few of
them are mentioned in this section. Not every company is publicly
traded, so not all of this type of information will be available for you
to review for every customer. This is where building a relationship with
your customer comes into play. As a trusted advisor for your customer
you may be able to learn more about their needs and pressing
initiatives, when no other resource is available.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Visit corporate website to gather information (investor
relations, board of directors, press releases, acquisitions, blogs, RSS
feeds)}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Investor Relations}

Most publicly traded companies will have an investor relations page on
their website that can give information on current financial
performance. This information can help you better understand their
ability to take on a new large project.

If your buyer works for a public company, it might be a good idea to
also check out its most recent financial reports on the SEC’s website.
This will give you an idea of how the company is performing, as well as
the problems it’s facing (check out “risk factors” sections).

Example: \sphinxurl{http://investor.apple.com} \textless{}\sphinxurl{http://investor.apple.com/}\textgreater{}\_\_

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Board of Directors}

Understanding who the influencers and decision makers are within the
organization you are trying to sell into can help you better understand
the decisions they make or may make.

Example: \sphinxurl{http://investor.apple.com/corporate-governance.cfm}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Press Releases}

Scroll through the recent press releases and see if anything major has
been announced such as leadership changes, product releases, financial
statements, events, security concerns, or customer wins.

Example: \sphinxurl{https://www.apple.com/newsroom/}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Acquisitions}

Acquisitions can sometimes accurately predict a company’s future
directions in a market space and can thus help you understand some of
their purchasing decisions or project demands.

Example: \sphinxurl{https://www.apple.com/newsroom/2018/09/apple-acquires-shazam-offering-more-ways-to-discover-and-enjoy-music/}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Blogs}

Read what your buyer reads and read what your buyer writes. If your
prospect maintains a blog, be sure to read at least the last few posts
and comment on them during your call or meeting. In addition, visit the websites of
popular industry blogs and peruse the latest posts to learn more about
the trends and challenges shaping the environment.

Example: \sphinxurl{http://investor.apple.com/corporate-governance.cfm}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{RSS Feeds}

RSS feeds are a type of web feed which allows users to access updates to
online content in a standardized, computer-readable format. You can look
up and subscribe to the RSS feed for each of your publicly held
companies in your territory.
\begin{itemize}
\item {} 
First look up the stock symbol \sphinxhref{https://www.marketwatch.com/tools/quotes/lookup.asp}{*https://www.marketwatch.com/tools/quotes/lookup.asp*}

\item {} 
Next subscribe to the RSS feed using the RSS feed reader of your
choice for each stock symbol

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{The Company’s Twitter and LinkedIn Account}

What kind of content and messaging has the company been promoting?
Understanding how the company is presenting itself to its customers can
help you better understand how to present yourself to your buyer.

\sphinxurl{https://twitter.com}

\sphinxurl{https://www.linkedin.com/}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{AngelList}

If you sell to startups, AngelList is an essential researching tool. You
can see the company’s funding history, including the timing, value, and
participants in each round; past and present employees; advisory team;
founders; products and launches; open jobs; and more.

\sphinxurl{https://angel.co}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 - Locate job postings to identify internal initiatives and
investments}

Some company initiatives can be seen in the type of job roles they have
open. As customers plan for projects they will typically make sure they
are hiring the expertise needed to get the job done or support the
initiative after implementation is complete. You can check a customer’s
Careers page to see what job role is in high demand.

Example: \sphinxurl{https://f5.com/careers}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.02 - Given a scenario, prospect customer opportunities}
\label{\detokenize{class4/modules/module1:objective-1-02-given-a-scenario-prospect-customer-opportunities}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine corporate challenges}

Many times, understanding the implications of the challenges that a customer/company is facing will help you pick the correct solution for that customer/company.  Doing research when customer prospecting (hunting!) is very important. Other than having face-to-face meetings where information can be exchanged, understanding the customer’s mission, vision, and value statement will help align your efforts when introducing technology to solve a business problem. Most of the time, attempts to gather key information using email or “cold calling” activities will not be successful - unless you have made a time investment in understanding the corporate and technology infrastructure of the prospect. To earn the trust of a decision maker , you must understand their needs and budget so you can articulate solutions that meets those needs.  Below are two examples of positioning F5 solutions to meet a company’s cloud and compliance challenges:

\sphinxstyleemphasis{Cloud Challenges}

If a company is trying to reduce capital expenditures (see section
3.02) and is not interested in buying any new hardware for their
data center because they are moving to the Cloud, F5 can help by
providing application services in the Cloud and thus moving the
costs of providing application services to operating expense.

Transition to the Cloud may not always be about CapEx vs OpEx. It
can also be about agility and speed to market. Many times, in the
rush of deployment/migration the necessary application services are
not at the top of mind of a DevOps team and it can be easy for
customers to just default to the built-in Cloud Service Provider
(CSP) application services regardless of capabilities. This can put
them in a hard spot if that application needs a function that the
CSP service can’t perform or if the application needs to move to a
different Cloud provider. F5 provides the same industry leading
application services across multiple CSP with consistency and
portability.

\sphinxstyleemphasis{Compliancy Challenges}

Security concerns are at the top of mind in many organizations and
F5 is there to help them with the application services that can
protect their mission critical Applications and data. Understanding
your customers business vertical can be critical to understanding
the challenges they face as a company. Certain business verticals
come with compliance regulations such as PCI and HIPPA that can
require more strict security policies.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Correlate business and technical initiatives}

Understand the correlation between the needs of a customer’s business
areas and which types of technical initiatives can meet those needs.
Sometimes, when you meet with different business areas within a
customer’s organization, you can gain a broader understanding of the organizations future needs across the entire company.  This information can allow you to see a clearer picture of what your customer needs and understand if you should perhaps position products that can grow their Data Center or if you should focus on Cloud enablement products.   You will need to know all F5 products and the problems they can solve to prepare for this section of the exam.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Determine technical organizational structure}

\sphinxurl{https://en.wikipedia.org/wiki/Organizational\_structure}

\sphinxstylestrong{Organizational Structure}

Understanding your customers organizational structure for the company as
well as organizational structure within the technical departments can
help you understand who is driving requirements and budgeting for the
projects you are involved in.

Some organizations will be very structured and have a clear line of
authority and role, while others may be more loose and harder to clearly
understand but mapping this out with your account team will make your
opportunities more successful.

An organizational structure is a system that outlines how certain
activities are directed in order to achieve the goals of an
organization. These activities can include rules, roles and
responsibilities. The organizational structure also determines how
information flows from level to level within the company. For example,
in a centralized structure, decisions flow from the top down, while in a
decentralized structure, the decisions are made at various levels.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.03 - Given a scenario, correlate which F5 products could solve issues or meet customer needs}
\label{\detokenize{class4/modules/module1:objective-1-03-given-a-scenario-correlate-which-f5-products-could-solve-issues-or-meet-customer-needs}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

You will need to be able to use your knowledge of F5 product
capabilities to correlate to customer needs. This will be a wide range
of questions focused on product capabilities.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Associate customer requirements to F5 solutions}

\sphinxurl{https://www.f5.com/solutions}

\sphinxurl{https://partners.f5.com/solutions}

When you do account discovery and discover the customer problems or
issues that need to be solved, your knowledge of the F5 product line
will allow you to find opportunities within the account. Understanding
the problems our products can solve will allow you to go deeper in the
account with F5 products. You will need to know all of our products and
the problems they can solve to prepare for this section of the exam.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Align potential F5 solutions to business and technical
initiatives and challenges}

\sphinxurl{https://www.f5.com/solutions}

\sphinxurl{https://partners.f5.com/solutions}

Sometimes when you meet with different business areas within a
Customer’s organization you will learn the individual business areas
needs as well as direction. Many times, the funding of IT projects come
directly from the individual business areas budgets. When understanding
those needs you can overlap them with other projects needs within the
customer and provide F5 solutions that not only meet one projects needs
but multiple projects needs potentially expanding budget once multiple
projects are involved. Once again, you will need to know all of our
products and the problems they can solve to prepare for this section of
the exam.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 2 - Education}
\label{\detokenize{class4/modules/module2:section-2-education}}\label{\detokenize{class4/modules/module2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.01 Educate and present on technical capabilities of F5 solutions}
\label{\detokenize{class4/modules/module2:objective-2-01-educate-and-present-on-technical-capabilities-of-f5-solutions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

As a sales architect/engineer, you will need to educate your customers
on the technical capabilities of the products you sell. This means you
will need to know the solutions as well as their use cases. You can
never be too well read when it comes to understanding how F5 solutions
can solve customer issues.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Present F5 overview, product feature sets, new version
features, reference architectures to a technical audience}

\sphinxurl{https://partners.f5.com/products/platforms/big-ip}

\sphinxstylestrong{F5 BIG-IP}

BIG-IP is a powerful application delivery platform that offers your
customers the most comprehensive set of application services in the
industry. When your customers put BIG-IP to work for their applications,
they are assured robust security, fast performance, and maximum
availability in the data center and the cloud.

All BIG-IP modules share a common, underlying full-proxy architecture,
F5’s Traffic Management Operating System (TMOS), which provides
intelligence, flexibility, and programmability. With the BIG-IP
platform, you can solve your customers’ immediate application delivery
challenges and leverage additional modules to grow your opportunity as
customers’ security, performance, global availability, and scaling needs
change.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-local-traffic-manager-ds.pdf}

\sphinxstylestrong{BIG-IP Local Traffic Manager}

BIG-IP Local Traffic Manager (LTM) helps you deliver your applications
to your users in a reliable, secure, and optimized way. You get the
extensibility and flexibility of application services with the
programmability you need to manage your physical, virtual, and cloud
infrastructure. With BIG‐IP LTM, you have the power to simplify,
automate, and customize applications faster and more predictably.

\sphinxstyleemphasis{Full proxy means full power}

Because BIG-IP LTM is a full proxy, you can inspect, manage, and
report on application traffic entering and exiting your network.
From basic load balancing to complex traffic management decisions
based on client, server, or application status, BIG-IP LTM gives you
granular control over app traffic.

\sphinxstyleemphasis{Blazing fast SSL}

The SSL performance of BIG-IP LTM lets you cost-effectively protect
the end-to-end user experience by encrypting everything from the
client to the server. It also scales on-demand and absorbs
potentially crippling DDoS attacks. BIG-IP LTM includes levels of
inspection necessary to block bad traffic and allow good traffic to
pass through.

\sphinxstyleemphasis{TCP Optimization}

The highly optimized TCP/IP stack, TCP Express, combines TCP/IP
techniques and improvements in the latest RFCs with extensions to
minimize the effect of congestion and packet loss and recovery.
Independent testing tools and customer experiences show TCP Express
delivers up to a 2x performance gain for users and a 4x increase in
bandwidth efficiency.

\sphinxstyleemphasis{Performance optimization}

BIG-IP LTM can optimize the speed and reliability of your
applications via both network and application layers. Using
real-time protocol and traffic management decisions based on
application and server conditions, extensive connection management,
and TCP and content offloading, BIG-IP LTM dramatically improves
page load times.

\sphinxstyleemphasis{Programmability}

BIG-IP LTM is programmable, so you can take the visibility and
control it provides and immediately act on it using iRules, F5’s
event-driven scripting language. From defeating zero-day attacks to
cloning specific app requests or dealing with custom application
protocols, iRules let you adapt to application delivery challenges
across any environment.

\sphinxstyleemphasis{Scale and Speed}

With BIG-IP LTM, you get a sophisticated, enterprise-class load
balancer. You also get granular layer 7 control, SSL offloading and
acceleration capabilities, and ScaleN technology that delivers
on-demand scaling.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/big-ip-services/big-ip-dns}

\sphinxstylestrong{BIG-IP DNS}

BIG-IP DNS improves the performance and availability of your global
applications by sending users to the closest or best-performing
physical, virtual, or cloud environment. It also hyperscales and secures
your DNS infrastructure from DDoS attacks.

\sphinxstyleemphasis{Speed and security}

BIG-IP DNS can hyperscale up to 100 million responses per second
(RPS) to manage rapid increases in DNS queries. With a set of
features that includes multicore scalability, DNS Express, and IP
Anycast integration, BIG-IP DNS handles millions of DNS queries,
protects your business from DDoS attacks, and ensures top
application performance for users.

\sphinxstyleemphasis{Always-on Availability}

BIG-IP DNS routes distributed app traffic to keep pace with changing
network and user volumes that can overwhelm data centers during peak
traffic times. BIG-IP DNS can also be configured as a full proxy for
global load balancing applications and DNS across architectures, as
well as across the globe.

\sphinxstyleemphasis{Integrates with your infrastructure}

BIG-IP DNS services integrate with DNS zone management solutions,
increase DNS performance at the network edge, and mask the DNS
back-end infrastructure. That translates into higher productivity,
server consolidation, faster responses, and protected DNS
management.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-advanced-firewall-manager-datasheet.pdf}

\sphinxstylestrong{BIG-IP Advanced Firewall Manager}

BIG-IP Advanced Firewall Manager (AFM) is a high-performance, stateful,
full-proxy network security solution designed to guard data centers
against incoming threats that enter the network on the most widely
deployed protocols. BIG-IP AFM gives enterprises and service providers
the scalability, flexibility, performance, and control needed to
mitigate the most aggressive, volumetric distributed denial-of-service
(DDoS) attacks before they reach the data center.

\sphinxstyleemphasis{Scale to meet network demand}

Meet demands for higher bandwidth usage and concurrency rates with
F5’s proven TMOS architecture, hardware systems, and virtual
editions to ensure performance while under attack.

\sphinxstyleemphasis{Ensure application availability}

Secure networks from DDoS threats across a variety of protocols,
with in-depth rules customization and increased performance and
scalability.

\sphinxstyleemphasis{Protect with app-centric, full-proxy firewall capabilities}

Inspect all incoming client connections and server-to-client
responses, and mitigate threats based on security and application
parameters before forwarding them on to the server.

\sphinxstyleemphasis{Inspect SSL sessions}

Fully terminate and decrypt SSL traffic to identify potentially
hidden attacks—at high rates and with high throughput.

\sphinxstyleemphasis{Streamline firewall deployment}

Simplify security configuration with firewall policies oriented
around applications and an efficient rules and policy GUI.

\sphinxstyleemphasis{Customize reporting for visibility}

Easily understand your security status with rich customizable
reports, logging, and charts that provide insight to all event types
and enable effective forensic analysis.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-application-security-manager-ds.pdf}

\sphinxstylestrong{BIG-IP Application Security Manager/Advanced Application Security
Manager}

BIG-IP Application Security Manager (ASM) is a flexible web application
firewall that secures web applications in traditional, virtual, and
private cloud environments. BIG-IP ASM provides unmatched application
and website protection, complete information about attacks from within
the user interface, and compliance for key regulatory mandates. BIG-IP
ASM is a key part of the F5 application delivery firewall solution,
which consolidates traffic management, network firewall, application
access, DDoS protection, SSL inspection, and DNS security

\sphinxstyleemphasis{Protect web and mobile applications from malicious bots}

F5 secures an organization’s most valued assets, applications, and
sensitive data from bots, automated attacks, web scrapers, and
exploits. Advanced WAF extends bot protection to mobile applications
through the F5 Anti-Bot Mobile SDK, providing rapid deployment of
mobile bot protection through an easy-to-use web portal without
requiring any changes to the application or mobile device.
Applications fused with mobile bot protection are supported in
vendor and third-party application stores.

\sphinxstyleemphasis{Safeguard credentials and sensitive data from theft and abuse}

Advanced WAF secures credentials and sensitive data from theft and
abuse, preventing data breaches and mitigating automated attacks
that leverage previously stolen credentials. F5 BIG-IP DataSafe
application layer encryption in Advanced WAF masks sensitive fields
directly within the user’s web browser, rendering data stolen by bad
actors through client-side attacks useless. Using BIG-IP DataSafe,
customers can encrypt data at the field level transparently, without
requiring any changes on clients or Web servers. Comprehensive brute
force mitigation including credential stuffing protection defends
against automated attacks that leverage previously stolen
credentials.

\sphinxstyleemphasis{Defend against sophisticated application denial-of-service (DoS)}

Advanced WAF discovers and fingerprints new and unusual traffic
patterns without human intervention, distinguishing and isolating
potential malicious traffic from legitimate traffic. This automated
mitigation capability is based on a continuous feedback loop of
client behavior and server stress. If anomalous behavior is
detected, Advanced WAF automatically builds a dynamic signature and
begins mitigating the attack. The effectiveness of the mitigation is
then monitored through the continuous feedback loop. False positives
are reduced while accuracy and performance are improved through
continuous mitigation tuning as the attack starts, evolves, or
stops.

\sphinxstyleemphasis{Mitigate sophisticated threat campaigns}

Threat Campaigns provide targeted signatures to protect
organizations from pervasive attacks that are often coordinated by
organized crime and nation states. Based on F5 Labs research, Threat
Campaigns provide critical intelligence to fingerprint and mitigate
sophisticated attacks with nearly real-time updates. Metadata is
used to determine both malicious requests and malicious intent, and
the high accuracy of Threat Campaign signatures immediately blocks
active threats with low false positives and no learning cycle.

\sphinxstyleemphasis{Protect APIs}

As web applications expand from connected to collaborative via the
extensive use of Application Programming Interfaces (APIs), Advanced
WAF ensures that API methods are enforced on URLs. It also secures
applications against API attacks that commonly go undetected by
traditional firewalls. With a unique defense mechanism that guards
XML, JSON, and GTW APIs through rate limiting, behavioral analysis,
and anti-automation, Advanced WAF automatically detects application
program interface threats, enforces strict policy rules for each use
case, and blocks attacks and special content types—closing the back
door on application threats. With F5 Access Manager, API protection
is improved through comprehensive authentication and token
enforcement.

\sphinxstyleemphasis{Ensure application security and compliance}

Gain comprehensive security against sophisticated layer 7 attacks,
blocking threats that evade traditional WAFs and enabling compliance
with key regulatory mandates.

\sphinxstyleemphasis{Turn on protection immediately}

Simplify security with pre-built policies, thousands of
out-of-the-box signatures, and a streamlined approach to policy
management that decreases operational expenses.

\sphinxstyleemphasis{Patch vulnerabilities fast}

Identify and resolve app vulnerabilities in minutes with leading
dynamic application security testing (DAST) integration and
automatic virtual patching.

\sphinxstyleemphasis{Deploy flexibly}

Deploy as an appliance, in virtual or cloud environments, and as a
managed service supporting multi-tenant services while incorporating
external intelligence that secures against known IP threats.

\sphinxstyleemphasis{Defend with proven advanced protections}

Defend with highly programmable technology that dynamically adapts
policies, proactively stops bots and DoS attacks, and demonstrates
99.89\% overall security effectiveness.

\sphinxstyleemphasis{Magnify threat knowledge}

Easily understand your security status with detailed forensic
analysis, full visibility into HTTP and WebSocket traffic, and rich
insight into all events and user types.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-access-policy-manager-ds.pdf}

\sphinxstylestrong{BIG-IP Access Policy Manager}

BIG-IP Access Policy Manager (APM) is a secure, flexible,
high-performance solution that provides unified global access to your
network, cloud, and applications. With a single management interface, it
converges and consolidates remote, mobile, network, virtual desktops,
and web access. BIG-IP APM enables the creation and enforcement of
simple, easy-to-manage, intelligent access policies.

\sphinxstyleemphasis{Centralize identity and access control}

Simplify access management with identity, context, and application-aware
policies.

\sphinxstyleemphasis{Unify access controls}

Consolidate remote, mobile, network, virtual desktop infrastructure
(VDI), and web access in one interface with adaptive identity
federation, single sign-on (SSO), and multi-factor authentication
(MFA).

\sphinxstyleemphasis{Reduce costs}

Replace proxy tiers with an integrated solution for VMware
Horizon/Workspace ONE, Citrix XenApp, Microsoft Exchange, and
others.

\sphinxstyleemphasis{Defend the weak links}

Protect against data loss, malware, and rogue device access with
comprehensive endpoint posture and security checks.

\sphinxstyleemphasis{Secure web access}

Control access to suspicious web content and apply intelligent
Forcepoint technology to defend against highly complex web threats.

\sphinxstyleemphasis{Do it all at scale}

No performance trade-offs for security, even in the most demanding
environments.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/access-manager/secure-web-gateway}

\sphinxstylestrong{F5 Secure Web Gateway}

F5 Secure Web Gateway (SWG) is an add-on license to BIG-IP APM. F5 SWG
services can enforce secure web access for on-premises, remote, and
mobile users. It also helps protect against web-borne malware, targeted
attacks, and other insidious dangers lurking on the web.

\sphinxstyleemphasis{URL filtering}

URL filtering helps to ensure appropriate usage policies. Using the
extensive Forcepoint database, URL filtering in Secure Web Gateway
Services controls access to websites, web-based applications,
protocols, and videos. Secure Web Gateway Services also filters
search results based on your policy, preventing the display of
offensive search results or images. URL filtering is customizable,
and it helps reduce and mitigate corporate exposure to web-based
threats and data leakage. BIG-IP APM provides flexibility for
enterprises to allow, block, or “confirm and continue” access for
certain users to the Internet, specific websites, and web
applications.

\sphinxstyleemphasis{URL categorization database}

Secure Web Gateway Services leverages the powerful Forcepoint URL
categorization engine and database that is constantly classifying
tens of millions of URLs across the Internet. URL categorization is
contextually-aware and applies real-time classification information
against known web pages—assessing new web pages and URLs using
advanced machine learning. This minimizes false positives and
improves URL classification.

\sphinxstyleemphasis{Web security}

Secure Web Gateway Services also detects and blocks malware or
malicious scripts within web pages by scanning return HTTP/HTTPS
traffic. The malware engine contains web malware analytics,
signatures, and heuristic detection engines that identify and
eradicate general and specialized threats. When a remote user
accesses the web through a per-app VPN tunnel in BIG-IP APM, Secure
Web Gateway Services protects the session as though the user was on
the corporate network. Authentication, URL filtering, and malware
scanning polices are applied. Secure Web Gateway Services can also
bypass or block SSL websites (based on inspection) for privacy and
compliance purposes—enabling flexible control for access to
SSL-encrypted websites.

\sphinxstyleemphasis{Real-time threat intelligence}

Leveraging the Forcepoint cloud-based threat intelligence
infrastructure to deliver constant, up-to-date security information,
Secure Web Gateway Services detects threats within web and social
networking content. It synchronizes with Forcepoint cloud-based
threat intelligence on a user-configurable schedule.

\sphinxstyleemphasis{User identification}

Secure Web Gateway Services keeps track of the mapping between user
identity and network addresses while enabling transparent,
user-based security policies through the F5 User Identity Agent. The
User Identity Agent runs on a Windows-based server and pulls
information from Active Directory domain controllers, enabling
Secure Web Gateway Services to fully track a user’s web activity by
user identity or group membership.

\sphinxstyleemphasis{Graphical security reporting and comprehensive logging}

The graphical user interface within Secure Web Gateway Services lets
system administrators view and export various security analytics
reports. These reports empower administrators with total visibility
of outbound and inbound web traffic, Internet use, and policy
enforcement. Logs may be published through the F5 log publisher to
well- known security information and event management (SIEM)
solutions, including ArcSight and Splunk for longer-term storage and
analytics.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/ip-intelligence-service-ds.pdf}

\sphinxstylestrong{F5 IP Intelligence}

F5 IP Intelligence incorporates external, intelligent services to
enhance automated application delivery with better IP intelligence and
stronger, context-based security. By identifying IP addresses and
security categories associated with malicious activity, the IP
Intelligence service can incorporate dynamic lists of threatening IP
addresses into the F5 BIG-IP® platform, adding context to policy
decisions. IP Intelligence service reduces risk and increases data
center efficiency by eliminating the effort to process bad traffic.

\sphinxstyleemphasis{Ensure IP threat protection}

Deliver contextual awareness and analysis to block threats from a
dynamic set of high-risk IP addresses.

\sphinxstyleemphasis{Improve visibility into threats from multiple sources}

Detect malicious activity and IP addresses with help from a global
threat-sensor network and IP intelligence database.

\sphinxstyleemphasis{Enable granular threat reporting and automated blocking}

Reveal communication with malicious IP addresses to create more
effective security policies.

\sphinxstyleemphasis{Optimize protection with real-time updates}

Automatically refresh the threat database as often as every five
minutes to keep the organization safe.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/websafe-datasheet.pdf}

\sphinxstylestrong{F5 WebSafe}

F5 WebSafe delivers web fraud protection that safeguards banks,
e-retailers, and other organizations exposed to online fraud. It
protects online customers from a broad range of web fraud across all
devices—without impacting the user experience. WebSafe helps
organizations to achieve success in the fight against credential theft,
web-based malware, and online fraud targeting web application users.
Using unique and advanced capabilities that complement existing fraud
prevention techniques and solutions, WebSafe gives your organization the
ability to provide greater online fraud protection and make more
informed overall security decisions that prevent account take overs,
identity theft, and system breaches.

\sphinxstyleemphasis{Guard against targeted and generic malware}

Recognize and safeguard against sophisticated threats, including web
injection, credential grabbing, man-in-the-browser (MITB), Remote
Access Trojans (RATs), form loggers, password stealers, and more.

\sphinxstyleemphasis{Preempt phishing attacks}

Identify phishing attacks before they are launched—at the point
where attackers are creating and testing spoofed domains.

\sphinxstyleemphasis{Protect without client downloads}

Inspect all users, whether they are browsing from a desktop, mobile
device, set-top box, or even a game console.

\sphinxstyleemphasis{Easily deploy fraud detection and prevention}

Secure your site without application modifications or changes to the
user experience.

\sphinxstyleemphasis{Maintain up-to-date global threat intelligence}

Monitor the latest and most sophisticated attacks that may
potentially impact your business.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/services/resources}

\sphinxstylestrong{Reference Architectures}

The F5 Resources page has a ton of useful material from customer stories
to recommended practice guides. You will also find reference
architectures in the white papers section. Below are links to just a
couple of the reference architectures you should review.


\bigskip\hrule\bigskip


\sphinxurl{https://f5.com/solutions/enterprise/reference-architectures/intelligent-dns-scale}

\sphinxstylestrong{Intelligent DNS Scale Reference Architecture}

F5’s end-to-end Intelligent DNS scale reference architecture enables
organizations to build a strong DNS foundation that maximizes resources
and increases service management, while remaining agile enough to
support both existing and future network architectures, devices, and
applications.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/services/resources/white-papers/the-f5-ssl-reference-architecture}

\sphinxstylestrong{SSL Reference Architecture}

SSL is becoming the primary protocol between an organization and its
customers. It protects traffic between those customers and the
organization’s services, whether those services are in the cloud or on
premise.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Present F5 overview, key F5 messaging, training options, value
of F5 to a non-technical audience}

\sphinxurl{https://www.f5.com/products/big-ip-services/local-traffic-manager}

\sphinxstylestrong{F5 Overview - BIG-IP Local Traffic Manager}

BIG-IP Local Traffic Manager enables you to control network traffic,
selecting the right destination based on server performance, security,
and availability.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/big-ip-services/big-ip-dns}

\sphinxstylestrong{F5 Overview - BIG-IP DNS}

BIG-IP DNS improves the performance and availability of your global
applications by sending users to the closest or best-performing
physical, virtual, or cloud environment. BIG-IP DNS services integrate
with DNS zone management solutions, increase DNS performance at the
network edge, and mask the DNS back-end infrastructure. That translates
into higher productivity, server consolidation, faster responses, and
protected DNS management.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/access-manager}

\sphinxstylestrong{F5 Overview - BIG-IP Access Policy Manager (Access Manager)}

Access Manager secures, simplifies, and protects user access to apps and
data, while delivering the most scalable access gateway on the market.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/F5\_advanced\_WAF\_overview.pdf}

\sphinxstylestrong{Value of F5 - BIG-IP Application Security Manager /Advanced WAF}

Applications are critical to your business. Without the right
protection, however, they can become an attack vector that may
ultimately lead to a data breach. Consider this alarming statistic:
Organizations have an average of 765 web applications and these
applications are the initial target of data breaches 53\% of the time.
Web application firewalls (WAF) protect your applications from data
breaches by fixing vulnerabilities and stopping attacks.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/advanced-firewall-manager}

\sphinxstylestrong{F5 Overview - BIG-IP Advanced Firewall Manager}

Protect your network against incoming threats, including the most
massive and complex DDoS attacks. DDoS attacks saturate bandwidth,
consume network resources, and disrupt application services. Can your
infrastructure successfully fend them off? Advanced Firewall Manager
mitigates network threats before they disrupt critical data center
resources.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/ssl-orchestrator}

\sphinxstylestrong{F5 Overview - SSL Orchestrator}

Maximize infrastructure investments, efficiencies, and security with
dynamic, policy-based decryption, encryption, and traffic steering
through multiple inspection devices. Over 80\% of page loads are
encrypted with SSL/TLS. Attackers commonly use encryption to hide
malicious payloads. If you’re not inspecting SSL/TLS traffic, you will
miss attacks, and leave your organization vulnerable. SSL Orchestrator
provides robust decryption/encryption of SSL/TLS traffic.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/ddos-hybrid-defender}

\sphinxstylestrong{F5 Overview - DDoS Hybrid Defender}

Get comprehensive DDoS protection for your network and at the
application layer with flexibility and scale for inline, out-of-band,
and hybrid deployments. DDoS Hybrid Defender is the only multi-layered
defense that protects against blended network attacks and sophisticated
application attacks, while enabling full SSL decryption, anti-bot
capabilities, and advanced detection methods—all in one appliance.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/automation-and-orchestration/big-iq}

\sphinxstylestrong{F5 Overview - BIG-IQ Centralized Manager}

BIG-IQ Centralized Management provides a central point of control for F5
physical and virtual devices. It simplifies management, helps ensure
compliance, and gives you the tools you need to deliver your
applications securely and effectively.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/big-ip-services/local-traffic-manager}

\sphinxstylestrong{Value of F5 - SSL Performance}

The SSL performance of BIG-IP LTM lets you cost-effectively protect the
end-to-end user experience by encrypting everything from the client to
the server. It also scales on-demand and absorbs potentially crippling
DDoS attacks. BIG-IP LTM includes levels of inspection necessary to
block bad traffic and allow good traffic to pass through.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.02 Gather resources to replicate F5 technical demonstrations}
\label{\detokenize{class4/modules/module2:objective-2-02-gather-resources-to-replicate-f5-technical-demonstrations}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Identify valuable technical resources (F5.com, DevCentral,
Askf5.com, GitHub, VLAB)}

This section is focused on the candidate understanding where to go for
information and resources.

\sphinxhref{https://www.f5.com/}{*https://www.f5.com/*}

\sphinxstylestrong{F5.com}

Get the detailed information you need on F5 products. Datasheets include
features, specifications, system requirements, and more.


\bigskip\hrule\bigskip


\sphinxhref{https://devcentral.f5.com/}{*https://devcentral.f5.com/*}

\sphinxstylestrong{DevCentral}

Learn F5 Technologies, Get Answers \& Share Community
Solutions. DevCentral is a source for tools, techniques, and
collaboration to help you build solutions with iControl, iCall, iApps
and iRules that enable applications to work in concert.


\bigskip\hrule\bigskip


\sphinxhref{https://support.f5.com/}{*https://support.f5.com/*}

\sphinxstylestrong{Askf5.com}

AskF5 is your storehouse for thousands of solutions to help you manage
your F5 products more effectively. Whether you want to search the
knowledge base periodically to research a solution, or you need the most
recent news on your F5 products.


\bigskip\hrule\bigskip


\sphinxhref{https://support.f5.com/csp/article/K80012344}{*https://support.f5.com/csp/article/K80012344*}

\sphinxstylestrong{Github}

To support the development community, F5 may post open source software
to an F5-specific GitHub community located
at \sphinxhref{https://github.com/F5Networks}{*https://github.com/F5Networks*}.
These repositories support Automation and Orchestration efforts for
BIG-IP in Private and Public clouds.


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com/learning/technicaldemos}

\sphinxstylestrong{Solution Demos}

Showing is better than telling, right? Check out these recordings that
walk you through how to create a live, compelling demo for your
customers.


\bigskip\hrule\bigskip


\sphinxurl{https://downloads.f5.com/}

\sphinxstylestrong{Virtual Lab Environment (vLab)}

Partners may download vLab environment to demonstrate BIG-IP features on
their laptop or work/personal lab environment.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.03 Given a scenario, articulate key values of F5 solutions}
\label{\detokenize{class4/modules/module2:objective-2-03-given-a-scenario-articulate-key-values-of-f5-solutions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Prepare solution pitches for F5 solutions and technology}

\sphinxurl{https://partners.f5.com/solutions/f5-sales-plays}

\sphinxstylestrong{F5 Sales Plays}

A sales play is designed to help our Channel Partner’s position F5
solutions for a specific customer need. Each sales play includes a set
of materials designed for training that will prepare and help you
position F5 solutions that will drive an end-to-end sale. The content of
the sales play includes the sales playbook, customer facing deck and
other associated documentation such as whiteboards, demos and/or
collateral to help support the sales pitch.


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com/learning/accreditation}

\sphinxstylestrong{F5 Sales Accreditation}

The F5 Sales Accreditation for technical and sales roles is the first
step in becoming fluent in F5 solutions and technologies and
understanding how to bring them to your customers. The accreditation is
offered online through \sphinxhref{https://account.f5.com/learnf5/signin}{Learn F5}.
Through the accreditation, you will learn how to address customers’
current business initiatives and future business challenges with F5’s
emphasis on making sure that customers’ applications are always fast,
available, and secure, anywhere.

Knowledge gained on Learn F5 will help with the exam.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Match products, features, solutions, to customer initiatives or
requirements}

\sphinxurl{https://www.f5.com/solutions}

\sphinxurl{https://partners.f5.com/solutions}

This section is very similar with section 1.03 just from a different
point of view. You need to be able to educate the customer on what
problems our products solve. The IT acronym machine has been running
strong for decades and talking in acronyms especially proprietary
product acronyms is not a good way to improve the customers
understanding of what F5 does. So, being able to correlate F5’s three
letter product offerings to the industry standard name of the solution
that can meet the customer’s needs is key. If a customer needs to block
cross-site scripting (XSS) on their primary internet facing application,
you should be able to say which product from F5 can solve their issue.
There are many solutions with our products and you should be familiar
with them all.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.04 Given a scenario, distinguish architectural considerations that may affect the F5 solution}
\label{\detokenize{class4/modules/module2:objective-2-04-given-a-scenario-distinguish-architectural-considerations-that-may-affect-the-f5-solution}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Determine cloud strategy}

\sphinxurl{https://www.f5.com/solutions/cloud}

\sphinxstylestrong{Consistent Application Services}

Get consistent app services in any cloud. F5 ensures apps are secure and
available, in any infrastructure. You can apply the same
enterprise-grade load balancing, DNS services, web application
firewalls, access control, application-level security, and policy
management found in on-premises environments.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Determine security constraints}

\sphinxurl{https://www.f5.com/solutions/cloud/public-cloud}

\sphinxstylestrong{Public Cloud Shared Security}

Public CSPs guarantee the security of the infrastructure, but
application owners are responsible for the security of their
applications and data. This means that Cloud infrastructure may be
secure, but customer’s data and applications are not protected by the
CSP. There is still a need for application services in the Cloud.

This is a diagram of the AWS shared security model.

\noindent\sphinxincludegraphics{{p1}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Determine management and orchestration}

\sphinxurl{https://www.f5.com/pdf/products/big-iq-datasheet.pdf}

F5 BIG-IQ Centralized Management provides a central point of control for
F5 physical and virtual devices and for the solutions that run on them.
It simplifies management, helps ensure compliance, and gives you the
tools you need to deliver your applications securely and effectively.

BIG-IQ manages policies, licenses, SSL certificates, images, and
configurations for F5 devices and for the following F5 modules:
\begin{itemize}
\item {} 
BIG-IP Local Traffic Manager (LTM)

\item {} 
BIG-IP Application Security Manager (ASM)

\item {} 
BIG-IP Advanced Firewall Manager (AFM)

\item {} 
BIG-IP Access Policy Manager (APM)

\item {} 
F5 Secure Web Gateway Services

\item {} 
BIG-IP DNS

\item {} 
F5 WebSafe and F5 MobileSafe (monitoring and updates)

\end{itemize}

BIG-IQ is ideal for organizations that require central management of F5
devices and modules, license management of BIG-IP VEs, or central
reporting and alerting on application availability, performance,

and security.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/solutions/automation-and-orchestration/management-visibility-and-orchestration}

\sphinxstylestrong{Super-NetOps}

NetOps, Super-NetOps, DevOps

Whether you want to automate your existing deployments or integrate into
CI/CD pipelines, F5 automation and orchestration solutions can help you
increase efficiency and decrease risk across your application portfolio.

Cloud, automated deployment, and DevOps practices are reshaping IT, as
developers increasingly bypass internal IT teams to meet business
demands for speed.

Super-NetOps self-pace curriculum designed to help previously siloed
NetOps and DevOps teams to begin to collaborate and teaches BIG-IP
administrators how to standardize services and provide them through
automation toolchains, reducing time-to-service from days to minutes.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 3 - Proposal}
\label{\detokenize{class4/modules/module3:section-3-proposal}}\label{\detokenize{class4/modules/module3::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.01 Given a scenario, recommend F5 solutions to meet technical requirements}
\label{\detokenize{class4/modules/module3:objective-3-01-given-a-scenario-recommend-f5-solutions-to-meet-technical-requirements}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Determine which application services are needed}

F5 provides many types of application services for our customer’s
applications. These services provide increased availability,
performance, access and protections regardless of where the customers
applications are located. Each of these application services are made
available through licensing on the platforms with Good, Better, Best
(GBB) licensing model and add-on licenses, as well as F5 aaS offerings.

\noindent\sphinxincludegraphics{{p21}.png}


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/solutions/application-security/ddos-protection}

\sphinxstylestrong{DDoS Protection}

Distributed Denial of Service (DDoS) attacks threaten businesses with
downtime that can damage their brand and even lead to financial losses.
With the many IoT device-powered botnets and for-hire DDoS services, the
threat of an attack is greater than ever. F5 provides DDoS protection
across the range of attack vectors and at each level of the application.

Volumetric DoS attacks consume all available bandwidth across the
network link that connects an application to the Internet or other
networks. Computational DoS attacks attempt to exhaust infrastructure
resources, such as firewall state tables, leading to crashing or
degraded performance. Application DoS attacks mimic legitimate
application requests but attempt to overload web server resources such
as CPU or memory.

Applications can be attacked at many different levels. Below are just a
sample of the types of application attacks at each level.
\sphinxstylestrong{Network Level DoS}

\sphinxstyleemphasis{SYN Flood}

Every client-server conversation begins with a standard three-way
handshake. The client sends a SYN packet, the server responds with a
SYN-ACK, and the TCP connection is established with a final client ACK.
In a SYN flood attack the client sends massive numbers of SYN requests,
and never responds to the SYN-ACK messages from the server.

This leaves the server with open connections waiting for responses from
the client. Each of these half-open connections is tracked in the TCP
connection table, eventually filling the table and blocking additional
connection attempts, legitimate or otherwise.

\sphinxstyleemphasis{Memcached Amplification}

An amplification attack is a type of reflection attack that takes
advantage of the ability to send small spoofed packets to services that,
as part of their normal operation, will reply back to the target with a
much larger response.

Memcached is a database caching system for speeding up websites and
networks. Attackers can spoof requests to a vulnerable internet-facing
memcached server, which then floods a target with traffic, potentially
overwhelming their resources. While the target’s infrastructure is
overloaded, new requests can’t be processed and regular traffic can’t
access the Internet resource, resulting in denial-of-service.

Other types of amplification attacks include NTP, SSDP, SNMPv2, CharGEN,
QOTD, and more.

\sphinxstyleemphasis{UDP Flood}

UDP is a standard communication protocol across IP networks. Because UDP
packets are stateless, they require less error checking and validation
in contrast to TCP. A UDP flood attack attempts to overload a server
with requests by saturating the connection tables on every accessible
server port.

Filling the connection table with these requests prevents legitimate
requests from being processed.

\sphinxstyleemphasis{IP Fragmentation}

IP fragmentation is a process established by design of the IP protocol
that breaks packets or datagrams into smaller fragments, so they can
pass through network links that have a smaller maximum transmission unit
(MTU) limit. The host or stateful security devices receiving the
fragments reassembles them into the original datagram. The packets’ or
datagrams’ IP header tells the receiver how to reassemble the datagram.

These attacks come in various forms, but all variations attempt to use
fragmentation to overwhelm the target server or network node.

\sphinxstylestrong{DNS Level DoS}

\sphinxstyleemphasis{DNS Flood}

DNS servers rely on the UDP protocol for name resolution, which (unlike
TCP queries) is connectionless. Because confirmation that UDP packets
have been received isn’t required, spoofing is easily accomplished.

This scripted botnet attack attempts to overwhelm server resources,
ultimately affecting the DNS servers’ ability to direct legitimate
requests. The attack can consist of valid UDP traffic from multiple
sources or randomized packet data. This helps this attack type evade
basic DDoS protection techniques like IP filtering.

\sphinxstyleemphasis{NXDomain Flood}

A variant of the DNS flood, an attacker floods the DNS server with
requests for invalid or nonexistent records. Then, the DNS server spends
its resources looking for something that doesn’t exist instead of
serving legitimate requests. The result is that the cache on the DNS
server gets filled with bad requests and clients can’t find the servers
they’re looking for.

\sphinxstyleemphasis{DNS Amplification}

DNS amplification is a type of reflection attack that manipulates
vulnerable internet facing DNS servers, causing them to flood an
internet resource with an influx of large UDP packets.

An attacker-controlled botnet is scripted to send small, but specially
formed, DNS queries to any publicly available DNS resolver. This elicits
a disproportionate response from the DNS resolver. The packet headers
also include a spoofed IP address, the IP address of the DDoS target.
Upon receiving the query, the open DNS resolvers provide an extremely
large response to the target of the attack, which eventually consumes
the bandwidth of the internet resource.

\sphinxstylestrong{TLS Level DoS}

\sphinxstyleemphasis{SSL Renegotiation}

This attack takes advantage of an asymmetric workload by requesting a
secure connection, and then continuously renegotiating it. This requires
a lot of CPU power from the server and can slow current or new
connections or even take down the server.

\sphinxstyleemphasis{SSL Flood}

Attackers send numerous TLS/SSL connection requests with the client
never closing the connection. Once the concurrent connection limit is
reached, the TLS termination point stops processing traffic, including
legitimate requests.

\sphinxstyleemphasis{SSL Squeeze}

A variant of an SSL renegotiation attack, the squeeze attack
continuously attempts to renegotiate the connection handshake, forcing
the server to decrypt “junk” requests.

Typical renegotiation attacks multiplex SSL handshakes, which can be
mitigated by disabling renegotiation on the server. However, SSL squeeze
opens new TCP connections for each request, eventually consuming I/O.

\sphinxstylestrong{Access Level DoS}

\sphinxstyleemphasis{Brute-Force Login Attack}

An attacker tries multiple username and password combinations, often
using a dictionary of words or commonly used passwords to gain
unauthorized access to an application or website.

A common mitigation is to temporarily lock out user accounts with
multiple failed login attempts. However, this can result in a denial of
service for those affected accounts.

\sphinxstylestrong{App Services Level DoS}

\sphinxstyleemphasis{HTTP Flood}

In an HTTP flood, the attacker exploits seemingly legitimate HTTP GET or
POST requests to attack a web server or application. These attacks
typically consume less bandwidth than others but focus on triggering
complex server-side processing to bring down the targeted site or app.
HTTP floods can sometimes trigger responses from web servers that can
turn it into a pipe-saturating volumetric attack.

\sphinxstyleemphasis{Slowloris}

Slowloris works by opening multiple connections to a web server and
sending HTTP requests, none of which are ever completed. Periodically,
the attacker sends subsequent HTTP headers for each request, but never
actually completes the request. Ultimately, the target server’s maximum
concurrent connection pool is filled and legitimate connections are
denied.

\sphinxstyleemphasis{Heavy URL}

During the reconnaissance phase, an attacker will map out the most
computationally expensive URLs on a site or application, also known as
heavy URLs. Heavy URLs include any URL causing greater server load upon
request. The initial HTTP request is relatively small but can take a
long time to complete or yield large response sizes. These requests can
require the server to load multiple large files or run
resource-intensive database queries.

\sphinxstyleemphasis{Slow Post}

An attacker begins by sending a legitimate HTTP POST request to a web
server, in which the header specifies the exact size of the message body
that will follow. However, that message body is then sent at an
extremely slow rate. Because the message is technically correct and
complete, the targeted server attempts to follow all specified rules. If
an attacker establishes enough of these POST attacks simultaneously,
they consume server resources to the extent legitimate requests are
denied.

F5 delivers complete DDoS coverage with our BIG-IP appliances in the datacenter and Silverline DDoS Protection managed services.  Silverline DDoS Protection provides a flexible, hybrid, solution combining granular threat detection with always-on or on-demand high mitigation capacity in the cloud.  Companies also benefit from 24x7x365 expert monitoring and support to augment resources when under a volumetric attack.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/big-ip-services/big-ip-dns}

\sphinxstylestrong{DNS / Global Load Balancer}

Global load balancing is used to gain performance and availability of
your global applications by sending users to the closest or
best-performing physical, virtual, or cloud environment.

BIG-IP DNS provides speed and security and can hyperscale up to 100
million responses per second (RPS) to manage rapid increases in DNS
queries. With a set of features that includes multicore scalability, DNS
Express, and IP Anycast integration, BIG-IP DNS handles millions of DNS
queries, protects your business from DDoS attacks, and ensures top
application performance for users.

BIG-IP DNS routes distributed app traffic to keep pace with changing
network and user volumes that can overwhelm data centers during peak
traffic times. BIG-IP DNS can also be configured as a full proxy for
global load balancing applications and DNS across architectures, as well
as across the globe.

BIG-IP DNS services integrate with DNS zone management solutions,
increase DNS performance at the network edge, and mask the DNS back-end
infrastructure. That translates into higher productivity, server
consolidation, faster responses, and protected DNS management


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-advanced-firewall-manager-datasheet.pdf}

\sphinxstylestrong{Firewall / Intrusion Prevention}

Unlike traditional firewalls, BIG-IP AFM is built on the full-proxy
architecture of the F5 TMOS operating system. Incoming client
connections are fully terminated, inspected for possible security
threats, and only then forwarded to the server—assuming no threats are
present.

With the full-proxy capabilities of TMOS, BIG-IP AFM has in-depth
understanding of the most commonly used inbound protocols such as
HTTP/S, DNS, ICMP, and TCP, and supports a rich set of services that
expand traditional stateful firewall capabilities. Additionally, this
security enables deeper visibility into connections, allowing data to be
manipulated and modified before it’s sent to servers or otherwise.

In the reverse direction, server-to-client communication is also
proxied. BIG-IP AFM can scrub return data for sensitive information—for
instance, protocol response codes that could divulge network information
for reconnaissance attacks—and private data, such as credit card or
Social Security numbers.

The full-proxy design enables termination of SSL, enforcement of
security policies, east-west firewall capabilities, and other
performance-related services—helping organizations address challenges in
volatility inside and outside of the data center.

Gone are the days of mapping applications to zones, or scouring through
spreadsheets of firewall policies to distinguish attacks on specific
applications or to identify the IP address for a particular application
server.

Unlike most network firewall solutions, BIG-IP AFM security policies are
logically aligned with the applications in specific traffic
flows—streamlining security operations and heightening security
effectiveness. But similar to web application firewall solutions,
BIG-AFM attaches network security policies to application objects.
Details about the application parameters, including server addressing,
SSL offload, and access policies, can be grouped together

with security parameters, including policies, SSL inspection, and
logging. This includes information on which layer 7 protocols are
permitted for specific application port access. F5’s app-centric
approach provides increased efficiency in addressing app concerns and
more accuracy in threat detection and policy effectiveness.

Further, since the configuration for an application is unified with an
associated network security policy, deprovisioning of applications is
also streamlined. When an application is deprovisioned, the obsolete
security rules are simultaneously deprovisioned. BIG-IP AFM helps ensure
the effectiveness of application deployment and simplifies policy
assurance above rigid zone-based or segment-based constructs.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-local-traffic-manager-ds.pdf}

\sphinxstylestrong{Traffic Management / Load Balancer}

Applications drive innovation and profitability, allowing businesses to
leverage trends such as cloud computing, mobility, and software‐defined
networking (SDN).

Load balancing helps deliver applications to users in a reliable,
secure, and optimized way. They provide the power to simplify, automate,
and customize applications faster and more predictably.

Key benefits:
\begin{itemize}
\item {} 
Deliver applications rapidly and reliably

\item {} 
Optimize for today’s web applications with HTTP/2 to ensure that
customers and users have access to the applications they
need—whenever they need them.

\item {} 
Automate and customize with programmable infrastructure

\item {} 
Control your applications—from connection and traffic to
configuration and management—with F5 iRules LX, the next stage of
evolution for network programmability that brings Node.js language
support to the BIG‐IP platform.

\item {} 
Transition to SDN and cloud networks

\item {} 
Realize operational consistency and comply with business needs across
physical, virtual, and cloud environments with deployment flexibility
and scalability.

\item {} 
Easily deploy and manage applications

\item {} 
User‐defined F5 iApps Templates make it easy to deploy, manage, and
get complete visibility into your applications.

\item {} 
Secure your critical applications

\item {} 
Protect the apps that run your business with industry‐leading SSL
performance and visibility.

\end{itemize}


\bigskip\hrule\bigskip


\sphinxstylestrong{SSL Visibility / Inspection / Analytics}

SSL/TLS enables businesses to securely communicate with customers and
partners. Problem is, SSL/TLS can also function as a tunnel that
attackers use to hide attacks and malware from security devices.
Inspection devices like a next-gen firewall, an IDS/IPS, or a malware
sandbox don’t see into encrypted SSL/TLS traffic or suffer degraded
performance when decrypting. F5 SSL Orchestrator easily integrates into
complex architectures and offers a centralized point for decryption and
re-encryption while strategically directing traffic to all the
appropriate inspection devices.

Managing the SSL/TLS connection between users and applications can be
tedious and leave room for security risks. F5 offers a solution to
centralize and simplify the management of keys, certificates, and
ciphers used in end-to-end encryption, so you can cost-effectively
protect data-in-transit by encrypting everything from the client to the
server. It also adheres to the FIPS 140-2 standard and scales to absorb
potentially crippling DDoS attacks. Use your solution to perform TLS
termination, TLS cipher policy enforcement, or TLS offload.

Attackers and security researchers are constantly trying to find new
ways to break today’s popular methods of encrypting data-in-transit.
Often, a flaw in the protocol design, a cipher, or an underlying library
is the culprit. Our solution provides for centralized management of your
TLS configuration which enables better application performance and
allows seamless flexibility in updating your TLS configurations as
needed.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/products/big-ip-access-policy-manager-ds.pdf}

\sphinxstylestrong{Identity Access / Multi-factor Auth / Single Sign-On}

BIG-IP APM simplifies and consolidates your infrastructure. The
flexibility and scalability helps you to combine network access
controls, identity federation, SSO, and adaptive authentication into a
single application delivery solution.

Identity federation and single sign-on (SSO)

BIG-IP APM supports SSO and Kerberos ticketing across multiple domains,

enabling additional types of authentication, such as U.S. Federal
Government Common Access Cards (CACs) and the use of Active Directory
authentication for all applications.

Users are automatically signed on to back-end applications and services
that are part

of a Kerberos realm. This provides a seamless authentication flow after
a user has been authenticated through a supported user-authentication
mechanism. BIG-IP APM also delivers smart card support with credential
providers, so that users can connect their devices to the network before
signing in.

BIG-IP APM simplifies mobile access to protected resources by enabling
remote access (VPN) authentication and authorization from Microsoft
Windows, Apple Mac OS, Apple iOS, and Google Android devices—as well as
devices running Chrome OS via SAML (such

as Google Chromebooks). SAML-based authentication increases security,
reduces user dependencies on passwords, and improves both the user
experience and productivity.

SAML 2.0 further enhances BIG-IP APM identity federation and SSO options
by supporting connections initiated by both SAML identity providers
(IdPs) and service providers.

This functionality extends identity federation, as well as SSO
capabilities to cloud-based applications and offers identity federation
across an organization’s BIG-IP products. It also empowers
administrators to centrally disable user access to all identity-enabled
applications, regardless of where they reside, saving time and boosting
administrative productivity.

BIG-IP APM can serve as a translator, enabling SSO via SAML to
applications that support SAML, as well as to those that are not
SAML-enabled. For applications that do not accept SAML, BIG-IP APM can
convert the authentication access to the appropriate authentication for
that application. This ensures users can utilize SSO to
applications—regardless of whether these apps support SAML, are
on-premises, or in the cloud.

BIG-IP APM secures the transport of SAML messages by supporting SAML
artifact binding, reducing the flow of SAML messages through browsers,
addressing certain browser restrictions, and extending identity
federation and SSO support to automatically submitted forms that do not
support JavaScript. BIG-IP APM also extends identity federation via SAML
to client-based applications and other browserless
environments—including desktop applications and server code in web
apps—and streamlines user workflow by supporting SAML Enhanced Client or
Proxy (ECP) profiles.

BIG-IP APM supports the OAuth 2.0 open-standard for authorization. It
can serve as a client for social networking logins, as an authorization
delegate for SaaS applications, and can enhance protection for and
authorization of application programmable interfaces (APIs)

for web services.

By delivering seamless user access to web applications in a highly
available and heterogeneous environment, BIG-IP APM improves business
continuity and saves your organization from decreased user productivity.
BIG-IP APM supports and integrates with AAA servers and user credential
stores—including Active Directory, Lightweight Directory Access
Protocols (LDAP), RADIUS, and Native RSA SecurID—and delivers high
availability through the intelligent traffic management capabilities of
BIG-IP LTM.

In addition, BIG-IP APM recognizes when an RSA SecurID software token is
installed on a user’s Windows or Mac device, prompting the user for an
RSA PIN and seamlessly authenticating that user. BIG-IP APM also
supports Google reCAPTCHA V2 for authentication and contextual
authentication.


\bigskip\hrule\bigskip


\sphinxurl{https://en.wikipedia.org/wiki/Web\_application\_firewall}

\sphinxstylestrong{Web Application Firewall}

A web application firewall (WAF) is a special type of application
firewall that applies specifically to web applications. It is deployed
in front of web applications and analyzes bi-directional web-based
(HTTP) traffic - detecting and blocking anything malicious. The OWASP
provides a broad technical definition for a WAF as “a security solution
on the web application level which - from a technical point of view -
does not depend on the application itself.” According to the PCI DSS
Information Supplement for requirement 6.6, a WAF is defined as “a
security policy enforcement point positioned between a web application
and the client endpoint. This functionality can be implemented in
software or hardware, running in an appliance device, or in a typical
server running a common operating system. It may be a stand-alone device
or integrated into other network components.” In other words, a WAF can
be a virtual or physical appliance that prevents vulnerabilities in web
applications from being exploited by outside threats. These
vulnerabilities may be because the application itself is a legacy type
or it was insufficiently coded by design. The WAF addresses these code
shortcomings by special configurations of rule-sets, also known as
policies.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Determine which technical solutions are needed}

\sphinxurl{https://www.f5.com/solutions}

\sphinxurl{https://partners.f5.com/solutions}

This section is very similar with section 1.03 and 2.03 just from a
different point of view. This section is focused on you understanding
the technical solutions that should be proposed to allow you to start
sizing and building the sales solution. Once again, you will need to
know all of our products and the problems they can solve to prepare for
this section of the exam.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Determine licensing needs to meet customer requirements}

\sphinxurl{https://www.f5.com/pdf/licensing/good-better-best-licensing-overview.pdf}

\sphinxurl{https://www.f5.com/products/get-f5/perpetual-licensing-gbb}

\sphinxstylestrong{Licensing the F5 Features and Capabilities}

No matter how a customer chooses to consume the F5 products in their
environments (Perpetual, Utility, Subscription or ELA) they will need
some or all of the features and capabilities of the TMOS operating
system (load balancing, global load balancing, WAF, IP intelligence, web
fraud protection, etc.). F5 came out with a simplified licensing model
in 2013 called Good, Better, Best (GBB) to make it easy for
you to bring advanced F5 capabilities to your customers’ environments at
a pace and cost that match their budget and deployment requirements.
Good licensing provides intelligent local traffic management for
increased operational efficiency and peak network performance of
applications. Better licensing provides all the benefits of “Good” plus
advanced application delivery optimization. And Best licensing provides
all the benefits of “Better” plus advanced access management and
application security. Delivers optimal security, performance, and
availability for your applications and network.

\sphinxstylestrong{Good-Better-Best}

\sphinxstyleemphasis{Good Provides:}

BIG-IP Local Traffic Manager
\begin{itemize}
\item {} 
Load balancing and monitoring

\item {} 
Application visibility and monitoring

\item {} 
L7 intelligent traffic management

\item {} 
Core protocol optimization (HTTP, TCP, HTTP/2, SSL)

\item {} 
SSL proxy and services

\item {} 
IPv6 support

\item {} 
Programmability (iRules, iCallTM, iControl, iApps)

\item {} 
ScaleNTM (on-demand scaling of performance and capacity)

\item {} 
BIG-IP APM Lite (user authentication, SSL VPN for 10 concurrent
users) SYN flood DDoS protection

\item {} 
Optional to Good, Included in Better: Advanced routing (BGP, RIP,
OSPF, ISIS, BFD)

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Better adds the following to Good:}

BIG-IP DNS
\begin{itemize}
\item {} 
Global server load balancing

\item {} 
DNS services

\item {} 
Real-time DNSSEC solution Global application high availability
Geolocation

\item {} 
DNS DDoS attack prevention

\end{itemize}

BIG-IP Advanced Firewall Manager
\begin{itemize}
\item {} 
High-performance ICSA firewall

\item {} 
Network DDoS protection

\item {} 
Application-centric firewall policies

\item {} 
Protocol anomaly detection

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Best adds the following to Better:}

BIG-IP Application Security Manager
\begin{itemize}
\item {} 
PCI-compliant web application firewall

\item {} 
Web scraping prevention

\item {} 
Integrated XML firewall

\item {} 
Violation correlation and incident grouping

\item {} 
Application DDoS protection

\end{itemize}

BIG-IP Access Policy Manager
\begin{itemize}
\item {} 
500 concurrent user sessions; scalable up to 200,000

\item {} 
BYOD enablement

\item {} 
Full proxy for VDI (Citrix, VMware)

\item {} 
Single sign-on enhancements (identity federation with SAML 2.0)

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p31}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

There are other add-on licensable features beyond GBB. Knowing all the
products we offer beyond GBB will help you understand how to best solve
customer issues. The list below is just a few.


\bigskip\hrule\bigskip


\sphinxhref{https://f5.com/products/modules/ip-intelligence-services\%20for\%20information}{https://f5.com/products/modules/ip-intelligence-services for information}

\sphinxstylestrong{IP Intelligence Services}

IP Intelligence Services increases data center efficiency by
blocking malicious activity at the earliest point.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/access-manager/secure-web-gateway}

\sphinxstylestrong{Secure Web Gateway}

Paired with F5 Access Policy Manager, our Secure Web Gateway
Services give you insight and tools to take action and ensure your
network is safe from malicious threats.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/websafe-and-mobilesafe}

\sphinxstylestrong{Web Fraud Protection}

WebSafe is a web fraud solution that provides clientless protection by leveraging advanced encryption capabilities, malware detection and session behavioral analysis.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/big-ip-services/carrier-grade-nat}

\sphinxstylestrong{CGNAT}

CGNAT offers a broad set of tools that enables service providers to
successfully migrate to iPv6 while continuing to support and
interoperate with existing iPv4 devices and content.

There are also other stand-alone products that allow F5 to solve
customer problems.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/ssl-orchestrator}

\sphinxstylestrong{SSL Orchestrator}

Over 80\% of page loads are encrypted with SSL/TLS. Attackers commonly
use encryption to hide malicious payloads. If you’re not inspecting
SSL/TLS traffic, you will miss attacks, and leave your organization
vulnerable. SSL Orchestrator provides robust decryption/encryption of
SSL/TLS traffic.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/security/ddos-hybrid-defender}

\sphinxstylestrong{DDoS Hybrid Defender}

DDoS Hybrid Defender provides a greater depth of defense. It’s the only
multi-layered defense that protects against blended network attacks and
sophisticated application attacks, while enabling full SSL decryption,
anti-bot capabilities, and advanced detection methods—all in one
appliance. It also delivers the highest performance with line-rate
capabilities and without impacting legitimate traffic.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/automation-and-orchestration/big-iq}

\sphinxstylestrong{BIG-IQ}

Manage all your BIG-IP devices from one place. BIG-IQ Centralized
Management provides a central point of control for F5 physical and
virtual devices. It simplifies management, helps ensure compliance, and
gives you the tools you need to deliver your applications securely and
effectively.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.02 Given a scenario, recommend F5 solutions to meet business requirements}
\label{\detokenize{class4/modules/module3:objective-3-02-given-a-scenario-recommend-f5-solutions-to-meet-business-requirements}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Conclude how F5 solutions and technology meets the customer’s
business needs}

\sphinxhref{https://www.f5.com/customer-stories}{*https://www.f5.com/customer-stories*}

Reviewing some of our customer success stories will help you understand
the issues and challenges and restrictions our customers use F5 to
solve.


\bigskip\hrule\bigskip


\sphinxhref{https://www.f5.com/services/resources/solution-profiles}{*https://www.f5.com/services/resources/solution-profiles*}

F5 solution profiles provide a high-level overview of how F5 products
and features work together to deliver a complete solution for a
particular technology or for a specific vertical market.


\bigskip\hrule\bigskip


\sphinxhref{https://partners.f5.com/solutions/f5-sales-plays}{*https://partners.f5.com/solutions/f5-sales-plays*}

F5 partner Sales Plays can provide background on how to position F5
products to solve customer issues.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Determine ROI needs, depreciation needs, CapEx, OpEx, payment
delivery timeframe}

Understanding the following concepts will help the sales account team
understand their customers restrictions and drivers for spending.

\sphinxhref{https://www.idealware.org/measuring-return-investment-technology/}{*https://www.idealware.org/measuring-return-investment-technology/*}

\sphinxstyleemphasis{Return on Investment (ROI)}

As companies purchase infrastructure such as F5 BIG-IP platforms to
handle all of their application services needs, they will weigh the
costs of that infrastructure against the benefits that it provides. This
measuring results in Return On Investment (ROI). Effective organizations
have a positive Return on Investment, or ROI, for individual technology
choices as well as their overall investment in technology.


\bigskip\hrule\bigskip


\sphinxhref{https://en.wikipedia.org/wiki/Depreciation}{*https://en.wikipedia.org/wiki/Depreciation*}

\sphinxstyleemphasis{Depreciation}

Hardware assets like BIG-IP appliances can be depreciated over time.
Depreciation is a method of reallocating the cost of a tangible asset
over its useful life span of it being in motion. Businesses depreciate
long-term assets for both accounting and tax purposes. The former
affects the balance sheet of a business or entity, and the latter
affects the net income that they report. Generally, the cost is
allocated, as depreciation expense, among the periods in which the asset
is expected to be used.


\bigskip\hrule\bigskip


\sphinxhref{https://en.wikipedia.org/wiki/Capital\_expenditure}{*https://en.wikipedia.org/wiki/Capital\_expenditure*}

\sphinxstyleemphasis{CapEx (Capital Expenditure)}

In short, it is the money a company spends to buy, maintain, or improve
its fixed assets, such as buildings, vehicles, equipment, or land. For
tax purposes, capex is a cost that cannot be deducted in the year in
which it is paid or incurred and must be capitalized. This is the driver
that motivates most companies to try to reduce CapEx and increase OpEx.


\bigskip\hrule\bigskip


\sphinxhref{https://en.wikipedia.org/wiki/Operating\_expense}{*https://en.wikipedia.org/wiki/Operating\_expense*}

\sphinxstyleemphasis{OpEx (Operating Expense)}

This is ongoing cost for running a product, business, or system. Its
counterpart, a capital expenditure (capex), is the cost of developing or
providing non-consumable parts for the product or system. In business,
an operating expense is a day-to-day expense such as sales and
administration, or research \& development, as opposed to production,
costs, and pricing. In short, this is the money the business spends in
order to turn inventory into throughput.

If the company is sensitive to CapEx expenditures, then putting BIG-IPs
into the operating budget may be preferable. BIG-IP VEs licensed under
an Enterprise License Agreement (ELA) or Subscription licensing
agreement.


\bigskip\hrule\bigskip


\sphinxhref{https://due.com/blog/10-invoicing-terms-need-know/}{*https://due.com/blog/10-invoicing-terms-need-know/*}

\sphinxstyleemphasis{Payment delivery timeframe}

Businesses, regardless of the industry or size, require regular cash
flow from their clients and the customer to pay their expenses, such as
their employees’ salaries and the utilities. That’s why invoicing is a
necessity. Without these bills, you won’t be compensated for the
services rendered or products sold, which in turn means that you won’t
be able to handle your expenses.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.03 Given a scenario, answer technical queries regarding a proposed F5 solution}
\label{\detokenize{class4/modules/module3:objective-3-03-given-a-scenario-answer-technical-queries-regarding-a-proposed-f5-solution}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.03 - Justify F5 product choice as the correct solution}

\sphinxhref{https://partners.f5.com/solutions}{*https://partners.f5.com/solutions*}

\sphinxstylestrong{Product Justification}

As you go through all of the available material on the F5 products and
solutions that help your customers solve the problems they face in their
application infrastructure, learning which products can work together to
solve the problems the most cost-effective way is a very important part.
Understanding that bundling products via licensing or even deploying a
product as a stand-alone instance may be the best for the customer’s
scenario.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.03 - Justify product sizing}

\sphinxhref{https://support.f5.com/csp/article/K14810}{*K14810: Overview of BIG-IP VE license and throughput
limits*}

\sphinxhref{https://support.f5.com/csp/article/K6475}{*K6475: Overview of SSL TPS licensing
limits*}

\sphinxhref{https://support.f5.com/csp/article/K95135311}{*K95135311: The BIG-IP APM platform session capacity for VIPRION,
iSeries, and Virtual
Edition*}

\sphinxhref{https://support.f5.com/csp/article/K14218}{*K14218: vCMP guest memory/CPU core allocation
matrix*}

\sphinxstylestrong{Sizing BIG-IP}

The platform and virtual editions datasheets will give you general
performance numbers. You should refer to the datasheets as you make
general sizing determinations. In most cases, these are the maximum
capabilities at which either CPU or memory is completely consumed. This
means determining CPU and memory requirements are extremely important in
determining the appliance or virtual edition that is purchase for a
solution. For, example, the amount of memory not only determines how
many modules can run on a BIG-IP, but also how many concurrent
connections can be maintained, as each current connection uses a finite
amount of memory. CPU can be a limiting factor, HTTP compression
consumers CPU, if not performed in hardware, SSL can consume CPU
depending on the key size, cipher and whether the cipher is supported by
hardware and for BIG-IP Virtual Editions this is always the case.

Often, CPU utilization and performance can be the key to determining
whether appliances are needed as opposed to virtual editions. Offloading
to hardware, functionality, as simple L4 operations to the ePVA, SSL key
exchange to the Cavium/Intel SSL chip or compression chip will save both
CPU and memory.

Some question you may want to ponder;
\begin{itemize}
\item {} 
Do I have enough CPUs and what kind of utilization should it expect?
\begin{itemize}
\item {} 
vCMP guest, multiple modules, complex or simple policies, iRules,
analytics

\end{itemize}

\item {} 
Am I leaving enough room for 3-5 years of growth?
\begin{itemize}
\item {} 
OpEx vs CapEx

\end{itemize}

\item {} 
Memory requirements?
\begin{itemize}
\item {} 
vCMP guest, concurrent connections, HTTP caching is done strictly
using memory

\end{itemize}

\item {} 
What will SSL TPS look like?
\begin{itemize}
\item {} 
What ciphers will be used, what is the key size, how many SSL key
exchanges will need to be built per second on both the client and
server side.

\end{itemize}

\item {} 
Concurrent connections?

\item {} 
Connections/Sec?
\begin{itemize}
\item {} 
How many new connections per second need to be build.

\item {} 
How much memory per connection is consumed (content spooling)

\end{itemize}

\item {} 
Config size?
\begin{itemize}
\item {} 
What is the size on the overall configuration of the BIG-IP, do
you need to allocate more memory to the control plane?

\end{itemize}

\item {} 
Is the control plane overwhelmed?

\item {} 
Are there multiple modules?

\item {} 
Where can I accelerate/optimize?

\end{itemize}

Module Memory Requirements

Memory requirements in the release notes are solely for provisioning.
They aren’t a substitute for sizing resources appropriately. When
combining multiple software modules, you should typically size for
the worst-case (heavy hitter) module and then adjust for running
multiple modules. Each module will consume memory and CPU resources, so
it’s better to oversize for multiple module use cases. BIG-IP ASM and
BIG-IP APM are examples of resource-intensive modules.

How much memory does a connection take

It depends! Layer 4 state uses much less memory than layer 7. Basic rule
of thumb is \textasciitilde{}750k L4 connections per 1 GB of memory. Basic rule of thumb
is 100-130k L7 connections per 1 GB of memory (\textasciitilde{}6X more memory than L4).
Basic rule of thumb is 50-170k SSL connections per 1 GB of memory. These
numbers are all for basic BIG-LTM functionality. Memory per connection
may increase if other advanced services such as BIG-IP ASM, BIG-IP APM,
and iRules are enabled.

CPU

CPU speed can be an important sizing metric when there are a lot of
CPU-intensive tasks running. It can also be combatted by throwing more
CPU cores at the problem, even if they are running at a slower speed.
Think about what type of processing the sizing for (L7 processing,
iRules, BIG-IP ASM, SSL ciphers that require software processing,
Monitors, Control plane).

Web Application Firewall performance depends on a number of parameters,
such as (Response size, Request size, Application/server response
latency, Policys in use, Number of simultaneous connections, Logging
profile, SSL key length in use). All of which are highly dependent on
the applications and how it operates.

Sizing BIG-IP Summary

While throughput and connections per second are important metrics, they
are not the only things that should be considered when sizing BIG-IP.
Memory and CPU are just as important if not more important than some of
the datasheet numbers. Plan for growth in any sizing exercise. You never
know what resources you’ll need a couple of years down the road. Ensure
you plan for the lifetime of the projected install.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.03 - Distinguish F5 products from competition}

\sphinxhref{https://partners.f5.com/Portals/4/Partner\%20Central\%20Assets/Products/Products\_Licensing\_GBB\%20Quick\%20Reference\%20Guide\_July\%202015.pdf}{*https://partners.f5.com/Portals/4/Partner\%20Central\%20Assets/Products/Products\_Licensing\_GBB\%20Quick\%20Reference\%20Guide\_July\%202015.pdf*}

\sphinxstylestrong{Distinguishing F5 from Competition}

Most of the time it is best as a customer’s trusted advisor to not
attack F5’s competition and try to make claims on what they can’t do. It
is always a better approach to explain how we can effectively solve the
problems or issues they are facing. F5 has a large repository of documentation on our
product capabilities. But there are a few generalized documents that
will help you with competitive differentiation and customer objection
handling. If you must have specific documentation that relates to F5’s
capabilities as opposed to one of our competitor’s, you should work with
the F5 sales team on the account and let them find the necessary
information.

\#1 most deployed WAF worldwide!!

\noindent\sphinxincludegraphics{{p41}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 4 - Supporting the Close}
\label{\detokenize{class4/modules/module4:section-4-supporting-the-close}}\label{\detokenize{class4/modules/module4::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.01 Gather appropriate information to size F5 solutions}
\label{\detokenize{class4/modules/module4:objective-4-01-gather-appropriate-information-to-size-f5-solutions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Determine quantity}

\sphinxhref{https://f5.com/de/products/technologies/scalen}{*https://f5.com/de/products/technologies/scalen*}

\sphinxstylestrong{How many F5 devices do you need?}

This question is partly about redundancy and partly about sizing. You
can look at how much capacity a customer will need based on throughput,
planning for growth, etc. and pick the right sized hardware appliance or
virtual appliance, to fit their needs. And a single appliance may fit
the capacity needs; however, it does not provide redundancy in the event
of hardware (appliance or hypervisor) failure. So, when determining how
many you need there is always a need for redundancy. If you deploy in an
HA pair for redundancy you can run them as Active/Standby or
Active/Active. Neither of these redundancy modes allows for more
capacity. It is simply a different means of failover management. The F5
ScaleN redundancy deployment model will allow for redundancy as well as
capacity management and is discussed in more detail in this document.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Determine high availability options}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-6-0/1.html}{*https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-6-0/1.html*}

\sphinxhref{https://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf}{*https://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf*}

\sphinxstylestrong{High Availability}

Device service clustering, or DSC, is an underlying architecture within
BIG-IP Traffic Management Operation System (TMOS), based on the F5
ScaleN technology. The DSC architecture allows you to create a redundant
system configuration for multiple BIG-IP devices on a network. System
redundancy includes the ability to mirror connection and persistence
information to a peer device to prevent service interruptions during
failover. DSC provides synchronization and failover of BIG-IP
configuration data at user-defined levels of granularity, among multiple
BIG-IP devices on a network. More specifically, you can configure a
BIG-IP device on a network to:
\begin{itemize}
\item {} 
Synchronize some or all of its configuration data among several
BIG-IP devices

\item {} 
Fail over to one of many available devices

\item {} 
Mirror connections to a peer device to prevent interruption in
service during failover

\end{itemize}

If you have two BIG-IP devices only, you can create either an
active-standby or an active-active configuration. With more than two
devices, you can create a configuration in which multiple devices are
active and can fail over to one of many, if necessary.

By setting up DSC, you ensure that BIG-IP configuration objects are
synchronized and can fail over at useful levels of granularity to the
most-available BIG-IP devices on the network. You also ensure that
failover from one device to another, when enabled, occurs seamlessly,
with minimal to no interruption in application delivery.

The BIG-IP system supports either homogeneous or heterogeneous hardware
platforms within a device group.

The most common DSC implementation is an active-standby configuration,
where a single traffic group is active on one of the devices in the
device group and is in a standby state on a peer device. If failover
occurs, the standby traffic group on the peer device becomes active and
begins processing the application traffic.

To implement this DSC implementation, you can create a Sync-Failover
device group. A Sync-Failover device group with two or more members and
one traffic group provides configuration synchronization and device
failover, and optionally, connection mirroring.

An active-active pair is a pair of BIG-IP devices configured so that
both devices are actively processing traffic and are ready to take over
one another if failover occurs. The two devices synchronize their
configuration data to one another.

In this configuration, both devices actively process application
traffic, each for a different application. One device processes its
application traffic using the configuration objects associated with the
default floating traffic group

F5 ScaleN technology enables organizations to scale performance,
virtualize, or horizontally cluster multiple BIG-IP devices, creating an
elastic Application Delivery Networking infrastructure that can
efficiently adapt as needs change.
\begin{itemize}
\item {} 
On-demand scaling—Increase capacity and performance with on-demand
scaling, simply adding more power to your existing infrastructure
instead of adding devices. Some BIG-IP appliance models can be
upgraded to the higher performance model within each series through
on-demand software licensing, which enables organizations to support
growth without new hardware.

\item {} 
Operational scaling—Virtualize ADC services with a multi-tenant
architecture that supports a variety of BIG-IP versions and product
modules on a single device. F5 Virtual Clustered Multiprocessing
(vCMP) technology enables select hardware platforms to run multiple
BIG-IP guest instances. Each guest instance acts like a physical
BIG-IP device, with a dedicated allocation of CPU, memory, and other
resources. vCMP offers per-guest rate limiting for bandwidth,
enabling different performance levels for each guest.

Further divide each vCMP guest using multi-tenant features such as
partitions and route domains, which can isolate configuration and
networks on a per-virtual-domain basis. Within each virtual domain,
you can further isolate and secure configuration and policies, with
a role-based access system for administrative control. When route
domains/partitions are combined with vCMP guests, F5 provides the
highest density multi-tenant virtualization solution, which can
scale to thousands of virtual ADC (vADC) instances.

This ability to virtualize BIG-IP ADC services means service
providers and enterprise users can isolate based on BIG-IP version,
enabling departmental or project-based tenancy as well as
performance guarantees, consolidated application delivery platform
management, and increased utilization.

\item {} 
Application scaling—Increase capacity by adding BIG-IP resources
through an

all-active approach, and scale beyond the traditional device pair to
eliminate idle and costly standby resources. Application scaling
achieves this through two forms of horizontal scale. One is
Application Service Clustering, which focuses on application
scalability and high availability. The other is Device Service
Clustering, designed to efficiently and seamlessly scale BIG-IP
application delivery services and sync application policies.

\end{itemize}

Application Service Clustering delivers sub-second failover and
comprehensive connection mirroring for a highly available cluster of up
to eight devices at the application layer, providing highly available
multi-tenant deployments. Workloads can be moved across a cluster of
devices or virtual instances without interrupting other services and can
be scaled to meet business demand.

Device Service Clustering can synchronize full device configurations in
an all-active deployment model, enabling consistent policy deployment
and enforcement across devices—up to 32 active nodes. This ensures a
consistent device configuration, with syncing of hardened firewall and
access policies to simplify operations and reduce attack surfaces.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Determine virtual environment details}

\sphinxhref{https://www.f5.com/services/resources/white-papers/virtual-clustered-multiprocessing-vcmp}{*https://www.f5.com/services/resources/white-papers/virtual-clustered-multiprocessing-vcmp*}

\sphinxstylestrong{Virtualization}

Data center consolidation and virtualization have changed the way
organizations look at CapEx and OpEx. Gone are the days when adding new
capacity or applications was simply accomplished by buying “more.”
Today, CIOs and architects are looking to maximize the return on
investment in hardware and software through virtualization technologies
that enable them to squeeze every ounce of computing power from their
existing data centers.

This is most apparent in the world of application servers, but the
potential benefits for other devices, firewalls, routers, and
Application Delivery Controllers (ADCs) cannot be ignored. Consequently,
most vendors offer strategies around multi-tenancy or virtual appliances
in one form or another to provide the same kind of flexibility for their
solutions that OS virtualization offers in the server world.

While both multi-tenancy and virtual appliances improve organizations’
deployment flexibility and their ability to get maximum ROI from both
CapEx and short-term OpEx, these strategies have failed to provide the
same kind of high-reliability, high-performance solutions as traditional
purpose-built systems.


\bigskip\hrule\bigskip


\sphinxhref{https://www.f5.com/pdf/products/big-ip-virtual-editions-datasheet.pdf}{*https://www.f5.com/pdf/products/big-ip-virtual-editions-datasheet.pdf*}

\sphinxhref{https://www.f5.com/pdf/white-papers/big-ip-ltm-ve-wp.pdf}{*https://www.f5.com/pdf/white-papers/big-ip-ltm-ve-wp.pdf*}

\sphinxstylestrong{F5 Virtual Edition}

F5 BIG-IP virtual editions (VEs) are virtual application delivery
controllers (vADCs) that can be deployed on all leading hypervisors and
cloud platforms running on commodity servers. BIG-IP VEs deliver all the
same market-leading application delivery services including advanced
traffic management, acceleration, DNS, firewall, and access management
that run on F5 purpose-built hardware. VE software images are
downloadable and portable between on-premises virtualized data center,
public cloud, and private cloud environments. With BIG-IP virtual
editions and F5 BIG-IQ Centralized Management solutions, you can rapidly
provision consistent application services across the data center and
into the cloud

\sphinxstyleemphasis{Key Benefits}
\begin{itemize}
\item {} 
Deploy with increased agility:

Quickly and easily spin up, spin down, or migrate application
delivery services in and across the data center and public cloud,
using instant deployment options as needed.

\item {} 
Achieve automation and orchestration in cloud architectures:

Automate deployment and configuration or integrate with leading
orchestration frameworks in cloud or software-defined networking
(SDN) environments through cloud solution templates, REST APIs, and
granular programmability.

\item {} 
Optimize application and security services:

Rapidly provision and consolidate application services on your
existing servers, unlocking the broadest feature density through
flexible licensing models that align to your business needs.

\item {} 
Provide the ultimate in flexibility:

Get the most flexible deployment options in the industry, with
support across all major virtualization and container platforms for
both private and public cloud environments.

\end{itemize}

\sphinxhref{https://clouddocs.f5.com/cloud/public/v1/matrix.html}{*https://clouddocs.f5.com/cloud/public/v1/matrix.html*}

\sphinxstylestrong{F5 Virtual Edition Supported Platforms}

Each customer may have different virtualization environments with in
their data centers, private cloud or even different pubic clouds which
each have their own hypervisors. F5 virtual editions can run on many
different versions of hypervisors. The link below shows the full matrix
of hypervisors our VE can run on. You should be aware of our flexibility.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/services/resources/white-papers/virtual-clustered-multiprocessing-vcmp}

\sphinxstylestrong{F5 vCMP}

Virtual Clustered Multiprocessing (vCMP) is the industry’s first
purpose-built hypervisor—it allows the complete segmentation of those
purpose-built, scalable resources into independent, virtual ADCs.

vCMP allows a BIG-IP system to run multiple instances of BIG-IP software
on a single hardware platform. The vCMP host (hypervisor) can allocate a
specific amount of hardware resources to each vCMP guest (instance). The
possible hardware allocations may change between versions.

The payoff of a purpose-built hypervisor that’s deeply integrated with
the underlying hardware and guest software is the most powerful
virtualized ADC solution available today. With vCMP, organizations can
independently operate virtual instances without sacrificing
interoperability with existing equipment, purpose-built hardware, or
orchestration solutions.

With vCMP, administrators can run multiple instances of TMOS, each
isolated from the others. Unlike some implementations, because vCMP is a
true hypervisor, the guest ADCs are completely isolated—so they can run
entirely different versions of ADC software. This means that test and
development staff can create new virtual ADC instances to test new
versions of software without any effect on existing deployments. Or,
competing business units can choose if/when they upgrade their virtual
instances to meet their unique business requirements. All they have to
do is provision a new instance, apply their existing configuration, and
then test the upgrade process and results. Any problems can be addressed
by simply removing the instance and starting over. Alternatively,
administrators can upgrade individual instances in place without having
to upgrade all instances.

Because each guest is its own complete ADC, individual business units or
other customers have complete control over their deployment, the ability
to further segment their deployment using administrative controls, and
the ability to manage independent logs and configurations. However, a
failure or misstep cannot affect any other virtual instance. Rebooting
the instance, runaway processes, and flat-out misconfigurations are
isolated from all other instances.

The deep integration of vCMP also enables it to work seamlessly with
existing functionality. For instance, CMP allows new compute resources
to be added incrementally and become instantly available to the ADC.
When vCMP is in operation, those new resources can be automatically
allocated to existing virtual instances without any interruption,
reboot, or reconfiguration. On the other side of the stack, when
configuring vCMP guest allocation, the hypervisor can directly assign IP
addresses for management and VLAN tags along with the resource
allocation restrictions. Creating a new ADC instance can be done in a
matter of minutes, and a new administrator can log in and start their
configuration. Other vendors’ virtual ADC solutions require reboot of
virtual instances before new resources are available, and each instance
must be manually configured before being ready for further
configuration. vCMP allows virtual instances full access to new network
interfaces, VLANs, and even entirely new resource blades instantly and
without interruption.

Flexible allocation allows administrators to designate CPU resources
(and blades on chassis models) to guests upon creation. Dynamic scaling
allows reallocation of CPU resources, without disruption. This makes it
possible to redistribute resources to better align with the need for
business agility in addressing growth and scale, as well as support
additional or new application delivery services that may require more
CPU resources. Administrators can size guests according to what’s
required for each deployment—and modify when those requirements change.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.01 - Determine hardware details}

\sphinxurl{https://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf}

\sphinxstylestrong{BIP-IP iSeries Hardware}

The massive performance and scalability of the BIG-IP platform reduces
the number of ADCs needed to deliver even the most demanding
applications. By offloading computationally intense processes, you can
significantly reduce the number of application servers needed.

The BIG-IP iSeries platform perfectly blends software and hardware
innovations that balance the need for performance, scalability, and
agility. The F5 TMOS operating system provides total visibility,
flexibility, and control across all application delivery services. With
TMOS, organizations can intelligently adapt to the diverse and evolving
requirements of applications and networks. Other unique or patented
hardware and software innovations enable the BIG-IP iSeries platform to
offer unmatched capabilities.

F5 TurboFlex optimization technology:

Field-programmable gate arrays (FPGAs), tightly integrated with
CPUs, memory, TMOS, and software, provide specific packet-flow
optimizations, L4 offload, support for private cloud tunneling
protocols, and denial-of- service (DoS) protection. These hardware
optimizations not only improve performance but free CPU capacity for
other app delivery and security tasks. Only BIG-IP iSeries
appliances feature TurboFlex performance profiles—user-selectable,
pre-packaged optimizations that provide different performance
characteristics depending on the business need.

FIPS Compliance:

The Federal Information Processing Standards (FIPS) specify
requirements for cryptographic modules. FIPS compliance is required
for many government agencies and industries such as financial
services and healthcare that demand the highest standards in
information, application, and data security. F5 offers a broad range
of FIPS-certified hardware appliances that support a FIPS 140-2
Level 2 implementation for RSA cryptographic key generation, use,
and protection (when running validated versions of TMOS). For
additional protection, the BIG-IP 10350v-F/i7820-DF/i5820-DF
supports a FIPS 140-2 Level 3 implementation of the Internal HSM
(PCI card). BIG-IP Hardware FIPS appliances include integrated HSMs
that have tamper-evident seals with a hardened-epoxy cover which, if
removed, will render the card useless. Keys generated on or imported
into a BIG-IP system hardware security module (HSM) are not
extractable in a plain-text format. This security rating means the
10350v-F/ i7820-DF/i5820-DF HSM card adds tamper-resistance, which
is an additional means of detection to the tamper-evident methods of
Level 2, as well as a response to physical access attempts, or to
cryptographic module use or tampering.

vCMP Support:

Not all models of hardware support provisioning vCMP. The list of
models that can provision vCMP are listed in this link:
\sphinxurl{https://support.f5.com/csp/article/K14088} . There are not any
physical differences between the lower iSeries model and the higher
model (i.e. i5600 and i5800). There is simply a software restriction
that makes the lower model exist. The higher model is simply running
a high-performance license. If a customer buys an i5600 and later
wants to upgrade to an i5800, it can be done without a forklift
upgrade of hardware by applying the upgrade license and all the
functionality of the i5800 (e.g. vCMP) is possible on their existing
hardware.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.02 Given a scenario, determine the appropriate F5 licensing requirements}
\label{\detokenize{class4/modules/module4:objective-4-02-given-a-scenario-determine-the-appropriate-f5-licensing-requirements}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.02 - Determine appropriate licensing solution (Perpetual, Utility, ELA, Subscription, BYOL)}

\sphinxstylestrong{F5 Consumption Models}

No matter which features and capabilities of TMOS a customer needs (e.g.
load balancing, global load balancing, WAF, IP intelligence, web fraud
protection, etc.) using Good, Better, Best (GBB) (discussed in Section
3) and add-on licenses, they still have licensing options on how they
consume the F5 products in their environments (Perpetual, Utility,
Subscription or ELA).


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/products/get-f5/perpetual-licensing-gbb}

\sphinxstylestrong{Perpetual/BYOL}

All F5 physical hardware and Virtual Editions are licensed with a
perpetual license key based on the GGB licensing model and add-on
licenses. These devices can be run in a customer’s data center, their
private cloud or even a public cloud. When a VE is deployed in the
public cloud using a perpetual license key, it is considered a BYOL in
the Cloud. There are other licensing models for cloud environments that
we will cover below.


\bigskip\hrule\bigskip


\sphinxurl{https://f5.com/products/platforms/f5-ready-cloud-program}

\sphinxstylestrong{Utility/PAYG}

Utility (pay-as-you-go) using GBB enables an hourly, daily, or monthly
billing model to support temporal deployments like dev \& test or for
customers who prefer the OpEx model.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/licensing/big-ip-virtual-edition-subscription-licensing-overview.pdf}

\sphinxstylestrong{Subscription Licensing}

Subscription Licensing Offer for BIG-IP VE is an auto-renewal agreement
for BIG-IP VE licenses using GBB, available in 1-year, 2-year, and
3-year periods. Within the agreement, organizations choose local BIG-IP
VE licenses at subscription initiation. The initial order of
subscription licenses is populated in F5 BIG-IQ License Manager and is
available for immediate deployment. Subscription Licensing Offer for
BIG-IP VE enables IT departments to self- manage their lifecycles.
License instantiation or revocation can be done via the BIG-IQ License
Manager either directly or via REST API. Net-new licenses from the
BIG-IP VE Subscription list can be instantiated at any time. Activity
reports are provided monthly to F5 via BIG-IQ API upload or email. F5
Premium 24x7 support and software updates are included in the
subscription.


\bigskip\hrule\bigskip


\sphinxurl{https://www.f5.com/pdf/licensing/big-ip-virtual-edition-enterprise-licensing-agreement-overview.pdf}

\sphinxstylestrong{Enterprise License Agreement (ELA)}

F5’s ELA is a licensing model designed to support your customers’ need
for more flexibility how they buy and deploy their investment in F5.
F5’s ELA is a 3-year monetary commitment for BIG-IP VE’s (e.g. LTM, ASM,
AFM, DNS, APM) that the customer deploys as needed when needed at a
predictable yearly cost.

\noindent\sphinxincludegraphics{{p51}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 4.03 Given a scenario, identify line items to build an F5 bill of materials (BOM)}
\label{\detokenize{class4/modules/module4:objective-4-03-given-a-scenario-identify-line-items-to-build-an-f5-bill-of-materials-bom}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4.03 - Gather necessary information (support options, interfaces,
power supplies, support options, product SKUs, Professional Services)}

\sphinxhref{https://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf}{*https://www.f5.com/pdf/products/big-ip-platforms-datasheet.pdf*}

\sphinxhref{https://www.f5.com/pdf/products/viprion-overview-ds.pdf}{*https://www.f5.com/pdf/products/viprion-overview-ds.pdf*}

\sphinxhref{https://support.f5.com/csp/article/K15045}{*https://support.f5.com/csp/article/K15045*}
- QSFP+ Breakout Cable Options

\sphinxhref{https://support.f5.com/csp/article/K8153}{*https://support.f5.com/csp/article/K8153*}
- F5 Support of Third Party Hardware Components

\sphinxhref{https://support.f5.com/csp/article/K4309}{*https://support.f5.com/csp/article/K4309*}
- F5 Support Lifecycle

\sphinxhref{https://support.f5.com/csp/article/K13435}{*https://support.f5.com/csp/article/K13435*}
- BIG-IP Power Cabling

As a sales engineer you will often need to create a Bill of Materials
(BoM). You can take all of the sizing information that determined what
F5 products will fit the customer’s needs and information you have
gathered to support the implementation of F5 in the customers
environment to create this list of necessary goods. You would normally
need the F5 price sheet for the SKU numbers that correlate to the parts
you need for the BoM. You will not need to know SKU numbers for the
exam. The exam may present you with a list of requirements and an
example BoM to have you determine what is missing or is not necessary.

You will generally need the F5 platform, possibly blades if it is
chassis-based solution and modular interfaces. iSeries models above the
i5000 series ship with redundant power supplies and are optional on
i5000 series and down. The Viprion chassis will need to be scoped for
power needs based on the model’s power or platform guides. That can be
found as a link off of the Viprion datasheet, which is linked above.

All devices ship with standard C19 to NEMA 5-20P in US/CANADA, so
normally you will need to understand if that will work in the customer’s
environment but as it is an exam is it there or not is the point.

F5 does not support third party transceivers or other hardware.

If there are 40GB interfaces and going with 10GB breakout cable requires
both the breakout cable and the transceivers. You must purchase the 40
GbE port transceivers for the F5 device from F5, as well as the
appropriate 10 GB port transceivers for the upstream switch from your
switch vendor.

For BIG-IP and VIPRION platforms that support 40 GbE ports, F5 provides
QSFP+ breakout cable options to convert a single 40 GbE port to four 10
GB ports. The QSFP+ breakout cable has a female MPO/MTP connector on one
end for connecting to the QSFP+ port on the VIPRION or BIG-IP device and
four LC duplex connectors on the other end for connecting to the SFP+
modules on an upstream switch. These cables do not have any active
components/transceivers on either end. F5 offers three length options
for the QSFP+ breakout cable, one meter, three meters, and 10 meters. If
you require QSFP+ breakout cable length other than the three lengths
offered by F5, you may be able to purchase QSFP+ breakout cables of
equivalent specifications from third-party vendors.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 5 - Ongoing support/maintenance}
\label{\detokenize{class4/modules/module5:section-5-ongoing-support-maintenance}}\label{\detokenize{class4/modules/module5::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.01 Given a scenario, understand organizational personas to best position F5 solutions}
\label{\detokenize{class4/modules/module5:objective-5-01-given-a-scenario-understand-organizational-personas-to-best-position-f5-solutions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Determine buying powers, influencers, and purchasing cycles}

\sphinxurl{https://partners.f5.com/}

This blueprint topic is related to choosing the correct answer for a
scenario type of question. You will determine the stake holders in
purchasing decisions for F5 products. Review the battle cards for
products located on the Sales Play link on the partners site. These
battle cards contain information on how to identify your target customer
and stake holders for specific F5 products.


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com/solutions/f5-sales-plays}

\sphinxstylestrong{Partners Sales Play Site}

A sales play is designed to help F5 Channel Partners position F5
solutions for a specific customer need. Each sales play includes a set
of materials designed for training that will prepare and help you
position F5 solutions that will drive an end-to-end sale. The content of
the sales play includes the sales playbook, customer facing deck and
other associated documentation such as whiteboards, demos and/or
collateral to help support the sales pitch.


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com/Portals/4/Partner\%20Central\%20Assets/Solutions/Sales\%20Plays/Solutions\_Sales\%20Plays\_DDoS\%20Protection\_Battlecard.pdf}

\sphinxstylestrong{DDoS Battlecard}

Learn more about selling F5 Hybrid DDoS and share the value of F5 as the
only single-vendor who seamlessly integrates on-premises DDoS solutions
and cloud scrubbing services. F5 delivers complete DDoS coverage with
our BIG-IP appliances in the datacenter and Silverline DDoS Protection
managed services. This flexible, hybrid, solution combines granular
threat detection with always-on or on-demand high mitigation capacity in
the cloud. Companies also benefit from 24x7x365 expert monitoring and
support to augment resources when under a volumetric attack. Discover
and leverage the tools for selling F5 DDoS solutions and help your
customers stay ahead of the fight against DDoS.


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com/Portals/4/Partner\%20Central\%20Assets/Solutions/Sales\%20Plays/Solutions\_Sales\%20Plays\_WAF\_battlecard.pdf}

\sphinxstylestrong{Web Application Firewall Battlecard}

Learn more about showing prospects the value of F5 Web Application
Firewall capabilities. Share BIG-IP ASM the \#1 most deployed and \#1 most
effective WAF in class to solve critical app security needs on prem. and
across hybrid cloud. For tier 2 apps on prem. and cloud-based
applications, share Silverline Web Application Firewall designed on
BIG-IP ASM for complete app protection managed by a 24x7x365 SOC team
for prospects without IT resources. Share the combined F5 Hybrid WAF
solution offerings to cover all apps enabling no app left unprotected.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Distinguish needs of buying powers and influencers}

\sphinxhref{https://business.linkedin.com/sales-solutions/blog/sales-trends/2018/08/what-are-influencers--and-how-do-they-affect-the-b2b-buyer-s-jou}{https://business.linkedin.com/sales-solutions/blog/sales-trends/2018/08/what-are-influencers\textendash{}and-how-do-they-affect-the-b2b-buyer-s-jou}

You cannot expect that you are the only one that has influence on the
buyer in your prospective customer. There are many different
influencers. This article from LinkedIn has a great perspective of how
influencers can impact your sales opportunities.

\sphinxstylestrong{Influencer Impact at Each Stage of the Deal}

It’s important to understand how various influencers affect your deal at
different stages of the purchase process. While it is impossible to
distill this to a one-size-fits-all mapping, we can make some useful
generalizations.

An effective practice is to review the type of content buyers seek at
each stage of the purchase journey and map these content types to the
field of external influencers. After all, content is simply an
information vehicle, just as influencers are an information source.

In the early stage, buyers usually seek out thought leadership and
educational content. As such, they will consult external experts who can
inform their understanding of top issues and trends during cursory
research. These could include analysts, subject matter experts, and
thought leaders. As a result, top-of-funnel prospects might come to the
table with preconceived notions they gathered from one or more industry
influencers.

\sphinxstyleemphasis{Early-Stage Influence Takeaway:}

Become familiar with respected authorities in your niche and keep a bead
on their content or social media updates to better understand viewpoints
and perspectives that might be instilled in your prospects.

Prospects in the middle stage want to evaluate and narrow down their
options. At this point, they consume more product-specific content along
with case studies, comparisons, and evaluation guides. According to
research by Influitive, nearly 90\% of buyers are influenced by customer
testimonials during the purchase decision.

When consulting internal influencers at this stage, prospects often call
upon those can help evaluate both business and technical details, such
as IT and engineering. For external perspectives, they might turn to
respected peers, partners, and customers of the vendor under
consideration.

\sphinxstyleemphasis{Middle-Stage Influence Takeaway:}

Customer testimonials and peer reviews are key as buyers begin to narrow
their options and gravitate toward a decision.

In the final stage of their journey, buyers need to validate their
purchase decision. They vet their choice through content such as demos,
total cost of ownership, and ROI calculators. It is common at this point
to again enlist the input of peers, partners, and existing customers.
Additionally, buyers will seek to generate consensus on the purchase
committee, and throughout the organization. So, lower-funnel prospects
might be influenced by operations colleagues, technology stakeholders,
user-level team members, and the finance group.

\sphinxstyleemphasis{Late-Stage Influence Takeaway:}

Expanding your own influence across the buying committee and in other
relevant areas of the organization can help solidify consensus.

\sphinxstyleemphasis{Position Yourself to Swing the Balance in Your Favor}

In addition to decision makers, hidden influencers can hold sway in the
ultimate purchase choice. They can impact whether a large deal is
awarded to you or a competitor — or whether the status quo prevails.
Failing to build strong ties to even one of these influencers could lead
to the collapse of important deals.

The more connections you establish within and beyond a prospect’s
company, and the more you interact with these people on social media,
the more fully you’ll understand how various decision makers and
influencers work together.

This approach empowers you to make the most of influence arriving from
any direction.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.01 - Recommend training/enablement based on operational needs}

\sphinxurl{https://www.f5.com/services/training}

\sphinxstylestrong{Training and Enablement}

Customers will normally need training and enablement on the F5 solutions
that they are utilizing in their environments. You should be aware of
the available training and how/where to access the different types.

\sphinxstyleemphasis{Instructor-led courses}

F5 courses are available in multiple training facilities across five
continents. Each one combines instructor presentations, classroom
discussions and interactive labs. The hands-on learning environment
helps provide a fast track to accomplishing your goals.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p61}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Subscription training}

F5 offers Subscription based training delivered as e-learning. Each
e-learning module contains:
\begin{itemize}
\item {} 
Conceptual video: a quick introduction to the feature, including
recommendations with tips and tricks

\item {} 
Requirements, process overview, and detailed content

\item {} 
A curated list of related resources

\end{itemize}

\sphinxstyleemphasis{Free online training}

You can use the self-paced Getting Started series of free, web-based
courses to learn how to deploy F5 solutions to address your most common
application delivery problems:
\begin{itemize}
\item {} 
Securing your web applications

\item {} 
Scaling, securing and optimizing your DNS infrastructure

\item {} 
Implementing a unified, context-aware, policy-based solution for
access to your corporate network resources

\item {} 
Directly manipulating and managing your application traffic to align
with your business rules

\end{itemize}

Each course lasts about 45 minutes and provides a thorough introduction
to the solution and what it feels like to configure and operate it in
the real-world.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.02 Given a scenario, determine when to engage appropriate F5 employees}
\label{\detokenize{class4/modules/module5:objective-5-02-given-a-scenario-determine-when-to-engage-appropriate-f5-employees}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.02 - Utilize SMEs during technical activities}

There will be times where you will need to leverage the an F5 subject
matter expert (SME) who has a deep understanding of the F5 products.
When performing a Proof-of-Concept for a customer or if you are trying
to size an F5 product to fit the customers environment, you will need to
work with the F5 account team and local Systems Engineer. If you are a
partner trying to gain knowledge about how an F5 product or function
works you can engage the Channel SE in your region for more information
or enablement training.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.02 - Determine when to advise a customer to engage F5 support}

A sales SE needs to determine the appropriate action plan or resource to
engage for F5 support. For example, if the customer has an issue during a Proof of Concept
(POC) or other presales activity, then the local F5 account manager and
F5 Field Systems Engineer (SE) should be engaged, but if a customer has an
implemented F5 solution and they are experiencing an issue, the sales
engineer will need to understand how to advise the customer to open a
support ticket with F5.

There are multiple ways to open a support case with F5. You can
review them here in this link: \sphinxurl{https://support.f5.com/csp/article/K2633}

\sphinxurl{https://www.f5.com/pdf/customer-support/guidelines-and-policies-ds.pdf}

\sphinxstyleemphasis{Scope of Support}

F5 offers several support options, so you can be confident your
organization has the level of care it needs, when it needs it.

\sphinxstyleemphasis{Maintenance agreements}

All F5 products come with a one-year manufacturer’s hardware warranty
and a 90-day software media warranty. Technical support is limited to F5
products with active support contracts.

\sphinxstyleemphasis{Contract support levels}

Annual support agreements are available for Standard hours, which
includes 10x5 support, or Premium hours, which includes 24x7 support.
Expedited RMA Services and Maintenance Add- On Packages are also
available.

\sphinxstyleemphasis{iRules and iApps support}

Standard and Premium support include F5 iRules scripting language and F5
iApps template assistance. Standard iRules and iApps support provides
basic troubleshooting help for customers with active Standard support
maintenance contracts. In addition to Standard iRules and iApps support,
Premium support includes validation, troubleshooting, and functional
analysis of scripted iRules and iApps templates.

To receive assistance with short-turnaround script creation requests,
use the iRules OnDemandTM service, which can usually handle a request
within one business day. For assistance with iApps templates, use the
Consulting OnDemand service, which usually handles a request within one
to two business days.

You can find additional resources for iRules assistance and iApps
templates at the F5 DevCentral online community. DevCentral includes
tools and techniques to help you build solutions with iRules and the F5
iControl API, enabling applications to work in concert with the
underlying network. You can also find new supported iApps templates that
are flexible and easy to use for deploying and managing application
services.

\sphinxstyleemphasis{Installation}

For comprehensive installation assistance, you can purchase on-site
installation services through F5 Professional Services or your local
authorized F5 reseller. F5 Technical Support does not provide remote
installation services.

\sphinxstyleemphasis{Professional Services offerings}

For assistance with planning, design, deployments, upgrades, migrations,
optimization, and application verification, contact F5 Professional
Services. A consultant will provide a detailed quote that includes a
comprehensive Scope of Work (SOW) statement.

\sphinxstyleemphasis{Network Support Centers}

F5 Network Support Centers are strategically located for partners and
customers in the Asia- Pacific region, Japan, Europe, the Middle East,
Africa, and the Americas. Regionally located support centers enable F5
to provide support in a number of languages through native- speaking
support engineers who are available when you are, during your business
day. Globally dispersing Network Support Centers allows for cases to
truly “follow the sun,” which means Network Support Engineers are
available to provide help when you need it.

\sphinxstyleemphasis{Case Severity Definitions and Response Times}

All F5 Network Support Centers uphold the following case severity
definitions and target response times to ensure that the appropriate
resources are used to resolve all technical issues as efficiently as
possible.

F5 will endeavor to respond to Severity 1 issues within one hour.
Understanding that unforeseen events could delay attempts, F5 expects
that most Severity 1 issues will be responded to within this service
level.

Initial response is defined as the time from when the F5 case was
created to when a Network Support Engineer first attempts to contact you
for troubleshooting, then updates the case log to reflect this action.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{Severity 1 (Urgent)}

Initial Response: 1 hr
&
\sphinxstylestrong{Site Down}
&
Software or hardware conditions on your F5 device are preventing the execution of critical business activities. The device will not power up or is not passing traffic. Security issue—Critical business impact due to an attack or vulnerability.
\\
\hline
\sphinxstylestrong{Severity 2 (High)}

Initial Response: 2 hrs
&
\sphinxstylestrong{Site at Risk}
&
Software or hardware conditions on your F5 device are preventing or significantly impairing high-level commerce or business activities. The device is in degraded state that places your network or commerce at risk. Security issue—Severe business impact due to an attack, vulnerability, compliance, or data at risk.
\\
\hline
\sphinxstylestrong{Severity 3 (Medium)}

Initial Response: 4 hrs
&
\sphinxstylestrong{Performance Degraded}
&
Software or hardware conditions on your F5 device have degraded service or functionality for normal business or commerce activities. Network traffic through the device is causing some applications to be unreachable, or operate in a diminished capacity. Security issue—Potential or partial business impact related to mitigation, audit results, or vulnerability.
\\
\hline
\sphinxstylestrong{Severity 4 (Low)}

Initial Response: 24 hrs
&
\sphinxstylestrong{General Assistance}
&
Questions regarding configurations “how-to.” Troubleshooting non-critical issue or request for product functionality that is not currently part of the current product feature set. Security issue—General security-related questions and/or concerns which are not related to an immediate need.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

When a case is logged as Severity 1, F5 Network Support Managers are
immediately notified to ensure the case is assigned within the
appropriate timeframe to an appropriately skilled Network Support
Engineer.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.02 - Locate and determine appropriate resource for account/customer escalations}

\sphinxurl{https://www.f5.com/services/support/support-offerings/support-policies}

If at any time you believe that a case is not being handled in
accordance with the service levels in your support contract, or if you
wish to comment on the way a particular case is being addressed by a
Network Support Engineer, please contact F5 Support and request to speak
with a Technical Support Manager.

F5 has identified four escalation situations each requiring a different
methodology to handle and escalate.

The first is a situation where an NSE intuitively knows that the issue
could become troublesome. This could be caused by a number of things; a
bug is detected, an NSE feels the situation may be beyond his/her
technical depth, or it could be a matter of a customer communicating an
unusual amount of agitation. We call these common sense or situational
escalations. We encourage escalation to a manager or other technical
resource in this scenario and depend heavily on our NSE’s common sense
to determine the proper timing of the escalation.

The second is a time-based escalation. We preset alerts and reports in
our call management system to use as a safety valve. This allows us to
monitor proper response time, ongoing communication between all the
parties and the eventual resolution of the issue.

The third is a technical escalation where due to the urgent nature of
the issue events are time triggered. When a Severity 1 or 2 case is
initially generated the F5 Support Manager is immediately notified via a
preset alert. It is the Support Managers responsibility to escalation
per the steps outlined below.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{Time}
&
\sphinxstylestrong{Technical Team}
&
\sphinxstylestrong{Action Taken}
\\
\hline
\sphinxstylestrong{Immediate}
&
NSE
&
Support Manager ensures resources are assigned
\\
\hline
\sphinxstylestrong{Hourly}
&
NSE to Support Manager
&
Status provided
\\
\hline
\sphinxstylestrong{4 Hours}
&
NSE to ENE
&
NSE/Manager develop technical action plan - Escalate to ENE
\\
\hline
\sphinxstylestrong{8 Hours}
&
ENE to Product Development
&
Escalate to Product Development
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The fourth is a management escalation where it is in the best interest
of the customer and the F5 team to communicate concerns to senior
management.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{Time}
&
\sphinxstylestrong{Management Team}
&
\sphinxstylestrong{Action Taken}
\\
\hline
\sphinxstylestrong{4 Hours}
&
Network Support Manager
&
Works with Technical to develop action plan
\\
\hline
\sphinxstylestrong{4.5 Hours}
&
Support Manager to NS Director and ENE Manager
&
Notification and review of plan
\\
\hline
\sphinxstylestrong{8 Hours}
&
NS Director to VP Global Services

ENE Manager to CTO
&
Escalate to Product Development
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The Support Manager will manage events and action plans throughout the
duration of the case. The Support Manager may assign additional F5
resources as required and will determine communications to F5 resources
and senior management.

\sphinxstyleemphasis{Severity Levels}

Outlined below are the Severity classifications and definitions that the
F5 NSC refers to when logging a new case or changing severity
status of an existing case:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline

\sphinxstylestrong{Case Severity}
&
\sphinxstylestrong{Condition}
&
\sphinxstylestrong{Support Response Time}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Severity 1}
&
\sphinxstylestrong{Site Down}
&
\sphinxstylestrong{1 Hour}
&
All network traffic has ceased, causing a critical impact to your business.
\\
\hline
\sphinxstylestrong{Severity 2}
&
\sphinxstylestrong{Site at Risk}
&
\sphinxstylestrong{4 Business Hours}
&
Primary unit has failed resulting; Site is at risk of going down.
\\
\hline
\sphinxstylestrong{Severity 3}
&
\sphinxstylestrong{Performance Impaired}

\sphinxstylestrong{———}

\sphinxstylestrong{Performance Degraded}
&
\sphinxstylestrong{8 Business Hours}
&
Network traffic is extremely slow; significant impact to your business.

Network traffic is partially functional; some applications to be un-reachable.
\\
\hline
\sphinxstylestrong{Severity 4}
&
\sphinxstylestrong{General Assistance}
&
\sphinxstylestrong{Next Business Day}
&
Questions regarding configurations “how to”. Troubleshooting non-critical issue.

Request for functionality that is not part the current product feature set.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 5.03 Identify F5 enablement resources and tools}
\label{\detokenize{class4/modules/module5:objective-5-03-identify-f5-enablement-resources-and-tools}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.03 - Define evaluation hardware and software tools and processes}

The presales SE can leverage the following tools.

\sphinxstylestrong{Strongbox Demo Appliance and License Site}

The F5 StrongBox program provides F5 UNITY Partners with an easy,
cost-effective way to allow their customers to test drive F5 technology.
StrongBox units are individually customized for each customer
evaluation. Once the evaluation is complete, the box is reset and
re-customized for the next evaluation assignment.

The StrongBox program is available for BIG-IP evaluation hardware and
Virtual Edition products. The hardware evaluation units are priced at
F5’s hardware cost, making them very affordable, and there is no limit
to the number of StrongBox units you can deploy. Since the StrongBox
unit is reusable, it offers a fantastic return on investment. In
addition, F5 Sales Representatives use partner StrongBox units as their
principal means of fulfilling customer evaluation requirements, so your
StrongBox could open doors to new, pre-qualified opportunities. Presales
engineers can also generate Strongbox 30-45-day Virtual Edition (VE)
licenses to use for customer evaluations.

Strong box evaluation site \sphinxurl{https://strongbox.f5.com/strongbox/eval.jsp}

\noindent\sphinxincludegraphics{{p71}.png}


\bigskip\hrule\bigskip


\sphinxurl{https://downloads.f5.com} (requires login credentials)

\sphinxstylestrong{F5 Partner vLabs}

Presales engineers have access to Partner vLabs that provide them with
manuals to build F5 product demo labs. Engineers can run these labs on
their computers or lab servers. The link to F5 Partner vLabs can be
found at the bottom of the download product line page. \sphinxstylestrong{Note: the
engineer’s login account must be associated to a partner account to view
the download}

\noindent\sphinxincludegraphics{{p81}.png}


\bigskip\hrule\bigskip


\sphinxurl{https://devcentral.f5.com/d/irule-editor}

\sphinxstylestrong{iRule Editor}

You can now develop iRules with full syntax highlighting, colorization,
textual auto-complete, integrated help, etc.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.03 - Identify technical enablement content}

The presales SE has access to various recourses F5 technical enablement
content to support their on-going education on F5 Network’s product
offerings.

\sphinxhref{https://account.f5.com/learnf5/signin}{Learn F5} (requires login credentials)

\sphinxstylestrong{Learn F5 Website}

The Presales engineer can leverage Learn F5 for online learning
courses on F5 products.


\bigskip\hrule\bigskip


\sphinxstylestrong{F5 Sales Accreditations}

The F5 Sales Accreditation helps sales and technical roles identify F5
sales opportunities. Both sales and technical roles take the same
course. Then, complete either the assessment for sales roles or the
assessment for technical roles. Presales engineers will need to take
this course to meet partner requirements and enhance their F5 sales
technical knowledge.

\noindent\sphinxincludegraphics{{p91}.png}


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com} (requires login credentials)

\sphinxstylestrong{F5 Partner Central Site}

F5 Partner Central site provides Presales engineer with knowledge and
resources on F5 sales plays, technical reference architectures,
marketing and sales related materials.


\bigskip\hrule\bigskip


\sphinxhref{https://devcentral.f5.com/}{*https://devcentral.f5.com/*}

\sphinxstylestrong{DevCentral}

Learn F5 Technologies, Get Answers \& Share Community
Solutions. DevCentral is a source for tools, techniques, and
collaboration to help you build solutions with iControl, iCall, iApps
and iRules that enable applications to work in concert.


\bigskip\hrule\bigskip


\sphinxurl{https://downloads.f5.com} (requires login credentials)

\sphinxstylestrong{F5 Partner vLabs}

Presales engineers have access to Partner vLabs that provide them with
manuals to build F5 product demo labs. Engineers can run these labs on
their computers or lab servers. The link to F5 Partner vLabs can be
found at the bottom of the download product line page. \sphinxstyleemphasis{Note: the
engineer’s login account must be associated to a partner account to view
the download}


\bigskip\hrule\bigskip


\sphinxurl{https://f5.com/education}

\sphinxstylestrong{F5 Education Training Courses}

F5 courses are available in multiple training facilities across five
continents. Each one combines instructor presentations, classroom
discussions and interactive labs. The hands-on learning environment
helps provide a fast track to accomplishing your goals. Presales
partners can attend free courses are F5 facilities across the country.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{5.03 - Describe the sales operations tools and processes}

\sphinxstylestrong{Understand the F5 sales cycle}
\begin{itemize}
\item {} 
Prospecting and Pipeline

\item {} 
Lead Qualification

\item {} 
Partner Deal Registration

\item {} 
Customer Engagement

\item {} 
Solution Recommendation

\item {} 
Production Evaluation

\item {} 
Quoting

\item {} 
Competitive Positioning

\item {} 
Technical and Business Value Proposals

\item {} 
Connecting with Buying Influencers

\item {} 
Forecasting

\item {} 
Closing

\end{itemize}


\bigskip\hrule\bigskip


\sphinxurl{https://partners.f5.com} (requires login credentials)

\sphinxstylestrong{F5 Partner Central Site}

F5 Partner Central site provides Presales engineer with knowledge and
resources on F5 sales plays, technical reference architectures,
marketing and sales related materials.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Conclusion}
\label{\detokenize{class4/modules/module5:conclusion}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

This document is intended as a study guide for the F5 202 - Pre-Sales
Fundamentals exam. This study guide is \sphinxstylestrong{NOT} an all-inclusive
document that will guarantee a passing grade on the exam. It is intended
to be a living doc and any feedback or material that you feel should be
included, to help exam takers better prepare, can be sent to
\sphinxhref{mailto:F5CertGuides@f5.com}{F5CertGuides@f5.com}.

Thank you for using this study guide to prepare the F5 202 - Pre-Sales
Fundamentals exam and good luck with your certification goals.

Thanks,

\sphinxstylestrong{Eric Mitchell}

Sr. Systems Engineer - Global SI


\chapter{F5 301A - BIG-IP LTM Specialist: Architect, Set-Up \& Deploy Study Guide 11/01/19}
\label{\detokenize{class5/class5:f5-301a-big-ip-ltm-specialist-architect-set-up-deploy-study-guide-11-01-19}}\label{\detokenize{class5/class5::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 301A - BIG-IP LTM Specialist: Architect, Set-Up \& Deploy}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Welcome to the 301a - LTM Specialist compiled Study Guide. The purpose of this
guide is to help you prepare for the F5 301a - LTM Specialist exam. The
contents of this document are based on the 301a - LTM Specialist Exam
Blueprint for TMOS v11.5.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on the Internet. All of the information locations are
referenced at the top of each topic instead of in an appendix of this document.
This was done to help the reader access the referenced information easier
without having to search through a formal appendix.

The F5 Certified Big-IP Administrator (F5-CA), which is made up of the 101 -
App Delivery Fundamentals and 201 - TMOS Administration exams, stands as a
pre-requisite to this exam.

Taking certified F5 LTM training, such as Administering BIG-IP v11 and
Configuring BIG-IP LTM v11, will surely help with the topics of this exam but
does not teach directly to the exam content. Hands on administrative experience
with the Big-IP platform licensed with LTM will reinforce many of the topics
contained in the 301a - LTM Specialist exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}

\sphinxstylestrong{Printed References}

These referenced books are important and should be considered basic reading
material for this exam.  However these reading materials are not available for
purchase. You can only gain access to the books by attending the associated F5
training class. These official F5 classes are now being offered in v12
and v13. So, if you have the newer copy of the material that is fine, be aware
that the exam is based on the 11.5 version and content could have changed. It
is possible that an ATC for F5 may still offer older 11.5 training but
this is not guaranteed.

(Ref:1) Configuring BIG-IP Local Traffic Manager v11.5, v11.5.0 Edition.  F5 Training Course Manual.

(Ref:2) Administering BIG-IP v11.5, v11.5.0 Edition.  F5 Training Course Manual.

(Ref:3) Troubleshooting BIG-IP v11.5, v11.5.0 Edition.  F5 Training Course Manual.

(Ref:4) Developing iRules for BIG-IP v11.5, v11.5.0 Edition.  F5 Training Course Manual.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{F5 301a Introduction}
\label{\detokenize{class5/modules/module1:f5-301a-introduction}}\label{\detokenize{class5/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{F5 - 301a Local Traffic Manager Specialist Exam}

The F5 BIG-IP Local Traffic Manager (LTM) increases an application’s
operational efficiency and ensures peak network performance by providing
a flexible, high-performance application delivery system. With its
application-centric perspective, LTM optimizes your network
infrastructure to deliver availability, security, and performance for
critical business applications. Although the Exam Blueprint is not
written in a structure that presents topics in an educational order, it
does provide all of the necessary building blocks. The Certified LTM
Training classes from F5 will help with many of the scenario-based
topics on the test. An LTM Specialist must be proficient with all
aspects Architecture, Setup and Deployment of the LTM within a network.

\sphinxurl{https://support.f5.com/content/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-tmsh-11-5-0/\_jcr\_content/pdfAttach/download/file.res/bigip-tmsh-11-5-0.pdf}

\sphinxstylestrong{Traffic Management Shell}

Although it is not mentioned in the blueprint as a requirement, a
candidate should not focus only on the GUI interface for management of
the LTM platform. Some test questions will refer to the command line
interface (CLI) TMSH commands. You should take time to understand where
in the CLI that common commands are issued so you can not only correctly
answer the questions presented on the exam but also have enough
knowledge of the CLI structure to eliminate bad commands from your
question’s answer choices.

Try building your training lab environment from command line to gain CLI
proficiency.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Section 1 - Architect and Deply Applications}
\label{\detokenize{class5/modules/module1:section-1-architect-and-deply-applications}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.01 - Given an expected traffic volume, determine the appropriate SNAT configuration}
\label{\detokenize{class5/modules/module1:objective-1-01-given-an-expected-traffic-volume-determine-the-appropriate-snat-configuration}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 \textendash{} Explain when SNAT is required}

\sphinxhref{https://support.f5.com/csp/article/K7820?sr=29125585}{K7820: Overview of SNAT features}

\sphinxstylestrong{What is SNAT and when is it required?}

A Secure Network Address Translation (SNAT) is a configuration object
that maps the source client IP address in a request to a translation
address defined on the BIG-IP device. When the BIG-IP system receives a
request from a client, and if the client IP address in the request is
defined in the origin address list for the SNAT, the BIG-IP system
translates the source IP address of the incoming packet to the SNAT
address.

A SNAT can be used by itself to pass traffic that is not destined for a
virtual server. For example, you can use a SNAT object to pass certain
traffic (such as DNS requests) from an internal network to an external
network where your DNS server resides. A SNAT can also be used in
conjunction with a virtual server to translate the source IP address of
an incoming packet (with no SNAT configured, no source address
translation takes place, and destination address translation takes place
as separately configured in the Virtual Server properties). You can also
use a SNAT to ensure that response traffic is returned through the
BIG-IP system without requiring other outbound non-load balanced traffic
to also route through the BIG-IP system, and without requiring any
changes in the router or server’s configuration. SNAT is also a critical
component in one-armed configurations, preventing the server from
responding directly to the client.

Port exhaustion or collisions may occur under heavy usage or special
client traffic patterns. As a result, connections that cannot be
translated due to lack of available ports on a given translation address
may be dropped.

When a SNAT is configured on the BIG-IP system (either by itself or in
conjunction with a virtual server), the source address of each
connection is translated to a configured SNAT address, and the source
port is mapped to a port currently available for that address. By
default, the BIG-IP system attempts to preserve the source port, but if
the port is already in use on the selected translation address, the
system also translates the source port.

Each SNAT address, like any IP address, has only \sphinxstylestrong{65535} ports
available. This is a limit of the TCP and User Datagram Protocol (UDP)
protocols, since they use a 16-bit unsigned integer (thus ranging from 0
to 65535) to specify the source and destination ports. However, each
SNAT address can potentially have to process more than 65535 concurrent
connections, as long as each socket pair is unique. A socket pair is
defined by a 4-tuple structure consisting of the following elements:
\begin{itemize}
\item {} 
Source IP address

\item {} 
Source port

\item {} 
Destination IP address

\item {} 
Destination port

\end{itemize}

For example, a given SNAT address can continue to use the same source
port as long as the remote socket is unique, thus allowing the SNAT
address to process more than 65535 concurrent connections.

For example:

SNAT address and port Remote socket

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}  \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.1}\PYG{p}{:}\PYG{l+m+mi}{1234} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.200}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}  \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.1}\PYG{p}{:}\PYG{l+m+mi}{1234} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.201}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}  \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.1}\PYG{p}{:}\PYG{l+m+mi}{1234} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.200}\PYG{p}{:}\PYG{l+m+mi}{8080}

\PYG{o}{\PYGZhy{}}  \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.1}\PYG{p}{:}\PYG{l+m+mi}{1234} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.201}\PYG{p}{:}\PYG{l+m+mi}{8080}
\end{sphinxVerbatim}

Note: When SNAT is used in conjunction with a virtual server that load
balances connections to a pool; the remote socket is the IP address and
port of the chosen pool member. Therefore, assuming a certain SNAT
address is configured on only one virtual server, the SNAT address is
able to process approximately 65535 concurrent connections for each pool
member in the pool (each unique remote socket).

While the uniqueness of remote sockets depends entirely on your specific
configuration and traffic, for simplicity you should think of 65535
concurrent connections as the maximum capacity for any given SNAT
address. \sphinxstyleemphasis{If you think more than 65535 connections may require
translation, you should configure more SNAT addresses (for example,
using a SNAT pool).}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 \textendash{} Describe the benefit of using SNAT pools}

\sphinxhref{https://support.f5.com/csp/article/K7820?sr=29125585}{K7820: Overview of SNAT features}

\sphinxstylestrong{SNAT Pools}

A SNAT pool represents a logical group of translation addresses that you
configure on the BIG-IP system.

When a single IP address is used to SNAT traffic, it has a limit of
65535 ports that can be used for port mapping on the IP address. SNAT
connections can fail if a large number of client requests are traversing
a SNAT, which is using a single IP address. This will show up in the
event logs on the BIG-IP as Port Exhaustion errors.

To mitigate port exhaustion, create SNAT pools or use SNAT Automap (with
an appropriate number of self-IP addresses on the VLAN) to support the
expected level of concurrent connections. Configuring a SNAT pool as the
translation allows the SNAT function to map client connections to more
than one IP address from the SNAT pool, thus increasing the total
available ports likewise the supported client connections.

You can build a SNAT pool for a SNAT to use as the translation addresses
and the BIG-IP will use an IP addresses from the pool in a Least
Connections fashion.

Since the SNAT function is intelligent enough to know what address from
the pool can be used for the address translation in each egress
scenario; a SNAT pool can contain addresses from more than one egress
network. This will allow you to build less SNAT pools by allowing you to
mix the egress network addresses in one pool if you desire.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 \textendash{} Describe the difference of SNAT object types}

\sphinxhref{https://support.f5.com/csp/article/K7820?sr=29125585}{K7820: Overview of SNAT features}

\sphinxstylestrong{Types of SNATs}

Standard SNATs and intelligent SNATs are illustrated in the following
sections:

\sphinxstylestrong{Standard SNATs}

The following three examples illustrate three types of standard SNATs:

A SNAT in which you specify a specific translation address

One way to create a SNAT is to directly map one or more original IP
address to a specific translation address that you choose. For the SNAT
origin address, you can specify host addresses, network addresses, or a
wildcard that matches all addresses. For example, the following SNAT
configuration translates the address of connections that originate from
the address 10.10.10.1 to the translation address 172.16.0.1:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ltm} \PYG{n}{snat} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{test}\PYGZbs{}\PYG{n}{\PYGZus{}snat} \PYG{p}{\PYGZob{}}
\PYG{n}{origins} \PYG{p}{\PYGZob{}}
\PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.1}\PYG{o}{/}\PYG{l+m+mi}{32} \PYG{p}{\PYGZob{}} \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\PYG{n}{translation} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{0.1}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Automap SNAT}

Of the available SNAT options, SNAT automap is often preferred because
it is simple to configure and maintain, and helps conserve IP addresses
by using the BIG-IP system’s existing self IP addresses.

When the BIG-IP system processes connections from the origin IP
addresses matching a SNAT automap definition, it chooses a translation
address from the available self IP addresses. Floating self IP addresses
on the egress Virtual Local Area Network (VLAN) are preferred to support
seamless failover. If multiple floating self IP addresses are configured
on the VLAN, the BIG-IP system translates the address of client
connections by alternating through a pool of all floating self IPs on
the VLAN.

Note: The SNAT automap feature may not use the intended translation
address if a floating self IP is not available on the egress VLAN, or
the floating self IP address was originally a static self IP address.
For more information, refer to K7336: The SNAT Automap and self IP
address selection.

For example, the following SNAT configuration translates the address of
connections that originate from the address 10.10.10.1 to one of the
system’s self IP addresses:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ltm} \PYG{n}{snat} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{test}\PYGZbs{}\PYG{n}{\PYGZus{}snat} \PYG{p}{\PYGZob{}}
\PYG{n}{automap}
\PYG{n}{origins} \PYG{p}{\PYGZob{}}
\PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.1}\PYG{o}{/}\PYG{l+m+mi}{32} \PYG{p}{\PYGZob{}} \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxstyleemphasis{SNAT pools}

A SNAT pool represents a pool of translation addresses that you
configure on the BIG-IP system. The original IP address is then mapped
to the entire translation pool, called a SNAT pool. For example, the
following SNAT pool configuration contains the translation addresses
172.16.0.1 and 172.16.0.2:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ltm} \PYG{n}{snatpool} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{my}\PYGZbs{}\PYG{n}{\PYGZus{}snatpool} \PYG{p}{\PYGZob{}}
\PYG{n}{members} \PYG{p}{\PYGZob{}}
\PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{0.1}
\PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{0.2}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

After you create the SNAT pool, you must associate it with a SNAT
object. For example, the following SNAT configuration translates the
address of connections that originate from the address 10.10.10.1 to one
of the IP addresses in the SNAT pool:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ltm} \PYG{n}{snat} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{test}\PYGZbs{}\PYG{n}{\PYGZus{}snatpool} \PYG{p}{\PYGZob{}}
\PYG{n}{origins} \PYG{p}{\PYGZob{}}
\PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.1}\PYG{o}{/}\PYG{l+m+mi}{32} \PYG{p}{\PYGZob{}} \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\PYG{n}{snatpool} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{my}\PYGZbs{}\PYG{n}{\PYGZus{}snatpool}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Important: When using a SNAT pool with IP addresses from the egress VLAN (the VLAN
for which the packet exits in the BIG-IP system) and non-egress VLAN
networks, the egress VLAN network address is given higher priority. For
example, egress VLAN external has a self IP of 172.16.0.254/24, and SNAT
pool member addresses of 172.16.0.1/24 and 10.1.1.1/24. The BIG-IP
system prefers the egress VLAN SNAT pool member address 172.16.0.1, and
will continue to use the same address until it becomes unavailable.

Note: The BIG-IP system load balances SNAT pool connections between
members using the least connections algorithm.

\sphinxstylestrong{Intelligent SNATs}

An intelligent SNAT is the mapping of one or more original client IP
address to a translation address. However, you implement this type of
SNAT mapping within an iRule. An intelligent SNAT allows the BIG-IP
system to base its selection of a translation address on any piece of
packet data that you specify. This piece of data could be the original
client IP address, or it could be another piece of data in the packet,
such as a server port or an HTTP cookie.

To configure an intelligent SNAT, you must complete the following tasks:
\begin{itemize}
\item {} 
Determine the type of packet data that the BIG-IP system uses as a basis for selecting a translation address, such as the server port.

\item {} 
Create the SNAT or SNAT pools that the BIG-IP system uses to select a translation address.

\item {} 
Assign the iRule as a resource to the virtual server.

\end{itemize}

The following two examples illustrate mapping original client IP
addresses to a translation address using an iRule:

Example 1

If you want the BIG-IP system to base its selection of a translation
address on the destination port, you would first create a data group
that contains the destination ports, and then create the iRule that
applies the SNAT translation address to connections using a port
specified in the data group. After you have created the data group and
SNAT, you must assign the iRule as a resource to the virtual server. The
following TMOS Shell (tmsh) command creates a data group called Ports,
containing ports 80, 81, and 8080:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{create} \PYG{o}{/}\PYG{n}{ltm} \PYG{n}{data}\PYG{o}{\PYGZhy{}}\PYG{n}{group} \PYG{n}{Ports} \PYG{n+nb}{type} \PYG{n}{string} \PYG{n}{records} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mi}{80} \PYG{l+m+mi}{81} \PYG{l+m+mi}{8080} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

After you create the data group, create the iRule that applies the SNAT
translation address to connections using ports from the Ports data
group. The following iRule examples apply the SNAT translation address
of 172.16.0.1 to connections using ports from the Ports data group:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{when} \PYG{n}{CLIENT}\PYGZbs{}\PYG{n}{\PYGZus{}ACCEPTED} \PYG{p}{\PYGZob{}}
\PYG{k}{if} \PYG{p}{\PYGZob{}} \PYG{p}{[}\PYG{k}{class} \PYG{n+nc}{match} \PYG{p}{[}\PYG{n}{TCP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{local}\PYGZbs{}\PYG{n}{\PYGZus{}port}\PYG{p}{]} \PYG{n}{equals} \PYG{n}{Ports}\PYG{p}{]}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}}
\PYG{n}{snat} \PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{0.1}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Example 2

If you want the BIG-IP system to base its selection of a translation
address on the client/source IP address and the destination port, and
then forward unchanged traffic that does not match this criteria, you
would first create two data groups that contain the client/source IP
addresses and destination ports respectively, and then create the iRule
that would apply the SNAT translation address.

The following tmsh command creates a data group called Hosts, which
contains IP addresses 10.10.10.1, 10.10.10.2, and 10.10.10.3:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{create} \PYG{o}{/}\PYG{n}{ltm} \PYG{n}{data}\PYG{o}{\PYGZhy{}}\PYG{n}{group} \PYG{n}{Hosts} \PYG{n+nb}{type} \PYG{n}{ip} \PYG{n}{records} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.1} \PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.2} \PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.3} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

The following tmsh command creates a data group called Ports, which
contains ports 80 and 8080:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{create} \PYG{o}{/}\PYG{n}{ltm} \PYG{n}{data}\PYG{o}{\PYGZhy{}}\PYG{n}{group} \PYG{n}{Ports} \PYG{n+nb}{type} \PYG{n}{string} \PYG{n}{records} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mi}{80} \PYG{l+m+mi}{8080} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

After you create the data groups, create the iRule that applies the SNAT
translation address to connections using IP addresses and ports from the
Hosts and Ports data groups, and forward all other connections. The
following iRule example apply the SNAT translation address of 172.16.0.1
to connections using IP addresses and ports fro
m the Hosts and Ports
data groups, and forward all other connections:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{when} \PYG{n}{CLIENT}\PYGZbs{}\PYG{n}{\PYGZus{}ACCEPTED} \PYG{p}{\PYGZob{}}
\PYG{k}{if} \PYG{p}{\PYGZob{}} \PYG{p}{[}\PYG{k}{class} \PYG{n+nc}{match} \PYG{p}{[}\PYG{n}{IP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{client}\PYGZbs{}\PYG{n}{\PYGZus{}addr}\PYG{p}{]} \PYG{n}{equals} \PYG{n}{Hosts}\PYG{p}{]}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}}
\PYG{k}{if} \PYG{p}{\PYGZob{}} \PYG{p}{[}\PYG{k}{class} \PYG{n+nc}{match} \PYG{p}{[}\PYG{n}{TCP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{local}\PYGZbs{}\PYG{n}{\PYGZus{}port}\PYG{p}{]} \PYG{n}{equals} \PYG{n}{Ports}\PYG{p}{]}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}}
\PYG{n}{snat} \PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{0.1}
\PYG{p}{\PYGZcb{}} \PYG{k}{else} \PYG{p}{\PYGZob{}}
\PYG{n}{forward}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.02 - Given a scenario, determine the minimum profiles for an application}
\label{\detokenize{class5/modules/module1:objective-1-02-given-a-scenario-determine-the-minimum-profiles-for-an-application}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - (Supplemental Example) Given a scenario, determine the minimum profiles for an application}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/6.html}

This topic is focused on assigning profiles to a virtual server
configuration for the functionality of application using that virtual
server. Understanding how why profiles are necessary and what
requirements the applications have for the processing of the application
traffic is the key to this topic. Experience with configuring virtual
servers will give the candidate the ability to answer the questions on
this topic.

Profiles are a configuration tool that you can use to affect the
behavior of certain types of network traffic. More specifically, a
profile is an object that contains settings with values, for controlling
the behavior of a particular type of network traffic, such as HTTP
connections. Profiles also provide a way for you to enable connection
and session persistence, and to manage client application
authentication.

By default, Local Traffic Manager provides you with a set of profiles
that you can use as is. These default profiles contain various settings
with default values that define the behavior of different types of
traffic. If you want to change those values to better suit the needs of
your network environment, you can create a custom profile. A custom
profile is a profile derived from a default profile and contains values
that you specify.

You can use profiles in the following ways:

You can use the default profiles, which means that you do not need to
actively configure any profile settings. Local Traffic Manager uses them
to automatically direct the corresponding traffic types according to the
values specified in those profiles.

You can create a custom profile, using the default profile as the parent
profile, modifying some or all of the values defined in that profile.

You can create a custom profile to use as a parent profile for other
custom profiles.

After configuring a profile, you associate the profile with a virtual
server. The virtual server then processes traffic according to the
values specified in the profile. Using profiles enhances your control
over managing network traffic, and makes traffic-management tasks easier
and more efficient.

You can associate multiple profiles with a single virtual server. For
example, you can associate a TCP profile, an SSL profile, and an HTTP
profile with the same virtual server.

At a minimum, a virtual server must reference a profile, and that
profile must be associated with a UDP, FastL4, Fast HTTP, or TCP profile
type. Thus, if you have not associated a profile with the virtual
server, Local Traffic Manager adds a udp, fastl4, fasthttp, or tcp
default profile to the profile list.

The default profile that Local Traffic Manager chooses depends on the
configuration of the virtual server’s protocol setting. For example, if
the protocol setting is set to UDP, Local Traffic Manager adds the udp
profile to its profile list.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain security options available for the application}

\sphinxstylestrong{Virtual Server Security}

A virtual server is essentially a listener that will be taking in and
processing traffic on the BIG-IP platform. Some of the biggest security
risks when configuring a virtual server are how it is listening, where
it is listening and who can get to it. If you are configuring virtual
server and not setting the necessary settings to restrict these areas of
concern you are opening yourself up to security risks.

\sphinxstylestrong{How Is the Virtual Server Listening?}

The broader you set a virtual server to listen the greater the risk of
unintended inbound traffic. An application based virtual server should
typically be configured to listen on the default port for the
application. For example, if you are configuring a virtual server for a
new HTTP based website you would listen on port 80. If you listen on all
ports (*), the virtual server will take in traffic destine for the
virtual server on all 65535 ports of the IP address. And if the pool
members for the virtual server are also listening on all ports (*), it
will send traffic to the servers on the port it arrived on the virtual
server.

If you need to listen on multiple ports for the same IP address you can
approach this in two different ways. You can build a virtual server for
each necessary port using the same IP address or you can build one
virtual server on all ports and use an iRule to restrict the allowed
inbound connections to your list of ports.

\sphinxstylestrong{Where is the Virtual Server Listening?}

When you configure a virtual server, you tell the BIG-IP where you want
it to listen for traffic destined for the IP address of the virtual
server. This virtual server setting is the VLAN and Tunnel Traffic
setting. By default, the setting is set to All VLANs and Tunnels. Which
means the BIG-IP will listen on all VLANs. You are probably thinking,
ARP is only going to happen on the local subnet’s VLAN, which is true.
So, what can it possibly mean to listen on all VLANs? When this setting
is set to all VLANs it means that if traffic comes to BIG-IP destined
for the virtual server address from a VLAN that is not the VLAN of the
virtual server IP address, it will still take the traffic in on VLAN
interface that it arrived on. BIG-IP is a default deny device but in
setting the setting to All VLANS and Tunnels you have told the system to
listen on all VLANs for traffic to the virtual server and allow it in.

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/14.html\#conceptid}

\sphinxstylestrong{Packet Filters}

Packet filters enhance network security by specifying whether a BIG-IP
system interface should accept or reject certain packets based on
criteria that you specify. Packet filters enforce an access policy on
incoming traffic. They apply to incoming traffic only.

You implement packet filtering by creating packet filter rules, using
the BIG-IP Configuration utility. The primary purpose of a packet filter
rule is to define the criteria that you want the BIG-IP system to use
when filtering packets. Examples of criteria that you can specify in a
packet filter rule are:
\begin{itemize}
\item {} 
The source IP address of a packet

\item {} 
The destination IP address of a packet

\item {} 
The destination port of a packet

\end{itemize}

You specify the criteria for applying packet filter rules within an
expression. When creating a packet filter rule, you can instruct the
BIG-IP system to build an expression for you, in which case you need
only choose the criteria from predefined lists, or you can write your
own expression text, using the syntax of the tcpdump utility. For more
information on the tcpdump utility, see the online man page for the
tcpdump command.

You can also configure global packet filtering that applies to all
packet filter rules that you create. The hyperlink of this section will
describe how to use the Configuration utility to set global packet
filtering options, as well as create and manage individual packet
filters rules.

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/18.html\#conceptid}

\sphinxstylestrong{iRules}

You can use iRules to restrict traffic in almost any way you can think
of. You can set an iRule to keep connections from happening when coming
from a certain IP address range or to a certain URI path in the HTTP
request.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Explain how to use LTM as a service proxy}

Since the F5 BIG-IP platform is designed as a full-proxy architecture
the LTM can act as a proxy for any service level connection.

You define the virtual server as a Standard virtual server that is
listening on an IP address and port combination, which represents the
application to the client. The virtual server should be configured with
an appropriate layer-4 profile, any optional layer-7 protocol profiles
you need and a pool for a resource. The LTM will then broker separate
layer-4 connections for the client and server sides. The server side
connections will be translated from the listening IP address and port
combination of the virtual server to the IP address and port combination
of the pool member that the connection will be sent to via the
load-balancing algorithm of the pool.

The return traffic must flow through the BIG-IP to be correctly
rewritten as it passes back to the client. The return traffic will be
rewritten from the IP address and port combination of the pool member
that received the inbound connection to the IP address and port
combination of the virtual server that the client connected to when the
connection was established.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxhref{https://support.f5.com/csp/article/K8082?sr=42818238\#standard}{K8082: Overview of TCP connection setup for BIG-IP LTM virtual server types}

\sphinxstylestrong{Standard virtual server}

The BIG-IP LTM TMOS operating system implements a full proxy
architecture for virtual servers configured with a TCP profile. By
assigning a custom TCP profile to the virtual server, you can configure
the BIG-IP LTM system to maintain compatibility to disparate server
operating systems in the data center. At the same time, the BIG-IP LTM
system can leverage its TCP/IP stack on the client side of the
connection to provide independent and optimized TCP connections to
client systems.

In a full proxy architecture, the BIG-IP LTM system appears as a TCP
peer to both the client and the server by associating two independent
TCP connections with the end-to-end session. Although certain client
information, such as the source IP address or source TCP port, may be
re-used on the server side of the connection, the BIG-IP LTM system
manages the two sessions independently, making itself transparent to the
client and server.

The Standard virtual server requires a TCP or UDP profile, and may
optionally be configured with HTTP, FTP, or SSL profiles if Layer 7 or
SSL processing is required.

The TCP connection setup behavior for a Standard virtual server varies
depending on whether a TCP profile or a TCP and Layer 7 profile, such as
HTTP, is associated with the virtual server.

\sphinxstylestrong{Standard virtual server with a TCP profile}

The TCP connection setup behavior for a Standard virtual server operates
as follows: the three-way TCP handshake occurs on the client side of the
connection before the BIG-IP LTM system initiates the TCP handshake on
the server side of the connection.

A Standard virtual server processes connections using the full proxy
architecture. The following TCP flow diagram illustrates the TCP
handshake for a Standard virtual server with a TCP profile:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p11}.jpeg}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Standard virtual server with Layer 7 functionality}

If a Standard virtual server is configured with Layer 7 functionality,
such as an HTTP profile, the client must send at least one data packet
before the server-side connection can be initiated by the BIG-IP LTM
system.

Note: The BIG-IP LTM system may initiate the server-side connection
prior to the first data packet for certain Layer 7 applications, such as
FTP, in which case the user waits for a greeting banner before sending
any data.

The TCP connection setup behavior for a Standard virtual server with
Layer 7 functionality operates as follows: the three-way TCP handshake
and initial data packet are processed on the client side of the
connection before the BIG-IP LTM system initiates the TCP handshake on
the server side of the connection.

A Standard virtual server with Layer 7 functionality processes
connections using the full proxy architecture. The following TCP flow
diagram illustrates the TCP handshake for a Standard virtual server with
Layer 7 functionality:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p2}.jpeg}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Describe how a given service is deployed on an LTM}

\sphinxhref{https://support.f5.com/csp/article/K4707?sr=28929465}{K4707: Choosing appropriate profiles for HTTP traffic}

\sphinxstylestrong{Processing HTTP traffic}

The BIG-IP system allows you to process HTTP traffic using various
profiles, including TCP+HTTP, FastHTTP, and FastL4. Each profile, or
combination of profiles, offers distinct advantages, limitations, and
features.

F5 recommends that you assess the needs of each HTTP virtual server
individually, using the following information, to determine which
profile, or profile combination, best meets the requirements for each
virtual server.

\sphinxstyleemphasis{Important}: The HTTP profile will work in all cases; however, the
HTTP profile places BIG-IP in full Layer 7 inspection mode, which
may be unnecessary when used on simple load balancing virtual
servers. Thus, you should consider the other profile options
provided in instances where the full Layer 7 engine is not necessary
for a particular virtual server.

\sphinxstylestrong{TCP+HTTP}

\sphinxstyleemphasis{Profiles:} TCP+HTTP

\sphinxstyleemphasis{Advantage:} The HTTP profile can take full advantage of all of BIG-IP
system’s Layers 4 - 7 HTTP/HTTPS features.

\sphinxstyleemphasis{When to use:} The HTTP profile is used when any of the following
features are required:
\begin{itemize}
\item {} 
IPv6 support

\item {} 
TCPexpress and content spooling features reduce server load

\item {} 
Full OneConnect functionality (including HTTP 1.0 transformations)

\item {} 
Layer 7 persistence (cookie, hash, universal, and iRule)

\item {} 
Full HTTP iRules logic

\item {} 
Cache and Web Acceleration features

\item {} 
HTTP Compression

\item {} 
HTTP pipelining

\item {} 
Virtual Server Authentication

\item {} 
Redirect Rewriting

\item {} 
SPDY protocol support (11.3.0 and later)

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Limitations}
\begin{itemize}
\item {} 
More CPU-intensive

\item {} 
Memory utilization:

\item {} 
Cache / Web Acceleration - The caching / web acceleration features provision user-defined memory for cache content for each virtual server that uses the given HTTP and Cache profiles.

\item {} 
Compression - Larger buffer sizes can increase memory utilization when compressing large objects.

\item {} 
TCP offloading/content spooling - This can increase memory utilization in cases where either the client-side or the server-side of the connection is slower than the other. The BIG-IP system holds the data in the buffer until the slower side of the connection is able to retrieve it.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{HTTP/2}

Note: The HTTP/2 profile requires that you apply a TCP, HTTP, and
client-side SSL profile to the virtual server.

Advantage: The HTTP/2 profile allows you to take advantage of the
improvements provided by the Hypertext Transfer Protocol Version 2
specification (RFC7540 and RFC7541).

When to use: The HTTP/2 profile allows the BIG-IP system to serve as a
gateway for HTTP/2 traffic. By multiplexing streams and compressing
headers, the perceived latency of requests and responses is reduced and
the overall efficiency of the network is improved. The HTTP/2 profile
can be used to provide the following:
\begin{itemize}
\item {} 
Multiplexed request/response streams with flow control for improved
network utilization

\item {} 
Automatic header compression

\item {} 
Binary instead of textual message framing for efficient message
processing

\item {} 
Support for SPDY, HTTP/1.1, and HTTP/2 protocol selection

\item {} 
Proactive server response push to client

\item {} 
iRules logic for HTTP/2

\end{itemize}

Limitations
\begin{itemize}
\item {} 
Header compression consumes CPU and memory resources

\item {} 
No support for source address persistence

\item {} 
Not compatible with NTLM protocols.

\item {} 
Not compatible with SSL profile (Client) renegotiation.

\end{itemize}

\sphinxstylestrong{FastHTTP}

\sphinxstyleemphasis{Profile:} FastHTTP

\sphinxstyleemphasis{Advantage:} Faster than HTTP profile

\sphinxstyleemphasis{When to use:} FastHTTP profile is recommended when it is not necessary
to use persistence and or maintain source IP addresses. FastHTTP also
adds a subset of OneConnect features to reduce the number of connections
opened to the backend HTTP servers. The FastHTTP profile requires that
the clients’ source addresses are translated. If an explicit SNAT or
SNAT pool is not specified, the appropriate self IP address is used.

Note: Typically, server efficiency increases as the number of SNAT addresses that are available to the virtual server increases. At the
same time, the increase in SNAT addresses that are available to the
virtual server also decreases the likelihood that the virtual server
will reach the point of ephemeral port exhaustion (65535 open
connections per SNAT address).

\sphinxstyleemphasis{Limitations}
\begin{itemize}
\item {} 
Requires client source address translation

\item {} 
Not compatible with persistence until version 10.0.0

\item {} 
Limited iRules support L4 and are limited to a subset of HTTP header
operations, and pool/pool member selection

\item {} 
No compression

\item {} 
No virtual server authentication

\item {} 
No support for HTTP pipelining

\item {} 
No TCP optimizations

\item {} 
No IPv6 support

\end{itemize}

Note: FastHTTP is optimized for ideal traffic conditions, but may
not be an appropriate profile to use when network conditions are
less than optimal. For more information about the FastHTTP profile,
refer to SOL8024: Overview of the FastHTTP profile.

\sphinxstylestrong{FastL4}

\sphinxstyleemphasis{Profile:} FastL4

\sphinxstyleemphasis{Advantage:} Accelerates packet processing

\sphinxstyleemphasis{When to use:} FastL4 is limited in functionality to socket level
decisions (for example, src\_ip:port dst\_ip:port). Thus, you can use
FastL4 only when socket level information for each connection is
required for the virtual server.

\sphinxstyleemphasis{Limitations}
\begin{itemize}
\item {} 
No HTTP optimizations

\item {} 
No TCP optimizations for server offloading

\item {} 
SNAT/SNAT pools demote PVA acceleration setting level to Assisted

\item {} 
iRules limited to L4 events, such as CLIENT\_ACCEPTED and
SERVER\_CONNECTED

\item {} 
No OneConnect

\item {} 
Limited persistence options:

\item {} 
Source address

\item {} 
Destination address

\item {} 
Universal

\item {} 
Hash (BIG-IP 9.x only)

\item {} 
No compression

\item {} 
No Virtual Server Authentication

\item {} 
No support for HTTP pipelining

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.03 - Given an application configuration, determine which functions can be offloaded to the LTM device}
\label{\detokenize{class5/modules/module1:objective-1-03-given-an-application-configuration-determine-which-functions-can-be-offloaded-to-the-ltm-device}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 \textendash{} Explain how to offload HTTP servers for SSL, compression and caching}

\sphinxstylestrong{Offloading}

One of the most prominent advantages to having a BIG-IP platform in your
network is that it can offload functions from the server environment to
improve their performance. SSL termination, HTTP compression and RAM
Caching are a few of the primary functions

Each of these optimizations are configurations that are completed in
profiles assigned to the virtual server.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/3.html\#unique\_2115148650}

\sphinxstylestrong{SSL Offload}

When you want the BIG-IP system to process application traffic over SSL,
you can configure the system to perform the SSL handshake that
destination servers normally perform. This ability for the BIG-IP system
to offload SSL processing from a destination server is an important
feature of the BIG-IP system.

The most common way to configure the BIG-IP system is to create a Client
SSL profile, which makes it possible for the BIG-IP system to decrypt
client requests before sending them on to a server, and encrypt server
responses before sending them back to the client.

Within a Client SSL profile specifically, you can specify multiple
certificate/key pairs, one per key type. This enables the system to
accept all types of cipher suites that a client might support as part of
creating a secure connection. The system then decrypts the client data,
manipulates any headers or payload according to the way that you
configured the Client SSL profile, and by default, sends the request in
clear text to the target server for processing.

For those sites that require enhanced security on their internal
network, you can configure a Server SSL profile. With a Server SSL
profile, the BIG-IP system re-encrypts the request before sending it to
the destination server. When the server returns an encrypted response,
the BIG-IP system decrypts and then re-encrypts the response, before
sending the response back to the client.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-implementations-11-5-0/20.html}

\sphinxstylestrong{HTTP compression}

An optional feature of the BIG-IP system is the system’s ability to
off-load HTTP compression tasks from the target server. All of the tasks
that you need to configure HTTP compression, as well as the compression
software itself, are centralized on the BIG-IP system. The primary way
to enable HTTP compression is by configuring an HTTP Compression type of
profile and then assigning the profile to a virtual server. This causes
the system to compress HTTP content for any responses matching the
values that you specify in the Request-URI or Content-Type settings of
the HTTP Compression profile.

\sphinxstylestrong{Configuration}

You should be familiar with how the configuration of HTTP Compression
looks in the CLI Configuration as well as in the GUI.

To configure HTTP data compression, you need to create an HTTP
compression type of profile, as well as a virtual server.

Creating a customized HTTP compression profile

If you need to adjust the compression settings to optimize compression
for your environment, you can modify a custom HTTP compression profile.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Acceleration \textgreater{} Profiles \textgreater{} HTTP Compression.
The HTTP Compression profile list screen opens.

\item {} 
Click Create. The New HTTP Compression profile screen opens.

\item {} 
In the Name field, type a unique name for the profile.

\item {} 
From the Parent Profile list, select one of the following profiles:
\begin{itemize}
\item {} 
httpcompression.

\item {} 
wan-optimized-compression.

\end{itemize}

\item {} 
Select the Custom check box.

\item {} 
Modify the settings, as required.

\item {} 
Click Finished.

\end{enumerate}

The modified HTTP compression profile is available in the HTTP
Compression list screen.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Creating a virtual server for HTTP compression

You can create a virtual server that uses an HTTP profile with an HTTP
compression profile to compress HTTP responses.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Virtual Servers. The Virtual
Server List screen displays a list of existing virtual servers.

\item {} 
Click the Create button. The New Virtual Server screen opens.

\item {} 
In the Name field, type a unique name for the virtual server.

\item {} 
Specify the Destination setting, using the Address field; type the IP
address you want to use for the virtual server. The IP address you
type must be available and not in the loopback network.

\item {} 
In the Service Port field, type 80, or select HTTP from the list.

\item {} 
Select http in the HTTP Profile list.

\item {} 
From the HTTP Compression Profile list, select one of the following
profiles:
\begin{itemize}
\item {} 
httpcompression

\item {} 
wan-optimized-compression

\item {} 
A customized profile

\end{itemize}

\item {} 
In the Resources area of the screen, from the Default Pool list,
select a pool name.

\item {} 
Click Finished.

\end{enumerate}

The virtual server with an HTTP profile configured with an HTTP
compression profile appears in the Virtual Server list.

After you have created a custom HTTP Compression profile and a virtual
server, you can test the configuration by attempting to pass HTTP
traffic through the virtual server. Check to see that the BIG-IP system
includes and excludes the responses that you specified in the custom
profile, and that the system compresses the data as specified.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/f5-tmos-operations-guide.pdf}

\sphinxstylestrong{BIG-IP Cache}

The BIG-IP Cache Setting feature, formerly known as RAM Cache, uses the
information from the Vary header to cache responses from the origin web
server (OWS). OWS can include information within the Vary header to
determine which resource the server returns in its response.

For example, if a page is optimized for a particular web browser, OWS
response may return the Vary: User-Agent HTTP header. The proxy server
then uses this information to determine whether to return a cached copy
of the response to subsequent requests, or to query the OWS for the
resource again (a subsequent client request containing a different
User-Agent value forces the proxy to query the OWS for the resource
again).

An HTTP cache is a collection of HTTP objects stored in the BIG-IP
system memory which subsequent connections can reuse to reduce traffic
load on the origin web servers. The goal of caching is to reduce the
need to send frequent requests for the same object, and eliminate the
need to send full responses in many cases. You can enable HTTP caching
on the BIG-IP system by associating a Web Acceleration profile with a
virtual server.

Cacheable content

The BIG-IP cache feature complies with the cache specifications
described in RFC 2616. You can configure the BIG-IP system to cache the
following content types:
\begin{itemize}
\item {} 
200, 203, 206, 300, 301, and 410 HTTP responses.

\item {} 
Responses to HTTP GET requests.

\item {} 
Other HTTP methods for uniform resource identifiers (URIs) specified
for inclusion in cached content, or specified in an iRule.

\item {} 
Content based on the User-Agent and Accept-Encoding values. The cache
feature holds different content for Vary headers.

\end{itemize}

The default cache configuration caches only responses to HTTP GET
requests. However, you can configure the Web Acceleration pro le to
cache other requests, including non-HTTP requests. To do this, you can
specify a URI in the URI Include or Pin List within an HTTP pro le, or
write an iRule.

Non-cacheable content

The cache feature does not cache the following items:
\begin{itemize}
\item {} 
Private data specified by cache control headers.

\item {} 
Action-oriented HTTP methods such as HEAD, PUT, DELETE, TRACE, and
CONNECT.

\item {} 
Set-Cookie headers sent by the origin web server.

\end{itemize}

BIG-IP DNS cache feature

You can configure a transparent cache on the BIG-IP system to use
external DNS resolvers to resolve queries and then cache the responses
from the resolvers. The next time the system receives a query for a
response that exists in the cache, the system immediately returns the
response from the cache. The transparent cache contains messages and
resource records.

A transparent cache in the BIG-IP system consolidates content that would
otherwise be cached across multiple external resolvers. When a
consolidated cache is in front of external resolvers (each with their
own cache), it can produce a much higher cache hit percentage.

BIG-IP AAM optimization cache feature

BIG-IP AAM optimization cache is a self-managing feature. A small amount
of TMM memory is used together with a disk-based datastore/metastore
database. The two ways to view BIG-IP AAM caching behavior are by using
X-WA-Info debug headers and through the dashboard in the Configuration
utility.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 \textendash{} Explain how to configure LTM to handle SSL offload}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/3.html\#unique\_2115148650}

\sphinxstylestrong{SSL Offload}

When you want the BIG-IP system to process application traffic over SSL,
you can configure the system to perform the SSL handshake that
destination servers normally perform. This ability for the BIG-IP system
to offload SSL processing from a destination server is an important
feature of the BIG-IP system.

The most common way to configure the BIG-IP system is to create a Client
SSL profile, which makes it possible for the BIG-IP system to decrypt
client requests before sending them on to a server, and encrypt server
responses before sending them back to the client.

Within a Client SSL profile specifically, you can specify multiple
certificate/key pairs, one per key type. This enables the system to
accept all types of cipher suites that a client might support as part of
creating a secure connection. The system then decrypts the client data,
manipulates any headers or payload according to the way that you
configured the Client SSL profile, and by default, sends the request in
clear text to the target server for processing.

For those sites that require enhanced security on their internal
network, you can configure a Server SSL profile. With a Server SSL
profile, the BIG-IP system re-encrypts the request before sending it to
the destination server. When the server returns an encrypted response,
the BIG-IP system decrypts and then re-encrypts the response, before
sending the response back to the client.

\sphinxstylestrong{Creating a custom Client SSL profile}

You create a custom Client SSL profile when you want the BIG-IP system
to terminate client-side SSL traffic for the purpose of decrypting
client-side ingress traffic and encrypting client-side egress traffic.
By terminating client-side SSL traffic, the BIG-IP system offloads these
decryption/encryption functions from the destination server. When you
perform this task, you can specify multiple certificate key chains, one
for each key type (RSA, DSA, and ECDSA). This allows the BIG-IP system
to negotiate secure client connections using different cipher suites
based on the client’s preference.

Note: At a minimum, you must specify a certificate key chain that
includes an RSA key pair. Specifying certificate key chains for DSA and
ECDSA key pairs is optional, although highly recommended.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Profiles \textgreater{} SSL \textgreater{} Client. The
Client profile list screen opens.

\item {} 
Click Create. The New Client SSL Profile screen opens.

\item {} 
In the Name field, type a unique name for the profile.

\item {} 
From the Parent Profile list, select clientssl.

\item {} 
Select the Custom check box. The settings become available for
change.

\item {} 
Using the Certificate Key Chain setting, specify one or more
certificate key chains:
\begin{itemize}
\item {} 
From the Certificate list, select a certificate name. This is the name of a certificate that you installed on the BIG-IP system. If you have not generated a certificate request nor installed a certificate on the BIG-IP system, you can specify the name of an existing certificate, default.

\item {} 
From the Key list, select the name of the key associated with the certificate specified in the previous step. This is the name of a key that you installed on the BIG-IP system. If you have not installed a key on the BIG-IP system, you can specify the name of an existing key, default.

\item {} 
From the Chain list, select the chain that you want to include in the certificate key chain. A certificate chain can contain either a series of public key certificates in Privacy Enhanced Mail (PEM) format or a series of one or more PEM files. A certificate chain can contain certificates for Intermediate certificate Authorities (CAs).

\item {} 
Note: The default self-signed certificate and the default CA bundle certificate are not appropriate for use as a certificate chain.

\item {} 
For the Passphrase field, type a string that enables access to SSL certificate/key pairs that are stored on the BIG-IP system with password protection. This setting is optional. For added security, the BIG-IP system automatically encrypts the pass phrase itself. This pass phrase encryption process is invisible to BIG-IP system administrative users.

\item {} 
Click Add and repeat the process for all certificate key chains that you want to specify.

\item {} 
\noindent\sphinxincludegraphics{{p32}.png}

\item {} 
Sample configuration with three key types specified

\item {} 
The result is that all specified key chains appear in the box.

\end{itemize}

\item {} 
If you want to use a cipher suite other than DEFAULT:
\begin{itemize}
\item {} 
From the Configuration list, select Advanced.

\item {} 
For the Ciphers setting, type the name of a cipher. You can specify a particular string to indicate the ciphers that you want the BIG-IP system to use for SSL negotiation, or you can specify ciphers that you do not want the system to use. Examples of cipher values that you can specify are ECDHE and DEFAULT:!ECDHE.

\end{itemize}

\item {} 
Configure all other profile settings as needed.

\item {} 
Click Finished.

\end{enumerate}

After performing this task, you can see the custom Client SSL profile in
the list of Client SSL profiles on the system.

You must also assign the profile to a virtual server.

\sphinxstylestrong{Creating a custom Server SSL profile}

With an Server SSL profile, the BIG-IP system can perform decryption and
encryption for server-side SSL traffic.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Profiles \textgreater{} SSL \textgreater{} Server. The
SSL Server profile list screen opens.

\item {} 
Click Create. The New Server SSL Profile screen opens.

\item {} 
In the Name field, type a unique name for the profile.

\item {} 
Select serverssl in the Parent Profile list.

\item {} 
From the Configuration list, select Advanced.

\item {} 
Select the Custom check box. The settings become available for
change.

\item {} 
From the Certificate list, select the name of an SSL certificate on
the BIG-IP system.

\item {} 
From the Key list, select the name of an SSL key on the BIG-IP
system.

\item {} 
In the Pass Phrase field, select a pass phrase that enables access
to the certificate/key pair on the BIG-IP system.

\item {} 
From the Chain list, select the name of an SSL chain on the BIG-IP
system.

\item {} 
If you want to use a cipher suite other than DEFAULT:
\begin{itemize}
\item {} 
From the Configuration list, select Advanced.

\item {} 
For the Ciphers setting, type the name of a cipher. You can specify a particular string to indicate the ciphers that you want the BIG-IP system to use for SSL negotiation, or you can specify ciphers that you do not want the system to use. Examples of cipher values that you can specify are ECDHE and DEFAULT:!ECDHE.

\end{itemize}

\item {} 
Select the Custom check box for Server Authentication.

\item {} 
Modify the settings, as required.

\item {} 
Click Finished.

\end{enumerate}

After performing this task, you can see the custom Server SSL profile in
the list of Server SSL profiles on the system.

You must also assign the profile to a virtual server.

\sphinxstylestrong{Assigning SSL profiles to a virtual server}

The final task in the process of implementing SSL profiles is to assign
the SSL profile to a virtual server. If the relevant virtual server does
not yet exist, you can assign the SSL profile (or profiles) to the
virtual server when you create it.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Virtual Servers. The Virtual
Server List screen opens.

\item {} 
Click the name of a virtual server.

\item {} 
From the Configuration list, select Advanced.

\item {} 
For the SSL Profile (Client) setting, from the Available list, select
the name of the Client SSL profile you previously created, and using
the Move button, move the name to the Selected list.

\item {} 
For the SSL Profile (Server) setting, from the Available list, select
the name of the Server SSL profile you previously created, and using
the Move button, move the name to the Selected list.

\item {} 
Click Update to save the changes.

\end{enumerate}

After you perform this task, you must assign the profile to a virtual
server.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.04 - Given an iRule functionality, determine the profiles and configuration options necessary to implement the iRule}
\label{\detokenize{class5/modules/module1:objective-1-04-given-an-irule-functionality-determine-the-profiles-and-configuration-options-necessary-to-implement-the-irule}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 \textendash{} Explain how to create an HTTP configuration to handle an HTTP server error}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/7.html}

\sphinxstylestrong{Introduction to HTTP profiles}

You can configure an HTTP profile to ensure that HTTP traffic management
suits your specific needs. You can configure the profile settings either
when you create a profile or after you create the profile by modifying
the profile’s settings. For all profile settings, you can specify values
where none exist, or modify any default values to suit your needs. The
BIG-IP system also includes default profiles that you can use as is, if
you do not want to create a custom profile.

\sphinxstylestrong{Fallback host}

Another feature that you can configure within an HTTP profile is HTTP
redirection. HTTP redirection allows you to redirect HTTP traffic to
another protocol identifier, host name, port number, or URI path.

Redirection to a fallback host occurs if all members of the targeted
pool are unavailable, or if a selected pool member is unavailable. (The
term unavailable refers to a member being disabled, marked as down, or
having exceeded its connection limit.) When one or more pool members are
unavailable, Local Traffic Manager can redirect the HTTP request to the
fallback host, with the HTTP reply Status Code 302 Found.

Although HTTP redirection often occurs when the system generates an
LB\_FAILED iRule event, redirection can also occur without the
occurrence of this event, such as when:

The selected node sends an RST after a TCP 3WHS has completed, but
before the node has sent at least a full response header.

Local Traffic Manager finds the selected node to be unreachable while
receiving the body portion of a request or a pipelined request.

When configuring Local Traffic Manager to redirect HTTP traffic to a
fallback host, you can specify an IP address or a fully-qualified domain
name (FQDN). The value that you specify becomes the value of the
Location header that the server sends in the response. For example, you
can specify a redirection as \sphinxurl{http://redirector.siterequest.com}.

\sphinxstylestrong{Fallback error codes}

In addition to redirecting traffic when a target server becomes
unavailable, you can also specify the HTTP error codes from server
responses that should trigger a redirection to the fallback host.
Typical error codes to specify are 500, 501, and 502.

\sphinxurl{https://devcentral.f5.com/wiki/iRules.HTTP\_RESPONSE.ashx}

\sphinxstylestrong{How to handle an HTTP server error}

Configuring a virtual server on your BIG-IP platform to load balance the
HTTP based traffic for your webservers can be a very simple
configuration. But you realize that periodically a server returns an
error and the clients are receiving a 404 error, and they are leaving
your site for a competitor’s site. You want to take an action on those
errors to send your customers to a “Sorry Page”.

If this were an issue of all of your servers be off line you could
simply apply a custom HTTP profile to the virtual server and set the
Fallback Host field with the URL to your Sorry Page. However, this is
happening intermittently on random server within the pool.

You could apply an iRule to your virtual server to send your customer to
your Sorry Page when it sees the 404 error.

To do this, follow these steps:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Setup your Sorry Server to run the Sorry Page.

\end{enumerate}

2. Write the iRule to meet your needs. The following is an example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{when} \PYG{n}{HTTP\PYGZus{}RESPONSE} \PYG{p}{\PYGZob{}}
\PYG{k}{if} \PYG{p}{\PYGZob{}} \PYG{p}{[}\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{status}\PYG{p}{]} \PYG{n}{contains} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{404}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}}
\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{redirect} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{http://www.mysorryserver.com/appsorrypage.html}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Apply an HTTP profile (the default http profile will work) to the
virtual server so that the virtual server will process the HTTP
traffic allowing the iRule to work correctly.

\item {} 
Apply the new iRule to your virtual server.

\end{enumerate}

You could do further rule work to track info about the server when the
errors happen but it is not necessary to solve the problem.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - (Supplemental Example) Given an iRule functionality, determine the profiles and configuration options necessary to implement the iRule}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/18.html}

\sphinxstylestrong{iRules and Profiles}

An iRule is a powerful and flexible feature within BIG-IP Local Traffic
Manager that you can use to manage your network traffic.

iRules are event-driven, which means that Local Traffic Manager triggers
an iRule based on an event that you specify in the iRule. An event
declaration is the specification of an event within an iRule that causes
Local Traffic Manager to trigger that iRule whenever that event occurs.
Examples of event declarations that can trigger an iRule are
HTTP\_REQUEST, which triggers an iRule whenever the system receives an
HTTP request, and CLIENT\_ACCCEPTED, which triggers an iRule when a
client has established a connection.

The virtual server that the iRule is assigned to also has profiles
configured. Profiles tell the virtual server to process traffic
according to the values specified in the profile. Using profiles not
only enhances your control over managing network traffic and makes
traffic-management tasks easier and more efficient, but they give the
virtual server the visibility into the traffic to know that an iRule
event is happening and an action should be taken. For example, without
the http profile assigned to the virtual server, the http request is not
visible to the LTM and an iRule using the HTTP\_REQUEST even to trigger
could not run.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.05 - Given application requirements, determine the appropriate profile and persistence settings}
\label{\detokenize{class5/modules/module1:objective-1-05-given-application-requirements-determine-the-appropriate-profile-and-persistence-settings}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain how to create an HTTP configuration for mobile clients}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/11.html}

\sphinxstylestrong{TCP Optimization}

The BIG-IP system includes several pre-configured TCP profiles that you
can use as is. In addition to the default TCP profile, the system
includes TCP profiles that are pre-configured to optimize LAN and WAN
traffic, as well as traffic for mobile users. You can use the
pre-configured profiles as is, or you can create a custom profile based
on a pre-configured profile and then adjust the values of the settings
in the profiles to best suit your particular network environment.

\sphinxstylestrong{About tcp-mobile-optimized profile settings}

The tcp-mobile-optimized profile is a pre-configured profile type, for
which the default values are set to give better performance to service
providers’ 3G and 4G customers. Specific options in the pre-configured
profile are set to optimize traffic for most mobile users, and you can
tune these settings to fit your network. For files that are smaller than
1 MB, this profile is generally better than the mptcp-mobile-optimized
profile. For a more conservative profile, you can start with the
tcp-mobile-optimized profile, and adjust from there.

Note: Although the pre-configured settings produced the best results in
the test lab, network conditions are extremely variable. For the best
results, start with the default settings and then experiment to find out
what works best in your network.
\begin{itemize}
\item {} 
This list provides guidance for relevant settings

\item {} 
Set the Proxy Buffer Low to the Proxy Buffer High value minus 64 KB.
If the Proxy Buffer High is set to less than 64K, set this value at
32K.

\item {} 
The size of the Send Buffer ranges from 64K to 350K, depending on
network characteristics. If you enable the Rate Pace setting, the
send buffer can handle over 128K, because rate pacing eliminates some
of the burstiness that would otherwise exist. On a network with
higher packet loss, smaller buffer sizes perform better than larger.
The number of loss recoveries indicates whether this setting should
be tuned higher or lower. Higher loss recoveries reduce the goodput.

\item {} 
Setting the Keep Alive Interval depends on your fast dormancy goals.
The default setting of 1800 seconds allows the phone to enter low
power mode while keeping the flow alive on intermediary devices. To
prevent the device from entering an idle state, lower this value to
under 30 seconds.

\item {} 
The Congestion Control setting includes delay-based and hybrid
algorithms, which might better address TCP performance issues better
than fully loss-based congestion control algorithms in mobile
environments. The Illinois algorithm is more aggressive, and can
perform better in some situations, particularly when object sizes are
small. When objects are greater than 1 MB, goodput might decrease
with Illinois. In a high loss network, Illinois produces lower
goodput and higher retransmissions. The Woodside algorithm relies on
timestamps to determine transmission. If timestamps are not available
in your network, avoid using Woodside.

\item {} 
For 4G LTE networks, specify the Packet Loss Ignore Rate as 0. For 3G
networks, specify 2500. When the Packet Loss Ignore Rate is specified
as more than 0, the number of retransmitted bytes and receives SACKs
might increase dramatically.

\item {} 
For the Packet Loss Ignore Burst setting, specify within the range of
6-12, if the Packet Loss Ignore Rate is set to a value greater than
0. A higher Packet Loss Ignore Burst value increases the chance of
unnecessary retransmissions.

\item {} 
For the Initial Congestion Window Size setting, round trips can be
reduced when you increase the initial congestion window from 0 to 10
or 16.

\item {} 
Enabling the Rate Pace setting can result in improved goodput. It
reduces loss recovery across all congestion algorithms, except
Illinois. The aggressive nature of Illinois results in multiple loss
recoveries, even with rate pacing enabled.

\end{itemize}

A tcp-mobile-optimized profile is similar to a TCP profile, except that
the default values of certain settings vary, in order to optimize the
system for mobile traffic.

You can use the tcp-mobile-optimized profile as is, or you can create
another custom profile, specifying the tcp-mobile-optimized profile as
the parent profile.

\sphinxstylestrong{About mptcp-mobile-optimized profile settings}

The mptcp-mobile-optimized profile is a pre-configured profile type for
use in reverse proxy and enterprise environments for mobile applications
that are front-ended by a BIG-IP system. This profile provides a more
aggressive starting point than the tcp-mobile-optimized profile. It uses
newer congestion control algorithms and a newer TCP stack, and is
generally better for files that are larger than 1 MB. Specific options
in the pre-configured profile are set to optimize traffic for most
mobile users in this environment, and you can tune these settings to
accommodate your network.

Note: Although the pre-configured settings produced the best results in
the test lab, network conditions are extremely variable. For the best
results, start with the default settings and then experiment to find out
what works best in your network.

The enabled Multipath TCP (MPTCP) option provides more bandwidth and
higher network utilization. It allows multiple client-side flows to
connect to a single server-side flow. MPTCP automatically and quickly
adjusts to congestion in the network, moving traffic away from congested
paths and toward uncongested paths.

The Congestion Control setting includes delay-based and hybrid
algorithms, which may better address TCP performance issues better than
fully loss-based congestion control algorithms in mobile environments.
Refer to the online help descriptions for assistance in selecting the
setting that corresponds to your network conditions.

The enabled Rate Pace option mitigates bursty behavior in mobile
networks and other configurations. It can be useful on high latency or
high BDP (bandwidth-delay product) links, where packet drop is likely to
be a result of buffer overflow rather than congestion.

An mptcp-mobile-optimized profile is similar to a TCP profile, except
that the default values of certain settings vary, in order to optimize
the system for mobile traffic.

You can use the mptcp-mobile-optimized profile as is, or you can create
another custom profile, specifying the mptcp-mobile-optimized profile as
the parent profile.

\sphinxstylestrong{HTTP Traffic to optimized pool resources}

Apart from optimizing traffic via protocol profile settings, you could
also use an iRule to look at the user agent string in HTTP headers of
the HTTP\_REQUEST to determine the browser type to be mobile based and
thus send their connection to a Pool resource that may be built or tuned
for mobile based browsers.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain how to create an HTTP configuration to optimize WAN connectivity}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/11.html}

\sphinxstylestrong{Optimize WAN Connectivity}

The tcp-wan-optimized profile is a pre-configured profile type. In cases
where the BIG-IP system is load balancing traffic over a WAN link, you
can enhance the performance of your wide-area TCP traffic by using the
tcp-wan-optimized profile.

If the traffic profile is strictly WAN-based, and a standard virtual
server with a TCP profile is required, you can configure your virtual
server to use a tcp-wan-optimized profile to enhance WAN-based traffic.
For example, in many cases, the client connects to the BIG-IP virtual
server over a WAN link, which is generally slower than the connection
between the BIG-IP system and the pool member servers. By configuring
your virtual server to use the tcp-wan-optimized profile, the BIG-IP
system can accept the data more quickly, allowing resources on the pool
member servers to remain available. Also, use of this profile can
increase the amount of data that the BIG-IP system buffers while waiting
for a remote client to accept that data. Finally, you can increase
network throughput by reducing the number of short TCP segments that the
BIG-IP system sends on the network.

A tcp-wan-optimized profile is similar to a TCP profile, except that the
default values of certain settings vary, in order to optimize the system
for WAN-based traffic.

You can use the tcp-wan-optimized profile as is, or you can create
another custom profile, specifying the tcp-wan-optimized profile as the
parent profile.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Determine when connection mirroring is required}

\sphinxurl{https://support.f5.com/csp/article/K13478}

\sphinxstylestrong{Connection Mirroring}

The connection and persistence mirroring feature allows you to configure
a BIG-IP system to duplicate connection and persistence information to
the standby unit of a redundant pair. This setting provides higher
reliability but might affect system performance.

Redundant BIG-IP systems are not stateful by default. The BIG-IP device
service clustering (DSC) architecture allows you to create a redundant
system configuration for multiple BIG-IP devices on a network. System
redundancy includes the ability to mirror connection and persistence
information to a peer device to prevent interruption in service during
failover. The Traffic Management Microkernel (TMM) manages the state
mirroring mechanism, and connection and persistence data is synchronized
to the standby unit with every packet or flow state update. The standby
unit decapsulates the packets and adds them to the connection table.

BIG-IP 11.3.0 and earlier versions maintain only a single global
connection and persistence mirroring channel. The active BIG-IP system
in a high availability (HA) device group can only mirror to one specific
standby BIG-IP system using the global mirror channel. The mirroring
channel is created on TCP port 1028.

Beginning with version 11.4.0, the BIG-IP system maintains a separate
mirroring channel for each traffic group. The active BIG-IP system in an
HA device group dynamically establishes a mirroring connection to the
standby with a status of Next Active for a given traffic group. The port
range for each connection channel begins at TCP 1029 and increments by
one for each new traffic group and channel created. For more
information, refer to K14894: The BIG-IP system establishes a separate
mirroring channel for each traffic group.

In BIG-IP 12.0.0 and later, you can configure the system to mirror
Secure Sockets Layer (SSL) connections that are terminated by the BIG-IP
system to peer device group members. For more information, refer to
K17391: Configuring SSL connection mirroring.

You can use the Configuration utility or Traffic Management Shell (tmsh)
to configure mirroring addresses, configure connection mirroring for
virtual servers and Secure Network Address Translations (SNATs), and
configure persistence mirroring. You can also view mirroring data on the
active and standby BIG-IP systems using the tmsh utility.

\sphinxstylestrong{When to Configure}

Not all applications have to have their connection state know by the
standby unit. Mainly applications that have long-term connections will
need to have their connections mirrored.

For example, where long-term connections, such as FTP and Telnet, are
good candidates for mirroring, mirroring short-term connections, such as
HTTP and UDP, is not recommended as this causes a decrease in system
performance. In addition, mirroring HTTP and UDP connections is
typically not necessary, as those protocols allow for failure of
individual requests without loss of the entire session.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - (Supplemental Example) Describe the persistence across pools and services (e.g., Match Across Services, Match Across vs Match Across Pools)}

\sphinxhref{https://support.f5.com/kb/en-us/solutions/public/5000/800/sol5837.html?sr=42216014}{Link to Online Topic Content}

\sphinxstylestrong{Match Across to Solve Deeper Persistence Issues}

The Match Across options specify that, regardless of the type of
persistence you are implementing, you can specify the criteria that the
BIG-IP system uses to send all requests from a client to the same pool
member. The criteria are based on the virtual servers that are hosting
the client connection.

\sphinxstylestrong{Match Across Services}

The Match Across Services option is used in the following two
configurations:
\begin{itemize}
\item {} 
Configurations that have multiple virtual servers with the same IP
address but have different services specified.

\item {} 
Configurations that have pool members sharing the same address but
have different services specified.

\end{itemize}

Important: The Match Across Services option uses only the node
IP address to find a persistence match in pools other than the one for
which the persistence record was written. This deviation from the normal
persistence matching behavior is required to accommodate the intended
use cases for the feature to match even when the service port does not.
Because of this lack of granularity, a pool containing multiple members
with the same node address may result in inconsistent load balancing
behavior. For this reason, F5 recommends that pools associated with
virtual servers that are configured to use the Match Across Services
option should not contain multiple members using the same node address.

A typical use of the Match Across Services feature is for combined
HTTP/HTTPS support for the same site. Commerce sites are typically
configured to allow customers to view and select merchandise using HTTP,
but then the site switches to HTTPS when the customer begins the
checkout process. The Match Across Services option is useful in this
configuration as it allows the session information to be shared between
the virtual servers and ensures that the client is directed to the same
pool member.

The example, the configuration below shows that clients are load
balanced to pool member \sphinxstylestrong{172.16.1.2:http}, and an entry is created in
the persistence table when they first connect to virtual server
\sphinxstylestrong{192.168.0.10:http}.

If the same clients connect to virtual server \sphinxstylestrong{192.168.0.10:https},
the BIG-IP system uses the persistence session information that was
established with the initial connection, and directs the request to pool
member \sphinxstylestrong{172.16.1.2:https}.

If the same clients connect to virtual server \sphinxstylestrong{192.168.0.20:http}, the
request is load balanced according to the method specified by the pool,
and a new persistence session is entered in the persistence table for
tracking.

Note: This behavior occurs because the third virtual server does not
share the same address as the other two that are configured.

If the client connects to a different virtual server that does not
utilize persistence, that connection will be load balanced according to
the load balancing option specified by the pool for that virtual server.

The following configuration shows how a request is directed with the
Match Across Services option enabled:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{20}{60}|\X{40}{60}|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Value
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.10:http}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Services
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{http\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:http, 172.16.1.2:http, 172.16.1.3:http}
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.10:https}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Services
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{https\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:https, 172.16.1.2:https, 172.16.1.3:https}
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.20:http}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Services
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{http2\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:8443, 172.16.1.2:8443, 172.16.1.3:8443}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Match Across Virtual Servers}

Match Across Virtual Servers is similar to Match Across Services, but it
does not require the virtual servers to share the same IP address. This
configuration allows clients to access different virtual servers,
regardless of their IP address, and still access the same pool member.

The example configuration below shows that clients are load balanced to
pool member \sphinxstylestrong{172.16.1.2:http}, and an entry is created in the
persistence table when they first connect to virtual server
\sphinxstylestrong{192.168.0.10:http}.

If the same clients connect to virtual server \sphinxstylestrong{192.168.0.10:https},
the BIG-IP system uses the persistence session information that was
established with the initial connection to virtual server
\sphinxstylestrong{192.168.0.10:http}, and directs the request to pool member
\sphinxstylestrong{172.16.1.2:https}.

If the same clients connect to virtual server \sphinxstylestrong{192.168.0.20:http}, the
BIG-IP uses the persistence session information that was established
with the initial connection to virtual server \sphinxstylestrong{192.168.0.10:http} and
directs the request to pool member \sphinxstylestrong{172.16.1.2:8443}.

Note: This behavior occurs because the pool members used by virtual
server \sphinxstylestrong{192.168.0.20:http} have the same node IP as those specified in
the http\_pool used by virtual server \sphinxstylestrong{192.168.0.10:http}.

If the client connects to a different virtual server that does not use
persistence, that connection will be load balanced according to the load
balancing option specified by the pool for that virtual server.

The following configuration shows how a request is directed when the
Match Across Virtual Servers option is enabled:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{20}{60}|\X{40}{60}|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Value
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.10:http}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Virtuals
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{http\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:http, 172.16.1.2:http, 172.16.1.3:http}
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.10:https}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Virtuals
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{https\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:https, 172.16.1.2:https, 172.16.1.3:https}
\\
\hline
HTTP Virtual Server
&
\sphinxstylestrong{192.168.0.20:http}
\\
\hline
Persistence Type
&
\sphinxstylestrong{Source Address Affinity}
\\
\hline
Match Across Virtuals
&
\sphinxstylestrong{enabled}
\\
\hline
HTTP Pool Name
&
\sphinxstylestrong{http2\_pool}
\\
\hline
HTTP Pool Members
&
\sphinxstylestrong{172.16.1.1:8443, 172.16.1.2:8443, 172.16.1.3:8443}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Match Across Pools}

The Match Across Pools option allows the BIG-IP system to use any pool
that contains a persistence record for that specific client. You must
proceed cautiously when using this option, as it can direct a client’s
request to a pool that is not specified by the virtual server.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - (Supplemental Example) Describe the cookie persistence options}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-2-0/ltm\_persist\_profiles.html?sr=42324734\#1184882}{Link to Online Topic Content}

\sphinxstylestrong{Cookie Persistence}

You can set up Local Traffic Manager to use HTTP cookie persistence.
Cookie persistence uses an HTTP cookie stored on a client’s computer to
allow the client to reconnect to the same pool member previously visited
at a web site.

There are four methods of cookie persistence available:
\begin{itemize}
\item {} 
HTTP Cookie Insert method

\item {} 
HTTP Cookie Rewrite method

\item {} 
HTTP Cookie Passive method

\item {} 
Cookie Hash method

\end{itemize}

The method you choose to use affects how Local Traffic Manager returns
the cookie when returning the cookie to the client.

\sphinxstylestrong{HTTP Cookie Insert method}

If you specify HTTP Cookie Insert method within the profile, the
information about the server to which the client connects is inserted in
the header of the HTTP response from the server as a cookie. The cookie
is named BIGipServer\textless{}pool\_name\textgreater{}, and it includes the address and port
of the server handling the connection. The expiration date for the
cookie is set based on the timeout configured on the BIG-IP system. HTTP
Cookie Insert is the default value for the Cookie Method setting.

Tip: You can assign this type of profile to a Performance (HTTP) type of
virtual server.

\sphinxstylestrong{HTTP Cookie Rewrite method}

If you specify HTTP Cookie Rewrite method, Local Traffic Manager
intercepts a Set-Cookie header, named BIGipCookie, sent from the server
to the client, and overwrites the name and value of the cookie. The new
cookie is named BIGipServer\textless{}pool\_name\textgreater{} and it includes the address and
port of the server handling the connection.

\sphinxstyleemphasis{Important}: We recommend that you use this method instead of the HTTP
Cookie Passive method whenever possible.

The HTTP Cookie Rewrite method requires you to set up the cookie created
by the server. For the HTTP Cookie Rewrite method to succeed, there
needs to be a blank cookie coming from the web server for Local Traffic
Manager to rewrite. With Apache variants, the cookie can be added to
every web page header by adding the following entry to the httpd.conf
file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Header} \PYG{n}{add} \PYG{n}{Set}\PYG{o}{\PYGZhy{}}\PYG{n}{Cookie} \PYG{n}{BIGipCookie}\PYG{o}{=}\PYG{l+m+mf}{0000000000000000000000000.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

(The cookie must contain a total of 120 zeros.)

Note: For backward compatibility, the blank cookie can contain only 75
zeros. However, cookies of this size do not allow you to use iRules and
persistence together.

\sphinxstylestrong{HTTP Cookie Passive method}

If you specify the HTTP Cookie Passive method, Local Traffic Manager
does not insert or search for blank Set-Cookie headers in the response
from the server. This method does not try to set up the cookie. With
this method, the server provides the cookie, formatted with the correct
server information and timeout.

\sphinxstyleemphasis{Important}: We recommend that you use the HTTP Cookie Rewrite method
instead of the HTTP Cookie Passive method whenever possible.

For the HTTP Cookie Passive method to succeed, there needs to be a
cookie coming from the web server with the appropriate server
information in the cookie. Using the Configuration utility, you generate
a template for the cookie string, with encoding automatically added, and
then edit the template to create the actual cookie.

For example, the following string is a generated cookie template with
the encoding automatically added, where {[}pool name{]} is the name of the
pool that contains the server, 336260299 is the encoded server address,
and 20480 is the encoded port:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Set}\PYG{o}{\PYGZhy{}}\PYG{n}{Cookie}\PYG{p}{:}\PYG{n}{BIGipServer}\PYG{p}{[}\PYG{n}{poolname}\PYG{p}{]}\PYG{o}{=}\PYG{l+m+mf}{336268299.20480}\PYG{o}{.}\PYG{l+m+mi}{0000}\PYG{p}{;} \PYG{n}{expires}\PYG{o}{=}\PYG{n}{Sat}\PYG{p}{,} \PYG{l+m+mi}{01}\PYG{o}{\PYGZhy{}}\PYG{n}{Jan}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2002} \PYG{l+m+mi}{00}\PYG{p}{:}\PYG{l+m+mi}{00}\PYG{p}{:}\PYG{l+m+mi}{00} \PYG{n}{GMT}\PYG{p}{;} \PYG{n}{path}\PYG{o}{=}\PYG{o}{/}
\end{sphinxVerbatim}

\sphinxstylestrong{Cookie Hash method}

If you specify the Cookie Hash method, the hash method consistently maps
a cookie value to a specific node. When the client returns to the site,
Local Traffic Manager uses the cookie information to return the client
to a given node. With this method, the web server must generate the
cookie; Local Traffic Manager does not create the cookie automatically
as it does when you use the HTTP Cookie Insert method.

Cookie profile settings

To implement cookie persistence, you can either use the default cookie
profile, or create a custom profile.

\sphinxstyleemphasis{Settings of a Cookie persistence profile}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{Setting}
&
\sphinxstylestrong{Description}
&
\sphinxstylestrong{Default Value}
\\
\hline
Name
&
Specifies a unique name for the profile. This setting is required.
&
No default value
\\
\hline
Persistence Type
&
Specifies the type of persistence. This setting is required.
&
Cookie
\\
\hline
Cookie Method
&
Specifies the type of cookie processing that the BIG-IP system is to use. For more information, see \sphinxstyleemphasis{HTTP Cookie Insert method}, following.
&
HTTP Cookie Insert
\\
\hline
Cookie Name
&
Specifies the name of the cookie that the BIG-IP system should look for or insert.
&
This value is autogenerated based on the pool name.
\\
\hline
Expiration
&
Sets the expiration time of the cookie. Applies to the HTTP Cookie Insert and HTTP Cookie Rewrite methods only. When using the default (checked), the system uses the expiration time specified in the session cookie.
&
Enabled (Checked)
\\
\hline
Hash Offset
&
With respect to Cookie persistence, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
0
\\
\hline
Hash Length
&
With respect to Cookie persistence, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
0
\\
\hline
Timeout
&
This setting applies to the \sphinxstylestrong{Cookie Hash} method only. The setting specifies the duration, in seconds, of a persistence entry.
&
180
\\
\hline
Mirror Persistence
&
Specifies, when enabled (checked), that if the active unit goes into the standby mode, the system mirrors any persistence records to its peer. With respect to Cookie profiles, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
Disabled (Cleared)
\\
\hline
Match Across Services
&
Specifies that all persistent connections from a client IP address that go to the same virtual IP address also go to the same node. With respect to Cookie profiles, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
Disabled (Cleared)
\\
\hline
Match Across Virtual Servers
&
Specifies that all persistent connections from the same client IP address go to the same node. With respect to Cookie profiles, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
Disabled (Cleared)
\\
\hline
Match Across Pools
&
Specifies that the BIG-IP system can use any pool that contains this persistence entry. With respect to Cookie profiles, this setting applies to the \sphinxstylestrong{Cookie Hash} method only.
&
Disabled (Cleared)
\\
\hline
Override Connection Limit
&
Specifies, when checked (enabled), that the system allows you to specify that pool member connection limits are overridden for persisted clients. Per-virtual connection limits remain hard limits and are not overridden.
&
Disabled (Cleared)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.06 - Explain the steps necessary to configure AVR}
\label{\detokenize{class5/modules/module1:objective-1-06-explain-the-steps-necessary-to-configure-avr}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Explain the steps necessary to configure the AVR}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/1.html}

\sphinxstylestrong{Application Visibility and Reporting}

Analytics (also called Application Visibility and Reporting (AVR)) is a
module on the BIG-IP system that you can use to analyze the performance
of web applications. It provides detailed metrics such as transactions
per second, server and client latency, request and response throughput,
and sessions. You can view metrics for applications, virtual servers,
pool members, URLs, specific countries, and additional detailed
statistics about application traffic running through the BIG-IP system.

Transaction counters for response codes, user agents, HTTP methods,
countries, and IP addresses provide statistical analysis of the traffic
that is going through the system. You can capture traffic for
examination and have the system send alerts so you can troubleshoot
problems and immediately react to sudden changes.

The Analytics module also provides remote logging capabilities so that
your company can consolidate statistics gathered from multiple BIG-IP
appliances onto syslog servers or SIEM devices, such as Splunk.

\sphinxstylestrong{AVR Profile}

An Analytics profile is a set of definitions that determines the
circumstances under which the system gathers, logs, notifies, and
graphically displays information regarding traffic to an application.
The Analytics module requires that you select an Analytics profile for
each application you want to monitor. You associate the Analytics
profile with one or more virtual servers used by the application, or
with an iApps application service. Each virtual server can have only one
Analytics profile associated with it.

In the Analytics profile, you customize:
\begin{itemize}
\item {} 
What statistics to collect

\item {} 
Where to collect data (locally, remotely, or both)

\item {} 
Whether to capture the traffic itself

\item {} 
Whether to send notifications

\end{itemize}

The BIG-IP system includes a default Analytics profile called analytics.
It is a minimal profile that internally logs application statistics for
server latency, throughput, response codes, and methods. You can modify
the default profile, or create custom Analytics profiles for each
application if you want to track different data for each one.

Charts shown on the Statistics \textgreater{} Analytics \textgreater{} HTTP screens display the
application data saved for all Analytics profiles associated with iApps
application services or virtual servers on the system. You can filter
the information, for example, by application or URL. You can also drill
down into the specifics on the charts, and use the options to further
refine the information in the charts.

\sphinxstylestrong{Setting Up AVR}

This implementation describes how to set up the BIG-IP system to collect
application performance statistics. The system can collect application
statistics locally, remotely, or both. You use these statistics for
troubleshooting and improving application performance.

You can collect application statistics for one or more virtual servers
or for an iApps application service. If virtual servers are already
configured, you can specify them when setting up statistics collection.
If you want to collect statistics for an iApps application service, you
should first set up statistics collection, creating an Analytics
profile, and then create the application service.

The system can send alerts regarding the statistics when thresholds are
exceeded, and when they cross back into the normal range. You can
customize the threshold values for transactions per second, latency,
page load time, and throughput.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Explain how to create an AVR profile and options}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/1.html}

\sphinxstylestrong{AVR profile and options}

You need to provision the AVR module before you can set up local
application statistics collection.

Note: Newer browsers (Internet Explorer 9 or later, Firefox 3.6 or
later, or Chrome 14 or later) support viewing Analytics charts with no
additional plug-in. If using older browsers (Internet Explorer 8 or
earlier, Firefox 3.5 or earlier, or Chrome 13 or earlier), Adobe Flash
Player (version 8 or later) must be installed on the computer where you
plan to view Analytics charts.

Setting up local application statistics collection

You can configure the BIG-IP system to collect specific application
statistics locally.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Profiles \textgreater{} Analytics. The Analytics screen opens.

\end{enumerate}

Tip: If Analytics is not listed, this indicates that Application
Visibility and Reporting (AVR) is not provisioned, or you do not
have rights to create profiles.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Click Create. The New Analytics Profile screen opens.

\item {} 
In the Profile Name field, type a unique name for the Analytics profile.

\item {} 
Select the Custom check box.

\item {} 
For the Statistics Logging Type setting, verify that Internal is selected. If it is not, select the check box on the right first to activate the setting, then select Internal.

\end{enumerate}

Selecting Internal causes the system to store statistics locally,
and you can view the charts on the system by clicking Statistics \textgreater{}
Analytics \textgreater{} HTTP.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
You can use the default values for the rest of the General Configuration settings.

\item {} 
In the Included Objects area, specify the virtual servers for which to capture application statistics:
\begin{itemize}
\item {} 
For the Virtual Servers setting, click Add.

\item {} 
From the Select Virtual Server list that displays, select the virtual servers to include and then click Done.

\end{itemize}

\end{enumerate}

Note: Only virtual servers previously configured with an HTTP
profile display in the list. Also, you can assign only one Analytics
profile to a virtual server; therefore, the list displays only
virtual servers that have not been assigned an Analytics profile.

Special considerations apply if using Analytics on a BIG-IP system
with both Application Security Manager and Access Policy Manager,
where security settings (in Portal Access Webtop or an iRule)
redirect traffic from one virtual server to another. In this case,
you need to attach the Analytics profile to the second virtual
server to ensure that the charts show accurate statistics.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{7}
\item {} 
In the Statistics Gathering Configuration area, select the Custom check box.

\item {} 
In the Statistics Gathering Configuration, for Collected Metrics, select the statistics you want the system to collect:

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Max TPS and Throughput
&
Collects statistics showing the maximum number of transactions occurring per second and the amount of traffic moving through the system (maximum request and response throughput is collected and recorded separately). In the Details table of the Analytics: HTTP Transactions screen, if you drill down into a specific entity, the system displays the maximum TPS. Drilling down in the Request Throughput details displays the maximum request throughput for each entity; and drilling down in the Response Throughput details displays the maximum response throughput for each entity.
\\
\hline
Page Load Time
&
Tracks how long it takes an application user to get a complete response from the application, including network latency and completed page processing.

Note: End user response times and latencies can vary significantly based on geography and connection types.
\\
\hline
User Sessions
&
Stores the number of unique user sessions. For Timeout, select the number of minutes of user inactivity to allow before the system considers the session to be over.

For Cookie Secure Attribute, specify whether to secure session cookies. Options are Always, the secure attribute is always added to the session cookie; Never, the secure attribute is never added to the session cookie; or Only SSL, the secure attribute is added to the session cookie only when the virtual server has a client SSL profile (the default value).
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
In the Statistics Gathering Configuration area, for Collected Entities, select the entities for which you want the system to collect statistics:

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
URLs
&
Collects the requested URLs.
\\
\hline
Countries
&
Saves the name of the country where the request came from based on the client IP address.
\\
\hline
Client IP Addresses
&
Saves the IP address where the request originated. The address saved also depends on whether the request has an XFF (X-forwarded-for) header and whether the HTTP profile accepts XFF headers.
\\
\hline
Client Subnets
&
Saves statistics for predefined client subnets. Client subnets can be added in the Subnets area of the default Analytics profile.
\\
\hline
Response Codes
&
Saves HTTP response codes that the server returned to requesters.
\\
\hline
User Agents
&
Saves information about browsers used when making the request.
\\
\hline
Methods
&
Saves HTTP methods in requests.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{10}
\item {} 
Click Finished.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.07 - Given a set of reporting requirements, determine the AVR metrics and entities to collect}
\label{\detokenize{class5/modules/module1:objective-1-07-given-a-set-of-reporting-requirements-determine-the-avr-metrics-and-entities-to-collect}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - (Supplemental Example) Given a set of reporting requirements, determine the AVR metrics and entities to collect}

\sphinxstylestrong{AVR Metrics and Entities to Collect}

As you are working with AVR in your lab and looking at results of the
metrics that you gather, you should be paying attention to what AVR
allows you to collect like Server Latency, Page Load Time, Throughput
and User Sessions. You should also know what each of these mean (defined
in the last section). You should also be aware of what you can gather
that information for, such as URLs, Countries, Client IP Addresses,
Response Codes, User Agents and Methods. You should also know what each
of those mean (defined in the last section).


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Explain the sizing implications of AVR on the LTM device}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/releasenotes/product/relnote-avr-11-5-0.html}

\sphinxstylestrong{AVR Sizing}

Provisioning AVR can be as impactful as provisioning any other licensed
module. AVR requires CPU and Memory resources to function. As you
increase the use of AVR within the BIG-IP device it can continue to
further impact system resources. If you intend to use AVR on your BIG-IP
environment you should consider the resource impact when you are doing
platform sizing, as if it were any other heavy impact licensable
software for the system.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Explain the logging and notifications options of AVR}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/2.html}

\sphinxstylestrong{AVR}

You can examine the statistics in the Analytics charts when Application
Visibility and Reporting (AVR) is provisioned. Analytics charts display
statistical information about traffic on your system, including the
following details:
\begin{itemize}
\item {} 
Overview

\item {} 
Transactions

\item {} 
Latency

\item {} 
Throughput

\item {} 
Sessions

\end{itemize}

The system updates the Analytics statistics every five minutes (you can
refresh the charts periodically to see the updates). The Analytics
Overview provides a summary of the most frequent recent types of
application traffic, such as the top virtual servers, top URLS, top pool
members, and so on. You can customize the Analytics Overview so that it
shows the specific type of data you are interested in. You can also
export the reports to a PDF or CSV file, or send the reports to one or
more email addresses.

Note: The displayed Analytics statistics are rounded up to two
digits, and might be slightly inaccurate.

Before you can look at the application statistics, you need to have
created an Analytics profile so that the system is capturing the
application statistics internally on the BIG-IP system. You must
associate the Analytics profile with one or more virtual servers (in the
Analytics profile or in the virtual server). If you created an iApp
application service, you can use the provided template to associate the
virtual server.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Explain the uses of the collected metrics and entities}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/1.html}

\sphinxstylestrong{Uses of AVR}

You can review charts that show statistical information about traffic to
your web applications. The charts provide visibility into application
behavior, user experience, transactions, and data center resource usage.

Collected Metrics


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Max TPS and Throughput
&
Collects statistics showing the maximum number of transactions occurring per second and the amount of traffic moving through the system (maximum request and response throughput is collected and recorded separately). In the Details table of the Analytics: HTTP Transactions screen, if you drill down into a specific entity, the system displays the maximum TPS. Drilling down in the Request Throughput details displays the maximum request throughput for each entity; and drilling down in the Response Throughput details displays the maximum response throughput for each entity.
\\
\hline
Page Load Time
&
Tracks how long it takes an application user to get a complete response from the application, including network latency and completed page processing.

Note: End user response times and latencies can vary significantly based on geography and connection types.
\\
\hline
User Sessions
&
Stores the number of unique user sessions. For Timeout, select the number of minutes of user inactivity to allow before the system considers the session to be over.

For Cookie Secure Attribute, specify whether to secure session cookies. Options are Always, the secure attribute is always added to the session cookie; Never, the secure attribute is never added to the session cookie; or Only SSL, the secure attribute is added to the session cookie only when the virtual server has a client SSL profile (the default value).
\\
\hline
URLs
&
Collects the requested URLs.
\\
\hline
Countries
&
Saves the name of the country where the request came from based on the client IP address.
\\
\hline
Client IP Addresses
&
Saves the IP address where the request originated. The address saved also depends on whether the request has an XFF (X-forwarded-for) header and whether the HTTP profile accepts XFF headers.
\\
\hline
Client Subnets
&
Saves statistics for predefined client subnets. Client subnets can be added in the Subnets area of the default Analytics profile.
\\
\hline
Response Codes
&
Saves HTTP response codes that the server returned to requesters.
\\
\hline
User Agents
&
Saves information about browsers used when making the request.
\\
\hline
Methods
&
Saves HTTP methods in requests.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.08 - Given a scenario, determine the appropriate monitor type and parameters to use}
\label{\detokenize{class5/modules/module1:objective-1-08-given-a-scenario-determine-the-appropriate-monitor-type-and-parameters-to-use}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.08 - Explain how to create an application specific monitor}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/14.html\#conceptid}

\sphinxstylestrong{Application Specific Monitor}

You can set up the BIG-IP system to monitor the health or performance of
certain nodes or servers that are members of a load balancing pool.
Monitors verify connections on pool members and nodes. A monitor can be
either a health monitor or a performance monitor, designed to check the
status of a pool, pool member, or node on an ongoing basis, at a set
interval. If a pool member or node being checked does not respond within
a specified timeout period, or the status of a pool member or node
indicates that performance is degraded, the BIG-IP system can redirect
the traffic to another pool member or node.

Some monitors are included as part of the BIG-IP system, while other
monitors are user-created. Monitors that the BIG-IP system provides are
called pre-configured monitors. User-created monitors are called custom
monitors.

Before configuring and using monitors, it is helpful to understand some
basic concepts regarding monitor types, monitor settings, and monitor
implementation.

Monitor types

Every monitor, whether pre-configured or custom, is a certain type of
monitor. Each type of monitor checks the status of a particular
protocol, service, or application. For example, one type of monitor is
HTTP. An HTTP type of monitor allows you to monitor the availability of
the HTTP service on a pool, pool member, or node. A WMI type of monitor
allows you to monitor the performance of a pool, pool member, or node
that is running the Windows Management Instrumentation (WMI) software.
An ICMP type of monitor simply determines whether the status of a node
is up or down.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{About address check monitors}

An address check monitor provides a simple verification of an address on
a network. This type of monitor sends a request to a virtual server.
When a response is received, the test is successful.

When an address check monitor is associated with a node, it determines
the availability of all services associated with that node’s IP address.
If the monitor is unsuccessful in determining that a node is available,
the monitor marks the node and all pool members at that IP address as
Offline.

The following illustration depicts a Local Traffic Manager™ using a TCP
Echo monitor to verify an IP address for a virtual server.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p42}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{About application check monitors}

An application check monitor interacts with servers by sending multiple
commands and processing multiple responses.

An FTP monitor, for example, connects to a server, logs in by using a
user ID and password, navigates to a specific directory, and then
downloads a specific file to the /var/tmp directory. If the file is
retrieved, the check is successful.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p52}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Local Traffic Manager opens a TCP connection to an IP address and port, and logs in to the server.

\item {} 
A specified directory is located and a specific file is requested.

\item {} 
The server sends the file to Local Traffic Manager.

\item {} 
Local Traffic Manager receives the file and closes the TCP connection.

\end{enumerate}

\sphinxstylestrong{About content check monitors}

A content check monitor determines whether a service is available and
whether the server is serving the appropriate content. This type of
monitor opens a connection to an IP address and port, and then issues a
command to the server. The response is compared to the monitors receive
rule. When a portion of the server’s response matches the receive rule,
the test is successful.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p62}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Local Traffic Manager opens a TCP connection to an IP address and
port, and issues a command to the server.

\item {} 
The server sends a response.

\item {} 
Local Traffic Manager compares the response to the monitors receive
rule and closes the connection

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/2.html}

\sphinxstylestrong{Creating a custom HTTP monitor}

Before creating a monitor, you must decide on a monitor type.

A custom HTTP monitor enables you to send a command to a server and
examine that server’s response, thus ensuring that it is serving
appropriate content.

Note: An HTTP monitor can monitor Outlook® Web Access (OWA) in
Microsoft® Exchange Server 2007 and Microsoft® SharePoint® 2007 web
sites that require NT LAN Manager (NTLM) authentication. NTLM
authentication requires a send string that complies with HTTP/1.1, a
user name, and a password.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Monitors. The Monitor List
screen opens.

\item {} 
Type a name for the monitor in the Name field.

\item {} 
From the Type list, select HTTP.

\end{enumerate}

The screen refreshes, and displays the configuration options for the HTTP monitor type.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
From the Import Settings list, select http.

\end{enumerate}

The new monitor inherits initial configuration values from the existing monitor.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
In the Configuration area of the screen, select Advanced.

\end{enumerate}

This selection makes it possible for you to modify additional
default settings.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
Type a number in the Interval field that indicates, in seconds, how
frequently the system issues the monitor check. The default is 5
seconds.

\item {} 
From the Up Interval list, do one of the following:
\begin{itemize}
\item {} 
Accept the default, Disabled, if you do not want to use the up interval.

\item {} 
Select Enabled, and specify how often you want the system to verify the health of a resource that is up.

\end{itemize}

\item {} 
Type a number in the Time Until Up field that indicates the number of
seconds to wait after a resource first responds correctly to the
monitor before setting the resource to up.

\end{enumerate}

The default value is 0 (zero), which disables this option.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{8}
\item {} 
Type a number in the Timeout field that indicates, in seconds, how
much time the target has to respond to the monitor check. The default
is 30 seconds.

\end{enumerate}

If the target responds within the allotted time period, it is
considered up. If the target does not respond within the time
period, it is considered down.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
Specify whether the system automatically enables the monitored resource, when the monitor check is successful, for Manual Resume.

\end{enumerate}

This setting applies only when the monitored resource has failed to respond to a monitor check.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Yes
&
The system does nothing when the monitor check succeeds, and you must manually enable the monitored resource.
\\
\hline
No
&
The system automatically re-enables the monitored resource after the next successful monitor check.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{10}
\item {} 
Type a text string in the Send String field that the monitor sends to the target resource. The default string is GET /\textbackslash{}r\textbackslash{}n. This string retrieves a default file from the web site.

\end{enumerate}

\sphinxstyleemphasis{Important}: Send string syntax depends upon the HTTP version.
Please observe the following conventions.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Version
&\sphinxstyletheadfamily 
Convention
\\
\hline
HTTP 0.9
&
“GET /\textbackslash{}n” or “GET /\textbackslash{}r\textbackslash{}n”.
\\
\hline
HTTP 1.0
&
“GET / HTTP/1.0\textbackslash{}r\textbackslash{}n\textbackslash{}r\textbackslash{}n” or “GET /HTTP/1.0\textbackslash{}n\textbackslash{}n”
\\
\hline
HTTP 1.1
&
“GET / HTTP/1.1\textbackslash{}r\textbackslash{}nHost: server.com\textbackslash{}r\textbackslash{}n\textbackslash{}r\textbackslash{}n” or “GET /HTTP/1.1\textbackslash{}r\textbackslash{}nHost: server.com\textbackslash{}r\textbackslash{}nConnection: close\textbackslash{}r\textbackslash{}n\textbackslash{}r\textbackslash{}n”
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Type a fully qualified path name, for example, “GET
/www/example/index.html\textbackslash{}r\textbackslash{}n”, if you want to retrieve a specific
web site page.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{11}
\item {} 
Type a regular expression in the Receive String field that represents the text string that the monitor looks for in the returned resource.

\end{enumerate}

The most common receive expressions contain a text string that is
included in an HTML file on your site. The text string can be
regular text, HTML tags, or image names.

Note: If you do not specify both a send string and a receive string,
the monitor performs a simple service check and connect only.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{12}
\item {} 
Type a regular expression in the Receive Disable String field that represents the text string that the monitor looks for in the returned resource.

\end{enumerate}

Use a Receive String value together with a Receive Disable String
value to match the value of a response from the origin web server
and create one of three states for a pool member or node: Up
(Enabled), when only Receive String matches the response; Up
(Disabled), when only Receive Disable String matches the response;
or Down, when neither Receive String nor Receive Disable String
matches the response.

Note: If you choose to set the Reverse setting to Yes, the Receive
Disable String option becomes unavailable and the monitor marks the
pool, pool member, or node Down when the test is successful.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{13}
\item {} 
Type a name in the User Name field.

\item {} 
Type a password in the Password field.

\item {} 
For the Reverse setting, do one of the following:
\begin{itemize}
\item {} 
Accept the No default option.

\item {} 
Select the Yes option to make the Receive Disable String option unavailable and mark the pool, pool member, or node Down when the test is successful.

\end{itemize}

\item {} 
For the Transparent setting, do one of the following:
\begin{itemize}
\item {} 
Accept the No default option.

\item {} 
Select the Yes option to use a path through the associated pool members or nodes to monitor the aliased destination.

\end{itemize}

\end{enumerate}

The HTTP monitor is configured to monitor HTTP traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.08 - Given a desired outcome, determine where to apply health monitors}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0.pdf}

\sphinxstylestrong{Applying Health Monitors}

You must associate a monitor with the server or servers to be monitored.
The server or servers can either be a pool, a pool member, or a node,
depending on the monitor type.

You can associate a monitor with a server in any of these ways:

Monitor-to-pool association

This type of association associates a monitor with an entire load
balancing pool. In this case, the monitor checks all members of the
pool. For example, you can create an instance of the monitor http for
every member of the pool my\_pool, thus ensuring that all members of
that pool are checked.

Monitor-to-pool member association

This type of association associates a monitor with an individual pool
member, that is, an IP address and service. In this case, the monitor
checks only that pool member and not any other members of the pool. For
example, you can create an instance of the monitor http for pool member
10.10.10.10:80 of my\_pool.

Monitor-to-node association

This type of association associates a monitor with a specific node. In
this case, the monitor checks only the node itself, and not any services
running on that node. For example, you can create an instance of the
monitor ICMP for node 10.10.10.10. In this case, the monitor checks the
specific node only, and not any services running on that node.

You can designate a monitor as the default monitor that you want Local
Traffic Manager to associate with one or more nodes. In this case, any
node to which you have not specifically assigned a monitor inherits the
default monitor.

Some monitor types are designed for association with nodes only, and not
pools or pool members. Other monitor types are intended for association
with pools and pool members only, and not nodes.

Node-only monitors specify a destination address in the format of an IP
address with no service port (for example, 10.10.10.2). Conversely,
monitors that you can associate with nodes, pools, and pool members
specify a destination address in the format of an IP address and service
port (for example, 10.10.10.2:80). Therefore, when you use the
Configuration utility to associate a monitor with a pool, pool member,
or node, the utility displays only those pre-configured monitors that
are designed for association with that server.

For example, you cannot associate the monitor ICMP with a pool or its
members, since the ICMP monitor is designed to check the status of a
node itself and not any service running on that node.

Monitor instances

When you associate a monitor with a server, Local Traffic Manager
automatically creates an instance of that monitor for that server. A
monitor association thus creates an instance of a monitor for each
server that you specify. This means that you can have multiple instances
of the same monitor running on your servers.

Because instances of monitors are not partitioned objects, a user can
enable or disable an instance of a monitor without having permission to
manage the associated pool or pool member.

For example, a user with the Manager role, who can access partition AppA
only, can enable or disable monitor instances for a pool that resides in
partition Common. However, that user cannot perform operations on the
pool or pool members that are associated with the monitor. Although this
is correct functionality, the user might not expect this behavior. You
can prevent this unexpected behavior by ensuring that all pools and pool
members associated with monitor instances reside in the same partition.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.08 - Determine under which circumstances an external monitor is required}

\sphinxurl{https://devcentral.f5.com/articles/ltm-external-monitors-the-basics}

\sphinxstylestrong{External Monitor}

LTM’s external monitors are incredibly flexible, fairly easy to
implement, and especially useful for monitoring applications for which
there is no built-in monitor template. They give you the ability to
effectively monitor the health of just about any application by writing
custom scripts to interact with your servers in the same way users
would.

An “External Monitor” is a script that is “external” to the
configuration file which contains specific logic designed to interact
with your servers to verify the health of load balanced services. LTM
runs a unique instance of the custom-crafted script against each pool
member to which it is applied, passing commandline arguments and
environment variables as specified in the monitor definition calling the
script. The script logic formulates and submits a request (or requests)
to the target pool member, evaluates the response(s), and manages the
pool member’s availability based on the results of the response
evaluation.

Do you really need an external monitor?

Never use an external monitor when a built-in one will work as well.
Forking a shell and running even the simplest shell script takes a
significant amount of system resources, so external monitors should be
avoided whenever possible. If possible, have the server administrator
script execution of the required transaction on the server itself (or
locate/author an alternative script on the server) that reliably
reflects its availability. Then, instead of an external monitor, you can
define a built-in monitor that requests that dynamic script from the
server, and let the server run the script locally and report results.
For example, the simple request/response HTTP transaction in the sample
script below would be much better implemented using the built-in basic
HTTP monitor.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.09 - Given a set of parameters, predict an outcome of a monitor status on other LTM device objects}
\label{\detokenize{class5/modules/module1:objective-1-09-given-a-set-of-parameters-predict-an-outcome-of-a-monitor-status-on-other-ltm-device-objects}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.09 - Determine the effect of a monitor on the virtual server status}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Effect of Monitoring}

Health monitoring with a BIG-IP allows you to monitor resources at many
different levels. Monitors are assigned to resources in two areas of the
configuration, at the node level and at the pool level. At the node
level, you can assign monitors to all nodes (Default Monitor) or to each
node (Node Specific). At the pool level, you can assign monitors to all
pool members (Default Pool Monitor) or to each member (Member Specific).

If a monitor at the node level marks the node down, then pool member
that uses the node IP address as its member IP address will
automatically be marked down. This function works as a parent-child
relationship between the node and the pool member. These monitors are
typically network level monitors (ping, TCP half open)

When a pool member that is being monitored by a health monitor does not
respond to a probe from the BIG-IP system within a specified timeout
period, the system marks the pool member down and no longer load
balances traffic to that pool member. If all of the pool members are
marked off line and no pool members are available to service the request
then the pool is marked down and thus the virtual server is marked down.
The status of a virtual server works as a parent-child relationship
between the pool and the virtual server.

When the failing health monitor starts to succeed again and at least one
pool member is able to respond, then pool will be marked available and
thus the virtual server will also become available.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.09 - Determine the effect of active versus inline monitors on the
application status or on the LTM device}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Active Monitoring}

Active monitoring checks the status of a pool member or node on an
ongoing basis as specified. If a pool member or node does not respond
within a specified timeout period, or the status of a node indicates
that performance is degraded, the BIG-IP system can redirect the traffic
to another pool member or node. There are many active monitors. Each
active monitor checks the status of a particular protocol, service, or
application. For example, one active monitor is HTTP. An HTTP monitor
allows you to monitor the availability of the HTTP service on a pool,
pool member, or node. A WMI monitor allows you to monitor the
performance of a node that is running the Windows Management
Instrumentation (WMI) software. Active monitors fall into two
categories: Extended Content Verification (ECV) monitors for content
checks, and Extended Application Verification (EAV) monitors for service
checks, path checks, and application checks.

An active monitor can check for specific responses, and run with or
without client traffic.

Note: An active monitor also creates additional network traffic
beyond the client request and server response and can be slow to
mark a pool member as down.

\sphinxstylestrong{Passive monitoring}

Passive monitoring occurs as part of a client request. This kind of
monitoring checks the health of a pool member based on a specified
number of connection attempts or data request attempts that occur within
a specified time period. If, after the specified number of attempts
within the defined interval, the system cannot connect to the server or
receive a response, or if the system receives a bad response, the system
marks the pool member as down. There is only one passive monitor, called
an Inband monitor.

A passive monitor creates no additional network traffic beyond the
client request and server response. It can mark a pool member as down
quickly, as long as there is some amount of network traffic.

Note: A passive monitor cannot check for specific responses and can
potentially be slow to mark a pool member as up.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.10 - Given a health monitor configuration and pool member response predict the resulting status of the pool member}
\label{\detokenize{class5/modules/module1:objective-1-10-given-a-health-monitor-configuration-and-pool-member-response-predict-the-resulting-status-of-the-pool-member}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.10 - (Supplemental Example) Given a health monitor configuration and pool member response predict the resulting status of the pool member}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Monitoring results}

Active monitoring checks the status of a pool member or node on an
ongoing basis as specified. If a pool member or node does not respond
within a specified timeout period, or the status of a node indicates
that performance is degraded, the BIG-IP system can redirect the traffic
to another pool member or node. There are many active monitors. Each
active monitor checks the status of a particular protocol, service, or
application.

For example, we may simply be using an HTTP monitor to monitor the pool
members, in which we send a GET request to the server for a URI path,
and then examine the response to see if it contains the correct RECV
string:

If the expected response contained the value of the RECV string, the
pool member will be marked up immediately. If the expected response did
NOT contain the value of the RECV string, the pool member will be marked
down when the timeout expires.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.10 - Given a set of parameters, predict an outcome of a monitor status on other LTM objects}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Monitors affecting other LTM Objects}

Health monitoring with a BIG-IP allows you to monitor resources at many
different levels. Monitors are assigned to resources in two areas of the
configuration, at the node level and at the pool level. At the node
level, you can assign monitors to all nodes (Default Monitor) or to each
node (Node Specific). At the pool level, you can assign monitors to all
pool members (Default Pool Monitor) or to each member (Member Specific).

If a monitor at the node level marks the node down, then pool member
that uses the node IP address as its member IP address will
automatically be marked down. This function works as a parent-child
relationship between the node and the pool member. These monitors are
typically network level monitors (ping, TCP half open)

When a pool member that is being monitored by a health monitor does not
respond to a probe from the BIG-IP system within a specified timeout
period, the system marks the pool member down and no longer load
balances traffic to that pool member. If all of the pool members are
marked off line and no pool members are available to service the request
then the pool is marked down and thus the virtual server is marked down.
The status of a virtual server works as a parent-child relationship
between the pool and the virtual server.

When the failing health monitor starts to succeed again and at least one
pool member is able to respond, then pool will be marked available and
thus the virtual server will also become available.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.10 - Determine the effect of a monitor on the status of a node, pool member, pool, and/or virtual server}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Monitors affecting other LTM Objects}

Health monitoring with a BIG-IP allows you to monitor resources at many
different levels. Monitors are assigned to resources in two areas of the
configuration, at the node level and at the pool level. At the node
level, you can assign monitors to all nodes (Default Monitor) or to each
node (Node Specific). At the pool level, you can assign monitors to all
pool members (Default Pool Monitor) or to each member (Member Specific).

If a monitor at the node level marks the node down, then pool member
that uses the node IP address as its member IP address will
automatically be marked down. This function works as a parent-child
relationship between the node and the pool member. These monitors are
typically network level monitors (ping, TCP half open)

When a pool member that is being monitored by a health monitor does not
respond to a probe from the BIG-IP system within a specified timeout
period, the system marks the pool member down and no longer load
balances traffic to that pool member. If all of the pool members are
marked off line and no pool members are available to service the request
then the pool is marked down and thus the virtual server is marked down.
The status of a virtual server works as a parent-child relationship
between the pool and the virtual server.

When the failing health monitor starts to succeed again and at least one
pool member is able to respond, then pool will be marked available and
thus the virtual server will also become available.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.10 - (Supplemental Example) Describe the functionality of Action On Service Down}

\sphinxurl{https://support.f5.com/csp/article/K15095}

\sphinxstylestrong{Action On Service Down}

The Action On Service Down feature allows the BIG-IP system to choose
another pool member and rebind the client connection to a new server
connection if the target pool member becomes unavailable.

When a pool member fails to respond, as configured, to a health monitor,
the system marks that pool member down, and continues to monitor it to
determine when the member becomes available again. While a pool member
is marked down, the system does not send any new connections to that
pool member.

The Action On Service Down feature specifies how the system should
respond to already-established connections when the target pool member
becomes unavailable.

The available settings for this feature as follows:

\sphinxstylestrong{None:}

The BIG-IP system takes no action on existing connections and removes
the connection table entry based on the associated profile’s idle
timeout value. The BIG-IP system sends a TCP Reset (RST) or ICMP
Unreachable once idle timeout is reached. This is the default setting.

This is the best option for most common scenarios, as this allows for
endpoints to resume gracefully on their own. This may be a good choice
for clients that transfer large amounts of data, as the pool member may
recover itself before the connection is reset, allowing the large
transfer to continue.

\sphinxstylestrong{Reject:}

The BIG-IP system sends RST or ICMP messages to reset active connections
and removes them from the BIG-IP connection table.

This may be a good choice for clients that need to be notified of pool
member state changes sooner than the configured idle timeout period for
that virtual server. Once the target pool member is deemed unavailable,
the BIG-IP system immediately alerts the client by resetting the
connection, causing the client to attempt a new connection.

\sphinxstylestrong{Drop:}

The BIG-IP system silently removes the connection table entry.

You should carefully consider this option, as the client receives no
feedback from the BIG-IP system regarding the connection state. However,
this option works well for short-lived, connectionless protocols, such
as UDP. For example, DNS queries.

\sphinxstylestrong{Reselect:}

The BIG-IP system manages established client connections by moving them
to an alternate pool member without a connection teardown or setup.

This option is only appropriate for:
\begin{itemize}
\item {} 
Virtual servers with address and port translation disabled

\end{itemize}

Note: This is default for FastL4 type virtual servers, such as
network or wildcard forwarding.
\begin{itemize}
\item {} 
Transparent pool members, such as firewalls, routers, proxy servers,
and cache servers

\end{itemize}

Note: Transparent devices can forward packets to destinations
without regard for the state of the connection.
\begin{itemize}
\item {} 
UDP virtual servers

\end{itemize}

Note: When choosing the Reselect option for Action on Service Down,
the BIG-IP system does not reform existing TCP connections, but
continues to forward existing connections. If the back-end pool
members are not transparent devices, and the virtual server has
address translation enabled, all existing TCP connections sent to a
pool member will likely reset due to the pool member having no
record of these ongoing connections in its connection table. This is
analogous to choosing the Reset action, except the pool members will
be resetting the connections instead of the BIG-IP system. F5 highly
recommends choosing a different Action on Service Down option, if
you do not meet the above criteria for the Reselect option.

Note: Services, such as HTTP require that the system establish a
transport layer connection before transmitting HTTP messages. This
is commonly referred to as a 3-way handshake and is used by the
client or server to establish communication options and to track
requests or responses. When a server receives a request from a
client without having established the transport layer connection,
normal behavior is for the server to reject the connection by
sending a TCP response with the RST flag set. For more information,
refer to Internet Engineering Task Force (RFC 793), section Reset
Generation. This link takes you to a resource outside of AskF5. The
third party could remove the document without our knowledge.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.11 - Given a set of SSL requirements, determine the appropriate profile options}
\label{\detokenize{class5/modules/module1:objective-1-11-given-a-set-of-ssl-requirements-determine-the-appropriate-profile-options}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.11 - (Supplemental Example) Given a set of SSL requirements, determine the appropriate profile options}

\sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/4.html\#unique\_1136687395}{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/4.html - unique\_1136687395}

OpenSSL supports a set of SSL options and defect workarounds. You can
enable these workarounds and options as settings of an individual
client-side or server-side SSL profile. The default value for the
Options setting is Options List. Retaining the default value enables one
option, which is Don’t insert empty fragments. You can then enable other
options that appear in the Available Options list.

Important: For security reasons, when you enable the Proxy SSL
setting, the BIG-IP system automatically disables the Don’t insert empty
fragments option. Disabling this option when Proxy SSL is enabled guards
against a particular type of cryptographic attack.

Note that when configuring protocol versions, you must ensure that the
protocol versions configured for the BIG-IP system match those of the
system’s peer. That is, protocol versions specified in the client-side
SSL profile must match those of the client, and protocol versions
specified in the server-side SSL profile must match those of the server.
Thus, for both client-side and server-side SSL connections, you can
specify the protocol versions that you do not want the BIG-IP system to
allow.

You can declare up to two of the three protocol versions to be invalid:
SSLv2 , SSLv3, and TLSv1. If no protocol versions are specified, Local
Traffic Manager allows all SSL protocol versions.

Note: F5 recommends that, at a minimum, you specify protocol
version SSLv2 as invalid.

\sphinxstylestrong{Workarounds and other SSL options}

This table lists and describes the possible workarounds and options that
you can configure for an SSL profile.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{SSL Attribute}
&
\sphinxstylestrong{Description}
\\
\hline
Cipher server preference
&
When the BIG-IP system chooses a cipher, this option uses the server’s preferences instead of the client preferences. When this option is not set, the SSL server always follows the client’s preferences. When this option is set, the SSLv3/TLSv1 server chooses by using its own preferences. Due to the different protocol, for SSLv2 the server sends its list of preferences to the client, and the client always chooses the cipher.
\\
\hline
Don’t insert empty fragments
&
This option disables a countermeasure against a SSL 3.0/TLS 1.0 protocol vulnerability affecting CBC ciphers. These ciphers cannot be handled by certain broken SSL implementations. This option has no effect for connections using other ciphers. This is the default value for the Options list.

Note: For security reasons, this option is not available when you enable the Proxy SSL setting.
\\
\hline
Ephemeral RSA
&
This option uses ephemeral (temporary) RSA keys when doing RSA operations. According to the specifications, this is only done when an RSA key can only be used for signature operations (namely under export ciphers with restricted RSA key length). By setting this option, Local Traffic Manager always uses ephemeral RSA keys. This option breaks compatibility with the SSL/TLS specifications and can lead to interoperability problems with clients, and we therefore do not recommend it. You should use ciphers with EDH (ephemeral Diffie-Hellman) key exchange instead. This option is ignored for server-side SSL.
\\
\hline
Microsoft session ID bug
&
This option handles a Microsoft session ID problem.
\\
\hline
Netscape CA DN bug workaround
&
This option handles a defect regarding system instability. If the system accepts a Netscape® browser connection, demands a client cert, has a non-self-signed CA that does not have its CA in Netscape, and the browser has a certificate, then the system crashes or hangs.
\\
\hline
Netscape challenge bug
&
This option handles the Netscape challenge problem.
\\
\hline
Netscape demo cipher change bug workaround
&
This option deliberately manipulates the SSL server session resumption behavior to mimic that of certain Netscape servers (see the Netscape reuse cipher change bug workaround description). We do not recommend this option for normal use and it is ignored for server-side SSL processing.
\\
\hline
Netscape reuse cipher change bug workaround
&
This option handles a defect within Netscape-Enterprise/2.01, only appearing when connecting through SSLv2/v3 then reconnecting through SSLv3. In this case, the cipher list changes. First, a connection is established with the RC4-MD5 cipher list. If it is then resumed, the connection switches to using the DES-CBC3-SHA cipher list. However, according to RFC 2246, (section 7.4.1.3, cipher\_suite) the cipher list should remain RC4-MD5. As a workaround, you can attempt to connect with a cipher list of DES-CBC-SHA:RC4-MD5 and so on. For some reason, each new connection uses the RC4-MD5 cipher list, but any re-connect ion attempts to use the DES-CBC-SHA cipher list. Thus Netscape, when reconnecting, always uses the first cipher in the cipher list.
\\
\hline
No SSLv2
&
Do not use the SSLv2 protocol.
\\
\hline
No SSLv3
&
Do not use the SSLv3 protocol.
\\
\hline
No session resumption on renegotiation
&
When Local Traffic Manager performs renegotiation as an SSL server, this option always starts a new session (that is, session resumption requests are only accepted in the initial handshake). The system ignores this option for server-side SSL processing.
\\
\hline
N0 TLSv1
&
Do not use the TLSv1 protocol.
\\
\hline
Microsoft big SSLV3 buffer
&
This option enables a workaround for communicating with older Microsoft® applications that use non-standard SSL record sizes.
\\
\hline
Microsoft IE SSLV2 RSA padding
&
This option enables a workaround for communicating with older Microsoft® applications that use non-standard RSA key padding. This option is ignored for server-side SSL.
\\
\hline
Passive close
&
Specifies that the SSL filter helps prevent packets from getting into the TCP half-closed state by waiting for a connection shutdown from the server. This is a workaround for HTTP/1.0 and HTTP/0.9 clients that send an HTTP request followed by a FIN, which immediately closes the connection for server-SSL-only proxies. Instead of closing immediately, the proxy waits for the server to close.
\\
\hline
PKCS1 check 1
&
This debugging option deliberately manipulates the PKCS1 padding used by SSL clients in an attempt to detect vulnerability to particular SSL server vulnerabilities. We do not recommend this option for normal use. The system ignores this option for client-side SSL processing.
\\
\hline
PKCS1 check 2
&
This debugging option deliberately manipulates the PKCS1 padding used by SSL clients in an attempt to detect vulnerability to particular SSL server vulnerabilities. We do not recommend this option for normal use. The system ignores this option for client-side SSL processing.
\\
\hline
Single DH use
&
This option creates a new key when using temporary/ephemeral DH parameters. You must use this option if you want to prevent small subgroup attacks, when the DH parameters were not generated using strong primes (for example, when using DSA-parameters). If strong primes were used, it is not strictly necessary to generate a new DH key during each handshake, but we do recommend this. You should enable the Single DH use option whenever temporary/ephemeral DH parameters are used.
\\
\hline
SSLEAY 080 client DH bug workaround
&
This option enables a workaround for communicating with older SSLeay-based applications that specify an incorrect Diffie-Hellman public value length. This option is ignored for server-side SSL.
\\
\hline
SSL Ref2 reuse cert type bug
&
This option handles the SSL re-use certificate type problem.
\\
\hline
TLS D5 bug workaround
&
This option is a workaround for communicating with older TLSv1-enabled applications that specify an incorrect encrypted RSA key length. This option is ignored for server-side SSL.
\\
\hline
TLS block padding bug workaround
&
This option enables a workaround for communicating with older TLSv1-enabled applications that use incorrect block padding.
\\
\hline
TLS rollback bug workaround
&
This option disables version rollback attack detection. During the client key exchange, the client must send the same information about acceptable SSL/TLS protocol levels as it sends during the first hello. Some clients violate this rule by adapting to the server’s answer. For example, the client sends an SSLv2 hello and accepts up to SSLv3.1 (TLSv1), but the server only understands up to SSLv3. In this case, the client must still use the same SSLv3.1 (TLSv1) announcement. Some clients step down to SSLv3 with respect to the server’s answer and violate the version rollback protection. This option is ignored for server-side SSL.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.11 - Describe the difference between client and server SSL profiles and functionality}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/3.html}

\sphinxstylestrong{Differences between Client and Server SSL Profiles}

With LTM, you can enable SSL traffic management for either client-side
traffic or server-side traffic.

Client-side traffic refers to connections between a client system and
the BIG-IP system. Server-side traffic refers to connections between the
BIG-IP system and a target server system:

\sphinxstylestrong{Client-side SSL traffic}

When you enable the BIG-IP system to manage client-side SSL traffic, LTM
terminates incoming SSL connections by decrypting the client request.
LTM then sends the request, in clear text, to a target server. Next, LTM
retrieves a clear-text response (such as a web page) and encrypts the
request, before sending the web page back to the client. During the
process of terminating an SSL connection, LTM can, as an option, perform
all of the SSL certificate verification functions normally handled by
the target web server.

You create a custom Client SSL profile when you want the BIG-IP system
to terminate client-side SSL traffic for the purpose of decrypting
client-side ingress traffic and encrypting client-side egress traffic.
By terminating client-side SSL traffic, the BIG-IP system offloads these
decryption/encryption functions from the destination server. When you
perform this task, you can specify multiple certificate key chains, one
for each key type (RSA, DSA, and ECDSA). This allows the BIG-IP system
to negotiate secure client connections using different cipher suites
based on the client’s preference.

\sphinxstylestrong{Server-side SSL traffic}

When you enable LTM to manage server-side SSL traffic, LTM enhances the
security of your network by re-encrypting a decrypted request before
sending it on to a target server. In addition to this re-encryption, LTM
can, as an option, perform the same verification functions for server
certificates that LTM can for client certificates.

For those sites that require enhanced security on their internal
network, you can configure a Server SSL profile. With a Server SSL
profile, the BIG-IP system re-encrypts the request before sending it to
the destination server. When the server returns an encrypted response,
the BIG-IP system decrypts and then re-encrypts the response, before
sending the response back to the client.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.11 - (Supplemental Example) Describe the difference between client and server SSL processing}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/3.html}

\sphinxstylestrong{Differences}

When you want the BIG-IP system to process application traffic over SSL,
you can configure the system to perform the SSL handshake that
destination servers normally perform. This ability for the BIG-IP system
to offload SSL processing from a destination server is an important
feature of the BIG-IP system.

The most common way to configure the BIG-IP system is to create a Client
SSL profile, which makes it possible for the BIG-IP system to decrypt
client requests before sending them on to a server, and encrypt server
responses before sending them back to the client.

Within a Client SSL profile specifically, you can specify multiple
certificate/key pairs, one per key type. This enables the system to
accept all types of cipher suites that a client might support as part of
creating a secure connection. The system then decrypts the client data,
manipulates any headers or payload according to the way that you
configured the Client SSL profile, and by default, sends the request in
clear text to the target server for processing.

For those sites that require enhanced security on their internal
network, you can configure a Server SSL profile. With a Server SSL
profile, the BIG-IP system re-encrypts the request before sending it to
the destination server. When the server returns an encrypted response,
the BIG-IP system decrypts and then re-encrypts the response, before
sending the response back to the client.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.11 - Explain how to configure the different SSL profile settings}

\sphinxurl{https://support.f5.com/csp/article/K14783}

\sphinxstylestrong{Client SSL Profiles}

The BIG-IP Client SSL profile enables the BIG-IP system to accept and
terminate client requests that are sent using a fully SSL-encapsulated
protocol. It also provides a number of configurable settings for
managing client-side SSL connections. Typically, you need to set only
some of the available settings and keep the remaining settings at their
default values unless otherwise advised by F5 Technical Support. The
following tables list and describe the BIG-IP Client SSL profile
settings.

Note: This list has been cleaned up for 11.5 settings only.

General Properties


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Name
&
The**Name** setting is required. To create a Client SSL profile, you must specify a unique name for the profile.
\\
\hline
Parent Profile
&
This setting specifies an existing profile to use as the parent profile. A profile inherits settings from its parent, unless you override the setting by selecting its \sphinxstylestrong{Custom}box and modifying the value. The default is \sphinxstylestrong{clientssl} profile.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Configuration

This section describes the most commonly used SSL settings for a Client
SSL profile, including, for example, the certificate and key to send to
SSL clients for certificate exchange.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Mode
&
Sets the profile state to \sphinxstylestrong{Enabled} (default) or \sphinxstylestrong{Disabled} (by clearing the check box). The \sphinxstylestrong{Mode} setting is introduced in BIG-IP 11.5.0.
\\
\hline
Certificate
&
The \sphinxstylestrong{Certificate}setting (\sphinxstylestrong{Certificate Key Chain} in BIG-IP 11.5.0 and later) is required. By default, the Client SSL profile uses a self-signed certificate, named \sphinxstylestrong{default.crt}. However, this box is almost always customized to reference a certificate that is specific to the site to which the profile is applied. The SSL certificate must be in Privacy Enhanced Mail (PEM) format and you must import it to the BIG-IP system with the corresponding key before the certificate and key can be referenced by an SSL profile. For information about importing an SSL certificate and key using the Configuration utility, refer to \sphinxhref{https://support.f5.com/csp/article/K14620}{K14620: Managing SSL certificates for BIG-IP systems using the Configuration utility}. For information about importing an SSL certificate and key using the TMOS Shell (\sphinxstylestrong{tmsh}), refer to \sphinxhref{https://support.f5.com/csp/article/K14031}{K14031: Importing the SSL certificate and key using the Traffic Management Shell}.

For information about verifying the certificate format, refer to \sphinxhref{https://support.f5.com/csp/article/K13349}{K13349: Verifying SSL certificate and key pairs from the command line (11.x - 13.x)}

After importing the SSL certificate and matching key to the BIG-IP system, choose the appropriate certificate from the \sphinxstylestrong{Certificate}setting.
\\
\hline
Key
&
The \sphinxstylestrong{Key}setting is required. By default, the Client SSL profile uses the built-in key, named \sphinxstylestrong{default.key}, which matches \sphinxstylestrong{default.crt}. You must choose the key that matches the configured certificate and the key must be in PEM format. After importing the SSL certificate and matching key to the BIG-IP system, choose the appropriate key from the \sphinxstylestrong{Key}setting.
\\
\hline
Passphrase
&
The \sphinxstylestrong{Passphrase}setting is optional. It is only required if the key is passphrase-protected. There is no default value for this setting. If your key is passphrase-protected, enter the required passphrase.
\\
\hline
Chain
&
The \sphinxstylestrong{Chain}setting is optional. You use this setting to specify a certificate bundle or chain the client can use to establish a trust relationship with a server that presents a certificate signed by an untrusted Certificate Authority (CA). The default value for the \sphinxstylestrong{Chain}setting is \sphinxstylestrong{None}, indicating that no chain certificate is presented to the client with the server SSL certificate. This setting lists the name of all the SSL certificates installed in the BIG-IP system’s SSL certificate store. If you are using certificates signed by an Intermediate CA, F5 recommends that you create and install a bundle that contains the certificates for all of the CAs in the chain between the certificate configured in the SSL profile and a root CA whose certificate is trusted by the expected client base. You can then select the new certificate bundle in the \sphinxstylestrong{Chain}setting. For information about creating and installing a custom certificate bundle, refer to \sphinxhref{https://support.f5.com/csp/article/K13302}{K13302: Configuring the BIG-IP system to use an SSL chain certificate }\sphinxhref{https://support.f5.com/csp/article/K13302}{(11.x - 13.x)}.

\sphinxstylestrong{Note}: Regardless of the \sphinxstylestrong{Chain}setting, if you configure the \sphinxstylestrong{Trusted Certificate Authorities} setting, the system presents the certificate bundle contained in the configured \sphinxstylestrong{Trusted Certificate Authorities} file.
\\
\hline
Ciphers
&
The \sphinxstylestrong{Ciphers}setting is optional. By default, the Client SSL profile uses the \sphinxstylestrong{DEFAULT} cipher string. In most cases, the \sphinxstylestrong{DEFAULT} cipher string is appropriate, but you can customize it as necessary to meet the security and performance needs of your site. For information about configuring the SSL cipher for an SSL profile, refer to \sphinxhref{https://support.f5.com/csp/article/K17370}{K17370: Configuring the cipher strength for SSL profiles (12.x - 13.x)}.
\\
\hline
Options
&
When enabled (\sphinxstylestrong{Options List}), references the \sphinxstylestrong{Options List} setting, which industry standard SSL options and workarounds use for handling SSL processing. The default setting is \sphinxstylestrong{All Options Disabled}.
\\
\hline
Options List
&
The \sphinxstylestrong{Options List} setting provides selection from a set of industry standard SSL options and workarounds for handling SSL processing.
\\
\hline
Proxy SSL
&
The \sphinxstylestrong{Proxy SSL} setting is introduced in BIG-IP 11.0.0. By default, the \sphinxstylestrong{Proxy SSL} setting is disabled (cleared). When enabled, the client can directly authenticate with the server, and the server can authenticate with the client, based on the client certificate presented. In a typical setup, with the BIG-IP system in the middle, the client and server cannot communicate directly to authenticate each other. The \sphinxstylestrong{Proxy SSL}setting requires both a Client SSL profile and a Server SSL profile, and you must enable the setting in both profiles. For information about the \sphinxstylestrong{Proxy SSL} setting, refer to the following resources:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K13385}{K13385: Overview of the Proxy SSL feature}

\item {} 
The \sphinxstylestrong{Implementing Proxy SSL on a Single BIG-IP system} chapter of the \sphinxstylestrong{BIG-IP LTM Implementations} manual.

\end{itemize}

\sphinxstylestrong{Note}: For information about how to locate F5 product manuals, refer to \sphinxhref{https://support.f5.com/csp/article/K12453464}{K12453464: Finding product documentation on AskF5}.
\\
\hline
ModSSL Methods
&
\sphinxstylestrong{ModSSL Methods} enables or disables ModSSL method emulation. Enable this option when OpenSSL methods are inadequate. For example, enable it when you want to use SSL compression over TLSv1. Disabled (cleared) by default.
\\
\hline
Cache Size
&
The \sphinxstylestrong{Cache Size} setting specifies the maximum number of SSL sessions allowed in the SSL session cache. The default value for \sphinxstylestrong{Cache Size} is**262144** sessions. For information about the SSL \sphinxstylestrong{Cache Size} settings, refer to \sphinxhref{https://support.f5.com/csp/article/K6767}{K6767: Overview of the BIG-IP SSL session cache profile settings}.
\\
\hline
Cache Timeout
&
The \sphinxstylestrong{Cache Timeout} setting specifies the number of seconds that the system allows SSL sessions to remain in the SSL session cache before removing them. The default value for \sphinxstylestrong{Cache Timeout} is**3600** seconds. The range of values configurable for \sphinxstylestrong{Cache Timeout} is between \sphinxstylestrong{0} and**86400** seconds inclusive.

\sphinxstylestrong{Note}: Longer cache timeout periods can increase the risk of SSL session hijacking.
\\
\hline
Alert Timeout
&
The \sphinxstylestrong{Alert Timeout} setting specifies the duration that the system tries to close an SSL connection by transmitting an alert or initiating an unclean shutdown before resetting the connection. The default value for BIG-IP 12.0.0 HF1 and later, as well as BIG-IP 12.1.0 and later, is indefinite. The default value for BIG-IP 11.2.0 -12.0.0 is \sphinxstylestrong{10} seconds. The default value for BIG-IP 11.0.0 - 11.1.0 is \sphinxstylestrong{60} seconds. Select \sphinxstylestrong{Indefinite} to specify that the connection should not be reset after transmitting an alert or initiating an unclean shutdown.
\\
\hline
Handshake Timeout
&
The \sphinxstylestrong{Handshake Timeout} setting specifies the number of seconds that the system tries to establish an SSL connection before terminating the operation. The default value for BIG-IP 11.2.0 and later is \sphinxstylestrong{10} seconds. The default value for BIG-IP 11.0.0 - 11.1.0 is \sphinxstylestrong{60} seconds. Selecting \sphinxstylestrong{Indefinite} specifies that the system continues trying to establish a connection for an unlimited time.
\\
\hline
Renegotiation
&
You can configure the \sphinxstylestrong{Renegotiation}setting to control if the virtual server allows midstream session renegotiation. When enabled (default),**Renegotiation**allows the BIG-IP system to process midstream SSL renegotiation requests. When disabled, the system either terminates the connection or ignores the request, depending on system configuration.
\\
\hline
Renegotiation Period
&
The \sphinxstylestrong{Renegotiation Period} setting indicates the amount of time before the system renegotiates the SSL session after the initial connection. If you set it to \sphinxstylestrong{Indefinite} (default), the system does not renegotiate the SSL session.
\\
\hline
Renegotiation Size
&
Indicates the amount of application data in megabytes the system must receive from the time of initial connection before it renegotiates the SSL session. If set to \sphinxstylestrong{Indefinite} (default), the system does not renegotiate the SSL session.
\\
\hline
Renegotiate Max Record Delay
&
Indicates the number of SSL records allowed during the SSL renegotiation before the system terminates the connection. If set to \sphinxstylestrong{Indefinite}, the system allows an unlimited number. \sphinxstylestrong{Indefinite} is the default setting in BIG-IP 11.4.0 and later. In BIG-IP 11.0.0 - 11.3.0, the default setting is \sphinxstylestrong{10}.
\\
\hline
Secure Renegotiation
&
The BIG-IP SSL profiles support the TLS Renegotiation Indication Extension, which allows you to specify the method of secure renegotiation for SSL connections. The default value for the Client SSL profile is \sphinxstylestrong{Require}. The values for the \sphinxstylestrong{Secure Renegotiation} setting in the Client SSL profile are as follows:
\begin{itemize}
\item {} 
\sphinxstylestrong{Request}: Specifies that the system requests secure renegotiation of SSL connections.

\item {} 
\sphinxstylestrong{Require}: Specifies that the system requires secure renegotiation of SSL connections. In this mode, the system permits initial SSL handshakes from clients but terminates renegotiations from clients that do not support secure renegotiation.

\item {} 
\sphinxstylestrong{Require Strict}: Specifies that the system requires strict, secure renegotiation of SSL connections. In this mode, the system denies initial SSL handshakes from clients that do not support secure renegotiation.

\end{itemize}
\\
\hline
Server Name
&
Starting in BIG-IP 11.1.0, the BIG-IP SSL profiles support the TLS Server Named Indication (SNI) extension, which allows the BIG-IP system to select the appropriate SSL profile based on the TLS SNI information provided by the client. The \sphinxstylestrong{Server Name} setting specifies the fully qualified DNS hostname of the server, or a wildcard string containing the asterisk * character to match multiple names, used in the TLS SNI connection. There is no default value for this setting. For information about configuring the TLS SNI feature on the BIG-IP system, refer to \sphinxhref{https://support.f5.com/csp/article/K13452}{K13452: Configuring a virtual server to serve multiple HTTPS sites using TLS Server Name Indication feature}.
\\
\hline
Default SSL Profile for SNI
&
When enabled, this setting indicates that the system should use the profile as the default SSL profile when there is no match to the server name or when the client does not support TLS SNI extension. By default, this setting is disabled (cleared). For information about configuring the TLS SNI feature on the BIG-IP system, refer to \sphinxhref{https://support.f5.com/csp/article/K13452}{K13452: Configuring a virtual server to serve multiple HTTPS sites using TLS Server Name Indication feature}.
\\
\hline
Require Peer SNI Support
&
When enabled, this setting requires that the client support the TLS SNI extension; otherwise, the BIG-IP system disconnects the client connection with a fatal alert. Disabled (cleared) by default.
\\
\hline
Unclean Shutdown
&
The SSL protocol performs a clean shutdown of an active TLS/SSL connection by sending a close notify alert to the peer system. The \sphinxstylestrong{Unclean Shutdown} setting allows the BIG-IP system to perform an unclean shutdown of SSL connections by closing the underlying TCP connection without sending the SSL close notify alerts. By default, this setting is enabled (selected) and is useful for certain browsers that handle SSL shutdown alerts differently. For example, some versions of Internet Explorer require SSL shutdown alerts from the server while other versions do not, and the SSL profile cannot always detect this requirement.

\sphinxstylestrong{Important:} If you disable (clear) the \sphinxstylestrong{Unclean Shutdown} check box, some browsers may display blank pages or errors when connecting to the virtual server.
\\
\hline
Strict Resume
&
The \sphinxstylestrong{Strict Resume} setting enables or disables the resumption of SSL sessions after an unclean shutdown. Disabled (cleared) by default.
\\
\hline
Session Ticket
&
Starting in BIG-IP 11.4.0, the BIG-IP SSL profiles support the stateless TLS session resumption mechanism as described in \sphinxhref{http://www.ietf.org/rfc/rfc5077.txt}{Internet Engineering Task Force (RFC 5077)}. This mechanism allows the BIG-IP system to encapsulate the TLS session state as a ticket to the client and allows the client to subsequently resume a TLS session using the same ticket. Disabled (cleared) by default.

\sphinxstylestrong{Note:} This link takes you to a resource outside of AskF5, and it is possible that the document may be removed without our knowledge.

\sphinxstylestrong{Note:} The \sphinxstylestrong{Session Ticket} option is visible in BIG-IP 11.3.0 but is not functional until BIG-IP 11.4.0.
\\
\hline
Session Ticket Timeout
&
Specifies the timeout for the session ticket. The default is \sphinxstylestrong{0} seconds, which means the system uses the cache timeout. The \sphinxstylestrong{Session Ticket Timeout} option is introduced in BIG-IP 12.0.0.
\\
\hline
Generic Alert
&
When enabled (default), this setting causes the system to send all SSL alerts using a generic \sphinxstylestrong{handshake failure} message. When the setting is disabled, the system sends more specific SSL alert messages. The \sphinxstylestrong{Generic Alert} setting is introduced in BIG-IP 11.5.0.
\\
\hline
Non-SSL Connections
&
Enables or disables acceptance of non-SSL connections. Disabled (cleared) by default.
\\
\hline
SSL Sign Hash
&
Specifies the hash algorithm that the BIG-IP system uses to sign server key exchanges with the Diffie-Hellman (DHE), including Elliptic Curve (ECDHE) ciphers, and for certificate verify messages. Possible choices are \sphinxstylestrong{SHA1}, \sphinxstylestrong{SHA256}, \sphinxstylestrong{SHA384Any}. When you select \sphinxstylestrong{Any}, you authorize the system to choose any one of the hash algorithms. In this case, the BIG-IP system chooses \sphinxstylestrong{SHA1} whenever possible. The \sphinxstylestrong{SSL Sign Hash} setting is introduced in BIG-IP 11.5.0.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Client Authentication

The Client Authentication section of the Client SSL profile is specific
to client certificate authentication. Some applications require clients
to establish their identity to the server before proceeding with the SSL
session. Client certificate authentication uses the following sequence
of events:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
The client requests an SSL connection.

\item {} 
The SSL server presents its SSL certificate, and any configured chain
certificate bundle, to the client.

\item {} 
The SSL client uses the CA certificates stored in its Trusted Device
Certificate store, and the supplied certificate chain, if necessary,
to authenticate the server.

\item {} 
The SSL server requests a client certificate, advertising a list of
preferred CAs if configured to do so.

\item {} 
The SSL client presents its SSL certificate.

\item {} 
The SSL server uses its configured, trusted CA certificate bundle, to
authenticate the client.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Client Certificate
&
The \sphinxstylestrong{Client Certificate} setting is required. Enables and disables client certificate authentication. The possible options for the \sphinxstylestrong{Client Certificate} setting are:
\begin{itemize}
\item {} 
\sphinxstylestrong{Ignore}: The \sphinxstylestrong{Ignore}setting is the default setting. It disables Client Certificate Authentication. The BIG-IP system ignores any certificate presented and does not authenticate the client before establishing the SSL session.

\item {} 
\sphinxstylestrong{Request}: The \sphinxstylestrong{Request}setting enables optional Client Certificate Authentication. The BIG-IP system requests a client certificate and attempt to verify it. However, an SSL session is established regardless of whether a trusted CA presents a valid client certificate. The \sphinxstylestrong{Request}setting is often used in conjunction with iRules to provide selective access depending on the certificate presented. For example, this option is useful if you want to allow clients who present a certificate from the configured trusted CA to gain access to the application, while redirecting clients who do not provide the required certificate are to a page that details the access requirements. However, if you are not using iRules to enforce a different outcome, depending on the certificate details, there is no functional benefit to using the \sphinxstylestrong{Request}setting instead of the default \sphinxstylestrong{Ignore}setting. In both cases, the system establishes an SSL session, regardless of the certificate presented, and it proxies the connection to the default pool.

\item {} 
\sphinxstylestrong{Require}: The \sphinxstylestrong{Require}setting enforces Client Certificate Authentication. The BIG-IP system requests a client certificate and attempts to verify it. The system establishes an SSL session only if a trusted CA presents a valid client certificate. Use the \sphinxstylestrong{Require}setting to restrict access to only clients that present a valid certificate from a trusted CA.

\end{itemize}

\sphinxstylestrong{Note}: The \sphinxstylestrong{Auto}setting is removed in BIG-IP 11.0.0.
\\
\hline
Frequency
&
The \sphinxstylestrong{Frequency}setting specifies the frequency of client authentication for an SSL session. The default value for this setting is \sphinxstylestrong{once}.
\\
\hline
Retain Certificate
&
Starting in BIG-IP 11.4.0, you can configure the BIG-IP SSL profile to not store a client certificate in an SSL session. Storing a client certificate in an SSL session is typically required in BIG-IP APM deployments only. When this setting is disabled, the client certificate is not stored in an SSL session. Enabled (selected) by default.
\\
\hline
Certificate Chain Traversal Depth
&
The \sphinxstylestrong{Certificate Chain Traversal Depth} setting specifies the maximum number of certificates to be traversed in a client certificate chain. The default value is \sphinxstylestrong{9}.
\\
\hline
Trusted Certificate Authorities
&
The \sphinxstylestrong{Trusted Certificate Authorities} setting is required only if the BIG-IP system performs Client Certificate Authentication. This setting specifies the BIG-IP system’s Trusted Certificate Authorities store (the CAs that the BIG-IP system trusts when the system verifies a client certificate that is presented during Client Certificate Authentication). The default value for the \sphinxstylestrong{Trusted Certificate Authorities} setting is \sphinxstylestrong{None}, which indicates that no CAs are trusted. The \sphinxstylestrong{None} value is only appropriate if you do not want to permit Client Certificate Authentication. The SSL server does not need to trust any CA, unless the server performs Client Certificate Authentication. If the BIG-IP Client Certificate Mode is set to \sphinxstylestrong{Require}, but \sphinxstylestrong{Trusted Certificate Authorities} is set to \sphinxstylestrong{None}, clients cannot establish SSL sessions with the virtual server. This setting lists the name of all the SSL certificates installed on the BIG-IP system.

The \sphinxstylestrong{ca-bundle} certificate may be appropriate for use as a Trusted Certificate Authorities certificate bundle. However, if this bundle is specified as the Trusted Certificate Authorities certificate store, any valid client certificate that is signed by one of the popular Root CAs included in the default \sphinxstylestrong{ca-bundle.crt} is authenticated. This provides some level of identification but very little access control because almost any valid client certificate could be authenticated. However, when configuring client certificate authentication, it is more common to accept client certificates from one, or a select few, PKIs or private CAs.

If you want to trust only certificates signed by a specific CA or set of CAs, F5 recommends that you create and install a bundle that contains trustworthy CA certificates. The new certificate bundle can then be selected in the \sphinxstylestrong{Trusted Certificate Authorities} setting. For information about creating a custom certificate bundle, refer to \sphinxhref{https://support.f5.com/csp/article/K13302}{K13302: Configuring the BIG-IP system to use an SSL chain certificate (11.x - 13.x)}.

Beginning in BIG-IP 11.6.0, the bundle can include only the root certificate and/or the intermediate CA signing certificates that signed client certificate. Prior to BIG-IP 11.6.0, the bundle must include the entire chain of CA certificates necessary to establish a chain of trust, as described in the \sphinxstylestrong{Chain}setting.

To support multiple PKI hierarchies, this bundle can contain CA certificates from several different PKIs. The bundle does not need to contain CA certificates from the PKI that signed the server SSL certificate, unless client SSL certificates from that PKI must be validated by the BIG-IP system. However, in practice, Client Certificate Authentication is most commonly used with Private PKIs, and the \sphinxstylestrong{Trusted Certificate Authorities} setting often contains only a certificate or chain from the PKI that signed the server certificate.

You can use the \sphinxstylestrong{openssl} command to verify the client certificate against the Trusted Certificate Authority bundle prior to importing it onto the BIG-IP system. For example, the following \sphinxstylestrong{openssl} command verifies the client certificate, \sphinxstylestrong{client.crt}, against the Trusted Certificate Authority bundle:

openssl verify -purpose sslclient -CAfile /path/to/trusted-ca-bundle.crt /path/to/client.crt

If the system can establish the chain of trust can for the server certificate using the specified chain, the command returns output similar to the following example:

client.crt: OK

\sphinxstylestrong{Important}: Configuring the \sphinxstylestrong{Trusted Certificate Authorities} setting has no effect on client validation of the SSL server certificate that the BIG-IP system presents when it connects to an SSL virtual server. It is the SSL client’s responsibility to verify the validity of the SSL server’s certificate using its own Trusted Certificate store. However, the certificate bundle contained in the associated \sphinxstylestrong{Trusted Certificate Authorities} file is presented with the server SSL certificate, regardless of the \sphinxstylestrong{Chain}setting.

\sphinxstylestrong{Important}: Beginning in BIG-IP 11.5.0, the system no longer presents the certificate bundle contained in the associated \sphinxstylestrong{Trusted Certificate Authorities} file when the \sphinxstylestrong{Client Certificate} option is set to \sphinxstylestrong{Request} or**Require**.
\\
\hline
Advertised Certificate Authorities
&
The \sphinxstylestrong{Advertised Certificate Authorities} setting is optional. You can use it to specify the CAs that the BIG-IP system advertises as trusted when soliciting a client certificate for client certificate authentication. If the \sphinxstylestrong{Client Certificate}setting is configured to \sphinxstylestrong{Require}or \sphinxstylestrong{Request}, you can configure the \sphinxstylestrong{Advertised Certificate Authorities} setting to send clients a list of CAs that the server is likely to trust. The default value for the \sphinxstylestrong{Advertised Certificate Authorities} setting is \sphinxstylestrong{None}, indicating that no CAs are advertised. When set to \sphinxstylestrong{None}, no list of trusted CAs is sent to a client with the certificate request. This setting lists the name of all the SSL certificates installed on the BIG-IP system. If you want to advertise only a specific CA, or set of CAs, F5 recommends that you create and install a bundle that contains the certificates of the CA to advertise. You can then select the new certificate bundle in the \sphinxstylestrong{Advertised Certificate Authorities} setting. For information about creating a custom certificate bundle, refer to \sphinxhref{https://support.f5.com/csp/article/K13302}{K13302: Configuring the BIG-IP to use an SSL chain certificate (11.x - 13.x)}.

You can configure the \sphinxstylestrong{Advertised Certificate Authorities} setting to send a list of CAs other than that specified for the Trusted Certificate Authorities. This allows greater control over the configuration information shared with unknown clients. You may not want to reveal the entire list of trusted CAs to a client that does not automatically present a valid client certificate from a trusted CA. Although you can configure the two settings differently, in most cases, you should configure the \sphinxstylestrong{Advertised Certificate Authorities}setting to use the same certificate bundle as the \sphinxstylestrong{Trusted Certificate Authorities} setting.

\sphinxstylestrong{Important}: Avoid specifying a bundle that contains many certificates when configuring the \sphinxstylestrong{Advertised Certificate Authorities}setting. This minimizes the number of certificates that must be exchanged during a client SSL handshake. The maximum size allowed by the BIG-IP system for native SSL handshake messages is 14,304 bytes. Although typical handshakes do not result in excessive message length, if the SSL handshake is negotiating a native cipher, and the total length of all messages in the handshake exceeds this byte threshold, the handshake will fail.
\\
\hline
Certificate Revocation List (CRL)
&
The \sphinxstylestrong{Certificate Revocation List (CRL)}setting allows you to specify a CRL that the BIG-IP system should use to check revocation status of a certificate prior to authenticating a client. If you want to use a CRL, you must import it to the BIG-IP system. The name of the CRL file can then be entered in the \sphinxstylestrong{Certificate Revocation List (CRL)} setting dialog box. For information about importing an SSL CRL file, refer to \sphinxhref{https://support.f5.com/csp/article/K14620}{K14620: Managing SSL certificates for BIG-IP systems using the Configuration utility}. Since CRLs can quickly become outdated, F5 recommends that you use either OCSP or CRLDP profiles for more robust and current verification functionality.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\sphinxurl{https://support.f5.com/csp/article/K14806}

\sphinxstylestrong{Server SSL Profiles}

The BIG-IP Server SSL profile enables the BIG-IP system to initiate
secure connections to your SSL servers by using a fully SSL-encapsulated
protocol and providing configurable settings for managing server-side
SSL connections. Typically, you need to set only some of the available
settings, while you should keep the remaining settings at their default
values unless otherwise advised by F5 Technical Support. The BIG-IP
Server SSL profile settings are organized into the following sections
and are described in the tables below.

Note: This list has been cleaned up for 11.5 settings only.

General Properties


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Name
&
The \sphinxstylestrong{Name}setting is required. To create a Server SSL profile, you must specify a unique name for the profile. For more information about the profile name requirements, refer to the following articles:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K6869}{K6869: Reserved words that should not be used in BIG-IP configurations}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K13209}{K13209: BIG-IP configuration object names must begin with an alphabetic character}

\end{itemize}
\\
\hline
Parent Profile
&
This setting specifies an existing profile to use as the parent profile. A profile inherits settings from its parent, unless you override the setting by selecting its \sphinxstylestrong{Custom}box and modifying the value. The default is the \sphinxstylestrong{serverssl} profile.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Configuration

This section describes the most common SSL settings for a Server SSL
profile, for example, the certificate and key to send to SSL servers for
certificate exchange.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Mode
&
Sets the profile state to Enabled (selected, default) or Disabled (cleared). The \sphinxstylestrong{Mode} setting was introduced in BIG-IP 11.5.0.
\\
\hline
Certificate
&
The \sphinxstylestrong{Certificate} setting is optional. The default value for this setting is \sphinxstylestrong{None}. When you apply a Server SSL profile to a virtual server, the BIG-IP system acts as an SSL client. If you do not intend for the BIG-IP system to present its client certificate on behalf of clients traversing the virtual server, select \sphinxstylestrong{None}. If you expect the BIG-IP system to present a client certificate, import the certificate and matching key to the BIG-IP system, and then choose the appropriate certificate from the menu. For information about importing an SSL certificate and key by using the Configuration utility, refer to \sphinxhref{https://support.f5.com/csp/article/K14620}{K14620: Managing SSL certificates for BIG-IP systems using the Configuration utility}. For information about importing an SSL certificate and key using the Traffic Management Shell (\sphinxstylestrong{tmsh}) utility, refer to \sphinxhref{https://support.f5.com/csp/article/K14031}{K14031: Importing the SSL certificate and key using the Traffic Management Shell}.

For information about verifying the certificate format, refer to \sphinxhref{https://support.f5.com/csp/article/K13349}{K13349: Verifying SSL certificate and key pairs from the command line (11.x - 13.x)}
\\
\hline
Key
&
The \sphinxstylestrong{Key} setting is required only for configured certificates. If you have configured a certificate, you must choose the key that matches the configured certificate.  The default value for this setting is \sphinxstylestrong{None}.
\\
\hline
Passphrase
&
The \sphinxstylestrong{Passphrase} setting is optional. It is only required if the key is passphrase-protected. There is no default value for this setting. If a key is specified and the key is passphrase protected, enter the required passphrase. When no passphrase is configured, the \sphinxstylestrong{Passphrase}field displays an eight-asterisk mask (********), giving the appearance that an eight-character password has been configured. The passphrase is encrypted before it is saved in the \sphinxstylestrong{bigip.conf} file.
\\
\hline
Chain
&
The \sphinxstylestrong{Chain} setting is optional. This setting is used to specify a certificate bundle or chain that the server can use to establish a trust relationship with a client that presents a certificate signed by an untrusted Certificate Authority (CA). The default value for the \sphinxstylestrong{Chain}setting is \sphinxstylestrong{None}, indicating that the BIG-IP system will not present a chain certificate with its client SSL certificate. This setting lists the name of all the SSL certificates installed in the BIG-IP system’s SSL certificate store. If the certificate configured in the Server SSL profile is signed by an Intermediate CA, F5 recommends that you create and install a bundle that contains the certificates of all the CAs in the chain between the certificate configured in the Server SSL profile and a root CA whose certificate is trusted by your SSL servers. The new certificate bundle can then be selected in the \sphinxstylestrong{Chain}setting. For information about creating and installing a custom certificate bundle, refer to \sphinxhref{https://support.f5.com/csp/article/K13302}{K13302: Configuring the BIG-IP system to use an SSL chain certificate }\sphinxhref{https://support.f5.com/csp/article/K13302}{(11.x - 13.x)}.
\\
\hline
SSL Forward Proxy Feature
&
The \sphinxstylestrong{SSL Forward Proxy Feature} was introduced in BIG-IP 11.3.0. By default, the \sphinxstylestrong{SSL Forward Proxy Feature} is disabled (cleared). When enabled, the system encrypts all traffic between a client and the BIG-IP system using one certificate, and encrypts all traffic between the BIG-IP system and the server using a different certificate. The \sphinxstylestrong{SSL Forward Proxy Feature} requires both a Client SSL profile and a Server SSL profile, and must be enabled in both profiles. For information about using the \sphinxstylestrong{SSL Forward Proxy Feature}setting, refer to the \sphinxstylestrong{Implementing SSL Forward Proxy on a Single BIG-IP system} chapter of the \sphinxhref{https://support.f5.com/content/kb/en-us/products/big-ip\_ltm.html}{**BIG-IP LTM Implementations**} guide.
\\
\hline
SSL Forward Proxy Bypass
&
Specifies, when checked (enabled), that the system encrypts all traffic between a client and the BIG-IP system using one certificate, and encrypts all traffic between the BIG-IP system and the server using a different certificate. The \sphinxstylestrong{SSL Forward Proxy Bypass} setting is available starting in BIG-IP 11.5.0.
\\
\hline
Ciphers
&
The \sphinxstylestrong{Ciphers} setting is optional. By default, the Server SSL profile uses the \sphinxstylestrong{DEFAULT} cipher string. In most cases, the default setting is appropriate, but can be customized, as necessary, to meet the security and performance needs of your site. The SSL server selects the cipher used in a particular connection from the ciphers presented by the SSL client. When using Server SSL, the BIG-IP system acts as an SSL client. Although the server decides which cipher to use, you can gain some control by customizing the ciphers presented by the client. For information about configuring the SSL cipher for an SSL profile, refer to:
\sphinxhref{https://support.f5.com/csp/article/K17370}{K17370: Configuring the cipher strength for SSL profiles (12.x - 13.x)}
\\
\hline
Options
&
When enabled, (\sphinxstylestrong{Options List}) references the \sphinxstylestrong{Options List} setting, which are industry standard SSL options and workarounds for handling SSL processing. The default setting is \sphinxstylestrong{All Options Disabled}.
\\
\hline
Options List
&
The \sphinxstylestrong{Options List} setting provides selection from a set of industry standard SSL options and workarounds for handling SSL processing.
\\
\hline
Proxy SSL
&
The \sphinxstylestrong{Proxy SSL} setting was introduced in BIG-IP 11.0.0. By default, the \sphinxstylestrong{Proxy SSL} setting is disabled (cleared). When enabled, the client is allowed to directly authenticate with the server, and the server can authenticate with the client, based on the client certificate presented. In a typical setup with the BIG-IP system in the middle, the client and server cannot communicate directly to authenticate each other. The \sphinxstylestrong{Proxy SSL} setting requires both a Client SSL profile and a Server SSL profile, and must be enabled in both profiles. For information about the \sphinxstylestrong{Proxy SSL} setting, refer to the following resources:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K13385}{K13385: Overview of the Proxy SSL feature}

\item {} 
The \sphinxstylestrong{Implementing Proxy SSL on a Single BIG-IP system} chapter of the \sphinxstylestrong{BIG-IP LTM Implementations} guide.
\begin{quote}

\sphinxstylestrong{Note}: For information about how to locate F5 product guides, refer to \sphinxhref{https://support.f5.com/csp/article/K12453464}{*K12453464: Finding product documentation on AskF5*}.
\end{quote}

\end{itemize}
\\
\hline
ModSSL Methods
&
The \sphinxstylestrong{ModSSL Methods} setting enables or disables ModSSL method emulation. Enable this option when OpenSSL methods are inadequate, for example, when you want to use SSL compression over TLSv1. By default, this setting is disabled (cleared).
\\
\hline
Cache Size
&
The \sphinxstylestrong{Cache Size} setting specifies the maximum number of SSL sessions allowed in the SSL session cache. The default value for the \sphinxstylestrong{Cache Size} setting is**262144** sessions. For information about the SSL \sphinxstylestrong{Cache Size} settings, refer to \sphinxhref{https://support.f5.com/csp/article/K6767}{K6767: Overview of the BIG-IP SSL session cache profile settings}.
\\
\hline
Cache Timeout
&
The \sphinxstylestrong{Cache Timeout} setting specifies the number of seconds that SSL sessions are allowed to remain in the SSL session cache before being removed. The default value for the \sphinxstylestrong{Cache Timeout} setting is \sphinxstylestrong{3600} seconds. The range of values configurable for the \sphinxstylestrong{Cache Timeout} setting is between 0 and 86400 seconds, inclusive.
\\
\hline
Alert Timeout
&
The \sphinxstylestrong{Alert Timeout} setting specifies the duration that the system tries to close an SSL connection by transmitting an alert or initiating an unclean shutdown before resetting the connection. The default value for this setting in BIG-IP 12.0.0 HF1 and later as well as BIG-IP 12.1.0 and later is indefinite. The default value for this setting in BIG-IP 11.2.0 through 12.0.0 is \sphinxstylestrong{10} seconds. The default value for this setting in BIG-IP 11.0.0 through 11.1.0 is \sphinxstylestrong{60} seconds. You can select \sphinxstylestrong{Indefinite} to specify that the connection should not be reset after transmitting an alert or initiating an unclean shutdown.
\\
\hline
Handshake Timeout
&
The \sphinxstylestrong{Handshake Timeout} setting specifies the number of seconds that the system tries to establish an SSL connection before terminating the operation. The default value for this setting in BIG-IP 11.2.0 and later is \sphinxstylestrong{10} seconds. The default value for this setting in BIG-IP 11.0.0 through 11.1.0 is \sphinxstylestrong{60} seconds. You can select \sphinxstylestrong{Indefinite} to specify that the system should continue to try and establish a connection for an unlimited time.
\\
\hline
Renegotiation
&
You can configure the \sphinxstylestrong{Renegotiation} setting to control whether the virtual server allows midstream session renegotiation. When \sphinxstylestrong{Renegotiation}is enabled, the BIG-IP system processes mid-stream SSL renegotiation requests. When \sphinxstylestrong{Renegotiation}is disabled, the system terminates the connection, or ignores the request, depending on the system configuration. By default, this setting is enabled (selected).
\\
\hline
Renegotiation Period
&
You can configure the \sphinxstylestrong{Renegotiate Period} setting to control the amount of time, in seconds, that the system waits before renegotiating the SSL session. By default, this setting is set to \sphinxstylestrong{Indefinite}. When this setting is set to \sphinxstylestrong{Indefinite}, the system does not renegotiate SSL sessions based on a specified time interval.
\\
\hline
Renegotiation Size
&
The \sphinxstylestrong{Renegotiate Size} setting controls the amount of data exchange, in megabytes, before the system renegotiates the SSL session. By default, this setting is set to \sphinxstylestrong{Indefinite}. When this setting is set to \sphinxstylestrong{Indefinite}, the system does not renegotiate SSL sessions based on the amount of exchanged data.
\\
\hline
Secure Renegotiation
&
The BIG-IP SSL profiles support the TLS Renegotiation Indication Extension, which allows the user to specify the method of secure renegotiation for SSL connections. The default value for the Server SSL profile is \sphinxstylestrong{Require Strict}. The values for the \sphinxstylestrong{Secure Renegotiation} setting in the Server SSL profile are as follows:
\begin{itemize}
\item {} 
\sphinxstylestrong{Request}: Specifies that the system requests secure renegotiation of SSL connections.

\item {} 
\sphinxstylestrong{Require}: Specifies that the system requires secure renegotiation of SSL connections. In this mode, SSL connections initiated from the system to an unpatched server fail when renegotiation is enabled.

\item {} 
\sphinxstylestrong{Require Strict}: Specifies that the system requires strict, secure renegotiation of SSL connections. In this mode, SSL connections that are initiated from the system to an unpatched server fail when renegotiation is enabled.

\end{itemize}

Within the context of the Server SSL profile, there is no behavioral difference between the  \sphinxstylestrong{Require} and \sphinxstylestrong{Require Strict} settings. In either mode, initial SSL connections from the BIG-IP system to unpatched servers fail.
\\
\hline
Server Name
&
Starting in BIG-IP 11.1.0, the BIG-IP SSL profiles support the TLS Server Named Indication (SNI) Extension, which allows the BIG-IP system to send ClientHello messages with SNI extension. The \sphinxstylestrong{Server Name} setting specifies the fully qualified DNS hostname of the server (or a wildcard string containing the asterisk * character to match multiple names) used in the TLS SNI connection. There is no default value for this setting.
\\
\hline
Default SSL Profile for SNI
&
When enabled, this setting indicates that the system should use the profile as the default SSL profile for connecting to the server. By default, this setting is disabled (cleared).
\\
\hline
Require Peer SNI support
&
When enabled, this setting requires that the server must support the TLS SNI extension; otherwise, the BIG-IP system disconnects the SSL connection with a fatal alert. By default, this setting is disabled (cleared).
\\
\hline
Unclean Shutdown
&
The SSL protocol performs a clean shutdown of an active TLS/SSL connection by sending a close notify alert to the peer system. The \sphinxstylestrong{Unclean Shutdown} setting allows the BIG-IP system to perform an unclean shutdown of SSL connections by closing the underlying TCP connection without sending the SSL close notify alerts. By default, this setting is enabled (selected).
\\
\hline
Strict Resume
&
The \sphinxstylestrong{Strict Resume} setting enables or disables the resumption of SSL sessions after an unclean shutdown. By default, this setting is disabled (cleared).
\\
\hline
Session Ticket
&
Starting in BIG-IP 11.4.0, the BIG-IP SSL profiles support the stateless TLS session resumption mechanism as described in \sphinxhref{http://www.ietf.org/rfc/rfc5077.txt}{Internet Engineering Task Force (RFC 5077)}. This mechanism allows the BIG-IP system to accept a TLS session ticket from the server and subsequently resume a TLS session using the same ticket. By default, this setting is disabled (cleared).
\\
\hline
Generic Alert
&
When enabled (default), the system sends all SSL alerts using a generic ‘handshake failure’ message. When disabled, the system sends more specific SSL alert messages. The \sphinxstylestrong{Generic Alert} setting was introduced in BIG-IP 11.5.0.
\\
\hline
SSL Sign Hash
&
Specifies the certificate signature hash algorithm that the BIG-IP advertises in the ClientHello signature\_algorithms extension, and specifies the signature hash algorithm the BIG-IP uses in the Certificate Verify handshake message when using a client certificate. Possible choices are SHA1, SHA256, SHA384, or Any. When you select Any, you authorize the system to choose any one of the hash algorithms. Note that in this case, the BIG-IP system chooses SHA1 whenever possible. The \sphinxstylestrong{SSL Sign Hash} setting was introduced in BIG-IP 11.5.0.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Server Authentication

The Server Authentication section of the Server SSL profile provides
configurable settings for handling server authentication before
proceeding with the SSL session.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Server Certificate
&
The \sphinxstylestrong{Server Certificate} setting specifies how the system handles server certificates. The possible values for the \sphinxstylestrong{Server Certificate}setting are:
\begin{itemize}
\item {} 
\sphinxstylestrong{Ignore}: The \sphinxstylestrong{Ignore} setting is the default setting. The BIG-IP system ignores certificates from the server and never authenticates the server.

\item {} 
\sphinxstylestrong{Require}: The \sphinxstylestrong{Require} setting enforces server authentication. The BIG-IP system requires the server to present a valid certificate before establishing the SSL session. If you select \sphinxstylestrong{Require} as the \sphinxstylestrong{Server Certificate} setting, you must also specify a value in the \sphinxstylestrong{Authenticate Name} setting. A blank \sphinxstylestrong{Authenticate Name} setting indicates that all servers are authenticated, even though you have specified \sphinxstylestrong{Require} as the \sphinxstylestrong{Server Certificate} setting.

\end{itemize}
\\
\hline
Expire Certificate Response Control
&
The \sphinxstylestrong{Expire Certificate Response Control} setting was introduced in BIG-IP 11.3.0. This setting specifies how the system handles SSL connections when the server certificate expires. The default value for this setting is \sphinxstylestrong{drop}, which causes the SSL connection to be dropped. Conversely, configuring this setting to \sphinxstylestrong{ignore} causes the system to ignore the expired server certificate and proceed with establishing the connection.
\\
\hline
Untrusted Certificate Response Control
&
The \sphinxstylestrong{Untrusted Certificate Response Control} setting was introduced in BIG-IP 11.3.0. This setting specifies how the system handles SSL connections when the server certificate has an untrusted CA. The default value for this setting is \sphinxstylestrong{drop}, which causes the SSL connection to be dropped. Conversely, configuring this setting to \sphinxstylestrong{ignore} causes the system to ignore the untrusted CA and proceed with establishing the connection.
\\
\hline
Frequency
&
The \sphinxstylestrong{Frequency} setting specifies the frequency of server authentication for an SSL session. The default value for this setting is \sphinxstylestrong{Once}, which causes the system to authenticate the server for an SSL session only once. When you configure this setting to \sphinxstylestrong{Always}, the system authenticates the server for an SSL session and every subsequent reuse of the SSL session.
\\
\hline
Retain Certificate
&
Starting in BIG-IP 11.4.0, you can configure the BIG-IP SSL profile to not store a server certificate in an SSL session. When this setting is disabled, the server certificate is not stored in an SSL session. The default value is true (selected).
\\
\hline
Certificate Chain Traversal Depth
&
The \sphinxstylestrong{Certificate Chain Traversal Depth} setting specifies the maximum number of certificates that the system traverses in a server certificate chain. The default value is \sphinxstylestrong{9}.
\\
\hline
Authenticate Name
&
This setting specifies a Common Name (CN) that is iframeded in a server certificate. The system authenticates a server based on the specified CN. There is no default value for this setting.
\\
\hline
Trusted Certificate Authorities
&
The \sphinxstylestrong{Trusted Certificate Authorities} setting is optional. The system uses this setting to specify the CAs that the BIG-IP system trusts when verifying a server certificate. The default value for this setting is \sphinxstylestrong{None}, which causes the system to accept a server certificate signed by any CA. If you select \sphinxstylestrong{Require} for the \sphinxstylestrong{Server Certificate} setting, you must specify a CA from the \sphinxstylestrong{Trusted Certificate Authorities} setting. The selected CA will be trusted by the system when verifying a server certificate.

The \sphinxstylestrong{ca-bundle} certificate may be appropriate for use as a Trusted Certificate Authorities certificate bundle. However, if this bundle is specified as the Trusted Certificate Authorities certificate store, any valid server certificate that is signed by one of the popular root CAs included in the default \sphinxstylestrong{ca-bundle.crt} is authenticated. This provides some level of identification, but very little access control because almost any valid server certificate could be authenticated.

If you want to trust only a server certificate that has been signed by a private PKI or set of private PKIs, F5 recommends that you create and install a custom certificate bundle that contains the private PKI certificates, including the CA that directly signed your servers’ certificates. You can then select the new certificate bundle in the \sphinxstylestrong{Trusted Certificate Authorities} setting. For information about creating a custom certificate bundle, refer to \sphinxhref{https://support.f5.com/csp/article/K13302}{K13302: Configuring the BIG-IP system to use an SSL chain certificate }\sphinxhref{https://support.f5.com/csp/article/K13302}{(11.x - 13.x)}.

\sphinxstylestrong{Important}: Configuring the \sphinxstylestrong{Trusted Certificate Authorities} setting has no effect on server validation of the SSL server certificate that the BIG-IP system presents when connecting to an SSL server. The SSL server is responsible for verifying the validity of the SSL client’s certificate using its own Trusted Certificate store. If you need to specify a chain of trust to support the SSL server’s verification of the BIG-IP system’s client certificate, refer to your SSL server documentation for configuration details.
\\
\hline
Certificate Revocation List (CRL)
&
The \sphinxstylestrong{Certificate Revocation List (CRL)} setting allows you to specify a CRL that the BIG-IP system should use to check revocation status of a certificate before the system authenticates a server. If you want to use a CRL, you must import it to the BIG-IP system. You can then select the name of the CRL file from the \sphinxstylestrong{Certificate Revocation List (CRL)} setting. For information about importing an SSL CRL file, refer to \sphinxhref{https://support.f5.com/csp/article/K14620}{K14620: Managing SSL certificates for BIG-IP systems using the Configuration utility}. Because CRLs can quickly become outdated, F5 recommends that you use either OCSP or CRLDP profiles for more robust and current verification functionality.
\\
\hline
Allow Expired CRL
&
Instructs the system to use the specified CRL file, even if it has expired. The default is disabled. The \sphinxstylestrong{Allow Expired CLR} option was introduced in BIG-IP 12.0.0.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.11 - Describe the process to update expired SSL certificates}

\sphinxurl{https://support.f5.com/csp/article/K14620}

\sphinxstylestrong{Creating an SSL CSR and private key}

CA signed SSL certificates are typically valid for one or two years. To
avoid warning messages or connectivity issues that may be caused by
expired SSL certificates, you must renew SSL certificates before they
expire. To renew a CA signed SSL certificate, perform the following
procedure.

Note: For more information about monitoring SSL certificate
expiration, refer to the following article: K14318: Monitoring SSL
certificate expiration on the BIG-IP system (11.x - 13.x).

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.

Note: When using this procedure to generate a new CSR and private
key, you must choose a unique Name. Consider appending the current
year for easier accountability. For example, name the CSR and
private key example\_2017.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Create.

\item {} 
Enter a unique Name for the new SSL certificate and key.

\item {} 
From the Issuer list, select Certificate Authority.

\item {} 
Enter the required Common Name. This value is embedded in the certificate for name-based authentication purposes, and is typically the fully-qualified domain name (FQDN) of the server (for example, www.domain.com).

\item {} 
Configure other certificate settings.

\item {} 
In the Key Properties section, select the key type and size.

\item {} 
Optional: If the BIG-IP system supports the FIPS hardware security module (HSM), specify the key type (FIPS or Normal).

\item {} 
Click Finished.

\item {} 
To download the request into a file on your system, complete one of the following tasks:
\begin{itemize}
\item {} 
Copy the certificate from the Request Text box.

\item {} 
Click the button in the Request File box.

\end{itemize}

\item {} 
Click Finished.

\item {} 
After the CSR has been signed and returned by the CA, continue to the next section, Importing an SSL certificate.

\end{enumerate}

\sphinxstylestrong{Importing an SSL certificate}

Certificate authorities typically send SSL certificates by email. The
certificate may be included as an attachment or embedded in the body of
the email. You should copy and paste the certificate into a text file
using a text editor. The file should include the BEGIN CERTIFICATE and
END CERTIFICATE lines and contain no white space, extra line breaks, or
additional characters. The text file should appear similar to the
following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{BEGIN} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}

\PYG{p}{[}\PYG{n}{encoded} \PYG{n}{data}\PYG{p}{]}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{END} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\end{sphinxVerbatim}

After you have saved the certificate to a text file, you can use the
Configuration utility to import the certificate. To do so, perform the
following procedure:

Note: When using this procedure to import a new SSL certificate, you
must choose a unique Name. Consider appending the current year for
easier accountability. For example, name the SSL certificate
example\_2017.

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Import.

\item {} 
From the Import Type list, select Certificate.

\item {} 
In the Certificate Name section, click Create New.

\item {} 
In the Certificate Name box, type a name for the certificate.

\item {} 
In the Certificate Source section, click either Upload File or Paste Text.

\item {} 
Click Import.

\end{enumerate}

\sphinxstylestrong{Importing an SSL private key}

You can use the following procedure to import an existing SSL private key.

Note: When using this procedure to import a new SSL key, you must
choose a unique Name. Consider appending the current year for easier
accountability. For example, name the SSL key example\_2017.

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Import.

\item {} 
From the Import Type list, select Key.

\item {} 
In the Key Name section, click Create New.

\item {} 
In the Key Name box, type a unique name for the key.

\item {} 
In the Key Source section, click either Upload File or Paste Text.

\item {} 
Click Import.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.12 - Given a scenario determine the steps required to maintain SSL certificates}
\label{\detokenize{class5/modules/module1:objective-1-12-given-a-scenario-determine-the-steps-required-to-maintain-ssl-certificates}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.12 - Describe the process to update expired SSL certificates}

\sphinxurl{https://support.f5.com/csp/article/K14620}

\sphinxstylestrong{Creating an SSL CSR and private key}

CA signed SSL certificates are typically valid for one or two years. To
avoid warning messages or connectivity issues that may be caused by
expired SSL certificates, you must renew SSL certificates before they
expire. To renew a CA signed SSL certificate, perform the following
procedure.

Note: For more information about monitoring SSL certificate
expiration, refer to the following article: K14318: Monitoring SSL
certificate expiration on the BIG-IP system (11.x - 13.x).

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.

Note: When using this procedure to generate a new CSR and private
key, you must choose a unique Name. Consider appending the current
year for easier accountability. For example, name the CSR and
private key example\_2017.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Create.

\item {} 
Enter a unique Name for the new SSL certificate and key.

\item {} 
From the Issuer list, select Certificate Authority.

\item {} 
Enter the required Common Name. This value is embedded in the certificate for name-based authentication purposes, and is typically the fully-qualified domain name (FQDN) of the server (for example, www.domain.com).

\item {} 
Configure other certificate settings.

\item {} 
In the Key Properties section, select the key type and size.

\item {} 
Optional: If the BIG-IP system supports the FIPS hardware security module (HSM), specify the key type (FIPS or Normal).

\item {} 
Click Finished.

\item {} 
To download the request into a file on your system, complete one of the following tasks:
\begin{itemize}
\item {} 
Copy the certificate from the Request Text box.

\item {} 
Click the button in the Request File box.

\end{itemize}

\item {} 
Click Finished.

\item {} 
After the CSR has been signed and returned by the CA, continue to the next section, Importing an SSL certificate.

\end{enumerate}

\sphinxstylestrong{Importing an SSL certificate}

Certificate authorities typically send SSL certificates by email. The
certificate may be included as an attachment or embedded in the body of
the email. You should copy and paste the certificate into a text file
using a text editor. The file should include the BEGIN CERTIFICATE and
END CERTIFICATE lines and contain no white space, extra line breaks, or
additional characters. The text file should appear similar to the
following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{BEGIN} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}

\PYG{p}{[}\PYG{n}{encoded} \PYG{n}{data}\PYG{p}{]}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{END} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\end{sphinxVerbatim}

After you have saved the certificate to a text file, you can use the
Configuration utility to import the certificate. To do so, perform the
following procedure:

Note: When using this procedure to import a new SSL certificate, you
must choose a unique Name. Consider appending the current year for
easier accountability. For example, name the SSL certificate
example\_2017.

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Import.

\item {} 
From the Import Type list, select Certificate.

\item {} 
In the Certificate Name section, click Create New.

\item {} 
In the Certificate Name box, type a name for the certificate.

\item {} 
In the Certificate Source section, click either Upload File or Paste Text.

\item {} 
Click Import.

\end{enumerate}

\sphinxstylestrong{Importing an SSL private key}

You can use the following procedure to import an existing SSL private
key.

Note: When using this procedure to import a new SSL key, you must
choose a unique Name. Consider appending the current year for easier
accountability. For example, name the SSL key example\_2017.

Impact of procedure: Performing the following procedures should not
have a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to the SSL Certificate List: System \textgreater{} File Management \textgreater{} SSL Certificate List

\item {} 
Click Import.

\item {} 
From the Import Type list, select Key.

\item {} 
In the Key Name section, click Create New.

\item {} 
In the Key Name box, type a unique name for the key.

\item {} 
In the Key Source section, click either Upload File or Paste Text.

\item {} 
Click Import.

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.12 - Explain how to implement SSL chain certificate}

\sphinxurl{https://support.f5.com/csp/article/K788}

\sphinxstylestrong{SSL chain certificate}

Every certificate is signed by its issuer. The issuer is known as the
Certificate Authority (CA) or Issuing Authority. When you receive the
certificate for another entity, you might need to use a certificate
chain to authenticate the entity. The chain, or path, begins with the
certificate of that entity, and each certificate in the chain is signed
by the entity identified by the next certificate in the chain. The chain
terminates with a root CA certificate. The root CA certificate is always
signed by the CA itself. The signatures of all certificates in the chain
must be verified until the root CA certificate is reached. Most popular
SSL clients are pre-configured with a set of well-known trusted root CA
certificates. The PKI (Public Key Infrastructure) Certificate
Authorities, such as Entrust, VeriSign, and Equifax, provide chain
certificates containing all the certificates in the chain required for
popular clients to verify certificates signed by their respective
organizations.

Chain certificate file details

A chain certificate file contains the public certificates for each
Certificate Authority in the chain leading to a trusted CA. If a
certificate is not signed directly by a root CA trusted by the client,
the client will attempt to verify its authenticity by following an
explicit chain of authority from the Certificate Authority signing the
certificate to the trusted first tier Certificate Authority. There may
be one or more intermediate CA certificates included in the chain. The
chain must include each CA between the certificate signer and the
trusted root CA. The certificate chain may be contained in a file,
separate from the certificate (Entrust, Equifax and VeriSign all use
this method), or within the same file as the certificate.

\sphinxurl{https://support.f5.com/csp/article/K788}

\sphinxstylestrong{Implementing Chain Certificates}

You must meet the following prerequisites to use these procedures:
\begin{itemize}
\item {} 
You must have the public root or intermediate certificate from the
Certificate Authority (CA) that signs the SSL certificate.

\item {} 
You must have command line access to the BIG-IP system if you need to
create a custom certificate bundle.

\end{itemize}

Description

Chain certificates are used to help systems that depend on SSL
certificates for peer identification. The chain certificate creates a
chain of trust between the CA that signed the certificate and the CA
that is already trusted by the recipient of the certificate. This allows
the recipient to verify the validity of the certificates presented, even
when the signing CA is unknown.

When a client connects to a virtual server using a Client SSL profile
that has a chain certificate configured, the BIG-IP system presents the
certificate bundle with the SSL server certificate. If an SSL server
certificate used in Client SSL profiles is signed by an Intermediate CA
whose certificate is not contained in the SSL client’s Trusted
Certificate store, the client will not explicitly trust the SSL server
certificate. However, if the client trusts the certificate of another CA
further up the same hierarchy, the SSL server can present a chain of
certificates that establish a chain of trust to a root CA whose
certificate is trusted by the SSL client. Since the SSL client trusts
the root CA, and the root CA, in turn, trusts the intermediate CA, the
SSL client implicitly trusts the SSL server certificate.

For example, in a Public Key Infrastructure (PKI) that consists of a
root CA and two Intermediate CAs, the bundle should consist of the three
CA certificates (Root CA, Intermediate-1 CA, Intermediate-2 CA). When a
client connection uses this profile, the BIG-IP system presents all four
certificates to the client (the three CA certificates plus the server
certificate).

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Root} \PYG{n}{CA} \PYG{o}{\PYGZhy{}}\PYGZbs{}\PYG{o}{\textbar{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Intermediate}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1} \PYG{n}{CA} \PYG{o}{\PYGZhy{}}\PYGZbs{}\PYG{o}{\textbar{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Chain} \PYG{n}{Bundle} \PYG{o}{=} \PYG{n}{These} \PYG{n}{three} \PYG{n}{CA} \PYG{n}{certificates}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Intermediate}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{n}{CA} \PYG{o}{\PYGZhy{}}\PYGZbs{}\PYG{o}{\textbar{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{site} \PYG{n}{certificate}
\end{sphinxVerbatim}

If the client already has the root CA certificate in its Trusted
Certificate store, and the BIG-IP system presents the Intermediate CA
certificates (1 and 2), the client can establish a chain of trust to the
root CA. If the client already has both the root CA certificate and the
Intermediate-1 CA certificate in its Trusted Certificate store, and the
BIG-IP system presents the Intermediate CA-2 certificate, the client can
establish a chain of trust to the Intermediate-1 CA.

Important: Putting the root CA certificate in the certificate bundle is
optional, and will never cause the client to trust the root CA. This
would defeat the purpose of third-party validation, since trusted CAs
should be predetermined and their certificates intentionally installed
on the client. Presenting the root CA in the chain is simply a courtesy
on the SSL server’s part, potentially providing the client the option to
manually accept and install any of the required certificates in their
Trusted Certificate store. For example, in popular client browsers, the
user may see a message asking Would you like to install this
certificate? If using a private PKI, this may be an acceptable way to
distribute the required CA certificates. However, if using well-known
public PKIs, manually accepting and installing a CA certificate is not
required to verify the authenticity of a server certificate.

The BIG-IP Configuration utility provides a means of importing SSL
certificates and configuring the SSL profiles to use the imported SSL
certificates. However, if you need to create a custom certificate bundle
(for example, from a private CA), you will need to perform additional
steps from the command line.

Using a custom chain certificate

To create and use a custom chain certificate (also known as an
intermediate certificate chain), you must perform the following three
procedures:
\begin{itemize}
\item {} 
Importing the intermediate certificates to the BIG-IP system

\item {} 
Creating the custom chain certificate

\item {} 
Configuring an SSL profile to use the chain certificate

\end{itemize}

Importing the intermediate certificates to the BIG-IP system

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.

BIG-IP 11.0.0 - 12.1.2
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to System \textgreater{} File Management \textgreater{} SSL Certificate List.

\item {} 
Click Import.

\item {} 
In the Import Type list, click Certificate.

\item {} 
In the Certificate Name box, type a unique name.

\item {} 
Click Browse, and then browse to the location of the certificate or certificate bundle.

\item {} 
To import the certificate or certificate bundle to the BIG-IP system, click Import.

\end{enumerate}

Creating the custom chain certificate

If you are using certificates signed by a private CA, you may need to
build your own chain certificate. To do so, perform the following
procedure:

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.

Note: Before completing the following procedure, import all of the
necessary certificates from your private CA to the BIG-IP system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line.

\end{enumerate}

2. To create a chain certificate file, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cat} \PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{partition}\PYG{o}{\PYGZgt{}}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{cert}
\PYG{n}{name} \PYG{n}{A}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{p}{(}\PYG{n}{echo} \PYG{o}{\PYGZhy{}}\PYG{n}{e} \PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYG{n}{r}\PYG{p}{)}
\PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{partition}\PYG{o}{\PYGZgt{}}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{cert} \PYG{n}{name}
\PYG{n}{B}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{p}{(}\PYG{n}{echo} \PYG{o}{\PYGZhy{}}\PYG{n}{e} \PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYG{n}{r}\PYG{p}{)} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{o}{\PYGZgt{}} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{chain} \PYG{n}{cert} \PYG{n}{name}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Note: The \textless{}(echo -e \textbackslash{}r) command substitution adds a carriage
return after each certificate. The … characters represent
additional certificates to be appended to the chain file.

For example, to create the chain certificate file named mychain.crt,
use the following imported intermediate certificates:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{:}\PYG{n}{Common}\PYG{p}{:}\PYG{n}{intermediateCA}\PYGZbs{}\PYG{n}{\PYGZus{}A}\PYG{o}{.}\PYG{n}{crt}\PYGZbs{}\PYG{n}{\PYGZus{}1} \PYG{o+ow}{in} \PYG{n}{the} \PYG{n}{Common} \PYG{n}{partition}

\PYG{p}{:}\PYG{n}{MyPart}\PYG{p}{:}\PYG{n}{intermediateCA}\PYGZbs{}\PYG{n}{\PYGZus{}B}\PYG{o}{.}\PYG{n}{crt}\PYGZbs{}\PYG{n}{\PYGZus{}1} \PYG{o+ow}{in} \PYG{n}{the} \PYG{n}{MyPart} \PYG{n}{partition}
\end{sphinxVerbatim}

To do so, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cat}
\PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{Common}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{p}{:}\PYG{n}{Common}\PYG{p}{:}\PYG{n}{intermediateCA}\PYGZbs{}\PYG{n}{\PYGZus{}A}\PYG{o}{.}\PYG{n}{crt}\PYGZbs{}\PYG{n}{\PYGZus{}1}
\PYG{o}{\PYGZlt{}}\PYG{p}{(}\PYG{n}{echo} \PYG{o}{\PYGZhy{}}\PYG{n}{e} \PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYG{n}{r}\PYG{p}{)}
\PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{MyPart}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{p}{:}\PYG{n}{MyPart}\PYG{p}{:}\PYG{n}{intermediateCA}\PYGZbs{}\PYG{n}{\PYGZus{}B}\PYG{o}{.}\PYG{n}{crt}\PYGZbs{}\PYG{n}{\PYGZus{}1}
\PYG{o}{\PYGZgt{}} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{mychain}\PYG{o}{.}\PYG{n}{crt}
\end{sphinxVerbatim}

3. To verify whether the chain certificate creates a chain of trust to the SSL certificate, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{openssl} \PYG{n}{verify} \PYG{o}{\PYGZhy{}}\PYG{n}{purpose} \PYG{p}{[}\PYG{n}{sslserver}\PYGZbs{}\PYG{o}{\textbar{}}\PYG{n}{sslclient}\PYG{p}{]} \PYG{o}{\PYGZhy{}}\PYG{n}{CAfile}
\PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{chain} \PYG{n}{cert} \PYG{n}{name}\PYG{o}{\PYGZgt{}}
\PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{partition}\PYG{o}{\PYGZgt{}}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{cert} \PYG{n}{name}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

For example, to verify the server SSL certificate MyCert.crt in the
Common partition using the chain certificate mychain.crt, created in
step 2, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{openssl} \PYG{n}{verify} \PYG{o}{\PYGZhy{}}\PYG{n}{purpose} \PYG{n}{sslserver} \PYG{o}{\PYGZhy{}}\PYG{n}{CAfile} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{mychain}\PYG{o}{.}\PYG{n}{crt}
\PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{filestore}\PYG{o}{/}\PYG{n}{files}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{Common}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{n}{certificate}\PYGZbs{}\PYG{n}{\PYGZus{}d}\PYG{o}{/}\PYG{p}{:}\PYG{n}{Common}\PYG{p}{:}\PYG{n}{MyCert}\PYG{o}{.}\PYG{n}{crt}\PYGZbs{}\PYG{n}{\PYGZus{}1}
\end{sphinxVerbatim}

If the chain of trust can be established for the certificate using
the specified chain, the command returns output that appears similar
to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{MyCert}\PYG{o}{.}\PYG{n}{crt}\PYG{p}{:} \PYG{n}{OK}
\end{sphinxVerbatim}

3. To import the chain certificate, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{install} \PYG{n}{sys} \PYG{n}{crypto} \PYG{n}{cert} \PYG{o}{\PYGZlt{}}\PYG{n}{chain} \PYG{n}{cert} \PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{n}{from}\PYG{o}{\PYGZhy{}}\PYG{n}{local}\PYG{o}{\PYGZhy{}}\PYG{n}{file}
\PYG{o}{\PYGZlt{}}\PYG{n}{path}\PYG{o}{/}\PYG{n}{to}\PYG{o}{/}\PYG{n}{chain}\PYG{o}{/}\PYG{n}{cert}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

For example, import the chain certificate mychain.crt created in
step 2 with the name MyChain by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{install} \PYG{n}{sys} \PYG{n}{crypto} \PYG{n}{cert} \PYG{n}{MyChain} \PYG{n}{from}\PYG{o}{\PYGZhy{}}\PYG{n}{local}\PYG{o}{\PYGZhy{}}\PYG{n}{file}
\PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{mychain}\PYG{o}{.}\PYG{n}{crt}
\end{sphinxVerbatim}

4. To save the configuration, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n}{save} \PYG{n}{sys} \PYG{n}{config}
\end{sphinxVerbatim}

Configuring an SSL profile to use the custom chain certificate

You can configure a Client SSL or Server SSL profile to use the imported
chain certificate. Any virtual servers that use the Client SSL or Server
SSL profile will present the chain certificate with the configured
certificate. To do so, perform one of the following two procedures:

Note: As with all profile customizations, F5 recommends that you not
edit the supplied default profiles on the BIG-IP system. Instead, you
should create new custom profiles based on the default profile of the
desired type. If non-default profile settings (such as ciphers and
certificate chains) are used for all custom child profiles, you should
consider first creating a new custom profile with the non-default base
settings, and then use the new custom profile as the parent for a second
generation of custom child profiles.

BIG-IP 11.5.0 - 11.6.2

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to Local Traffic \textgreater{} Profiles \textgreater{} SSL.

\item {} 
Click Client or Server.

\item {} 
Click the name of the Client SSL or Server SSL profile.

\item {} 
If it is not already selected, select Custom check box for Certificate Key Chain.

\item {} 
In the Certificate Key Chain box.

\item {} 
From the Chain box, click the appropriate chain certificate.

\item {} 
Click Add.

\item {} 
To save the modifications, click Update.

\end{enumerate}

Using a CA-provided chain certificate

To use a CA-provided chain certificate, perform the following two procedures:
\begin{itemize}
\item {} 
Importing the chain certificate to the BIG-IP system

\item {} 
Configuring an SSL profile to use the chain certificate

\end{itemize}

You can obtain intermediate certificates or chain certificates for a
Public Key Infrastructure (PKI) from the certificate vendor. The
intermediate certificate or chain certificate must be in PEM format. The
most common VeriSign intermediate certificates are the Secure Site
certificate and the Secure Site Pro certificate, available at the
following location:

New VeriSign CA certificates

Note: This link takes you to a resource outside of AskF5, and it is
possible that the documents may be removed without our knowledge.

Importing the chain certificate to the BIG-IP system

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.

BIG-IP 11.0.0 - 12.1.2
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Click System \textgreater{} File Management \textgreater{} SSL Certificate List.

\item {} 
Click Import.

\item {} 
In the Import Type box, click Certificate.

\item {} 
In the Certificate Name box, type a unique name.

\item {} 
Click Browse, and then browse to the location of the certificate or
certificate bundle.

\item {} 
To import the certificate or certificate bundle to the BIG-IP system, click Import.

\end{enumerate}

Configuring an SSL profile to use the CA-provided chain certificate

You can configure a Client SSL or Server SSL profile to use the imported
chain certificate; any virtual servers that use the Client SSL or Server
SSL profile will present the chain certificate with the configured
certificate. To do so, perform one of the following procedures:

Note: As with all profile customizations, F5 recommends that you not
edit the supplied default profiles on the BIG-IP system. Instead, you
should create new custom profiles based on the default profile of the
desired type. If non-default profile settings (such as ciphers and
certificate chains) are used for all custom child profiles, you should
consider first creating a new custom profile with the non-default base
settings, and then use the new custom profile as the parent for a second
generation of custom child profiles.

BIG-IP 11.5.0 - 11.6.2

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Click Local Traffic \textgreater{} Profiles \textgreater{} SSL.

\item {} 
Click Client or Server.

\item {} 
Click the name of the Client SSL or Server SSL profile.

\item {} 
If it is not already selected, select Custom check box for Certificate Key Chain.

\item {} 
In the Chain box, click the appropriate chain certificate.

\item {} 
Click Add.

\item {} 
To save the modifications, click Update.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.13 - Given a set of application requirements, determine the appropriate virtual server type to use}
\label{\detokenize{class5/modules/module1:objective-1-13-given-a-set-of-application-requirements-determine-the-appropriate-virtual-server-type-to-use}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.13 \textendash{}Describe the relationship between profiles and virtual servers}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/6.html\#unique\_980637508}

\sphinxstylestrong{Profiles and virtual servers}

Once you have created a profile for a specific type of traffic, you
implement the profile by associating that profile with one or more
virtual servers.

You associate a profile with a virtual server by configuring the virtual
server to reference the profile. Whenever the virtual server receives
that type of traffic, Local Traffic Manager applies the profile settings
to that traffic, thereby controlling its behavior. Thus, profiles not
only define capabilities per network traffic type, but also ensure that
those capabilities are available for a virtual server.

Because certain kinds of traffic use multiple protocols and services,
users often create multiple profiles and associate them with a single
virtual server.

For example, a client application might use the TCP, SSL, and HTTP
protocols and services to send a request. This type of traffic would
therefore require three profiles, based on the three profile types TCP,
Client SSL, and HTTP.

Each virtual server lists the names of the profiles currently associated
with that virtual server. You can add or remove profiles from the
profile list, using the BIG-IP Configuration utility. Note that Local
Traffic Manager (LTM) has specific requirements regarding the
combinations of profile types allowed for a given virtual server.

In directing traffic, if a virtual server requires a specific type of
profile that does not appear in its profile list, Local Traffic Manager
uses the relevant default profile, automatically adding the profile to
the profile list. For example, if a client application sends traffic
over TCP, SSL, and HTTP, and you have assigned SSL and HTTP profiles
only, LTM automatically adds the default profile tcp to its profile
list.

At a minimum, a virtual server must reference a profile, and that
profile must be associated with a UDP, FastL4, Fast HTTP, or TCP profile
type. Thus, if you have not associated a profile with the virtual
server, Local Traffic Manager adds a udp, fastl4, fasthttp, or tcp
default profile to the profile list.

The default profile that Local Traffic Manager chooses depends on the
configuration of the virtual server’s protocol setting. For example, if
the protocol setting is set to UDP, Local Traffic Manager adds the udp
profile to its profile list.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.13 - Describe which steps are necessary to complete prior to
creating the virtual server}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/2.html\#conceptid}

\sphinxstylestrong{Configuring Virtual Servers}

When creating virtual server objects in the configuration utility or the
GUI you will need to do a few tasks prior to jumping into building the
virtual server. It is true that you can create a simple virtual server
in the GUI without doing anything prior because the GUI will allow you
to build the Pool and Node objects on the fly inside the virtual server
creation task. If you are creating a new virtual server in the
configuration utility you will have to create all necessary
configuration objects that the virtual server will need to use for its
creation.

It is always a good idea to have an established object naming convention
figured out prior to configuring any objects as well as a good
understanding of IP addresses to be used for the virtual server
creation.

The objects you should create are as follows:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Health monitors for nodes and pool members

\item {} 
SNAT pools

\item {} 
Any necessary profiles

\item {} 
Any necessary iRules

\item {} 
Nodes that will be used in the pool members

\item {} 
Pool and pool members

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.13 - Describe the security features when creating a virtual server (i.e., VLAN limitation, route domains, packet filters, iRules)}

\sphinxstylestrong{Virtual Server Security}

A virtual server is essentially a listener that will be taking in and
processing traffic on the BIG-IP platform. Some of the biggest security
risks when configuring a virtual server are how it is listening, where
it is listening and who can get to it. If you are configuring a virtual
server and not setting the necessary settings to restrict these areas of
concern you are opening yourself up to security risks.

\sphinxstylestrong{How is the Virtual Server Listening?}

The broader you set a virtual server to listen the greater the risk of
unintended inbound traffic. An application based virtual server should
typically be configured to listen on the default port for the
application. For example, if you are configuring a virtual server for a
new HTTP based website you would listen on port 80. If you listen on all
ports (*), the virtual server will take in traffic destine for the
virtual server on all 65535 ports of the IP address. And if the pool
members for the virtual server are also listening on all ports (*), it
will send traffic to the servers on the port it arrived on the virtual
server.

If you need to listen on multiple ports for the same IP address you can
approach this in two different ways. You can build a virtual server for
each necessary port using the same IP address or you can build one
virtual server on all ports and use an iRule to restrict the allowed
inbound connections to your list of ports.

\sphinxstylestrong{Where is the Virtual Server Listening?}

When you configure a virtual server, you tell the BIG-IP where you want
it to listen for traffic destined for the IP address of the virtual
server. This virtual server setting is the VLAN and Tunnel Traffic
setting. By default, the setting is set to All VLANs and Tunnels. Which
means the BIG-IP will listen on all VLANs. You are probably thinking,
ARP is only going to happen on the local subnet’s VLAN, which is true.
So, what can it possibly mean to listen on all VLANs? When this setting
is set to all VLANs it means that if traffic comes to BIG-IP destined
for the virtual server address from a VLAN that is not the VLAN of the
virtual server IP address, it will still take the traffic in on VLAN
interface that it arrived on. BIG-IP is a default deny device but in
setting the setting to All VLANS and Tunnels you have told the system to
listen on all VLANs for traffic to the virtual server and allow it in.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-ip-routing-administration-11-5-0/2.html}

\sphinxstylestrong{Route Domains}

A route domain is a configuration object that isolates network traffic
for a particular application on the network.

Because route domains segment network traffic, you can assign the same
IP address or subnet to multiple nodes on a network, provided that each
instance of the IP address resides in a separate routing domain in the
BIG-IP system. This feature will allow you to isolate traffic and let
upstream devices such as firewalls apply policy to the connections
between systems.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/14.html}

\sphinxstylestrong{Packet Filters}

Packet filters enhance network security by specifying whether a BIG-IP
system interface should accept or reject certain packets based on
criteria that you specify. Packet filters enforce an access policy on
incoming traffic. They apply to incoming traffic only.

You implement packet filtering by creating packet filter rules, using
the BIG-IP Configuration utility. The primary purpose of a packet filter
rule is to define the criteria that you want the BIG-IP system to use
when filtering packets. Examples of criteria that you can specify in a
packet filter rule are:
\begin{itemize}
\item {} 
The source IP address of a packet

\item {} 
The destination IP address of a packet

\item {} 
The destination port of a packet

\end{itemize}

You specify the criteria for applying packet filter rules within an
expression. When creating a packet filter rule, you can instruct the
BIG-IP system to build an expression for you, in which case you need
only choose the criteria from predefined lists, or you can write your
own expression text, using the syntax of the tcpdump utility. For more
information on the tcpdump utility, see the online man page for the
tcpdump command.

You can also configure global packet filtering that applies to all
packet filter rules that you create. The following sections describe how
to use the Configuration utility to set global packet filtering options,
as well as create and manage individual packet filters rules.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/18.html}

\sphinxstylestrong{iRules}

You can use iRules to restrict traffic in almost any way you can think
of. You can set an iRule to keep connections from happening when coming
from a certain IP address range or to a certain URI path in the HTTP
request.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.13 - Explain the effect of changing different virtual server types}

\sphinxurl{https://support.f5.com/csp/article/K14163}

\sphinxstylestrong{Changing virtual server types}

Each virtual server that you configure will have a type and the type
designates how the virtual server will process the traffic it allows in
as a listener. If you change the type of an existing virtual server it
is likely that the virtual server will no longer process the traffic
that it is allowing in to the BIG-IP in the same way.

You should expect to see many questions that involve knowing what type
of virtual server should be used in different scenarios, as well as, if
a type were used what the outcome would be. The following table lists
the virtual server type options and defines each virtual server type:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Virtual server type}
&
\sphinxstylestrong{Description of virtual server type}
\\
\hline
Standard
&
A Standard virtual server directs client traffic to a load balancing pool and is the most basic type of virtual server. It is a general purpose virtual server that does everything not expressly provided by the other type of virtual servers.
\\
\hline
Forwarding (Layer 2)
&
A Forwarding (Layer 2) virtual server typically shares the same IP address as a node in an associated VLAN. A Forwarding (Layer 2) virtual server is used in conjunction with a VLAN group.
\\
\hline
Forwarding (IP)
&
A Forwarding (IP) virtual server forwards packets directly to the destination IP address specified in the client request. A Forwarding (IP) virtual server has no pool members to load balance.
\\
\hline
Performance (Layer 4)
&
A Performance (Layer 4) virtual server has a FastL4 profile associated with it. A Performance (Layer 4) virtual server increases the speed at which the virtual server processes packets.
\\
\hline
Performance (HTTP)
&
A Performance (HTTP) virtual server has a FastHTTP profile associated with it. The Performance (HTTP) virtual server and related profile increase the speed at which the virtual server processes HTTP requests.
\\
\hline
Stateless
&
A Stateless virtual server improves the performance of UDP traffic in specific scenarios.
\\
\hline
Reject
&
A Reject virtual server rejects any traffic destined for the virtual server IP address.
\\
\hline
DHCP Relay
&
A DHCP Relay virtual server relays DHCP client requests for an IP address to one or more DHCP servers, and provides DHCP server responses with an available IP address for the client. (11.1.0 and later)
\\
\hline
Internal
&
An Internal virtual server enables usage of ICAP servers to modify HTTP requests and responses by creating and applying an ICAP profile and adding Request Adapt or Response Adapt profiles to the virtual server. (11.3.0 and later)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.14 - Given a set of application requirements, determine the appropriate virtual server configuration settings}
\label{\detokenize{class5/modules/module1:objective-1-14-given-a-set-of-application-requirements-determine-the-appropriate-virtual-server-configuration-settings}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.14 - Explain the effect of changing different virtual server options: types, configuration settings, and/or resource settings}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/13.html}

At a high level, a virtual server is a listener that takes in traffic.
And the type of virtual server tells the BIG-IP how to handle the
traffic (i.e. should the traffic be load balanced, routed, etc.). The
configuration settings explain the details of how to process the traffic
(i.e. is this TCP based Traffic at layer 4, is this HTTP based traffic
at layer 7, should we process this traffic to layer 7, should we decrypt
this traffic, should we persist the traffic). And lastly, the resource
of the virtual server tells the BIG-IP where to send it(i.e. should we
send it to a pool, should we send it to an iRule for further decision
making).

A virtual server has a number of properties and settings that you can
configure to affect the way that a virtual server manages traffic. You
can also assign certain resources to a virtual server, such as a load
balancing pool and various policies. Together, these properties,
settings, and resources represent the definition of a virtual server,
and most have default values. When you create a virtual server, you can
either retain the default values or adjust them to suit your needs.

If you have created a virtual server that is a load balancing type of
virtual server, one of the resources you must assign to the virtual
server is a default load balancing pool. A default pool is the pool to
which Local Traffic Manager sends traffic if no iRule or policy exists
that specifies a different pool. Note that if you plan on using an iRule
or policy to direct traffic to a pool, you must assign the iRule or
policy as a resource to the virtual server.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/11.html}

\sphinxstylestrong{Protocol Settings}

Protocol profiles support parameters concerning timeouts in connection
management.

Making changes to these profiles directly affects the behaviors
connections at layer 4 for the associated virtual server. If the
protocol profile is currently being used and you make a change to the
profile it can break the existing layer 4 connections using that
profile. Making a change to a parent protocol profile can not only
affect the connections using that profile where it is assigned but also
any connections using a child of that parent profile.

All virtual servers have at least one protocol profile associated with
them. While the HTTP Class is a protocol profile for configuration
purposes, it cannot be the sole profile of any virtual server and must
always be combined with both the TCP and HTTP profile.

The protocol profiles types are:
\begin{itemize}
\item {} 
Fast L4

\item {} 
Fast HTTP

\item {} 
UDP

\item {} 
SCTP

\end{itemize}

For each protocol profile type, BIG-IP Local Traffic Manager provides a
pre-configured profile with default settings. In most cases, you can use
these default profiles as is. If you want to change these settings, you
can configure protocol profile settings when you create a profile, or
after profile creation by modifying the profile’s settings.

To configure and manage protocol profiles, log in to the BIG-IP
Configuration utility, and on the Main tab, expand Local Traffic, and
click Profiles.

\sphinxstylestrong{The Fast L4 profile type}

The purpose of a Fast L4 profile is to help you manage Layer 4 traffic
more efficiently. When you assign a Fast L4 profile to a virtual server,
the Packet Velocity® ASIC (PVA) hardware acceleration within the BIG-IP
system can process some or all of the Layer 4 traffic passing through
the system. By offloading Layer 4 processing to the PVA hardware
acceleration, the BIG-IP system can increase performance and throughput
for basic routing functions (Layer 4) and application switching (Layer
7).

You can use a Fast L4 profile with these types of virtual servers:
Performance (Layer 4), Forwarding (Layer 2), and Forwarding (IP).

\sphinxstylestrong{PVA hardware acceleration}

Once you implement a Fast L4 profile, Local Traffic Manager
automatically selects the most efficient PVA hardware acceleration mode
for Layer 4 traffic, if PCVA is supported on the specific BIG-IP
platform. Possible modes are Full, Assisted, and None.

The particular hardware acceleration mode that Local Traffic Manager
selects depends on these factors:

\sphinxstylestrong{The Fast L4 profile settings}

The mode that the BIG-IP selects is influenced by the way that you
configure the settings of the Fast L4 profile.

\sphinxstylestrong{The virtual server configuration}

The mode that Local Traffic Manager selects is influenced by the
specific features that you assigned to the virtual server (such as
pools, SNAT pools, and iRules).

\sphinxstylestrong{A monitor assigned to associated nodes}

For full PVA acceleration, you must assign monitors to the relevant
nodes.

\sphinxstylestrong{The value of the PVA Acceleration setting}

The PVA Acceleration setting in the Fast L4 profile defines the maximum
amount of hardware acceleration that you want to allow, for Layer 4
traffic passing through the virtual server. Therefore, if you set the
value to:
\begin{itemize}
\item {} 
Full: The system can set hardware acceleration to any of the three
modes (Full, Assisted, or None), depending on the virtual server
configuration. This is the default value.

\item {} 
Assisted: The system can set hardware acceleration to either Assisted
or None mode, depending on the virtual server configuration.

\item {} 
None: The system does not perform hardware acceleration.

\end{itemize}

Depending on the current mode to which hardware acceleration is
automatically set, Local Traffic Manager accelerates Layer 4 traffic

Important: If you have a VLAN group configured on the BIG-IP system
and its Transparency Mode setting is set to Translucent or Transparent,
Local Traffic Manager automatically sets the PVA Acceleration value to
None.

\sphinxstylestrong{The Fast HTTP profile type}

The Fast HTTP profile is a configuration tool designed to speed up
certain types of HTTP connections. This profile combines selected
features from the TCP, HTTP, and OneConnect profiles into a single
profile that is optimized for the best possible network performance.
When you associate this profile with a virtual server, the virtual
server processes traffic packet-by-packet, and at a significantly higher
speed.

You might consider using a Fast HTTP profile when:
\begin{itemize}
\item {} 
You do not need features such as remote server authentication, SSL
traffic management, and TCP optimizations, nor HTTP features such as
data compression, pipelining, and RAM Cache.

\item {} 
You do not need to maintain source IP addresses.

\item {} 
You want to reduce the number of connections that are opened to the
destination servers.

\item {} 
The destination servers support connection persistence, that is,
HTTP/1.1, or HTTP/1.0 with Keep-Alive headers. Note that IIS servers
support connection persistence by default.

\item {} 
You need basic iRule support only (such as limited Layer 4 support
and limited HTTP header operations). For example, you can use the
iRule events CLIENT\_ACCEPTED, SERVER\_CONNECTED, and HTTP\_REQUEST.

\end{itemize}

A significant benefit of using a Fast HTTP profile is the way in which
the profile supports connection persistence. Using a Fast HTTP profile
ensures that for client requests, Local Traffic Manager can transform or
add an HTTP Connection header to keep connections open. Using the
profile also ensures that Local Traffic Manager pools any open
server-side connections. This support for connection persistence can
greatly reduce the load on destination servers by removing much of the
overhead caused by the opening and closing of connections.

Note: The Fast HTTP profile is incompatible with all other profile
types. Also, you cannot use this profile type in conjunction with
VLAN groups, or with the IPv6 address format.

You can use the default fasthttp profile as is, or create a custom Fast
HTTP profile.

\sphinxstylestrong{The TCP profile type}

TCP profiles are configuration tools that help you to manage TCP network
traffic. Many of the configuration settings of TCP profiles are standard
SYSCTL types of settings, while others are unique to Local Traffic
Manager.

TCP profiles are important because they are required for implementing
certain types of other profiles. For example, by implementing TCP, HTTP,
Rewrite, HTML, and OneConnect profiles, along with a persistence
profile, you can take advantage of various traffic management features,
such as:
\begin{itemize}
\item {} 
Content spooling, to reduce server load

\item {} 
OneConnect, to pool idle server-side connections

\item {} 
Layer 7 session persistence, such as hash or cookie persistence

\item {} 
iRules for managing HTTP traffic

\item {} 
HTTP data compression

\item {} 
HTTP pipelining

\item {} 
URI translation

\item {} 
HTML content modification

\item {} 
Rewriting of HTTP redirections

\end{itemize}

The BIG-IP system includes several pre-configured TCP profiles that you
can use as is. In addition to the default tcp profile, the system
includes TCP profiles that are pre-configured to optimize LAN and WAN
traffic, as well as traffic for mobile users. You can use the
pre-configured profiles as is, or you can create a custom profile based
on a pre-configured profile and then adjust the values of the settings
in the profiles to best suit your particular network environment.

To access the full set of TCP profiles, log in to the BIG-IP BIG-IP
Configuration utility and navigate to Acceleration \textgreater{} Profiles \textgreater{} TCP or
Local Traffic \textgreater{} Profiles \textgreater{} Protocol \textgreater{} TCP.

\sphinxstylestrong{The UDP profile type}

The UDP profile is a configuration tool for managing UDP network
traffic.

Because the BIG-IP system supports the OpenSSL implementation of
datagram Transport Layer Security (TLS), you can optionally assign both
a UDP and a Client SSL profile to certain types of virtual servers.

\sphinxstylestrong{The SCTP profile type}

Local Traffic Manager includes a profile type that you can use to manage
Stream Control Transmission Protocol (SCTP) traffic. Stream Control
Transmission Protocol (SCTP) is a general-purpose, industry-standard
transport protocol, designed for message-oriented applications that
transport signaling data. The design of SCTP includes appropriate
congestion-avoidance behavior, as well as resistance to flooding and
masquerade attacks.

Unlike TCP, SCTP includes the ability to support several streams within
a connection. While a TCP stream refers to a sequence of bytes, an SCTP
stream represents a sequence of messages.

You can use SCTP as the transport protocol for applications that require
monitoring and detection of session loss. For such applications, the
SCTP mechanisms to detect session failure actively monitor the
connectivity of a session.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.14 - Differentiate between client side and server side settings}

\sphinxstylestrong{Client side and Server side}

The concept of Client side and server side is important for most
administrators to understand. The concept is straight forward but very
important to remember that in a full proxy environment we need to think
about the connections from client to server as multiple connections and
thus the actions that need to be taken or processing that has to happen
may need to be done in different ways on either side of the proxy.

A few of the profile settings in the configuration of a virtual server
provide the option to use a separate client side and server side
profile. This gives the administrator the ability to process traffic
different on each side of the proxied connection for protocol level
traffic and for SSL termination and encryption. For example, you could
set a TCP profile for a virtual server that is WAN optimized for the
client side and LAN optimized for the server side. This is better known
as TCP express and is a very powerful function that the BIG-IP can
perform.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.15 - Explain the matching order of multiple virtual servers}
\label{\detokenize{class5/modules/module1:objective-1-15-explain-the-matching-order-of-multiple-virtual-servers}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.15 - Explain how to configure source addresses from which virtual servers can accept traffic}

\sphinxurl{https://support.f5.com/csp/article/K14800}

\sphinxstylestrong{BIG-IP system’s order of precedence for virtual server matching}

Starting in BIG-IP 11.3.0, you can configure source addresses from which
virtual servers accept traffic. The BIG-IP system uses the destination
address, source address, and service port configuration to determine the
order of precedence applied to new inbound connections. When a
connection matches multiple virtual servers, the BIG-IP system uses an
algorithm that places virtual server precedence in the following order:
\begin{itemize}
\item {} 
Destination address

\item {} 
Source address

\item {} 
Service port

\end{itemize}

Note: Neither the numerical order of virtual server IP addresses nor the
order in which they are listed in the configuration affect BIG-IP
performance.

When configuring a virtual server with a source address, you should be
as specific as possible when defining the destination and source
addresses for your application environment.

This algorithm uses the following order of precedence.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Order}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Destination}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Source}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Service port}
\\
\hline
1
&
\textless{}host address\textgreater{}
&
\textless{}host address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
2
&
\textless{}host address\textgreater{}
&
\textless{}host address\textgreater{}
&
*
\\
\hline
3
&
\textless{}host address\textgreater{}
&
\textless{}network address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
4
&
\textless{}host address\textgreater{}
&
\textless{}network address\textgreater{}
&
*
\\
\hline
5
&
\textless{}host address\textgreater{}
&
*
&
\textless{}port\textgreater{}
\\
\hline
6
&
\textless{}host address\textgreater{}
&
*
&
*
\\
\hline
7
&
\textless{}network address\textgreater{}
&
\textless{}host address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
8
&
\textless{}network address\textgreater{}
&
\textless{}host address\textgreater{}
&
*
\\
\hline
9
&
\textless{}network address\textgreater{}
&
\textless{}network address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
10
&
\textless{}network address\textgreater{}
&
\textless{}network address\textgreater{}
&
*
\\
\hline
11
&
\textless{}network address\textgreater{}
&
*
&
\textless{}port\textgreater{}
\\
\hline
12
&
\textless{}network address\textgreater{}
&
*
&
*
\\
\hline
13
&
*
&
\textless{}host address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
14
&
*
&
\textless{}host address\textgreater{}
&
*
\\
\hline
15
&
*
&
\textless{}network address\textgreater{}
&
\textless{}port\textgreater{}
\\
\hline
16
&
*
&
\textless{}network address\textgreater{}
&
*
\\
\hline
17
&
*
&
*
&
\textless{}port\textgreater{}
\\
\hline
18
&
*
&
*
&
*
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K9038}

Multiple source and destination listeners

Beginning in BIG-IP 11.3.0, the only local traffic object that can
create a listener for new connection requests matching the source and
destination host or network IP address is the following:
\begin{itemize}
\item {} 
Virtual Servers (Source Address / Destination Address)

\end{itemize}

Connection matching multiple Virtual Servers

When a new connection request matches multiple virtual servers, the
BIG-IP system places a higher precedence on the virtual server listener
with a more specific IP destination address/netmask.

For example, when the BIG-IP system receives a new connection request
from source IP address 192.168.20.1 to destination IP address
192.168.10.1, the virtual server listener destination 192.168.10.1 and
source 192.168.20.0/24 will have a higher precedence than virtual server
listener destination 192.168.10.0/24 and source 192.168.20.1.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.16 - Given a scenario, determine the appropriate load balancing method(s)}
\label{\detokenize{class5/modules/module1:objective-1-16-given-a-scenario-determine-the-appropriate-load-balancing-method-s}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.16 - (Supplemental Example) Identify the behavior of the application to be load balanced}

\sphinxstylestrong{Application behavior}

The key to choosing which load balancing method to use for an
application, is to understand the behavior of the application. What
understanding the behavior really means is, to understand how users
access and use the application. Every application will have somewhat
different client access behaviors. You will need to gather as much
information as you can to gain an understanding of how the application
is used. Sometimes this may mean using the application yourself.

If the application is used the same by every user, and the amount of
data transmitted and length of the connection time to the application is
the same for every user; then Round Robin will likely work well for the
application. If you have disparate hardware all servicing the same
application, you may want to use a ratio-based algorithm.

But as the transmitted size of the content and length of the session
varies more you will need to move to dynamic algorithms. Dynamic load
balancing methods take into account one or more dynamic factors, such as
current connection count or even server system performance. Because each
application is unique, and distribution of load can depend on a number
of different factors, it is recommended that you experiment with
different load balancing methods and select the one that offers the best
performance in your particular application.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.16 - Differentiate different load balancing methods}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/5.html}

\sphinxstylestrong{Load Balancing Methods}

There are many different types of load balancing algorithms that can be
used to decide how connections are distributed across a group of servers
that are hosting an application or service. All of these can be grouped
into two different types of algorithms, static and dynamic.

Some examples of static load balancing algorithms are Round-Robin and
Ratio. These types of algorithms do not take any environmental
information into consideration and simply do what they are defined to do
for connection distribution. Round-Robin may work well for short-lived,
simple connections that return about the same amount of data in all
responses. Ratio is typically used when the servers in the group are not
all of equal capacity, or licensing levels differ per server and an
uneven load should go to one server over the other in the group.

Some examples of dynamic load balancing algorithms are least connections
and fastest. These types of algorithms can be affected by environmental
information and use that information to make a better server choice.
Least Connections looks at current connection counts at Layer 4 to the
server and choses the server with the least connections. Fastest looks
at the outstanding Layer 7 request and choses the server with the lowest
amount.

\sphinxstylestrong{Local Traffic Manager load balancing methods}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Method
&
Description
&
When to use
\\
\hline
Round Robin
&
This is the default load balancing method. Round Robin mode passes each new connection request to the next server in line, eventually distributing connections evenly across the array of machines being load balanced.
&
Round Robin mode works well in most configurations, especially if the equipment that you are load balancing is roughly equal in processing speed and memory.
\\
\hline
Ratio (member)

Ratio (node)
&
Local Traffic Manager distributes connections among pool members or nodes in a static rotation according to ratio weights that you define. In this case, the number of connections that each system receives over time is proportionate to the ratio weight you defined for each pool member or node. You set a ratio weight when you create each pool member or node.
&
These are static load balancing methods, basing distribution on user-specified ratio weights that are proportional to the capacity of the servers.
\\
\hline
Dynamic Ratio (member) Dynamic Ratio (node)
&
The Dynamic Ratio methods select a server based on various aspects of real-time server performance analysis. These methods are similar to the Ratio methods, except that with Dynamic Ratio methods, the ratio weights are system-generated, and the values of the ratio weights are not static. These methods are based on continuous monitoring of the servers, and the ratio weights are therefore continually changing.

Note: To implement Dynamic Ratio load balancing, you must first install and configure the necessary server software for these systems, and then install the appropriate performance monitor.
&
The Dynamic Ratio methods are used specifically for load balancing traffic to RealNetworks$^{\text{®}}$ RealSystem$^{\text{®}}$ Server platforms, Windows$^{\text{®}}$ platforms equipped with Windows Management Instrumentation (WMI), or any server equipped with an SNMP agent such as the UC Davis SNMP agent or Windows 2000 Server SNMP agent.
\\
\hline
Fastest (node)

Fastest (application)
&
The Fastest methods select a server based on the least number of current sessions. These methods require that you assign both a Layer 7 and a TCP type of profile to the virtual server.

Note: If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.
&
The Fastest methods are useful in environments where nodes are distributed across separate logical networks.
\\
\hline
Least Connections (member)

Least Connections (node)
&
The Least Connections methods are relatively simple in that Local Traffic Manager passes a new connection to the pool member or node that has the least number of active connections.

Note: If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.
&
The Least Connections methods function best in environments where the servers have similar capabilities. Otherwise, some amount of latency can occur.

For example, consider the case where a pool has two servers of differing capacities, A and B. Server A has 95 active connections with a connection limit of 100, while server B has 96 active connections with a much larger connection limit of 500. In this case, the Least Connections method selects server A, the server with the lowest number of active connections, even though the server is close to reaching capacity.

If you have servers with varying capacities, consider using the Weighted Least Connections methods instead.
\\
\hline
Weighted Least Connections (member)

Weighted Least Connections (node)
&
Like the Least Connections methods, these load balancing methods select pool members or nodes based on the number of active connections. However, the Weighted Least Connections methods also base their selections on server capacity.

The Weighted Least Connections (member) method specifies that the system uses the value you specify in Connection Limit to establish a proportional algorithm for each pool member. The system bases the load balancing decision on that proportion and the number of current connections to that pool member. For example, member\_a has 20 connections and its connection limit is 100, so it is at 20\% of capacity. Similarly, member\_b has 20 connections and its connection limit is 200, so it is at 10\% of capacity. In this case, the system select selects member\_b. This algorithm requires all pool members to have a non-zero connection limit specified.

The Weighted Least Connections (node) method specifies that the system uses the value you specify in the node’s Connection Limit setting and the number of current connections to a node to establish a proportional algorithm. This algorithm requires all nodes used by pool members to have a non-zero connection limit specified.

If all servers have equal capacity, these load balancing methods behave in the same way as the Least Connections methods.

Note: If the OneConnect feature is enabled, the Weighted Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Weighted Least Connections methods use only active connections in their calculations.
&
Weighted Least Connections methods work best in environments where the servers have differing capacities.

For example, if two servers have the same number of active connections but one server has more capacity than the other, Local Traffic Manager calculates the percentage of capacity being used on each server and uses that percentage in its calculations.
\\
\hline
Observed (member)

Observed (node)
&
With the Observed methods, nodes are ranked based on the number of connections. The Observed methods track the number of Layer 4 connections to each node over time and create a ratio for load balancing.
&
The need for the Observed methods is rare, and they are not recommended for large pools.
\\
\hline
Predictive (member)

Predictive (node)
&
The Predictive methods use the ranking methods used by the Observed methods, where servers are rated according to the number of current connections. However, with the Predictive methods, Local Traffic Manager analyzes the trend of the ranking over time, determining whether a nodes performance is currently improving or declining. The servers with performance rankings that are currently improving, rather than declining, receive a higher proportion of the connections.
&
The need for the Predictive methods is rare, and they are not recommended for large pools.
\\
\hline
Least Sessions
&
The Least Sessions method selects the server that currently has the least number of entries in the persistence table. Use of this load balancing method requires that the virtual server reference a type of profile that tracks persistence connections, such as the Source Address Affinity or Universal profile type.

Note: The Least Sessions methods are incompatible with cookie persistence.
&
The Least Sessions method works best in environments where the servers or other equipment that you are load balancing have similar capabilities.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.16 - Explain how to perform outbound load balancing}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-implementations-11-5-0/2.html}

\sphinxstylestrong{Outbound Load Balancing}

You might find that as your network grows, or network traffic increases,
you require an additional connection to the Internet. You can use this
configuration to add an Internet connection to your existing network.
The following illustration shows a network configured with two Internet
connections.

Illustration of ISP load balancing

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p72}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

ISP load balancing (Outbound Load Balancing)

Task summary for ISP load balancing

\sphinxstylestrong{Creating a pool of outbound routers}

You can a create load balancing pool, which is a logical set of devices,
such as web servers, that you group together to receive and process
traffic, to efficiently distribute the load on your resources. Using
this procedure, create one pool to load balance the routers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Pools. The Pool List screen opens.

\item {} 
Click Create. The New Pool screen opens.

\item {} 
In the Name field, type a unique name for the pool.

\item {} 
For the Health Monitors setting, in the Available list, select a monitor type, and click \textless{}\textless{} to move the monitor to the Active list.

\item {} 
From the Load Balancing Method list, select how the system distributes traffic to members of this pool. The default is Round Robin.

\item {} 
For the Priority Group Activation setting, specify how to handle priority groups:
\begin{itemize}
\item {} 
Select Disabled to disable priority groups. This is the default option.

\item {} 
Select Less than, and in the Available Members field, type the minimum number of members that must remain available in each priority group in order for traffic to remain confined to that group.

\end{itemize}

\item {} 
Using the New Members setting, add each resource that you want to include in the pool:
\begin{itemize}
\item {} 
Either type an IP address in the Address field, or select a node address from the Node List.

\item {} 
Type a port number in the Service Port field, or select a service name from the list.

\item {} 
To specify a priority group, type a priority number in the Priority field.

\item {} 
Click Add.

\end{itemize}

\item {} 
Click Finished.

\end{enumerate}

The load balancing pool appears in the Pools list.

\sphinxstylestrong{Creating a virtual server for outbound traffic for routers}

You must create a virtual server to load balance outbound connections.
The default pool that you assign as a resource in this procedure is the
pool of routers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Virtual Servers. The Virtual Server List screen displays a list of existing virtual servers.

\item {} 
Click the Create button. The New Virtual Server screen opens.

\item {} 
In the Name field, type a unique name for the virtual server.

\item {} 
Specify the Destination setting, using the Address field; type the IP address you want to use for the virtual server. The IP address you type must be available and not in the loopback network.

\item {} 
In the Resources area of the screen, from the Default Pool list, select a pool name.

\item {} 
Click Finished.

\end{enumerate}

The virtual server is configured to load balance outbound connections to
the routers.

\sphinxstylestrong{Creating self IP addresses an external VLAN}

You must assign two self IP addresses to the external VLAN.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Network \textgreater{} Self IPs. The Self IPs screen opens.

\item {} 
Click Create. The New Self IP screen opens.

\item {} 
In the IP Address field, type an IP address. This IP address should represent the network of the router. The system accepts IP addresses in both the IPv4 and IPv6 formats.

\item {} 
In the Netmask field, type the network mask for the specified IP address.

\item {} 
Select External from the VLAN list.

\item {} 
Click Repeat.

\item {} 
In the IP Address field, type an IP address. This IP address should represent the address space of the VLAN that you specify with the VLAN/Tunnel setting. The system accepts IP addresses in both the IPv4 and IPv6 formats.

\item {} 
Click Finished. The screen refreshes, and displays the new self IP address in the list.

\end{enumerate}

The self IP address is assigned to the external VLAN.

\sphinxstylestrong{Enabling SNAT automap for internal and external VLANs}

You can configure SNAT automapping on the BIG-IP system for internal and
external VLANs.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} SNATs. The SNAT List screen displays a list of existing SNATs.

\item {} 
Click Create.

\item {} 
Name the new SNAT.

\item {} 
From the Translation list, select automap.

\item {} 
For the VLAN List setting, in the Available field, select external and external, and using the Move button, move the VLANs to the Selected field.

\item {} 
Click Finished.

\end{enumerate}

SNAT automapping on the BIG-IP system is configured for internal and
external VLANs.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.16 - Explain how persistence and pool member status effects load balancing decisions}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/5.html\#unique\_1882440537}

\sphinxstylestrong{Pool member availability}

You can specify a minimum number of health monitors. Before Local
Traffic Manager can report the pool member as being in an up state, this
number of monitors, at a minimum, must report a pool member as being
available to receive traffic.

You can enable or disable individual pool members. When you enable or
disable a pool member, you indirectly set the value of the pool member’s
State property, in the following way:
\begin{itemize}
\item {} 
Enable sets the State property of the pool member to Enabled.

\item {} 
Disable sets the State property of the pool member to Disabled.

\end{itemize}

Note that the difference between a disabled pool member and a pool
member that a monitor reports as down is that a disabled pool member
continues to process persistent and active connections. Conversely, a
pool member reported as down processes no connections whatsoever.

The status icons on the pool-member list screen and properties screen
indicate whether a pool member is currently enabled or disabled.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/10.html\#conceptid}

\sphinxstylestrong{Persistence and Load Balancing}

When you configure session persistence, Local Traffic Manager tracks and
stores session data, such as the specific pool member that serviced a
client request. The primary reason for tracking and storing session data
is to ensure that client requests are directed to the same pool member
throughout the life of a session or during subsequent sessions. So, if
you configure persistence, the first call to the application by the user
will be load balanced to the best available pool member according to the
algorithm but all additional calls by that user will be sent to that
same pool member based on the persistence type’s criteria regardless of
the algorithm.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.17 - Given a scenario, describe how to configure or modify pool settings}
\label{\detokenize{class5/modules/module1:objective-1-17-given-a-scenario-describe-how-to-configure-or-modify-pool-settings}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.17 - Describe priority group activation within a pool}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/5.html}

\sphinxstylestrong{Pool features}

\sphinxstylestrong{About priority-based member activation}

Priority-based member activation is a feature that allows you to
categorize pool members into priority groups, so that pool members in
higher priority groups accept traffic before pool members in lower
priority groups. The priority-based member activation feature has two
configuration settings:

\sphinxstylestrong{Priority group activation}

For the priority group activation setting, you specify the minimum
number of members that must remain available in each priority group in
order for traffic to remain confined to that group. The allowed value
for this setting ranges from 0 to 65535. Setting this value to 0
disables the feature (equivalent to using the default value of
Disabled).

\sphinxstylestrong{Priority group}

When you enable priority group activation, you also specify a priority
group for each member when you add that member to the pool. Retaining
the default priority group value of 0 for a pool member means that the
pool member is in the lowest priority group and only receives traffic
when all pool members in higher priority groups are unavailable.

If the number of available members assigned to the highest priority
group drops below the number that you specify, the BIG-IP system
distributes traffic to the next highest priority group, and so on.

For example, this configuration has three priority groups, 3, 2, and 1,
with the priority group activation value (shown here as min active
members) set to 2.

pool my\_pool \{ lb\_mode fastest min active members 2 member
10.12.10.7:80 priority 3 member 10.12.10.8:80 priority 3 member
10.12.10.9:80 priority 3 member 10.12.10.4:80 priority 2 member
10.12.10.5:80 priority 2 member 10.12.10.6:80 priority 2 member
10.12.10.1:80 priority 1 member 10.12.10.2:80 priority 1 member
10.12.10.3:80 priority 1 \}

Connections are first distributed to all pool members with priority 3
(the highest priority group). If fewer than two priority 3 members are
available, traffic is directed to the priority 2 members as well. If
both the priority 3 group and the priority 2 group have fewer than two
members available, traffic is directed to the priority 1 group. The
BIG-IP system continuously monitors the priority groups, and whenever a
higher priority group once again has the minimum number of available
members, the BIG-IP system limits traffic to that group.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.17 - Describe the effects of Slow Ramp Time}

\sphinxurl{https://support.f5.com/csp/article/K14804}

\sphinxstylestrong{Slow Ramp Time}

When a previously unavailable pool member becomes available (for
example, after having been marked down by a health monitor, manually
disabled, or forced offline), connection requests can overload the new
pool member, depending on the pool’s load balancing method. For example,
if you configure a pool to use the Least Connections load balancing
method, the system load balances all new connections to the new pool
member because the new pool member has the least amount of connections.

The Slow Ramp Time feature (enabled by default) is used to slowly
increase the number of connection requests that are load balanced to a
new pool member. The Slow Ramp Time setting controls the percentage of
connections that are sent to a new pool member by specifying the
duration, in seconds, that a pool member is in slow ramp mode. For
example, if the Slow Ramp Time setting is set to 10 seconds (the default
setting), when a newly enabled pool member has been available for one
second, the system begins load balancing 1/10 of the connections that
would have been sent to the new pool member had the Slow Ramp Time
setting been disabled. Each second thereafter, the system increases the
amount of traffic load balanced to the new pool member. So, after the
pool member has been available for nine seconds, the system is load
balancing 90 percent of the normal load to that pool member. When the
pool member has been available for longer than the Slow Ramp Time value,
the pool member receives its full proportion of the incoming traffic.

Note: Setting the Slow Ramp Time setting to a value of 0 (zero) disables
the Slow Ramp Time feature of the pool.

The Slow Ramp Time setting represents an approximate number of seconds
that the pool member remains in slow ramp mode. When a pool member is
marked-up, Traffic Management Microkernel (TMM) sets a slow ramp flag
for the pool member. The slow ramp timer then commences when the new
pool member becomes active, and TMM updates the new pool member’s slow
ramp status for each subsequent load balanced connection to the pool
member.

Note: Beginning in BIG-IP 11.3.0, TMM also updates the slow ramp status
for a pool member when processing persisted connections.

When TMM is updating the slow ramp status for a pool member, if the slow
ramp time has elapsed, TMM clears the slow ramp flag. Depending on the
rate at which connections are received, a new pool member’s slow ramp
flag may remain set longer than the duration of the Slow Ramp Time
setting specifies because TMM checks the slow ramp flag status only
while processing connection requests.

In most production environments, the rate at which connections are
received is sufficient for the Slow Ramp Time setting to act as a timer.
However, in environments with a low connection rate, such as a test
environment, a pool configured to use priority groups could experience
unexpected behavior. For example, a lower priority pool member may
remain in the active priority group longer than the Slow Ramp Time
setting indicates.

Consider the following factors when the BIG-IP system uses priority
groups and the Slow Ramp Time setting is enabled:
\begin{itemize}
\item {} 
Beginning in BIG-IP 11.0.0, a pool member does not count toward a
pool’s priority group minimum-up requirements until the pool member
is no longer in slow ramp mode.

\item {} 
In BIG-IP versions prior to 11.0.0, pool members are immediately
counted toward the minimum-up requirements. As a result, load
balancing could fail for the duration of the slow-ramp period. For
more information, refer to K13100: Load balancing may fail when the
Slow Ramp Time pool setting is enabled with priority groups.

\end{itemize}

Recommendations
\begin{itemize}
\item {} 
You should not disable the Slow Ramp Time pool setting if you use
dynamic load balancing methods. If the Slow Ramp Time setting is
disabled, the statistics for a new pool member could affect the load
balancing algorithm and overload the pool member.

\item {} 
For a production environment with a low connection rate that is
configured to use priority groups, disabling the Slow Ramp Time
setting may improve how quickly active priority groups are adjusted
when a pool member’s availability changes.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.17 - Describe how an iRule can effect the persistence behavior}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/10.html}

\sphinxstylestrong{iRules and Persistence}

Instead of configuring a persistence profile, which enables a
persistence type for all sessions passing through the virtual server,
you can write an iRule, which enables a persistence type for particular
requests (for example, for HTTP traffic that includes a certain cookie
version only).

You can also use an iRule to enable persistence for SSL-terminated
requests, that is, requests that Local Traffic Manager terminates by
performing decryption and re-encryption and by handling SSL certificate
authentication. In iRules of this type, you can use an HTTP header
insertion iRule command to insert an SSL session ID as a header into an
HTTP request.

You can assign a persistence profile from within an iRule as you can
most profiles. But there is a persistence method that specifically
relies on an iRule to function. This type of persistence is known as
Universal Persistence.

Universal Persistence

Included in Local Traffic Managers Universal Inspection Engine (UIE) is
a set of functions that you can specify within BIG-IP system iRules to
direct traffic in more granular ways. Using these iRule functions, you
can write expressions that direct traffic based on content data, or
direct traffic to a specific member of a pool.

Universal persistence takes this iRules feature one step further, by
allowing you to use the iRule persist uie command to implement
persistence for sessions based on content data or based on connections
to a specific member of a pool. Universal persistence does this by
defining some sequence of bytes to use as a session identifier.

To use iRule expressions for persistence, a universal persistence
profile includes a setting that specifies the name of the iRule
containing the expression.

\sphinxstyleemphasis{Sample iRule for universal persistence}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{rule} \PYG{n}{my\PYGZus{}persist}\PYGZbs{}\PYG{n}{\PYGZus{}irule} \PYG{p}{\PYGZob{}}
 \PYG{n}{when} \PYG{n}{HTTP\PYGZus{}REQUEST} \PYG{p}{\PYGZob{}} \PYG{n}{persist} \PYG{n}{uie} \PYG{p}{[}\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{header} \PYG{n}{myheader}\PYG{p}{]} \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Unlike hash persistence, which uses a hash of the data as the
persistence key, universal persistence uses the data itself as the
persistence key.

Note: F5 recommends that you configure a OneConnect profile in
addition to the Universal profile, to ensure that Local Traffic Manager
load balances HTTP requests correctly.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.17 - Explain how load balancing decisions are impacted by the statistics of nodes or pool members}

\sphinxurl{https://support.f5.com/csp/article/K10430}

\sphinxstylestrong{Statistics Impacting Load Balancing Methods}

The load balancing algorithm is the primary mechanism that determines
how connections are distributed across pool members. You can define
static or dynamic load balancing methods for a pool. Certain load
balancing methods are designed to distribute requests evenly across pool
members, and other load balancing methods are designed to favor higher
performing servers, possibly resulting in uneven traffic distribution
across pool members.

Static load balancing methods

Certain static load balancing methods are designed to distribute traffic
evenly across pool members. For example, the Round Robin load balancing
method causes the BIG-IP system to send each incoming request to the
next available member of the pool, thereby distributing requests evenly
across the servers in the pool. However, when a static load balancing
method such as Round Robin is used along with a BIG-IP configuration
object that affects load distribution, such as a OneConnect profile or a
persistence profile, traffic may not be evenly distributed across BIG-IP
pool members as expected.

Dynamic load balancing methods

Dynamic load balancing methods typically favor higher performing servers
and may result in uneven traffic distribution across pool members.
Dynamic load balancing methods are designed to work with servers that
differ in processing speed and memory. For example, when a dynamic load
balancing method such as the Observed method is defined for a pool,
higher performing servers process more connections over time than lower
performing servers. As a result, connection statistics for the higher
performing servers exceed those for lower performing severs.

Some dynamic load balancing methods, such as Least Connections, base the
decision of which available pool member to choose from the pool member’s
amount of Layer 4 connections.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K6406}

Least Connections mode

The Least Connections load balancing mode is a dynamic load balancing
algorithm that distributes connections to the server that is currently
managing the fewest open connections at the time the new connection
request is received.

Ratio Least Connections mode

Starting in BIG-IP LTM 11.0.0, the Ratio Least Connections load
balancing mode specifies that the system selects the pool member
according to the ratio of the number of connections each pool member has
active.

Note: Excluding the Ratio Least Connections mode load balancing
selection, members configured with a Ratio must reference a ratio load
balancing method to use the applied ratios.

Fastest mode

The Fastest load balancing mode load balances based on the number of
outstanding Layer 7 (L7) requests to a pool member. When the BIG-IP
system receives a L7 request, the BIG-IP system increments a counter for
the pool member handling the connection. The BIG-IP system decrements
this counter when the corresponding L7 response is received from the
node. For requests presented to the node, this counter represents the
current number of those requests that have not yet received a response.
The Fastest methods may be particularly useful in environments where
nodes are distributed across different logical networks. Virtual servers
using this load balancing mode must be configured with both a L7
Services profile and a TCP profile. If a L7 Services profile is not
configured for the virtual server, the Fastest algorithm will not
operate as documented.

Note: An outstanding request is one that has not yet received a
response. The BIG-IP system maintains a counter of outstanding L7
requests for each pool member.

Observed mode

The Observed mode dynamic load balancing algorithm calculates a dynamic
ratio value which is used to distribute connections among available pool
members. The ratio is based on the number of Layer 4 (L4) connections
last observed for each pool member. Every second, the BIG-IP system
observes the number of L4 connections to each pool member and assigns a
ratio value to each pool member. When a new connection is requested,
Observed mode load balances the connections based on the ratio values
assigned to each pool member, preferring the pool member with the
greatest ratio value.

Predictive mode

The Predictive mode dynamic load balancing algorithm ranks server
performance over time and prefers pool members that exhibit an
improvement in performance over those that exhibit a decline. The BIG-IP
system calculates a dynamic ratio value based on the number of L4
connections to each pool member over time. Every second, the BIG-IP
system observes the number of L4 connections to each pool member,
compares it to the previous connection counts to determine the relative
performance trend, and assigns a ratio value to each pool member. If the
connection count is unchanged, the system does not change the ratio
value. If the connection count is increasing for a pool member, the
system reduces the ratio value for that pool member. If the connection
counts are decreasing on a particular pool member, the system increases
its ratio value. When a new connection is requested, Predictive mode
load balances the connections based on the ratio values that the system
has assigned to each pool member, preferring the pool member with the
greatest ratio value.

Predictive mode uses the same metric as Observed mode (concurrent
connections). However, since the algorithm takes into account the
ongoing performance trend, Predictive mode more aggressively adjusts the
pool member ratios. As a result, Predictive mode may result in better
performance than Observed mode for some applications.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.17 - Explain the effects of action on service down}

\sphinxurl{https://support.f5.com/csp/article/K15095}

\sphinxstylestrong{Action On Service Down}

When a pool member fails to respond to a health monitor, the system
marks that pool member down. Persistence entries associated with the
pool member are removed when a new connection matches the entry or when
the timeout period is reached. If a new connection matches a persistence
record that has not timed out, the BIG-IP system removes the old
persistence record and creates a new entry.

The Action On Service Down feature specifies how the system should
respond to already-established connections when the target pool member
becomes unavailable.

The following table describes the available settings for this feature.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{3}{\X{1}{3}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Usage}
\\
\hline
\sphinxstylestrong{None}
&
The BIG-IP system takes no action on existing connections, and removes the connection table entry based on the associated profile’s idle timeout value. The BIG-IP system sends a \sphinxstylestrong{TCP Reset} (\sphinxstylestrong{RST}) or \sphinxstylestrong{ICMP Unreachable} once idle timeout is reached. This is the default setting.
&
This is the best option for most common scenarios, as this allows for endpoints to resume gracefully on their own. This may be a good choice for clients that transfer large amounts of data, as the pool member may recover itself before the connection is reset, allowing the large transfer to continue.
\\
\hline
\sphinxstylestrong{Reject}
&
The BIG-IP system sends \sphinxstylestrong{RST} or \sphinxstylestrong{ICMP} messages to reset active connections and removes them from the BIG-IP connection table.

\sphinxstylestrong{Note}: This selection is named “\sphinxstylestrong{reset}” instead of “\sphinxstylestrong{reject}” when using the TMOS Shell (\sphinxstylestrong{tmsh}).
&
This may be a good choice for clients that need to be notified of pool member state changes sooner than the configured idle timeout period for that virtual server.
Once the target pool member is deemed unavailable, the BIG-IP system immediately alerts the client by resetting the connection, causing the client to attempt a new connection.
\\
\hline
\sphinxstylestrong{Drop}
&
The BIG-IP system silently removes the connection table entry.
&
You should carefully consider this option, as the client receives no feedback from the BIG-IP system regarding the connection state.

However, this option works well for short-lived, connectionless protocols, such as UDP. For example, DNS queries.
\\
\hline
\sphinxstylestrong{Reselect}
&
The BIG-IP system manages established client connections by moving them to an alternate pool member without a connection teardown or setup.
\sphinxstylestrong{Note:} The \sphinxstylestrong{Reselect} action is not performed when a Standard virtual server is configured with a TCP profile and has port and address translation disabled. This is analogous to using the \sphinxstylestrong{None} option.
&
This option is only appropriate for:
\begin{itemize}
\item {} 
Virtual servers with address and port translation disabled

\end{itemize}

\sphinxstylestrong{Note}: This is the default for FastL4 type virtual servers, such as network or wildcard forwarding.
\begin{itemize}
\item {} 
Transparent pool members, such as firewalls, routers, proxy servers, and cache servers

\end{itemize}

\sphinxstylestrong{Note}: Transparent devices can forward packets to destinations without regard for the state of the connection.
\begin{itemize}
\item {} 
UDP virtual servers

\end{itemize}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.18 - Explain the effect of configuration options and resource health on load balancing decisions}
\label{\detokenize{class5/modules/module1:objective-1-18-explain-the-effect-of-configuration-options-and-resource-health-on-load-balancing-decisions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.18 - (Supplemental Example) Explain the effect of configuration options and resource health on load balancing decisions}

There are many configuration settings and resource status that can
affect load balancing decisions. The following are a few of the more
common.

\sphinxstylestrong{Load Balancing Algorithm’s Mode (Member vs Node)}

There are two modes for many of the load balancing algorithms available
to the pool, that can be used as the method to distribute load across
the available pool members of a pool. One algorithm mode is \sphinxstylestrong{Member}
and the other mode is \sphinxstylestrong{Node}.

The difference between a Member and Node mode for each algorithm is how
it assesses the pool member for the criteria that it uses to make the
load balancing decision.

With Member as the Algorithm mode the algorithm will only look at the
member of the pool as it is defined to assess current connections. With
Node as the algorithm mode the algorithm will look at all current
connections that the Pool member’s node IP has in every pool it is
defined in.

Choosing Member or Node as the mode for the algorithm can directly
affect load distribution in your pools.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K14358}

\sphinxstylestrong{CMP Effects Load Balancing Methods}

Load balancing behavior for CMP-enabled virtual servers

The BIG-IP system uses a Layer 4 (L4) hash to distribute connections for
a CMP-enabled virtual server among the available TMM processes. The pool
load balancing algorithm is then applied independently in each TMM
instance. Since each TMM handles load balancing independently from the
other TMMs, distribution across the pool members may appear to be
incorrect when compared with a non-CMP enabled virtual server using the
same load balancing algorithm.

Consider the following example configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Virtual} \PYG{n}{Server}\PYG{p}{:} \PYG{l+m+mf}{172.16}\PYG{o}{.}\PYG{l+m+mf}{10.10}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{n}{Pool} \PYG{k}{with} \PYG{l+m+mi}{4} \PYG{n}{members}\PYG{p}{:} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.2}\PYG{p}{:}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.3}\PYG{p}{:}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.4}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{n}{Pool} \PYG{n}{Load} \PYG{n}{Balancing} \PYG{n}{Method}\PYG{p}{:} \PYG{n}{Round} \PYG{n}{Robin}

\PYG{n}{Scenario} \PYG{l+m+mi}{1}\PYG{p}{:} \PYG{n}{Virtual} \PYG{n}{server} \PYG{k}{with} \PYG{n}{CMP} \PYG{n}{disabled}
\end{sphinxVerbatim}

Four connections are made to the virtual server; all of which are
processed by TMM. The BIG-IP system load balances the four individual
connections to the four pool members, based on the Round Robin
load-balancing algorithm:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM0} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{2}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{BIG}\PYG{o}{\PYGZhy{}}\PYG{n}{IP} \PYG{n}{Virtual} \PYG{n}{Server} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{2}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM0}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.2}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{3}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{3}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM0} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.3}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM0} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.4}\PYG{p}{:}\PYG{l+m+mi}{80}
\end{sphinxVerbatim}

Scenario 2: Virtual server with CMP enabled

Four connections are made to the virtual server. Unlike the first
scenario where CMP was disabled, the BIG-IP system distributes the
connections across the multiple TMM instances. For example, the BIG-IP
6900 uses four TMM instances. Since each TMM handles load balancing
independently of the other TMM instances, it is possible that all four
connections are directed to the same pool member.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM0} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{2}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{BIG}\PYG{o}{\PYGZhy{}}\PYG{n}{IP} \PYG{n}{Virtual} \PYG{n}{Server} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{2}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM1}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{3}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{3}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM2} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}

\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYGZbs{}\PYG{o}{\textbar{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{Connection} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{TMM3} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{10.0}\PYG{o}{.}\PYG{l+m+mf}{0.1}\PYG{p}{:}\PYG{l+m+mi}{80}
\end{sphinxVerbatim}

The CMP feature is designed to speed up connection handling by
distributing connections across multiple TMM instances. While initially
this behavior may appear to favor one or several servers, over time, the
load is distributed equally across all servers.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K5911}

\sphinxstylestrong{OneConnect}

The BIG-IP OneConnect feature can increase network throughput by
efficiently managing connections created between the BIG-IP system and
back end nodes. OneConnect allows the BIG-IP system to minimize the
number of server-side TCP connections by making existing idle
connections available for reuse by other clients. The OneConnect source
mask setting manages connection reuse, and is applied to the server-side
source IP address of a request to determine its eligibility for
connection reuse.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.18 - Determine the effect that virtual server traffic and/or resource status will have on load balancing decisions}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/5.html}

\sphinxstylestrong{Load Balancing decisions}

When you create a pool, you assign pool members to the pool. A pool
member is a logical object that represents a physical node (server), on
the network. You then associate the pool with a virtual server on the
BIG-IP system. Once you have assigned a pool to a virtual server, Local
Traffic Manager (LTM) directs traffic coming into the virtual server to
a member of that pool. An individual pool member can belong to one or
multiple pools, depending on how you want to manage your network
traffic.

The specific pool member to which Local Traffic Manager chooses to send
the request is determined by the load balancing method that you have
assigned to that pool. A load balancing method is an algorithm that LTM
uses to select a pool member for processing a request. For example, the
default load balancing method is Round Robin, which causes Local Traffic
Manager to send each incoming request to the next available member of
the pool, thereby distributing requests evenly across the servers in the
pool.

Health monitors are a key feature of Local Traffic Manager. Health
monitors help to ensure that a server is in an up state and able to
receive traffic. When you want to associate a monitor with an entire
pool of servers, you do not need to explicitly associate that monitor
with each individual server. Instead, you can simply assign the monitor
to the pool itself. Local Traffic Manager then automatically monitors
each member of the pool.

With Local Traffic Manager, you can configure your monitor associations
in many useful ways:
\begin{itemize}
\item {} 
You can associate a health monitor with an entire pool instead of an
individual server. In this case, Local Traffic Manager automatically
associates that monitor with all pool members, including those that
you add later. Similarly, when you remove a member from a pool, Local
Traffic Manager no longer monitors that server.

\item {} 
When a server that is designated as a pool member allows multiple
processes to exist on the same IP address and port, you can check the
health or status of each process. To do this, you can add the server
to multiple pools, and then within each pool, associate a monitor
with the that server. The monitor you associate with each server
checks the health of the process running on that server.

\item {} 
When associating a monitor with an entire pool, you can exclude an
individual pool member from being associated with that monitor. In
this case, you can associate a different monitor for that particular
pool member, or you can exclude that pool member from health
monitoring altogether. For example, you can associate pool members A,
B, and D with the http monitor, while you associate pool member C
with the https monitor.

\item {} 
You can associate multiple monitors with the same pool. For instance,
you can associate both the http and https monitors with the same
pool.

\end{itemize}

Pool member availability

You can specify a minimum number of health monitors. Before Local
Traffic Manager can report the pool member as being in an up state, this
number of monitors, at a minimum, must report a pool member as being
available to receive traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.18 - Given a scenario, determine the appropriate load balancing methods}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/5.html}

\sphinxstylestrong{Load Balancing Methods}

There are several load balancing methods available within the BIG-IP
system for load balancing traffic to pool members.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{When to use}
\\
\hline
Round Robin
&
This is the default load balancing method. Round Robin mode passes each new connection request to the next server in line, eventually distributing connections evenly across the array of machines being load balanced.
&
Round Robin mode works well in most configurations, especially if the equipment that you are load balancing is roughly equal in processing speed and memory.
\\
\hline
Ratio (member) Ratio (node)
&
Local Traffic Manager distributes connections among pool members or nodes in a static rotation according to ratio weights that you define. In this case, the number of connections that each system receives over time is proportionate to the ratio weight you defined for each pool member or node. You set a ratio weight when you create each pool member or node.
&
These are static load balancing methods, basing distribution on user-specified ratio weights that are proportional to the capacity of the servers.
\\
\hline
Dynamic Ratio (member) Dynamic Ratio (node)
&
The Dynamic Ratio methods select a server based on various aspects of real-time server performance analysis. These methods are similar to the Ratio methods, except that with Dynamic Ratio methods, the ratio weights are system-generated, and the values of the ratio weights are not static. These methods are based on continuous monitoring of the servers, and the ratio weights are therefore continually changing.

\sphinxstylestrong{Note:} To implement Dynamic Ratio load balancing, you must first install and configure the necessary server software for these systems, and then install the appropriate performance monitor.
&
The Dynamic Ratio methods are used specifically for load balancing traffic to RealNetworks RealSystem Server platforms, Windows platforms equipped with Windows Management Instrumentation (WMI), or any server equipped with an SNMP agent such as the UC Davis SNMP agent or Windows 2000 Server SNMP agent.
\\
\hline
Fastest (node) Fastest (application)
&
The Fastest methods select a server based on the least number of current sessions. These methods require that you assign both a Layer 7 and a TCP type of profile to the virtual server.

\sphinxstylestrong{Note:} If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.
&
The Fastest methods are useful in environments where nodes are distributed across separate logical networks.
\\
\hline
Least Connections (member) Least Connections (node)
&
The Least Connections methods are relatively simple in that Local Traffic Manager passes a new connection to the pool member or node that has the least number of active connections.

\sphinxstylestrong{Note:} If the OneConnect feature is enabled, the Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Least Connections methods use only active connections in their calculations.
&
The Least Connections methods function best in environments where the servers have similar capabilities. Otherwise, some amount of latency can occur. For example, consider the case where a pool has two servers of differing capacities, A and B. Server A has 95 active connections with a connection limit of 100, while server B has 96 active connections with a much larger connection limit of 500. In this case, the Least Connections method selects server A, the server with the lowest number of active connections, even though the server is close to reaching capacity. If you have servers with varying capacities, consider using the Weighted Least Connections methods instead.
\\
\hline
Weighted Least Connections (member) Weighted Least Connections (node)
&
Like the Least Connections methods, these load balancing methods select pool members or nodes based on the number of active connections. However, the Weighted Least Connections methods also base their selections on server capacity. The Weighted Least Connections (member) method specifies that the system uses the value you specify in Connection Limit to establish a proportional algorithm for each pool member. The system bases the load balancing decision on that proportion and the number of current connections to that pool member. For example, member\_a has 20 connections and its connection limit is 100, so it is at 20\% of capacity. Similarly, member\_b has 20 connections and its connection limit is 200, so it is at 10\% of capacity. In this case, the system select selects member\_b. This algorithm requires all pool members to have a non-zero connection limit specified. The Weighted Least Connections (node) method specifies that the system uses the value you specify in the node’s Connection Limit setting and the number of current connections to a node to establish a proportional algorithm. This algorithm requires all nodes used by pool members to have a non-zero connection limit specified. If all servers have equal capacity, these load balancing methods behave in the same way as the Least Connections methods.

\sphinxstylestrong{Note:} If the OneConnect feature is enabled, the Weighted Least Connections methods do not include idle connections in the calculations when selecting a pool member or node. The Weighted Least Connections methods use only active connections in their calculations.
&
Weighted Least Connections methods work best in environments where the servers have differing capacities. For example, if two servers have the same number of active connections but one server has more capacity than the other, Local Traffic Manager calculates the percentage of capacity being used on each server and uses that percentage in its calculations.
\\
\hline
Observed (member) Observed (node)
&
With the Observed methods, nodes are ranked based on the number of connections. The Observed methods track the number of Layer 4 connections to each node over time and create a ratio for load balancing.
&
The need for the Observed methods is rare, and they are not recommended for large pools.
\\
\hline
Predictive (member) Predictive (node)
&
The Predictive methods use the ranking methods used by the Observed methods, where servers are rated according to the number of current connections. However, with the Predictive methods, Local Traffic Manager analyzes the trend of the ranking over time, determining whether a node’s performance is currently improving or declining. The servers with performance rankings that are currently improving, rather than declining, receive a higher proportion of the connections.
&
The need for the Predictive methods is rare, and they are not recommend for large pools.
\\
\hline
Least Sessions
&
The Least Sessions method selects the server that currently has the least number of entries in the persistence table. Use of this load balancing method requires that the virtual server reference a type of profile that tracks persistence connections, such as the Source Address Affinity or Universal profile type.

\sphinxstylestrong{Note:} The Least Sessions methods are incompatible with cookie persistence.
&
The Least Sessions method works best in environments where the servers or other equipment that you are load balancing have similar capabilities.
\\
\hline
Ratio Least Connections
&
The Ratio Least Connections methods cause the system to select the pool member according to the ratio of the number of connections that each pool member has active.
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.19 - Describe how to deploy and modify applications using existing and/or updated iApp application templates}
\label{\detokenize{class5/modules/module1:objective-1-19-describe-how-to-deploy-and-modify-applications-using-existing-and-or-updated-iapp-application-templates}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.19 - (Supplemental Example) Describe how to deploy and modify applications using existing and/or updated iApp application templates}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-iapps-developer-11-4-0/2.html}

iApps is the BIG-IP system framework for deploying services-based,
template-driven configurations on BIG-IP systems running TMOS 11.0.0 and
later. iApps allows creation of application-centric configuration
interfaces on BIG-IP systems, reducing configuration time and increasing
accuracy of complex traffic management configurations.

\sphinxstylestrong{Deploying an application service}

The following procedure covers the minimum steps needed to deploy a
configuration using an iApps application service.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, expand iApp, and click Application Services.

\item {} 
Click Create.

\item {} 
In the Name field, type the name for your application service.

\item {} 
From the Template List menu, select a template for your application, and wait for the screen to automatically refresh.

\item {} 
Configure remaining settings as needed.

\item {} 
At the bottom of the screen click Finished to save your changes.

\item {} 
Wait for the application properties to load.

\item {} 
(Optional) In the Description field, enter information to describe this application service and click Update.

\end{enumerate}

Your application service is now deployed on the BIG-IP system.

\sphinxstylestrong{Modifying an application service}

The following procedure tells how to modify an existing application
service.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, expand iApp, and click Application Services.

\item {} 
From the Application Service List, select an application service to view.

\item {} 
Click the Reconfigure tab. The screen displays the settings for the application service.

\item {} 
Click the Components tab and use the components tree to view the components that belong to the application service.

\item {} 
Edit the fields that require modification and then click Finished to save your changes.

\end{enumerate}

The system saves the application service modifications and they are
ready to use.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.19 - Identify use cases for deploying application templates}

\sphinxurl{https://support.f5.com/csp/article/K13422}

\sphinxstylestrong{iApp templates}

Templates are normally named after the application for which they are
created.

An iApp template bundles the configuration options for a particular
application. Each iApp template is user-customizable and allows you to
easily edit the configuration it creates. Using an iApp template to
build your application-specific configuration reduces configuration
errors and can protect against accidental changes to the configuration,
making it simpler for you to manage the application.

The HTTP iApp template is common for most websites and web applications.

\sphinxstylestrong{Current F5 supported iApps}
\begin{itemize}
\item {} 
Acceleration Disable by Cookie

\item {} 
Citrix XenApp / XenDesktop

\item {} 
F5 Analytics

\item {} 
HTTP iApp template

\item {} 
Microsoft Active Directory Federation Services

\item {} 
Microsoft Dynamics CRM 2011 and 2013

\item {} 
Microsoft Exchange Server 2010 and 2013 Client Access servers

\item {} 
Microsoft Exchange 2016 Mailbox servers

\item {} 
Microsoft Lync Server 2010 and 2013

\item {} 
Microsoft Office 365 IdP

\item {} 
Microsoft Remote Desktop Gateway servers

\item {} 
Microsoft Remote Desktop Session Host servers

\item {} 
Microsoft SharePoint Server 2010 and 2013

\item {} 
NIST SP-800-53r4

\item {} 
SSL Intercept

\item {} 
VMware View and Horizon View

\end{itemize}

Note: F5 also supports all iApp templates that ship, by default, with
the BIG-IP system.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.19 - Describe how to locate, retrieve, and import new updated application templates}

\sphinxurl{https://support.f5.com/csp/article/K13422}

\sphinxstylestrong{Downloading and installing F5 supported iApp templates}

To download and install an iApp template, you can perform the following
procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Go to the F5 Downloads site.

\item {} 
From the Downloads Overview page, click Find a Download.

\end{enumerate}

The Select a Product Line page displays.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
From the Product Line column, select iApp-Templates.

\item {} 
Read the End User Software License Agreement and either accept the license by clicking I Accept, or cancel the process by clicking Cancel.

\end{enumerate}

If you accept the End User Software License Agreement, the Select a
Download page appears, which shows a table with the file name,
product description, and file size details.

Note: After you accept the End User Software License Agreement, the
system will not present the agreement again for subsequent downloads
that you perform during the same browser session.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
From the Filename column of the table, select the file named iapps-x.x.x.x.x.zip. For example, the file for the March 2017 iApp release is named iapps-1.0.0.444.0.zip. The Select a Download Method page appears.

\item {} 
F5 supports the FTP, HTTP, and HTTPS protocols for downloading files from F5. Select one of the three supported protocols listed by clicking the down arrow button.

\end{enumerate}

A pop-up window appears, prompting you to either open or save the file.

Note: Some browsers save the file to a default location. You can
review your specific browser’s documentation to change the default
location of where you want to save files.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{6}
\item {} 
Select the option to save the file.

\item {} 
Unzip the zip file to a location accessible from your BIG-IP system.

\item {} 
Log in to the BIG-IP Configuration utility.

\item {} 
From the iApp tab, select Templates.

\item {} 
Click Import.

\item {} 
Select the Overwrite Existing Templates box.

\item {} 
Click Browse.

\item {} 
Browse to the location where you saved the iApp file.

\item {} 
Select the file that corresponds to the iApp version you want to install.

\item {} 
Click Upload.

\end{enumerate}

When the upload completes, the iApp is available for use.

\sphinxstylestrong{F5 Release Candidate iApp templates}

Release Candidate iApp templates are included in the RELEASE\_CANDIDATES
directory of the iApp package. The Release Candidate iApp templates are
created, tested, and supported by F5. However, the templates differ from
the official F5-supported iApps (those found in the root directory of
the iApp package) in the following ways:

While Release Candidate iApp templates have been tested by F5 engineers,
the templates have not yet passed the extensive automated test suite
required to achieve the official F5-supported iApp status.

Release Candidate iApp templates are supported by F5 only until an
official F5-supported iApp template is provided. Once an official
F5-supported iApp template is available, any previous Release Candidate
versions of the iApp template will no longer be supported. The official
F5-supported iApp templates are supported according to K8986: F5
software support life cycle policy.

Release Candidate iApp templates are not archived. Once an official
F5-supported iApp template is provided, the Release Candidate version is
removed from the iApp package.

Note: The previous versions directory of the iApp package contains only
previous versions of F5-supported iApp templates.

\sphinxstylestrong{F5-contributed iApp templates}

F5 creates and tests F5-contributed iApp templates; however, the
templates have not been subjected to thorough regression testing, and F5
does not offer technical support for the templates. For more
information, refer to the online Help and deployment guides. For a list
of the available F5-contributed iApps, refer to the F5 DevCentral
codeshare.

Note: A DevCentral login is required to access this content.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.19 - Describe how to update an existing application that was created from an iApp}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-iapps-developer-11-4-0/2.html}

\sphinxstylestrong{About the strict updates setting}

When you are working in the Application Services properties screen, and
select the Advanced view, the Strict Updates field is shown. Selecting
Strict Updates protects against accidental changes to an application
service’s configuration. The Strict Updates setting is on by default
when an application service is created.

Note: Unless you have a specific reason to turn off strict updates, F5
recommends that you leave the setting on. If you do turn strict updates
off, we do not recommend using Template reentrancy (discussed in the
iApps Template Authoring chapter).

When the strict updates setting is enabled, users can control only
objects that are exposed through the templates.

Note: Even with strict updates enabled, it is possible to enable and
disable some objects using interfaces (such as tmsh or the Configuration
utility) other than the reentrant template. These objects include:
\begin{itemize}
\item {} 
nodes

\item {} 
pool members

\item {} 
virtual addresses

\item {} 
virtual servers

\end{itemize}

\sphinxstylestrong{Deploying an application service}

The following procedure covers the minimum steps needed to deploy a
configuration using an iApps application service.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, expand iApp, and click Application Services.

\item {} 
Click Create.

\item {} 
In the Name field, type the name for your application service.

\item {} 
From the Template List menu, select a template for your application, and wait for the screen to automatically refresh.

\item {} 
Configure remaining settings as needed.

\item {} 
At the bottom of the screen click Finished to save your changes.

\item {} 
Wait for the application properties to load.

\item {} 
(Optional) In the Description field, enter information to describe this application service and click Update.

\end{enumerate}

Your application service is now deployed on the BIG-IP system.

\sphinxstylestrong{Modifying an application service}

The following procedure tells how to modify an existing application
service.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, expand iApp, and click Application Services.

\item {} 
From the Application Service List, select an application service to view.

\item {} 
Click the Reconfigure tab. The screen displays the settings for the application service.

\item {} 
Click the Components tab and use the components tree to view the components that belong to the application service.

\item {} 
Edit the fields that require modification and then click Finished to save your changes.

\end{enumerate}

The system saves the application service modifications and they are
ready to use.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 2 - Set-up, administer, and secure LTM devices}
\label{\detokenize{class5/modules/module2:section-2-set-up-administer-and-secure-ltm-devices}}\label{\detokenize{class5/modules/module2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.01 Distinguish between the management interface configuration and application traffic interface configuration}
\label{\detokenize{class5/modules/module2:objective-2-01-distinguish-between-the-management-interface-configuration-and-application-traffic-interface-configuration}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Explain the requirements for management of the LTM devices}

\sphinxurl{https://support.f5.com/csp/article/K7312?sr=29126873}

\sphinxstylestrong{LTM Management}

The BIG-IP can be managed through either the TMM switch interfaces or
the MGMT interface. However, F5 recommends that you use the management
port.

The TMM switch ports are the interfaces that the BIG-IP system uses to
send and receive load-balanced traffic.

The system uses the MGMT interface to perform system management
functions. The MGMT interface is intended for administrative traffic and
cannot be used for load-balanced traffic. Additionally, since no access
controls can be applied on the MGMT interface, F5 recommends that you
limit network access through the MGMT interface to trusted traffic. For
security reasons, the MGMT interface should be connected to only a
secure, management-only network, such as one that uses an RFC1918
private IP address space. If you do not have a trusted and secure
management network, F5 recommends that you do not use the MGMT
interface, and that you grant administrative access through the TMM
switch interfaces or the local serial console.

Note: In BIG-IP versions earlier than 11.2.0, you must assign an IPv4
address to the management port. Beginning in BIG-IP 11.2.0, you can
assign either an IPv4 or IPv6 to the management port.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/f5-plat-hw-essentials/1.html}

\sphinxstylestrong{Serial Console Connection}

In the event that network access is impaired or not yet configured, the
serial console might be the only way to access your BIG-IP® system.

Important: You should perform all BIG-IP software installations and
upgrades using the serial console, as these procedures require reboots,
in which network connectivity is lost temporarily.

Note: If you cannot see or read output on the serial console, make sure
that the baud rate is set to 19200.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Explain the differences between the flow of management and application traffic}

\sphinxurl{https://support.f5.com/csp/article/K7312}

The BIG-IP system uses the following two network connection entry
points:
\begin{itemize}
\item {} 
Traffic Management Microkernel (TMM) switch interfaces

\item {} 
Management interface

\end{itemize}

Either the TMM switch interfaces or the management interface can provide
administrative access to the BIG-IP system. However, F5 recommends that
you use the management interface.

The TMM switch ports are the interfaces that the BIG-IP system uses to
send and receive load-balanced traffic.

The system uses the management interface to perform system management
functions. The management interface is intended for administrative
traffic and cannot be used for load-balanced traffic. Additionally,
since there are limited access controls that can be applied to the
management interface, F5 recommends that you limit network access
through the management interface to trusted traffic. For security
reasons, the management interface should only be connected to a secure,
management-only network, such as one that uses an RFC1918 private IP
address space. If you do not have a trusted and secure management
network, F5 recommends that you do not use the management interface and
that you grant administrative access through the TMM switch interfaces
or the local serial console.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Explain how to configure management connectivity options: AOM, serial console, USB \& Management Ethernet Port}

\sphinxurl{https://support.f5.com/csp/article/K13117?sr=42528406}

\sphinxstylestrong{USB}

On rare occasions, you may be required to perform a clean installation
of BIG-IP 11.x. During a clean installation, all mass-storage devices
are wiped, therefore restoring the BIG-IP system to its factory
defaults. In addition, a clean installation allows you to reinstall a
BIG-IP unit that no longer boots from any of its boot locations.

You should choose an installation method based on the equipment
available to you, and whether you have physical access to the system
that requires reinstalling. Choose one of the following installation
methods, which are listed in order of preference:

USB DVD-ROM drive

Note: F5 recommends that you perform a clean installation by using a
USB DVD-ROM drive, as this is the simplest and most reliable of all
the installation methods.

USB thumb drive

Burn the product ISO image to a DVD.

Image the USB thumb drive using the product ISO image file.

\sphinxstylestrong{Installing the software}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Connect to the BIG-IP system serial console.

\item {} 
Depending on the choice you made in the previous procedure, perform one of the following actions:
\begin{itemize}
\item {} 
Connect the USB DVD-ROM drive to the F5 system and load the disc you burned with the product ISO image.

\item {} 
Connect the USB thumb drive to the F5 system.

\end{itemize}

\item {} 
Reboot the BIG-IP system. If the F5 system cannot reboot, power cycle the BIG-IP system.

\end{enumerate}

Note: Upon completion of this step, regardless of the installation
method, the BIG-IP system boots into the Maintenance Operating
System (MOS).
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
The MOS asks you to specify the type of terminal you are using. If you do not know what to specify, press Enter. The default setting (vt100) is fine in most cases.

\item {} 
If you have booted the F5 system from a USB device, the system may display a manufacturing installation dialog.

\item {} 
Press Ctrl+C to exit the dialog.

\item {} 
Continue with step 8 if you have booted the F5 system from a USB removable media containing a BIG-IP 11.0.0 image, but you want to perform a custom installation using the diskinit and image2disk utilities. Otherwise, to reinstall the system according to the manufacturing installation plan displayed in the output, press Enter and skip to step 10.

\end{enumerate}

7. To wipe all mass-storage devices inside the BIG-IP system, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{diskinit} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{style} \PYG{n}{volumes}
\end{sphinxVerbatim}

Important: Do not omit the \textendash{}style option; if you omit it, the
system wipes the drives but does not reformat them.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{7}
\item {} 
The diskinit utility asks whether you want to proceed wiping the drives. To continue, type y and press Enter. Otherwise, type n and press Enter.

\end{enumerate}

\sphinxstyleemphasis{Important}: Confirming this operation destroys all data on the
system. Do not proceed with this step if you have data that needs to
be recovered from the system. Using the MOS, you may be able to
manually mount a partition or volume and recover such data.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{8}
\item {} 
Install the software using one of the following methods:

\end{enumerate}

If you are using a USB DVD-ROM drive or a USB thumb drive, use the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{image2disk} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{volumes} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosaveconfig} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosavelicense}
\end{sphinxVerbatim}

If you are using a PXE server, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{image2disk} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{volumes} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosaveconfig} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosavelicense}
\PYG{n}{http}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{SERVER\PYGZus{}IP}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{PATH}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

For example, to install BIG-IP 11.x on HD1.1 using the http server
configured in the previous procedure, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{image2disk} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{volumes} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosaveconfig} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{nosavelicense}
\PYG{n}{http}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{l+m+mf}{192.168}\PYG{o}{.}\PYG{l+m+mf}{1.1}\PYG{o}{/}\PYG{n}{SOL13117}
\end{sphinxVerbatim}

Note: BIG-IP 11.x cannot be installed on a CompactFlash media drive;
you must use boot locations on the system’s hard drive.

Note: You must specify the \textendash{}nosaveconfig option, as the system does
not have a configuration to save.

Note: If you are using a USB DVD-ROM drive or a USB thumb drive, you
do not need to specify an installation repository, as the image2disk
utility automatically finds and defaults to /cdserver.

Note: For more information about the image2disk utility, refer to
the Help screen by using the image2disk \textendash{}h command.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
Once the installation has completed, disconnect any removable media from the BIG-IP system.

\end{enumerate}

11. To restart the system, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{reboot}
\end{sphinxVerbatim}

The system boots from the location you have just reinstalled.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K7683?sr=42527838}

\sphinxstylestrong{Serial Console}

You can administer a BIG-IP system by using a null modem cable to
connect a management system that runs a terminal emulator program to the
BIG-IP serial port. To connect to the BIG-IP system using the serial
port, you must have a DB9 null modem cable and a VT100-capable terminal
emulator available on the management system.

To configure a serial terminal console for the BIG-IP system, perform
the following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Connect the null modem cable to the console port on the BIG-IP system.

\item {} 
Connect the null modem cable to a serial port on the management system with the terminal emulator.

\item {} 
Configure the serial terminal emulator settings according to the following table:

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Setting}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Value}
\\
\hline
Bits per second {[}baud{]}
&
19200
\\
\hline
Data bits
&
8
\\
\hline
Parity
&
None
\\
\hline
Stop bit
&
1
\\
\hline
Flow control
&
None
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Turn on the BIG-IP system.

\end{enumerate}

When the BIG-IP system starts up with the console working correctly, the
system start-up sequence displays, and then the sequence completes with
a BIG-IP system login prompt. If garbled text displays on the console,
you may be required to change the baud of the serial console port using
the LCD panel on the BIG-IP system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K15040?sr=42528282}

\sphinxstylestrong{Management Ethernet Port}

The management port on a BIG-IP system provides administrative access to
the system out-of-band of the application traffic. This allows you to
restrict administrative access to an internal secure network. You can
display and configure the management IP address for the BIG-IP system
using the Configuration utility, the command line, and the LCD panel.

\sphinxstylestrong{Configuring the management IP address using the Configuration utility,
command line, or LCD panel}

You can configure the management IP address using the Configuration
utility, the tmsh utility, the config command, or the LCD panel. To do
so, perform one of the following procedures:

Impact of procedure: Changing the management IP address will disconnect
you from the BIG-IP system if you are connected through the management
port.

\sphinxstylestrong{Configuring the management IP address using the Configuration utility}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to System \textgreater{} Platform.

\item {} 
In the Management Port section, configure the IP address, network mask, and management route.

\item {} 
To save the changes, click Update.

\end{enumerate}

\sphinxstylestrong{Configuring the management IP address using the tmsh utility}

1. Log in to the Traffic Management Shell (tmsh) by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh}
\end{sphinxVerbatim}

2. To configure the management IP address, use the following syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{ip} \PYG{p}{[}\PYG{n}{ip} \PYG{n}{address}\PYG{o}{/}\PYG{n}{netmask}\PYG{p}{]}

\PYG{o+ow}{or}

\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{ip} \PYG{p}{[}\PYG{n}{ip} \PYG{n}{addres}\PYG{o}{/}\PYG{n}{prefixlen}\PYG{p}{]}

\PYG{n}{For} \PYG{n}{example}\PYG{p}{:}

\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{ip} \PYG{l+m+mf}{192.168}\PYG{o}{.}\PYG{l+m+mf}{1.245}\PYG{o}{/}\PYG{l+m+mf}{255.255}\PYG{o}{.}\PYG{l+m+mf}{255.0}

\PYG{o+ow}{or}

\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{ip} \PYG{l+m+mf}{192.168}\PYG{o}{.}\PYG{l+m+mf}{1.245}\PYG{o}{/}\PYG{l+m+mi}{24}
\end{sphinxVerbatim}

3. To configure a default management gateway, use the following syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{route} \PYG{n}{default} \PYG{n}{gateway} \PYG{o}{\PYGZlt{}}\PYG{n}{gateway} \PYG{n}{ip} \PYG{n}{address}\PYG{o}{\PYGZgt{}}

\PYG{n}{For} \PYG{n}{example}\PYG{p}{:}

\PYG{n}{create} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{management}\PYG{o}{\PYGZhy{}}\PYG{n}{route} \PYG{n}{default} \PYG{n}{gateway} \PYG{l+m+mf}{192.168}\PYG{o}{.}\PYG{l+m+mf}{1.254}
\end{sphinxVerbatim}

4. Save the changes by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{save} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{config} \PYG{n}{partitions} \PYG{n+nb}{all}
\end{sphinxVerbatim}

\sphinxstylestrong{Configuring the management IP address using the config command}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line of the BIG-IP system.

\end{enumerate}

2. Enter the F5 Management Port Setup Utility by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{config}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
To configure the management port, type the appropriate IP address, netmask, and management route in the screens that follow.

\end{enumerate}

\sphinxstylestrong{Configuring the management IP address using the LCD panel}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Press the X button to activate Menu mode for the LCD.

\item {} 
Use the arrow keys to select System, and press the Check button.

\item {} 
To select Management, press the Check button.

\item {} 
To select Mgmt IP, press the Check button.

\item {} 
Enter your management IP address using the arrow keys, and press the Check button.

\item {} 
Use the arrow keys to select Mgmt Mask, and press the Check button.

\item {} 
Enter the netmask using the arrow keys, and press the Check button.

\item {} 
Use the arrow keys to select Mgmt Gateway, and press the Check button.

\item {} 
Enter your default route using the arrow keys, and press the Check button.

\end{enumerate}

If you do not have a default route, enter 0.0.0.0.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
Use the arrow keys to select Commit, and press the Check button.

\item {} 
To select OK, press the Check button.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K14595}

\sphinxstylestrong{AOM}

Always-On Management (AOM) is a separate subsystem that provides
lights-out management for the BIG-IP system by using the 10/100/1000
Ethernet management port over secure shell (SSH), or by using the serial
console.

AOM allows you to manage BIG-IP platforms using SSH (most platforms) or
the serial console, even if the Host subsystem is turned off. The BIG-IP
Host subsystem and the AOM subsystem operate independently. If AOM is
reset or fails, the BIG-IP Host subsystem continues to operate and there
is no interruption to load-balanced traffic. AOM is always turned on
when power is supplied to the platform. If the BIG-IP Host subsystem
stops responding, you can use the AOM Command Menu to reset it.

\sphinxstylestrong{Configuring AOM network access}

To configure AOM so that it can be accessed over the network, perform
the following procedure:

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Connect the serial console to the CONSOLE port.

\end{enumerate}

2. Display the AOM command menu by typing the following key sequence:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Esc} \PYG{p}{(}
\end{sphinxVerbatim}

The AOM command menu displays as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{AOM} \PYG{n}{Command} \PYG{n}{Menu}\PYG{p}{:}

\PYG{n}{B} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Set} \PYG{n}{console} \PYG{n}{baud} \PYG{n}{rate}

\PYG{n}{I} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Display} \PYG{n}{platform} \PYG{n}{information}

\PYG{n}{P} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Power} \PYG{n}{on}\PYG{o}{/}\PYG{n}{off} \PYG{n}{host} \PYG{n}{subsystem}

\PYG{n}{R} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Reset} \PYG{n}{host} \PYG{n}{subsystem}

\PYG{n}{N} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Configure} \PYG{n}{AOM} \PYG{n}{network}

\PYG{n}{S} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Configure} \PYG{n}{SSH} \PYG{n}{Server}

\PYG{n}{A} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Reset} \PYG{n}{AOM}

\PYG{n}{E} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Error} \PYG{n}{report}

\PYG{n}{Q} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}} \PYG{n}{Quit} \PYG{n}{menu} \PYG{o+ow}{and} \PYG{k}{return} \PYG{n}{to} \PYG{n}{console}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
To configure network access, press the N key.

\end{enumerate}

The AOM management network configurator screen appears.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Complete the network configurator screens.

\end{enumerate}

\sphinxstyleemphasis{Important}: The AOM IP address must be different than the BIG-IP
management address, but on the same IP subnet.

To disable the network configuration, re-run the N —Configure AOM
network option, and enter 0.0.0.0 for the IP address.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.02 Given a network diagram, determine the appropriate network and system settings (i.e., VLANs, selfIPs, trunks, routes, NTP servers, DNS servers, SNMP receivers and syslog servers)}
\label{\detokenize{class5/modules/module2:objective-2-02-given-a-network-diagram-determine-the-appropriate-network-and-system-settings-i-e-vlans-selfips-trunks-routes-ntp-servers-dns-servers-snmp-receivers-and-syslog-servers}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Explain the requirements for self IPs (including port lockdown)}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/13.html}

\sphinxstylestrong{Self IPs}

It is when you initially run the Setup utility on a BIG-IP system that
you normally create any static and floating self IP addresses and assign
them to VLANs. However, if you want to create additional self IP
addresses later, you can do so using the Configuration utility.

Note: Only users with either the Administrator or Resource
Administrator user role can create and manage self IP addresses.

Note: A self IP address can be in either IPv4 or IPv6 format.

\sphinxstylestrong{IP address}

A self IP address, combined with a netmask, typically represents a range
of host IP addresses in a VLAN. If you are assigning a self IP address
to a VLAN group, the self IP address represents the range of self IP
addresses assigned to the VLANs in that group.

\sphinxstylestrong{Netmask}

When you specify a netmask for a self IP address, the self IP address
can represent a range of IP addresses, rather than a single host
address. For example, a self IP address of 10.0.0.100 can represent
several host IP addresses if you specify a netmask of 255.255.0.0.

\sphinxstylestrong{VLAN/Tunnel assignment}

You assign a unique self IP address to a specific VLAN or a VLAN group:
\begin{itemize}
\item {} 
Assigning a self IP address to a VLAN

\end{itemize}

The self IP address that you assign to a VLAN should represent an
address space that includes the self IP addresses of the hosts that
the VLAN contains. For example, if the address of one destination
server in a VLAN is 10.0.0.1 and the address of another server in
the VLAN is 10.0.0.2, you could assign a self IP address of
10.0.0.100, with a netmask of 255.255.0.0, to the VLAN.
\begin{itemize}
\item {} 
Assigning a self IP address to a VLAN group

\end{itemize}

The self IP address that you assign to a VLAN group should represent
an address space that includes the self IP addresses of the VLANs
that you assigned to the group. For example, if the self IP address
of one VLAN in a VLAN group is 10.0.20.100 and the address of the
other VLAN in a VLAN group is 10.0.30.100,you could assign an
address of 10.0.0.100, with a netmask of 255.255.0.0, to the VLAN
group.

The VLAN/Tunnel list in the BIG-IP Configuration utility displays the
names of all existing VLANs and VLAN groups.

\sphinxstylestrong{Port lockdown}

Each self IP address has a feature known as port lockdown. Port lockdown
is a security feature that allows you to specify particular UDP and TCP
protocols and services from which the self IP address can accept
traffic. By default, a self IP address accepts traffic from these
protocols and services:
\begin{itemize}
\item {} 
For UDP, the allowed protocols and services are: DNS (53), SNMP
(161), RIP (520)

\item {} 
For TCP, the allowed protocols and services are: SSH (22), DNS (53),
SNMP (161), HTTPS (443), 4353 (iQuery)

\end{itemize}

If you do not want to use the default setting (Allow Default), you can
configure port lockdown to allow either all UDP and TCP protocols and
services (Allow All), no UDP protocols and services (Allow None), or
only those that you specify (Allow Custom).

\sphinxstylestrong{Traffic groups}

If you want the self IP address to be a floating IP address, that is, an
address shared between two or more BIG-IP devices in a device group, you
can assign a floating traffic group to the self IP address. A floating
traffic group causes the self IP address to become a floating self IP
address.

A floating self IP address ensures that application traffic reaches its
destination. More specifically, a floating self IP address enables a
source node to successfully send a request, and a destination node to
successfully send a response, when the relevant BIG-IP device is
unavailable.

If you want the self IP address to be a static (non-floating) IP address
(used mostly for standalone devices), you can assign a non-floating
traffic group to the self IP address. A non-floating traffic group
causes the self IP address to become a non-floating self IP address. An
example of a non-floating self IP address is the address that you assign
to the default VLAN named HA, which is used strictly to process failover
communications between BIG-IP devices, instead of processing application
traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Explain routing requirements for management and application traffic (including route domains and IPv6)}

\sphinxurl{https://support.f5.com/csp/article/K13284?sr=42499558}

The Traffic Management Microkernel (TMM) controls all of the BIG-IP
switch ports (TMM interfaces), and the underlying Linux operating system
controls the BIG-IP management interface. The management interface
processes only administrative traffic. The TMM interfaces process both
application traffic and administrative traffic.

Inbound administrative traffic

The Linux operation system processes inbound traffic sent to the BIG-IP
management IP address and arriving on the management interface. Inbound
connections sent to the BIG-IP self IP addresses that arrive on a TMM
interface are processed by TMM. If the self IP address is configured to
allow a connection to the destination service port, TMM hands the
connection off to the Linux operating system, which then processes the
connection request. By default, the BIG-IP system uses Auto Last Hop to
return response traffic to a remote host. Auto Last Hop returns response
traffic to the MAC address of the device from which the traffic last
traversed before reaching the BIG-IP system.

Note: Beginning in BIG-IP 14.1.0, the Auto Last Hop feature is no longer
available on the BIG-IP management interface. For more information,
refer to K55225090: BIG-IP VE no longer supports Auto Last Hop for
management connections.

Outbound administrative traffic

The Linux operating system processes outbound traffic sent from the
BIG-IP system by administrative applications, such as SNMP, SMTP, SSH,
and NTP. These connections may use either the management address or a
self IP address as the source address. The BIG-IP system compares the
destination address to the routing table to determine the interface
through which the BIG-IP system routes the traffic.

BIG-IP routing tables

The BIG-IP routing table consists of a combination of routing subtables.
A subtable for management routes, and a subtable for TMM routes. Routes
in the TMM subtable are defined with a lower metric than routes in the
management subtable. As a result, if an equally specific route exists as
both a TMM route and a management route, the system will prefer the TMM
route. This also applies if the only defined management route is a
default gateway, the system will prefer the TMM default gateway.

TMM switch routes are routes that the BIG-IP system uses to forward
traffic through the TMM switch interfaces instead of through the
management interface. Traffic sourced from a TMM (self IP) address will
always use the most specific matching TMM route. Traffic sourced from a
TMM address will never use a management route. When TMM is not running,
the TMM addresses are not available, and all TMM routes are removed. As
a result, when TMM is not running, all outbound administrative traffic
uses the most specific matching management route.

The BIG-IP system uses management routes to forward traffic through the
management interface.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K84417414}

\sphinxstylestrong{Route domains}

Route domains are designed to overcome the problem of overlapping
network IP address spaces. Because of this design, forwarding traffic
between route domains is limited.

Description

One intended route domain implementation would be when the BIG-IP system
hosts multiple tenants that use the same private IP address space to
configure their networking devices. In this case, route domains allow
the hosting BIG-IP system to use the same IP address space for multiple
tenants, while preventing direct access between the tenants.

You can allow access between route domains in a limited capacity by
using parent-child relationships and strict isolation.

Parent-child relationship

When you create a route domain, you can associate a parent route domain.
When the BIG-IP system is unable to find a necessary route in the child
domain, the system can then search an associated parent route domain for
a possible route. The default associated route domain is None.

Strict isolation

When enabled, strict isolation specifies whether the system enforces
cross-routing restrictions. When enabled, routes cannot cross-route
domain boundaries; they are strictly isolated to the current route
domain. The default setting is Enabled. When disabled, a route can
cross-route domains. For example, you can add a route to the routing
table where the destination is 10.0.0.0\%20 (route domain 20) and the
gateway is 172.27.84.29\%32 (route domain 32).

Note: When strict isolation is enabled on a route domain, the BIG-IP
system allows traffic forwarding from that route domain to the specified
parent route domain only. To enforce strict isolation between
parent-child route domains, you must enable the strict isolation feature
on both the child and the parent route domains.

VLANs

Route domains may not be the proper choice if the intended use does not
involve overlapping IP address spaces. Virtual Local Area Networks
(VLAN) serve as a logical separation of hosts using the same IP address
space. Unlike route domains, the BIG-IP system can forward traffic
between VLANs with simple modifications to the routing table.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K7267}

\sphinxstylestrong{IPV6}

The BIG-IP is a native IPV6 device.

In BIG-IP versions prior to 11.0.0, there is no option in the
Configuration utility to specify an IPv6 default route. The default
configuration when creating network routes on the BIG-IP system is for
IPv4. To specify a default route for an IPv6 address, you must specify
both a destination network that uses the route, and a netmask value.
Otherwise, the route will be added to the BIG-IP system configuration as
an IPv4 default route pointing to an IPv6 gateway.

To specify an IPv6 default route on the BIG-IP system using the
Configuration utility, perform the following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to Network \textgreater{} Routes.

\item {} 
Click Add.

\item {} 
From the Type menu, click Route.

\item {} 
Specify :: as the Destination.

\item {} 
Specify :: as the Netmask.

\item {} 
From the Resource list, click Use Gateway.

\item {} 
In the box, type the IPv6 IP address.

\item {} 
Click Finished.

\end{enumerate}

To specify an IPv6 default route on the BIG-IP system using the Traffic
Management Shell (tmsh), perform the following procedure:

1. Log in to the tmsh utility by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh}
\end{sphinxVerbatim}

2. Create the IPv6 default route using the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{o}{/}\PYG{n}{net} \PYG{n}{route} \PYG{n}{default}\PYG{o}{\PYGZhy{}}\PYG{n}{inet6} \PYG{n}{gw} \PYG{o}{\PYGZlt{}}\PYG{n}{ipv6} \PYG{n}{gw} \PYG{n}{address}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

Note: A corresponding self IP address residing in the same network
of the IPv6 gateway must exist to create the IPv6 route gateway.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{For} \PYG{n}{example}\PYG{p}{:}

\PYG{n}{create} \PYG{o}{/}\PYG{n}{net} \PYG{n}{route} \PYG{n}{default}\PYG{o}{\PYGZhy{}}\PYG{n}{inet6} \PYG{n}{gw} \PYG{n}{fd00}\PYG{p}{:}\PYG{l+m+mi}{9}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{2}
\end{sphinxVerbatim}

3. Save the configuration changes by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{save} \PYG{o}{/}\PYG{n}{sys} \PYG{n}{config}
\end{sphinxVerbatim}

4. To exit the tmsh utility, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{quit}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Explain the effect of system time on LTM devices}

\sphinxurl{https://support.f5.com/csp/article/K10240?sr=29127185}

\sphinxstylestrong{NTP}

Having the correct system time set on your BIG-IP devices is critical
for many different administrative functions. Time stamping for logging
is all based on system time. SSL certificates could have issues with the
expiration dates. In HA environments if the system time is not set
correctly between the units in the HA configuration the systems may not
be able to sync configs.

When the BIG-IP system clock is not showing the correct timezone, or the
date and time is not synchronized correctly, this could be caused by
incorrect NTP configuration or a communication issue with a valid NTP
peer server. Remember that even if you have the NTP settings correct in
the BIG-IP system it may not be able to reach the NTP if there is an
up-stream Firewall or other network restrictions.

\sphinxstylestrong{Network Time Protocol (NTP)}

NTP is a protocol for synchronizing the clocks of computer systems over
the network. On BIG-IP systems, accurate timestamps are essential to
guarantee the correct behavior of a number of features. While in most
cases it is sufficient to configure a couple of time servers that the
BIG-IP system will use to update its system time, it is also possible to
define more advanced NTP configurations on the BIG-IP system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.03 Explain how to configure remote authentication and multiple administration roles on the LTM device}
\label{\detokenize{class5/modules/module2:objective-2-03-explain-how-to-configure-remote-authentication-and-multiple-administration-roles-on-the-ltm-device}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Explain the mapping between remote users and remote role groups}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-implementations-11-5-0/29.html}

\sphinxstylestrong{Remote authentication and authorization of BIG-IP user accounts}

The BIG-IP system includes a comprehensive solution for managing BIG-IP
administrative accounts on your network. With this solution, you can:

\sphinxstylestrong{Use a remote server to store BIG-IP system user accounts.}

The BIG-IP system includes support for using a remote authentication
server to store BIG-IP system user accounts. After creating BIG-IP
system accounts on the remote server (using the server vendor’s
instructions), you can configure the BIG-IP system to use remote user
authentication and authorization (access control) for that server type.

\sphinxstylestrong{Assign group-based access.}

The BIG-IP system includes an optional feature known as remote role
groups. With the remote role groups feature, you can use existing group
definitions on the remote server to define the access control properties
for users in a group. This feature not only provides more granularity in
assigning user privileges, but also removes any need to duplicate remote
user accounts on the BIG-IP system for the purpose of assigning those
privileges.

\sphinxstylestrong{Propagate a set of authorization data to multiple BIG-IP systems.}

The BIG-IP system includes a tool for propagating BIG-IP system
configuration data to multiple BIG-IP devices on the network. This tool
is known as the Single Configuration File (SCF) feature.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Explain the options for partition access and terminal access}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/10.html\#unique\_1660055220}

\sphinxstylestrong{Partition Access}

A user role defines the access level that a user has for each object in
the users assigned partition. An access level refers to the type of task
that a user can perform on an object. Possible access levels are:
\begin{itemize}
\item {} 
Write

\end{itemize}

Grants full access, that is, the ability to create, modify, enable and disable, and delete an object.
\begin{itemize}
\item {} 
Update

\end{itemize}

Grants the ability to modify, enable, and disable an object.
\begin{itemize}
\item {} 
Enable/disable

\end{itemize}

Grants the ability to enable or disable an object.
\begin{itemize}
\item {} 
Read

\end{itemize}

Grants the ability to view an object.

\sphinxstylestrong{Terminal Access}

Specifies the level of access to the BIG-IP system command line
interface. Possible values are: Disabled and Advanced shell.

Users with the Administrator or Resource Administrator role assigned to
their accounts can have advanced shell access, that is, permission to
use all BIG-IP system command line utilities, as well as any Linux
commands.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.04 Explain the uses of administrative partitions}
\label{\detokenize{class5/modules/module2:objective-2-04-explain-the-uses-of-administrative-partitions}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Explain the relationship between route domains, user roles and administrative partitions}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/10.html\#unique\_1327994881}

\sphinxstylestrong{Administrative partitions}

When you create configurable objects for the BIG-IP system, you have the
option of putting those objects into administrative partitions. An
administrative partition is a logical container of BIG-IP system objects
such as virtual servers, pools, and monitors. When you first install the
BIG-IP system, a default partition already exists named Common.

By putting objects into partitions, you establish a finer granularity of
access control. Rather than having control over all resources on the
BIG-IP system or no resources whatsoever, users with certain permissions
can control resources within a designated partition only. For example,
users with the role of Operator can mark nodes up or down, but can only
mark those nodes that reside within their designated partition.

User accounts are another type of object that you can put into a
partition. You put user accounts into administrative partitions strictly
for the purpose of giving other users administrative access to those
accounts. For example, you can put user accounts into partition B, and
then assign a set of permissions (known as a user role) to user Jane so
that she is allowed to modify user accounts in partition B.

Each user account on the BIG-IP system has a property known as Partition
Access. The Partition Access property defines the partitions that the
user can access. A user account can have access to either one partition
or all partitions. Access to all partitions is known as universal
access.

This figure shows how partition access can differ for different user
accounts on the BIG-IP system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p82}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

In this example, the BIG-IP system objects reside in multiple
partitions. Note that user accounts are also a type of BIG-IP system
object, and as such, reside in a partition named Users. (Although you
are not required to group user accounts together in a separate
partition, for security purposes F5 highly recommends that you
do so.)

To continue with the example, each user account in partition Users has
access to specific, but different, partitions. Note that user accounts
sjones, cjohnson, and gnelson can access one partition only, while the
tbrown account has universal access.

To summarize, an administrative partition defines a set of objects,
including user accounts, that other administrative users can potentially
manage. This gives computing organizations greater control over user
access to specific objects on the BIG-IP system.

\sphinxstylestrong{Effect of user roles on objects within partitions}

A user role defines the access level that a user has for each object in
the user’s assigned partition. An access level refers to the type of
task that a user can perform on an object. Possible access levels are:

\sphinxstylestrong{Write}

Grants full access: that is, the ability to create, modify, enable and
disable, and delete an object.

\sphinxstylestrong{Update}

Grants the ability to modify, enable, and disable an object.

\sphinxstylestrong{Enable/disable}

Grants the ability to enable or disable an object.

\sphinxstylestrong{Read}

Grants the ability to view an object.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Explain the options for partition access and terminal access}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/10.html\#unique\_1660055220}

\sphinxstylestrong{Partition Access}

A user role defines the access level that a user has for each object in
the users assigned partition. An access level refers to the type of task
that a user can perform on an object. Possible access levels are:
\begin{itemize}
\item {} 
Write

\end{itemize}

Grants full access, that is, the ability to create, modify, enable and disable, and delete an object.
\begin{itemize}
\item {} 
Update

\end{itemize}

Grants the ability to modify, enable, and disable an object.
\begin{itemize}
\item {} 
Enable/disable

\end{itemize}

Grants the ability to enable or disable an object.
\begin{itemize}
\item {} 
Read

\end{itemize}

Grants the ability to view an object.

\sphinxstylestrong{Terminal Access}

Specifies the level of access to the BIG-IP system command line
interface. Possible values are: Disabled and Advanced shell.

Users with the Administrator or Resource Administrator role assigned to
their accounts can have advanced shell access, that is, permission to
use all BIG-IP system command line utilities, as well as any Linux
commands.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.05 Given a scenario, determine an appropriate high availability configuration (i.e., failsafe, failover and timers)}
\label{\detokenize{class5/modules/module2:objective-2-05-given-a-scenario-determine-an-appropriate-high-availability-configuration-i-e-failsafe-failover-and-timers}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain how the score is calculated for HA groups}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-implementations-11-5-0/8.html}

\sphinxstylestrong{Specifying the HA capacity of a device}

Before you perform this task, verify that this device is a member of a
device group and that the device group contains three or more devices.

You perform this task when you have more than one type of hardware
platform in a device group and you want to configure load-aware
failover. Load-aware failover ensures that the BIG-IP system can
intelligently select the next-active device for each active traffic
group in the device group when failover occurs. As part of configuring
load-aware failover, you define an HA capacity to establish the amount
of computing resource that the device provides relative to other devices
in the device group.

Note: If all devices in the device group are the same hardware platform,
you can skip this task.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Devices. This displays a list of device objects discovered by the local device.

\item {} 
In the Name column, click the name of the device for which you want to view properties. This displays a table of properties for the device.

\item {} 
In the HA Capacity field, type a relative numeric value. You need to configure this setting only when you have varying types of hardware platforms in a device group and you want to configure load-aware failover. The value you specify represents the relative capacity of the device to process application traffic compared to the other devices in the device group.

\end{enumerate}

Important: If you configure this setting, you must configure the
setting on every device in the device group.

If this device has half the capacity of a second device and a third
of the capacity of a third device in the device group, you can
specify a value of 100 for this device, 200 for the second device,
and 300 for the third device. When choosing the next active device
for a traffic group, the system considers the capacity that you
specified for this device.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Click Update.

\end{enumerate}

After you perform this task, the BIG-IP system uses the HA Capacity
value to calculate the current utilization of the local device, to
determine the next-active device for failover of other traffic groups in
the device group.

\sphinxstylestrong{Specifying an HA load factor for a traffic group}

You perform this task when you want to specify the relative application
load for an existing traffic group, for the purpose of configuring
load-aware failover. Load-aware failover ensures that the BIG-IP system
can intelligently select the next-active device for each active traffic
group in the device group when failover occurs. When you configure
load-aware failover, you define an application traffic load (known as an
HA load factor) for a traffic group to establish the amount of computing
resource that an active traffic group uses relative to other active
traffic groups.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, click the name of a traffic group. This displays the properties of the traffic group.

\item {} 
From the Failover Methods list, select Load Aware. This displays the HA Load Factor setting.

\item {} 
In the HA Load Factor field, specify a value that represents the application load for this traffic group relative to other active traffic groups on the local device.

\end{enumerate}

Important: If you configure this setting, you must configure the
setting on every traffic group in the device group.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Click Update.

\end{enumerate}

After performing this task, the BIG-IP system uses the HA Load Factor
value as a factor in calculating the current utilization of the local
device, to determine whether this device should be the next-active
device for failover of other traffic groups in the device group.

\sphinxstylestrong{Implementation Results}

For this implementation example, the load-aware configuration now
consists of both a user-specified relative high availability (HA)
hardware capacity for each device and a relative load factor for each
active traffic group.

Using the example in the overview, devices Bigip\_A and Bigip\_B are the
same hardware platform and therefore have the same HA capacity, while
Bigip\_C has twice the HA capacity of the other two devices. Also,
devices Bigip\_A and Bigip\_B currently have one active traffic group
each, while Bigip\_C has two active traffic groups. All three traffic
groups process the same amount of application traffic.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p92}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Device utilization scores based on device capacity and traffic group
load

The device utilization score that the BIG-IP system calculates in this
implementation is the sum of all traffic load values on a device divided
by the device capacity.

Table 1. Calculating the utilization score for Bigip\_A


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
HA capacity
&\sphinxstyletheadfamily 
Active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Potential active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Device utilization score
\\
\hline
10
&
Traffic-group-1
&
1
&
Traffic-group-2
&
1
&
2/10 = .2
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table 2. Calculating the utilization score for Bigip\_B


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
HA capacity
&\sphinxstyletheadfamily 
Active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Potential active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Device utilization score
\\
\hline
10
&
Traffic-group-2
&
1
&
Traffic-group-3
&
1
&
2/10=.2
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table 3. Calculating the utilization score for Bigip\_C


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
HA capacity
&\sphinxstyletheadfamily 
Active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Potential active traffic group
&\sphinxstyletheadfamily 
HA load factor
&\sphinxstyletheadfamily 
Device utilization score
\\
\hline
20
&
Traffic-group-3 and Traffic-group-4
&
1 and 1
&
Traffic-group-1
&
1
&
3/20=.15
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

This example shows the results of the calculations that the BIG-IP
system performs for each device in the device group. The example shows
that although device Bigip\_C currently has the two active traffic
groups, the device has the most available resource due to having the
lowest utilization score of .15. In this case, Bigip\_C is most likely
the next-active device for the other two devices in the device group.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain the required objects on an HA pair}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-implementations-11-5-0/2.html}

\sphinxstylestrong{Configuration objects for HA}

The following BIG-IP configuration will be on each device of the HA
pair:
\begin{itemize}
\item {} 
A management port, management route, and administrative passwords defined.

\item {} 
A VLAN named internal, with one static and one floating IP address.

\item {} 
A VLAN named external, with one static and one floating IP address.

\item {} 
A VLAN named HA with a static IP address.

\item {} 
Configuration synchronization, failover, and mirroring enabled.

\item {} 
Failover methods of serial cable and network (or network-only, for a VIPRION platform.

\item {} 
A designation as an authority device, where trust was established with the peer device.

\item {} 
A Sync-Failover type of device group with two members defined.

\item {} 
A default traffic group that floats to the peer device to process application traffic when this device becomes unavailable. This traffic group contains two floating self IP addresses for VLANs internal and external.

\end{itemize}

On either device in the device group, you can create additional
configuration objects, such as virtual IP addresses and SNATs. The
system automatically adds these objects to Traffic-Group-1.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain how to configure device trust}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-implementations-11-5-0/3.html}

\sphinxstylestrong{Establishing device trust}

Before you begin this task, verify that:
\begin{itemize}
\item {} 
Each BIG-IP device that is to be part of the local trust domain has a device certificate installed on it.

\item {} 
The local device is designated as a certificate signing authority.

\end{itemize}

You perform this task to establish trust among devices on one or more
network segments. Devices that trust each other constitute the local
trust domain. A device must be a member of the local trust domain prior
to joining a device group.

By default, the BIG-IP software includes a local trust domain with one
member, which is the local device. You can choose any one of the BIG-IP
devices slated for a device group and log into that device to add other
devices to the local trust domain. For example, devices A, B, and C each
initially shows only itself as a member of the local trust domain. To
configure the local trust domain to include all three devices, you can
simply log into device A and add devices B and C to the local trust
domain. Note that there is no need to repeat this process on devices B
and C.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Device Trust, and then either Peer List or Subordinate List.

\item {} 
Click Add.

\item {} 
Type a device IP address, administrator user name, and administrator password for the remote BIG-IP device with which you want to establish trust. The IP address you specify depends on the type of BIG-IP device:

\end{enumerate}
\begin{itemize}
\item {} 
If the BIG-IP device is a non-VIPRION device, type the management IP address for the device.

\item {} 
If the BIG-IP device is a VIPRION device that is not licensed and provisioned for vCMP, type the primary cluster management IP address for the cluster.

\item {} 
If the BIG-IP device is a VIPRION device that is licensed and provisioned for vCMP, type the cluster management IP address for the guest.

\item {} 
If the BIG-IP device is an Amazon Web Services EC2 device, type one of the Private IP addresses created for this EC2 instance.

\end{itemize}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Click Retrieve Device Information.

\item {} 
Verify that the certificate of the remote device is correct.

\item {} 
Verify that the name of the remote device is correct.

\item {} 
Verify that the management IP address and name of the remote device are correct.

\item {} 
Click Finished.

\end{enumerate}

The device you added is now a member of the local trust domain.

Repeat this task for each device that you want to add to the local trust
domain.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.06 Given a scenario, describe the steps necessary to set up a device group, traffic group and HA group}
\label{\detokenize{class5/modules/module2:objective-2-06-given-a-scenario-describe-the-steps-necessary-to-set-up-a-device-group-traffic-group-and-ha-group}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain how to set up sync-only and sync-failover device service cluster}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/6.html}

\sphinxstylestrong{About Sync-Failover Device Groups}

One of the types of device groups that you can create is a Sync-Failover
type of device group. A Sync-Failover device group contains devices that
synchronize their configuration data and fail over to one another when a
device becomes unavailable. A Sync-Failover device group supports a
maximum of eight devices.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p101}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

traffic\_group\_1 is active on a device in a Sync-Failover device group

\noindent\sphinxincludegraphics{{p111}.png}

On failover, traffic\_group\_1 becomes active on another device in the
Sync-Failover device group

A device in the trust domain can be a member of both a Sync-Failover
group and a Sync-Only group simultaneously.

For devices in a Sync-Failover group, the BIG-IP system uses both the
device group and the traffic group attributes of a folder to make
decisions about which devices to target for synchronizing the contents
of the folder, and which application-related configuration objects to
include in failover.

You can control the way that the BIG-IP chooses a target failover
device. This control is especially useful when a device group contains
heterogeneous hardware platforms that differ in load capacity, because
you can ensure that when failover occurs, the system will choose the
device with the most available resource to process the application
traffic.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p121}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Sample Sync-Failover device groups in a trust domain

\sphinxstylestrong{Sample Sync-Failover configuration}

You can use a Sync-Failover device group in a variety of ways. This
sample configuration shows two separate Sync-Failover device groups in
the local trust domain. Device group A is a standard active-standby
configuration. Prior to failover, only BIGIP1 processes traffic for
application A. This means that BIGIP1 and BIGIP2 synchronize their
configurations, and BIGIP1 fails over to BIGIP2 if BIGIP1 becomes
unavailable. BIGIP1 cannot fail over to BIGIP3 or BIGIP4 because those
devices are in a separate device group.

Device group B is also a standard active-standby configuration, in which
BIGIP3 normally processes traffic for application B. This means that
BIGIP3 and BIGIP4 synchronize their configurations, and BIGIP3 fails
over to BIGIP4 if BIGIP3 becomes unavailable. BIGIP3 cannot fail over to
BIGIP1 or BIGIP2 because those devices are in a separate device group.

\sphinxstylestrong{Sync-Failover device group considerations}

The following configuration restrictions apply to Sync-Failover device
groups:
\begin{itemize}
\item {} 
A specific BIG-IP device in a trust domain can belong to one
Sync-Failover device group only.

\item {} 
On each device in a Sync-Failover device group, the BIG-IP system
automatically assigns the device group name to the root and /Common
folders. This ensures that the system synchronizes any traffic groups
for that device to the correct devices in the local trust domain.

\item {} 
The BIG-IP system creates all device groups and traffic-groups in the
/Common folder, regardless of the partition to which the system is
currently set.

\item {} 
If no Sync-Failover device group is defined on a device, then the
system sets the device group value that is assigned to the root and
/Common folders to None.

\item {} 
By default, on each device, the BIG-IP system assigns a Sync-Failover
device group to any sub-folders of the root or /Common folders that
inherit the device group attribute.

\item {} 
You can configure a maximum of 15 floating traffic groups for a
Sync-Failover device group.

\end{itemize}

\sphinxstylestrong{Creating a Sync-Failover device group}

This task establishes failover capability between two or more BIG-IP
devices. If the active device in a Sync-Failover device group becomes
unavailable, the configuration objects fail over to another member of
the device group and traffic processing is unaffected. You can perform
this task on any authority device within the local trust domain.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Device Groups. The Device Groups screen displays a list of existing device groups.

\item {} 
On the Device Group List screen, click Create.

\item {} 
Type a name for the device group, select the device group type Sync-Failover, and type a description for the device group.

\item {} 
In the Configuration area of the screen, select a host name from the available list for each BIG-IP device that you want to include in the device group. Use the Move button to move the host name to the selected list.

\end{enumerate}

The Available list shows any devices that are members of the
device’s local trust domain but not currently members of a
Sync-Failover device group. A device can be a member of one
Sync-Failover group only.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
For Network Failover, select the Enabled check box.

\item {} 
Click Finished.

\end{enumerate}

You now have a Sync-Failover type of device group containing BIG-IP
devices as members.

\sphinxstylestrong{About Sync-Only device groups}

One of the types of device groups that you can create is a Sync-Only
device group. A Sync-Only device group contains devices that synchronize
configuration data with one another, but their configuration data does
not fail over to other members of the device group. A Sync-Only device
group supports a maximum of 32 devices.

A device in a trust domain can be a member of more than one Sync-Only
device group. A device can also be a member of both a Sync-Failover
group and a Sync-Only group simultaneously.

A typical use of a Sync-Only device group is one in which you configure
a device to synchronize the contents of a specific folder to a different
device group than to the device group to which the other folders are
synchronized.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p13}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Sync-only device group

\sphinxstylestrong{Sample Sync-Only configuration}

The most common reason to use a Sync-Only device group is to synchronize
a specific folder containing policy data that you want to share across
all BIG-IP devices in a local trust domain, while setting up a
Sync-Failover device group to fail over the remaining configuration
objects to a subset of devices in the domain. In this configuration, you
are using a Sync-Only device group attribute on the policy folder to
override the inherited Sync-Failover device group attribute. Note that
in this configuration, BIGIP1 and BIGIP2 are members of both the
Sync-Only and the Sync-Failover groups.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p141}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Sync-Only Device Group

To implement this configuration, you can follow this process:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Create a Sync-Only device group on the local device, adding all devices in the local trust domain as members.

\item {} 
Create a Sync-Failover device group on the local device, adding a subset of devices as members.

\item {} 
On the folder containing the policy data, use tmsh to set the value of the device group attribute to the name of the Sync-Only device group.

\item {} 
On the root folder, retain the default Sync-Failover device group assignment.

\end{enumerate}

\sphinxstylestrong{Creating a Sync-Only device group}

You perform this task to create a Sync-Only type of device group. When
you create a Sync-Only device group, the BIG-IP system can then
automatically synchronize certain types of data such as security
policies and acceleration applications and policies to the other devices
in the group, even when some of those devices reside in another network.
You can perform this task on any BIG-IP device within the local trust
domain.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Device Groups.

\item {} 
On the Device Groups list screen, click Create. The New Device Group screen opens.

\item {} 
Type a name for the device group, select the device group type Sync-Only, and type a description for the device group.

\item {} 
From the Configuration list, select Advanced.

\item {} 
For the Members setting, select an IP address and host name from the Available list for each BIG-IP device that you want to include in the device group. Use the Move button to move the host name to the Includes list. The list shows any devices that are members of the device’s local trust domain.

\item {} 
For the Automatic Sync setting, select or clear the check box:

\end{enumerate}
\begin{itemize}
\item {} 
Select the check box when you want the BIG-IP system to automatically
sync the BIG-IP configuration data whenever a config sync operation
is required. In this case, the BIG-IP system syncs the configuration
data whenever the data changes on any device in the device group.

\item {} 
Clear the check box when you want to manually initiate each config
sync operation. In this case, F5 recommends that you perform
a config sync operation whenever configuration data changes on one of
the devices in the device group.

\end{itemize}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{6}
\item {} 
For the Full Sync setting, select or clear the check box:

\end{enumerate}
\begin{itemize}
\item {} 
Select the check box when you want all sync operations to be full
syncs. In this case, the BIG-IP system syncs the entire set of BIG-IP
configuration data whenever a config sync operation is required.

\item {} 
Clear the check box when you want all sync operations to be
incremental (the default setting). In this case, the BIG-IP system
syncs only the changes that are more recent than those on the target
device. When you select this option, the BIG-IP system compares the
configuration data on each target device with the configuration data
on the source device and then syncs the delta of each target-source
pair.

\end{itemize}

If you enable incremental synchronization, the BIG-IP system might
occasionally perform a full sync for internal reasons. This is a
rare occurrence and no user intervention is required.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{7}
\item {} 
In the Maximum Incremental Sync Size (KB) field, retain the default value of 1024, or type a different value. This value specifies the total size of configuration changes that can reside in the incremental sync cache. If the total size of the configuration changes in the cache exceeds the specified value, the BIG-IP system performs a full sync whenever the next config sync operation occurs.

\item {} 
Click Finished.

\end{enumerate}

You now have a Sync-Only type of device group containing BIG-IP devices
as members.

\sphinxstylestrong{A note about folders and overlapping device groups}

Sometimes when one BIG-IP object references another, one of the objects
gets synchronized to a particular device, but the other object does not.
This can result in an invalid device group configuration.

For example, suppose you create two device groups that share some
devices but not all. In the following illustration, Device A is a member
of both Device Group 1 and Device Group 2.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p151}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

One device with membership in two device groups

Device Group 1 is associated with folder /Common, and Device Group 2 is
associated with the folder /Common/my\_app. This configuration causes
Device A to synchronize all of the data in folder /Common to Device B in
Device Group 1. The only data that Device A can synchronize to Device C
in Device Group 2 is the data in the folder /Common/my\_app, because
this folder is associated with Device Group 2 instead of Device Group 1.

Now suppose that you create a pool in the /Common/my\_app folder, which
is associated with Device Group 2. When you create the pool members in
that folder, the BIG-IP system automatically creates the associated node
addresses and puts them in folder /Common. This results in an invalid
configuration, because the node objects in folder /Common do not get
synchronized to the device on which the nodes’ pool members reside,
Device C. When an object is not synchronized to the device on which its
referenced objects reside, an invalid configuration results.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain how to configure HA groups}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/8.html}

\sphinxstylestrong{Creating an HA group}

You use this task to create an HA group for a traffic group on a device
in a BIG-IP device group. Also known as fast failover, an HA group is
most useful when you want an active traffic group on a device to fail
over to another device based on trunk and pool availability, and on
VIPRION systems, also cluster availability. You can create multiple HA
groups on a single device, and you associate each HA group with the
local instance of a traffic group.

Important: Once you create an HA group on a device and associate the HA
group with a traffic group, you must create an HA group and associate it
with that same traffic group on every device in the device group. For
example, on Device\_A, if you create HA\_GroupA\_TG1 and associate it
with trafffic-group-1, then on Device\_B you can create HA\_GroupB\_TG1)
and also associate it with traffic-group-1.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} High Availability \textgreater{} HA Groups

\item {} 
In the HA Group Name field, type a name for the HA group, such as ha\_group1.

\item {} 
Verify that the Enable check box is selected.

\item {} 
In the Active Bonus field, specify an integer the represents the
amount by which you want the system to increase the overall score of
the active device. The purpose of the active bonus is to prevent
failover when minor or frequent changes occur to the configuration of
a pool, trunk, or cluster.

\item {} 
In the table displayed along the bottom of the screen, for the
Threshold setting, for each pool, trunk, or VIPRION cluster in the HA
group, optionally specify an integer for a threshold value.

\item {} 
For the Weight setting, for each pool, trunk, or VIPRION cluster in
the HA group, specify an integer for the weight. The allowed weight
for an HA group object ranges from 10 through 100. This value is
required.

\item {} 
Click Create.

\end{enumerate}

You now have an HA group that the BIG-IP system can later use to
calculate an HA score for fast failover.

After creating an HA group on the local device, you must assign it to a
traffic group on the local device.

\sphinxstylestrong{Associating an HA group with a traffic group}

You use this task to associate an HA group with an existing traffic
group. Also known as fast failover, this configuration option is most
useful when you want an active traffic group to fail over to another
device due to trunk, pool, and/or VIPRION cluster availability
specifically. When you configure an HA group for a traffic group, you
ensure that the traffic group, when active, fails over to the device on
which the traffic group has the highest HA score.

\sphinxstyleemphasis{Important}: HA groups are not included in config sync operations. For
this reason, you must create a separate HA group on every device in the
device group for this traffic group. For example, if the device group
contains three devices and you want to create an HA group for
traffic-group-1, you must configure the HA group property for
traffic-group-1 on each of the three devices separately. In a typical
device group configuration, the values of the HA group settings on the
traffic group will differ on each device.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, click the name of a traffic group on the local device. This displays the properties of the traffic group.

\item {} 
From the Failover Methods list, select HA Group.

\item {} 
From the HA Group list, select an HA group.

\item {} 
Click Update.

\end{enumerate}

After you perform this task for this traffic group on each device group
member, the BIG-IP system ensures that this traffic group is always
active on the device with the highest HA score.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain how to assign virtual servers to traffic groups}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/8.html}

\sphinxstylestrong{Traffic Group Assignment}

You perform this task to add members to a newly-created or existing
traffic group. Traffic group members are the floating IP addresses
associated with application traffic passing through the BIG-IP system.
Typical members of a traffic group are: a floating self IP address, a
floating virtual address, and a floating SNAT translation address.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
From the Main tab, display the properties page for an existing BIG-IP object, such as a self IP address or a virtual address. For example, from the Main tab, click Network \textgreater{} Self IPs, and then from the Self IPs list, click a self IP address.

\item {} 
From the Traffic Group list, select the floating traffic group that you want the BIG-IP object to join.

\item {} 
Click Update.

\end{enumerate}

After performing this task, the BIG-IP object belongs to the selected
traffic group.

Repeat this task for each BIG-IP object that you want to be a member of
the traffic group.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - (Supplemental Example) Explain use cases for MAC masquerading}

\sphinxurl{https://support.f5.com/csp/article/K13502}

\sphinxstylestrong{MAC Masquerading}

Using MAC masquerading will reduce ARP convergence issues within the
BIG-IP LAN environments when a failover event happens.

To optimize the flow of traffic during failover events, you can
configure MAC masquerade addresses for any defined traffic groups on the
BIG-IP system. A MAC masquerade address is a unique, floating MAC
address that you create. You can assign one MAC masquerade address to
each traffic group on a BIG-IP device. By assigning a MAC masquerade
address to a traffic group, you associate that address with any floating
IP addresses associated with the traffic group. By configuring a MAC
masquerade address for each traffic group, a single Virtual Local Area
Network (VLAN) can potentially carry traffic and services for multiple
traffic groups, with each service having its own MAC masquerade address.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.07 Predict the behavior of an LTM device group or traffic groups in a given failure scenario}
\label{\detokenize{class5/modules/module2:objective-2-07-predict-the-behavior-of-an-ltm-device-group-or-traffic-groups-in-a-given-failure-scenario}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - (Supplemental Example) Predict the behavior of an LTM device group or traffic groups in a given failure scenario}

\sphinxurl{https://support.f5.com/csp/article/K13946?sr=29127385}

This topic is focused on predicting behaviors during failovers between
BIG-IP systems. Understanding how device groups and traffic groups
behave is the key to this topic. Experience with failing over HA systems
will give the candidate the ability to answer the questions on this
topic.

F5 introduced the Device Service Clustering (DSC) architecture in BIG-IP
11.x. DSC provides the framework for ConfigSync, and other
high-availability features, including the following components:

\sphinxstylestrong{Device trust and trust domains}

Device trust establishes trust relationships between BIG-IP devices
through certificate-based authentication. Each device generates a device
ID key and Secure Socket Layer (SSL) certificate upon upgrade or
installation. A trust domain is a collection of BIG-IP devices that
trust each other, and can synchronize and fail over their BIG-IP
configuration data, as well as regularly exchange status and failover
messages.

When the local BIG-IP device attempts to join a device trust with a
remote BIG-IP device, the following applies:

If the local BIG-IP device is added as a peer authority device, the
remote BIG-IP device presents a certificate signing request (CSR) to the
local device, which then signs the CSR and returns the certificate along
with its CA certificate and key.

If the local BIG-IP device is added as a subordinate (non-authority)
device, the remote BIG-IP device presents a CSR to the local device,
which then signs the CSR and returns the certificate. The CA certificate
and key are not presented to the remote BIG-IP device. The subordinate
device is unable to request other devices to join the device trust.

\sphinxstylestrong{Device groups}

A device group is a collection of BIG-IP devices that reside in the same
trust domain and are configured to securely synchronize their BIG-IP
configuration and failover when needed. Device groups can initiate a
ConfigSync operation from the device group member with the desired
configuration change. You can create two types of device groups:

A Sync-Failover device group contains devices that synchronize
configuration data and support traffic groups for failover purposes.

A Sync-Only device group contains devices that synchronize configuration
data, but do not synchronize failover objects and do not fail over to
other members of the device group.

\sphinxstylestrong{Traffic groups}

A traffic group represents a collection of related configuration objects
that are configured on a BIG-IP device. When a BIG-IP device becomes
unavailable, a traffic group can float to another device in a device
group.

\sphinxstylestrong{Folders}

A folder is a container for BIG-IP configuration objects. You can use
folders to set up synchronization and failover of configuration data in
a device group. You can sync all configuration data on a BIG-IP device,
or you can sync and fail over objects within a specific folder only.

\sphinxstylestrong{Centralized Management Infrastructure (CMI) communication channel}

The BIG-IP system uses SSL certificates to establish a trust
relationship between devices. In a device trust, BIG-IP devices can act
as certificate signing authorities, peer authorities, or subordinate
non-authorities. When acting as a certificate signing authority, the
BIG-IP device signs x509 certificates for another BIG-IP device that is
in the local trust domain. The BIG-IP device for which a certificate
signing authority device signs its certificate is known as a subordinate
non-authority device.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - Compare and contrast network and serial failover}

\sphinxurl{https://support.f5.com/csp/article/K2397?sr=42496090}

\sphinxstylestrong{Network Failover}

Network failover is based on heartbeat detection where the system sends
heartbeat packets over the internal network.

The system uses the primary and secondary failover addresses to send
network failover heartbeat packets. For more information about the
BIG-IP mirroring and network failover transport protocols, refer to the
following articles:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K9057}{K9057: Service port and protocol used for BIG-IP network
failover}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K7225}{K7225: Transport protocol used for BIG-IP connection and persistence
mirroring}

\end{itemize}

The BIG-IP system considers the peer down after the
Failover.NetTimeoutSec timeout value is exceeded. The default value of
Failover.NetTimeoutSec is three seconds, after which the standby unit
attempts to switch to an active state. The following database entry
represents the default settings for the failover time configuration:

Failover.NetTimeoutSec = 3

Device Service Clustering (DSC) was introduced in BIG-IP 11.0.0 and
allows many new features such as synchronization and failover between
two or more devices. Network failover provides communication between
devices for synchronization, failover, and mirroring and is required for
the following deployments:
\begin{itemize}
\item {} 
Sync-Failover device groups containing three or more devices

\item {} 
Active-active configurations between two BIG-IP platforms

\item {} 
BIG-IP VIPRION platforms

\item {} 
BIG-IP Virtual Edition

\end{itemize}

An active-active pair must communicate over the network to indicate the
objects and resources they service. Otherwise, if network communications
fail, the two systems may attempt to service the same traffic management
objects, which could result in duplicate IP addresses on the network.

A broken network may cause BIG-IP systems to enter into active-active
mode. To avoid this issue, F5 recommends that you dedicate one interface
on each system to perform only failover communications and, when
possible, directly connect these two interfaces with an Ethernet cable
to avoid network problems that could cause the systems to go into an
active-active state.

Important: When you directly connect two BIG-IP systems with an
Ethernet cable, do not change the speed and duplex settings of the
interfaces involved in the connection. If you do, depending on the
BIG-IP software version, you may be required to use a crossover
cable. For more information, refer to SOL9787: Auto MDI/MDIX
behavior for BIG-IP platforms.

If you configure a BIG-IP high-availability pair to use network
failover, and the hardwired failover cable also connects the two units,
hardwired failover always has precedence; if network failover traffic is
compromised, the two units do not fail over because the hardwired
failover cable still connects them.

\sphinxstylestrong{Hardwired Failover}

Hardwired failover is also based on heartbeat detection, where one
BIG-IP system continuously sends voltage to another. If a response does
not initiate from one BIG-IP system, failover to the peer occurs in less
than one second. When BIG-IP redundant devices connect using a hardwired
failover cable, the system automatically enables hardwired failover.

The maximum hardwired cable length is 50 feet. Network failover is an
option if the distance between two BIG-IP systems exceeds the acceptable
length for a hardwired failover cable.

Note: For information about the failover cable wiring pinouts, refer
to \sphinxhref{https://support.f5.com/kb/en-us/solutions/public/1000/400/sol1426.html}{SOL1426: Pinouts for the failover cable used with BIG-IP
platforms}.

Hardwired failover can only successfully be deployed between two
physical devices. In this deployment, hardwired failover can provide
faster failover response times than network failover. However, peer
state may be reported incorrectly when using hardwired failover alone.

Hardwired failover is only a heartbeat and carries no status
information. Communication over the network is necessary for certain
features to function properly. For example, Traffic Management
Microkernel (TMM) uses the network to synchronize packets and flow state
updates to peers for connection mirroring. To enable proper state
reporting and mirroring, F5 recommends that you configure network
failover in addition to hardwired failover.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - Compare and contrast failover unicast and multicast}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/8.html}

\sphinxstylestrong{Failover Unicast and Multicast}

The unicast failover configuration uses a self-IP address and TMM switch
port to communicate failover packets between each BIG-IP appliance. For
appliance platforms, specifying two unicast addresses should suffice.

For VIPRION platforms, you should enable multicast and retain the
default multicast address that the BIG-IP system provides. The multicast
failover entry uses the management port to communicate failover packets
between each VIPRION system. As an alternative to configuring the
multicast failover option, you can define a unicast mesh using the
management port for each VIPRION system.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.08 Determine the effect of LTM features and/or modules on LTM device performance and/or memory}
\label{\detokenize{class5/modules/module2:objective-2-08-determine-the-effect-of-ltm-features-and-or-modules-on-ltm-device-performance-and-or-memory}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.08 - Determine the effect of iRules on performance}

\sphinxurl{https://devcentral.f5.com/articles/irules-optimization-101-05-evaluating-irule-performance}

\sphinxstylestrong{Effect of iRules on Performance}

This is a classic case of “It Depends”. Since iRules are written
individually to solve specific issues or do specific functions necessary
for a particular scenario, there is not a fixed sheet of performance
numbers showing how an iRule will impact performance. iRules do get
compiled into byte code, and can run at wire speed, but it really
depends on what you’re doing. Many times, there is more than one way to
write an iRule and one method may work more efficiently than another.

That said there are ways to see how an iRule is performing by collecting
and interpreting runtime statistics by inserting a timing command into
event declarations to see over all CPU usage when under load. This tool
will help you to create an iRule that is performing the best on your
system.

\sphinxstylestrong{Collecting Statistics}

To generate \& collect runtime statistics, you can insert the command
“timing on” into your iRule. When you run traffic through your iRule
with timing enabled, LTM will keep track of how many CPU cycles are
spent evaluating each iRule event. You can enable rule timing for the
entire iRule, or only for specific events.

To enable timing for the entire iRule, insert the “timing on” command at
the top of the rule before the first “when EVENT\_NAME” clause.

With the timing command in place, each time the rule is evaluated, LTM
will collect the timing information for the requested events.

To get a decent average for each of the events, you’ll want to run at
least a couple thousand iterations of the iRule under the anticipated
production load.

\sphinxstylestrong{Viewing Statistics}

The statistics for your iRule (as measured in CPU cycles) may be viewed
at the command line or console by running

tmsh show ltm rule rule\_name all

The output includes totals for executions, failures \& aborts along with
minimum, average \& maximum cycles consumed for each event since stats
were last cleared.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
 \PYG{n}{Ltm}\PYG{p}{:}\PYG{p}{:}\PYG{n}{Rule} \PYG{n}{rule\PYGZus{}name}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
 \PYG{n}{Executions}
 \PYG{n}{Total} \PYG{l+m+mi}{729}
 \PYG{n}{Failures} \PYG{l+m+mi}{0}
 \PYG{n}{Aborts} \PYG{l+m+mi}{0}
 \PYG{n}{CPU} \PYG{n}{Cycles} \PYG{n}{on} \PYG{n}{Executing}
 \PYG{n}{Average} \PYG{l+m+mi}{3959}
 \PYG{n}{Maximum} \PYG{l+m+mi}{53936}
 \PYG{n}{Minimum} \PYG{l+m+mi}{3693}
\end{sphinxVerbatim}

\sphinxstylestrong{Evaluating statistics}

“Average cycles reported” is the most useful metric of real-world
performance, assuming a large representative load sample was evaluated.

The “maximum cycles reported” is often very large since it includes some
one-time and periodic system overhead. (More on that below.)

Here’s a spreadsheet (iRules Runtime Calculator) that will calculate
percentage of CPU load per iteration once you populate it with your
clock speed and the statistics gathered with the “timing” command.
(Clock speed can be found by running ‘cat /proc/cpuinfo’ at the command
line.)

\sphinxstylestrong{Caveats}

Timing is intended to be used only as an optimization/debug tool, and
does have a small impact on performance; so don’t leave it turned on
indefinitely.

Timing functionality seems to exhibit a 70 - 100 cycle margin of error.

Use average cycles for most analyses. Maximum cycles is not always an
accurate indicator of actual iRule performance, as the very first call a
newly edited iRule includes the cycles consumed for compile-time
optimizations, which will be reflected in an inflated maximum cycles
value. The simple solution to this is to wait until the first time the
rule is hit, then reset the statistics.

However, maximum cycles is also somewhat inflated by OS scheduling
overhead incurred at least once per tick, so the max value is often
overstated even if stats are cleared after compilation.

\sphinxurl{https://support.f5.com/csp/article/K13033?sr=43030558}

\sphinxstylestrong{Global Variable Impact}

iRules use global variables to make variable data that is created in one
context, that is available to other connections, virtual servers, and
Traffic Management Microkernel (TMM) instances. If a virtual server
references an iRule that uses a global variable that is not Clustered
Multiprocessing (CMP) compatible, the virtual server will be ineligible
for CMP processing. In most cases, it is good to retain the benefits of
CMP processing when using iRules. This document expands on the various
ways to represent global variable data, making it available to other
connections, other virtual servers, and other TMM instances.

In many cases, variable data used in an iRule is required to be
available only within the scope of the current connection. The use of
TCL local variables satisfies this requirement and does not affect CMP
compatibility.

In other cases, variable data must be available globally, that is,
outside the context of a connection. The most common requirement people
have is to capture data from one connection, then to reference that data
from subsequent connections that are part of the same session. This
requirement can be further refined to include both multiple connections
traversing the same TMM instance, such as would be seen on a
non-CMP-enabled system or virtual server, and also multiple related
connections on CMP-enabled virtual servers, which may traverse different
TMM instances.

Another common use for global variables is to share data among multiple
iRules that run on the same BIG-IP system. For example, to set and
enforce a cumulative concurrent connection limit, an iRule would need to
both set a globally accessible limit value, and also allow each iRule
instance to update a separate globally-accessible counter value.

The use of global variables can force the BIG-IP system to automatically
disable CMP processing, which is known as demotion. Demotion of a
virtual server limits processing of that virtual server to only one CPU
core. This can adversely affect performance on multi-core BIG-IP
systems, as only a fraction of the available CPU resources are available
for each demoted virtual server. In addition, CMP demotion can create an
internal communication bottleneck for virtual servers that are
WebAccelerator-enabled or ASM-enabled.

The following sections explain each of three popular methods for sharing
iRules-derived data globally, including the CMP compatibility of each
method.

\sphinxstylestrong{Using TCL global variables}

TCL global variables are not actually global on a CMP-enabled BIG-IP
system, since the global variables are not shared among TMM instances.
TCL global variables are accessible globally only within the local TMM
instance (meaning that each TMM instance would need to set and update
separately its own copy of the variable and the value of the variable).
As a result, the TMM process running on one processor is not able to
access the contents of the same TCL global variable that was set by a
different TMM process, even if both TMM processes are handling
connections for the same virtual server. Because of this limitation, the
use of a TCL global variable in an iRule automatically demotes from CMP
any virtual server to which it is applied. This avoids the confusion
that would otherwise result from accessing and updating multiple
instances of the same “global” variable. Because the virtual server will
be automatically demoted from CMP, you should restrict the use of TCL
global variables to iRules that will be applied to virtual servers that
do not depend on CMP processing.

\sphinxstylestrong{Using static global variables}

If you must share static data (data that will never be modified by the
iRule itself) across CMP-enabled virtual servers, you can use a static
global variable. A static global variable stores data globally to the
entire BIG-IP system, and is set within each TMM instance each time the
iRule is initialized. The value of a static global variable is assumed
not to change unless the iRule is re-initialized. As a result, static
global variables must be set within the RULE\_INIT event. Static global
variables set within the RULE\_INIT event are propagated to all TMM
instances each time the iRule is initialized: when the iRule is loaded
at system startup, when the configuration is re-loaded, or when the
iRule is modified from within the BIG-IP Configuration utility and
saved.

\sphinxstyleemphasis{Important}: While it is possible to use the set command to modify a
static global variable within the iRule and outside of the RULE\_INIT
event, such modifications will not be propagated to each TMM instance;
they will be visible to only the TMM process on which the modification
was made, resulting in inconsistent values for the static global
variable across TMM instances. As a result, F5 strongly recommends that
you do not update the value of any static global variable within the
iRule.

\sphinxstylestrong{Using the session table to store global variables}

If you must share non-static global data across CMP-enabled virtual
servers, you can use the session table to store and reference the data.
Session table data is shared among all TMM instances. Using the session
table imposes considerable operational overhead, but the preservation of
CMP processing for the virtual server typically far outweighs any such
impact.

You can use the table command to manipulate the session table. For
details, refer to the DevCentral article linked in the Supplemental
Information section below.

\sphinxstylestrong{Recommendations}

As you can see, there are several different options for using global
variables, or the equivalent functionality, in session tables. Each of
these options has advantages and disadvantages in their use. Typically,
these decisions are made on performance and ease of implementation.

In summary:
\begin{itemize}
\item {} 
TCL global variables

\item {} 
You should restrict the use of TCL global variables to iRules that will
be applied to virtual servers that do not depend on CMP processing.

\end{itemize}

Static global variables

The use of static global variables is recommended for sharing static
data (data that will not be updated by any iRule) among TMM instances
that are used by CMP-enabled virtual servers, or for sharing static data
among multiple iRules without affecting the CMP status of any virtual
server to which it is applied.

Session table

The use of the session table is recommended for sharing dynamic global
variable data (data that will be updated within the iRule) among
CMP-enabled virtual servers.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.08 - Determine the effect of RAM cache on performance and memory}

\sphinxurl{https://support.f5.com/techdocs/home/solutions/related/ramcache.pdf}

\sphinxstylestrong{Effect of RAM Cache on Performance}

The largest effect of using the RAM Cache feature on the BIG-IP system
is system memory utilization. There is a finite amount of RAM in every
system and using any amount of that RAM for caching HTTP objects can
impact performance and even limit provisioning additional licensing
options.

\sphinxstylestrong{RAM Cache}

A RAM Cache is a cache of HTTP objects stored in the BIG-IP system’s RAM
that are reused by subsequent connections to reduce the amount of load
on the back-end servers.

\sphinxstylestrong{When to use the RAM Cache}

The RAM Cache feature provides the ability to reduce the traffic load to
back-end servers. This ability is useful if an object on a site is under
high demand, if the site has a large quantity of static content, or if
the objects on the site are compressed.
\begin{itemize}
\item {} 
High demand objects

\end{itemize}

This feature is useful if a site has periods of high demand for
specific content. With RAM Cache configured, the content server only
has to serve the content to the BIG-IP system once per expiration
period.
\begin{itemize}
\item {} 
Static content

\end{itemize}

This feature is also useful if a site consists of a large quantity
of static content such as CSS, javascript, or images and logos.
\begin{itemize}
\item {} 
Content compression

\end{itemize}

For compressible data, the RAM Cache can store data for clients that
can accept compressed data. When used in conjunction with the
compression feature on the BIG-IP system, the RAM Cache takes stress
off of the BIG-IP system and the content servers.

\sphinxstylestrong{Items you can cache}

The RAM Cache feature is fully compliant with the cache specifications
described in RFC 2616, Hypertext Transfer Protocol \textendash{} HTTP/1.1. This
means you can configure RAM Cache to cache the following content types:
\begin{itemize}
\item {} 
200, 203, 206, 300, 301, and 410 responses

\item {} 
Responses to GET methods by default.

\item {} 
Other HTTP methods for URIs specified in the URI Include list or
specified in an iRule.

\item {} 
Content based on the User-Agent and Accept-Encoding values. The RAM
Cache holds different content for Vary headers.

\end{itemize}

The items that the RAM Cache does not cache are:
\begin{itemize}
\item {} 
Private data specified by cache control headers

\item {} 
By default, the RAM Cache does not cache HEAD, PUT, DELETE, TRACE,
and CONNECT methods.

\end{itemize}

\sphinxstylestrong{Understanding the RAM Cache mechanism}

The default RAM Cache configuration caches only the HTTP GET methods.
You can use the RAM Cache to cache both the GET and other methods,
including non-HTTP methods, by specifying a URI in the URI Include list
or writing an iRule.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.08 - Determine the effect of compression on performance}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/7.html\#unique\_766348760}

\sphinxstylestrong{Effect of Compression on Performance}

The function of data compression is highly CPU intensive. The largest
effect of using the RAM Cache feature on the BIG-IP system is system
memory utilization. There is a finite amount of RAM in every system and
using any amount of that RAM for caching HTTP objects can impact
performance and even limit provisioning additional licensing options.

\sphinxstylestrong{HTTP Compression}

An optional feature is the BIG-IP systems ability to off-load HTTP
compression tasks from the target server. All of the tasks needed to
configure HTTP compression in Local Traffic Manager, as well as the
compression software itself, are centralized on the BIG-IP system.

\sphinxstylestrong{gzip compression levels}

A gzip compression level defines the extent to which data is compressed,
as well as the compression rate. You can set the gzip level in the range
of 1 through 9. The higher the gzip level, the better the quality of the
compression, and therefore the more resources the system must use to
reach that specified quality. Setting a gzip level yields these results:
\begin{itemize}
\item {} 
A lower number causes data to be less compressed but at a higher
performance rate. Thus, a value of 1 causes the least compression but
the fastest performance.

\item {} 
A higher number causes data to be more compressed but at a slower
performance rate. Thus, a value of 9 (the highest possible value)
causes the most compression, but the slowest performance.

\end{itemize}

Warning: Selecting any value other than 1 - Least Compression (Fastest)
can degrade system performance.

For example, you might set the gzip compression level to 9 if you are
utilizing Local Traffic Manager cache feature to store response data.
The reason for this is that the stored data in the cache is continually
re-used in responses, and therefore you want the quality of the
compression of that data to be very high.

As the traffic flow on the BIG-IP system increases, the system
automatically decreases the compression quality from the gzip
compression level that you set in the profile. When the gzip compression
level decreases to the point where the hardware compression provider is
capable of providing the specified compression level, the system uses
the hardware compression providers rather than the software compression
providers to compress the HTTP server responses.

Tip: You can change the way that Local Traffic Manager uses gzip levels
to compress data by configuring the compression strategy. The
compression strategy determines the particular compression provider
(hardware or software) that the system uses for HTTP responses. The
available strategies are: Speed (the default strategy), Size, Ratio, and
Adaptive.

Memory levels for gzip compression

You can define the number of kilobytes of memory that Local Traffic
Manager uses to compress data when using the gzip or deflate compression
method. The memory level is a power-of-2 integer, in bytes, ranging from
1 to 256.

Generally, a higher value causes Local Traffic Manager to use more
memory, but results in a faster and higher compression ratio.
Conversely, a lower value causes Local Traffic Manager to use less
memory, but results in a slower and lower compression ratio.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.08 - Determine the effect of modules on performance and memory}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-system-essentials-11-6-0/7.html?sr=42462566}

\sphinxstylestrong{Effect of Modules on Performance}

Enabling additional software on any F5 hardware platform will increase
the utilization of the hardware resources of the unit. As you provision
the software modules in TMOS the Resource Provisioning screen will show
the administrator how much CPU, Disk and Memory is being used by each
module. And if provisioning an additional module requires more resources
than are available on the system, the system will not allow the
provisioning of the module.

Resource Provisioning is a management feature to help support the
installation and configuration of many modules available with BIG-IP.
Provisioning gives you some control over the resources, both CPU and
RAM, which are allocated to each licensed module. You may want, for
example, to minimize the resources available to GTM on a system licensed
for LTM and GTM. Since all models have some reliance on both management
(Linux) and local traffic features, they will always be provisioned.
Other modules must be manually provisioned. When you provision the
modules, you can choose between four levels of resources. A fifth level
may be allowed on certain modules. Dedicated, Nominal, Minimum and None
are available for all modules and Lite is a fifth level available for
trials only.

You can manage the provisioning of system memory, disk space, and CPU
usage among licensed modules on the BIG-IP system.

There are five available resource allocation settings for modules.
\begin{itemize}
\item {} 
None/Disabled

\end{itemize}

Specifies that a module is not provisioned. A module that is not
provisioned does not run.
\begin{itemize}
\item {} 
Dedicated

\end{itemize}

Specifies that the system allocates all CPU, memory, and disk
resources to one module. When you select this option, the system
sets all other modules to None (Disabled).
\begin{itemize}
\item {} 
Nominal

\end{itemize}

Specifies that, when first enabled, a module gets the least amount
of resources required. Then, after all modules are enabled, the
module gets additional resources from the portion of remaining
resources.
\begin{itemize}
\item {} 
Minimum

\end{itemize}

Specifies that when the module is enabled, it gets the least amount
of resources required. No additional resources are ever allocated to
the module.
\begin{itemize}
\item {} 
Lite

\end{itemize}

Lite is available for selected modules granting limited features for
trials.

\sphinxstylestrong{Provisioning the BIG-IP system using the Configuration utility}

After you have activated a license on the BIG-IP® system, you can
use the Configuration utility to provision the licensed modules.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} Resource Provisioning.

\item {} 
For licensed modules, select either Minimum or Nominal, as needed.

\item {} 
Click Submit.

\item {} 
Reboot the system:
\begin{itemize}
\item {} 
On the Main tab, click System \textgreater{} Configuration \textgreater{} Device \textgreater{} General.

\item {} 
Click Reboot.

\end{itemize}

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.09 Determine the effect of traffic flow on LTM device performance and/or utilization}
\label{\detokenize{class5/modules/module2:objective-2-09-determine-the-effect-of-traffic-flow-on-ltm-device-performance-and-or-utilization}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.09 - Explain how to use traffic groups to maximize capacity}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/8.html}

\sphinxstylestrong{Traffic Groups}

A traffic group is a collection of related configuration objects, such
as a floating self IP address, a virtual IP address, and a SNAT
translation address, that run on a BIG-IP device. Together, these
objects process a particular type of application traffic on that device.
When a BIG-IP device becomes unavailable, a traffic group floats (that
is, fails over) to another device in a device group to ensure that
application traffic continues to be processed with little to no
interruption in service. In general, a traffic group ensures that when a
device becomes unavailable, all of the failover objects in the traffic
group fail over to any one of the available devices in the device group.

A traffic group is initially active on the device on which you create
it, until the traffic group fails over to another device. For example,
if you initially create three traffic groups on Device A, these traffic
groups remain active on Device A until one or more traffic groups fail
over to another device. If you want an active traffic group to become
active on a different device in the device group when failover has not
occurred, you can intentionally force the traffic group to switch to a
standby state, thereby causing failover to another device.

Only objects with floating IP addresses can be members of a floating
traffic group.

An example of a set of objects in a traffic group is an iApps
application service. If a device with this traffic group is a member of
a device group, and the device becomes unavailable, the traffic group
floats to another member of the device group, and that member becomes
the device that processes the application traffic.

Note: A Sync-Failover device group can support a maximum of 15 floating
traffic groups.

\sphinxstylestrong{Maximizing Capacity}

For every active traffic group on a device, the BIG-IP system identifies
the device that is to be the next-active device if failover of that
active traffic group occurs. A next-active device is the device on which
a traffic group will become active if that traffic group eventually
fails over to another device. This next-active designation changes
continually depending on which devices are currently available in the
device group.

There are various configuration options for you to choose from to affect
the BIG-IP system’s selection of the next-active device for failover:
\begin{itemize}
\item {} 
Load-aware failover

\item {} 
An ordered list with auto-failback

\item {} 
HA groups

\end{itemize}

\sphinxstylestrong{What is load-aware failover?}

Load-aware failover is a BIG-IP feature designed for use in a
Sync-Failover device group. Configuring load-aware failover ensures that
the traffic load on all devices in a device group is as equivalent as
possible, factoring in any differences in device capacity and the amount
of application traffic that traffic groups process on a device. The
load-aware configuration option is most useful for device groups with
heterogeneous hardware platforms or varying application traffic loads
(or both).

For example, suppose you have a heterogeneous three-member device group
in which one device (BIGIP\_C) has twice the hardware capacity of the
other two devices (BIGIP\_A and BIGIP\_B).

If the device group has four active traffic groups that each process the
same amount of application traffic, then the load on all devices is
equivalent when devices BIGIP\_A and BIGIP\_B each contain one active
traffic group, while device BIGIP\_C contains two active traffic groups.

The BIG-IP system implements load-aware failover by calculating a
numeric, current utilization score for each device, based on numeric
values that you specify for each device and traffic group relative to
the other devices and traffic groups in the device group. The system
then uses this current utilization score to determine which device is
the best device in the group to become the next-active device when
failover occurs for a traffic group.

The overall result is that the traffic load on each device is as
equivalent as possible in a relative way, that is, factoring in
individual device capacity and application traffic load per traffic
group.

\sphinxstylestrong{About device utilization calculation}

The BIG-IP system on each device performs a calculation to determine the
device’s current level of utilization. This utilization level indicates
the ability for the device to be the next-active device in the event
that an active traffic group on another device must fail over within a
heterogeneous device group.

The calculation that the BIG-IP performs to determine the current
utilization of a device is based on these factors:

\sphinxstylestrong{Device capacity}

A local device capacity relative to other device group members.

\sphinxstylestrong{Active local traffic groups}

The number of active traffic groups on the local device.

\sphinxstylestrong{Active remote traffic groups}

The number of remote active traffic groups for which the local device is
the next-active device.

A multiplying load factor for each active traffic group

A multiplier value for each traffic group. The system uses this value to
weight each active traffic group’s traffic load compared to the traffic
load of each of the other active traffic groups in the device group.

The BIG-IP system uses all of these factors to perform a calculation to
determine, at any particular moment, a score for each device that
represents the current utilization of that device. This utilization
score indicates whether the BIG-IP system should, in its attempt to
equalize traffic load on all devices, designate the device as a
next-active device for an active traffic group on another device in the
device group.

The calculation that the BIG-IP performs for each device is:

(The sum of all local active traffic group HA load factors + The sum of
all remote active traffic group HA load factors) / device capacity

\sphinxstylestrong{About HA capacity}

For each device in a BIG-IP device group, you can assign a high
availability (HA) capacity value. An HA capacity value is a number that
represents the relative processing capacity of that device compared to
the other devices in a device group. Assigning different HA capacity
values to the devices in the device group is useful when the device
group contains heterogeneous hardware platforms.

For example, if the device group has two devices with equal capacity and
a third device that has twice the capacity of each of the other two
devices, then you can assign values of 2, 2, and 4, respectively. You
can assign any number to represent the HA capacity, as long as the
number reflects the device’s relative capacity compared to the other
devices in the device group.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.10 Determine the effect of virtual server settings on LTM device performance and/or utilization}
\label{\detokenize{class5/modules/module2:objective-2-10-determine-the-effect-of-virtual-server-settings-on-ltm-device-performance-and-or-utilization}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Determine the effect of connection mirroring on performance}

\sphinxurl{https://support.f5.com/csp/article/K13478}

\sphinxstylestrong{Connection Mirroring Performance Implications}

The connection and persistence mirroring feature allows you to configure
a BIG-IP system to duplicate connection and persistence information to
the standby unit of a redundant pair. This setting provides higher
reliability, but might affect system performance.

The BIG-IP device service clustering (DSC) architecture allows you to
create a redundant system configuration for multiple BIG-IP devices on a
network. System redundancy includes the ability to mirror connection and
persistence information to a peer device to prevent interruption in
service during failover. Traffic Management Microkernel (TMM) manages
the state mirroring mechanism, and connection and persistence data is
synchronized to the standby unit with every packet or flow state update.
The standby unit decapsulates the packets and adds them to the
connection table.

Beginning with version 11.4.0, the BIG-IP system maintains a separate
mirroring channel for each traffic group. The active BIG-IP system in an
HA device group dynamically establishes a mirroring connection to the
standby with a status of Next Active for a given traffic group. The port
range for each connection channel begins at TCP 1029 and increments by
one for each new traffic group and channel created. For more
information, refer to K14894: The BIG-IP system establishes a separate
mirroring channel for each traffic group.

In BIG-IP 12.0.0 and later, you can configure the system to mirror
Secure Sockets Layer (SSL) connections that are terminated by the BIG-IP
system to peer device group members. For more information, refer to
K17391: Configuring SSL connection mirroring.

You can use the Configuration utility or Traffic Management Shell (tmsh)
to configure mirroring addresses, configure connection mirroring for
virtual servers and Secure Network Address Translations (SNATs), and
configure persistence mirroring. You can also view mirroring data on the
active and standby BIG-IP systems using the tmsh utility.

This feature can add CPU overhead to the system and can also cause
network congestion depending on the system configuration.

\sphinxstylestrong{Recommendations}

When configuring mirroring on the BIG-IP system, F5 recommends that you
consider the following factors:

Note: Only FastL4 and SNAT connections are re-mirrored after
failback.
\begin{itemize}
\item {} 
Enable connection and persistence mirroring when a BIG-IP failover
would cause the user’s session to be lost or significantly disrupted

\end{itemize}

For example, where long-term connections, such as FTP and Telnet,
are good candidates for mirroring, mirroring short-term connections,
such as HTTP and UDP, is not recommended as this causes a decrease
in system performance. In addition, mirroring HTTP and UDP
connections is typically not necessary, as those protocols allow for
failure of individual requests without loss of the entire session.
\begin{itemize}
\item {} 
Configure a dedicated VLAN and dedicated interfaces to process
mirroring traffic

\end{itemize}

The TMM process manages the BIG-IP LTM state mirroring mechanism,
and connection data is synchronized to the standby unit with every
packet or flow state update. In some mirroring configurations, this
behavior may generate a significant amount of traffic. Using a
shared VLAN and shared interfaces for both mirroring and production
traffic reduces the overall link capacity for either type of
traffic. Due to high traffic volumes, production traffic and
mirroring traffic may interfere, potentially causing latency in
mirrored connections or interrupting the network mirror connection
between the two BIG-IP devices. If the network mirror connection is
interrupted, it can cause loss of mirror information and interfere
with the ability of the peer device to take over connections in the
event of a failover.
\begin{itemize}
\item {} 
Directly cable network mirroring interfaces

\end{itemize}

You can directly cable network mirroring interfaces on the BIG-IP
systems in the failover pair, and F5 highly recommends that you do
this when configuring a dedicated VLAN for mirroring. Configuring
the pair in this way removes the need to allocate additional ports
on surrounding switches, and removes the possibility of switch
failure and switch-induced latency. Interfaces used for mirroring
should be dedicated to the mirroring VLAN. Tagged interfaces shared
with other VLANs could become saturated by traffic on other VLANs.
\begin{itemize}
\item {} 
Configure both primary and secondary mirroring addresses

\end{itemize}

This would allow an alternate mirroring path and ensure reliable
mirroring in the event of equipment or cable failure.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.11 Describe how to deploy vCMP guests and how the resources are distributed}
\label{\detokenize{class5/modules/module2:objective-2-11-describe-how-to-deploy-vcmp-guests-and-how-the-resources-are-distributed}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.11 - Identify the performance impact of vCMP guests on other guests}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/vcmp-administration-viprion-11-5-0/3.html\#conceptid}

\sphinxstylestrong{Flexible Resource Allocation}

Flexible resource allocation is a built-in vCMP feature that allows vCMP
host administrators to optimize the use of available system resources.
Flexible resource allocation gives you the ability to configure the vCMP
host to allocate a different amount of CPU and memory to each guest
through core allocation, based on the needs of the specific BIG-IP
modules provisioned within a guest. When you create each guest, you
specify the number of logical cores that you want the host to allocate
to the guest, and you identify the specific slots that you want the host
to assign to the guest. Configuring these settings determines the total
amount of CPU and memory that the host allocates to the guest. With
flexible allocation, you can customize CPU and memory allocation in
granular ways that meet the specific resource needs of each individual
guest.

\sphinxstylestrong{Resource allocation planning}

When you create a vCMP guest, you must decide the amount of dedicated
resource, in the form of CPU and memory, that you want the vCMP host to
allocate to the guest. You can allocate a different amount of resources
to each guest on the system.

\sphinxstylestrong{Prerequisite hardware considerations}

Blade models vary in terms of how many cores the blade provides and how
much memory each core contains. Also variable is the maximum number of
guests that each blade model supports. For example, a single B2100 blade
provides eight cores and approximately 3 gigabytes (GB) of memory per
core, and supports a maximum of four guests.

Before you can determine the number of cores to allocate to a guest and
the number of slots to assign to a guest, you should understand:
\begin{itemize}
\item {} 
The total number of cores that the blade model provides

\item {} 
The amount of memory that each blade model provides

\item {} 
The maximum number of guests that the blade model supports

\end{itemize}

By understanding these metrics, you ensure that the total amount of
resource you allocate to guests is aligned with the amount of resource
that your blade model supports.

For specific information on the resources that each blade model
provides, see the vCMP guest memory/CPU core allocation matrix on the
AskF5 Knowledge Base at \sphinxurl{http://support.f5.com}.

\sphinxstylestrong{Understanding guest resource requirements}

Before you create vCMP guests and allocate system resources to them, you
need to determine the specific CPU and memory needs of each guest. You
can then decide how many cores to allocate and slots to assign to a
guest, factoring in the resource capacity of your blade model.

To determine the CPU and memory resource needs, you must know:
\begin{itemize}
\item {} 
The number of guests you need to create

\item {} 
The specific BIG-IP modules you need to provision within each guest

\item {} 
The combined memory requirement of all BIG-IP modules within each
guest

\end{itemize}

\sphinxstylestrong{About core allocation for a guest}

When you create a guest on the vCMP system, you must specify the total
number of cores that you want the host to allocate to the guest based on
the guest’s total resource needs. Each core provides some amount of CPU
and a fixed amount of memory. You should therefore specify enough cores
to satisfy the combined memory requirements of all BIG-IP modules that
you provision within the guest. When you deploy the guest, the host
allocates this number of cores to every slot on which the guest runs,
regardless of the number of slots you have assigned to the guest.

It is important to understand that the total amount of memory available
to a guest is only as much as the host has allocated to each slot. If
you instruct the host to allocate a total of two cores per slot for the
guest (for example, 6 GB of memory depending on blade model) and you
configure the guest to run on four slots, the host does not aggregate
the 6 GB of memory on each slot to provide 24 GB of memory for the
guest. Instead, the guest still has a total of 6 GB of memory available.
This is because blades in a chassis operate as a cluster of independent
devices, which ensures that if the number of blades for the guest is
reduced for any reason, the remaining blades still have the required
memory available to process the guest traffic.

\sphinxstylestrong{Formula for host memory allocation to a guest}

You can use a formula to confirm that the cores you plan to allocate to
a specific guest are sufficient, given the guest’s total memory
requirements:

(total\_GB\_memory\_per\_blade - 3 GB) x (cores\_per\_slot\_per\_guest /
total\_cores\_per\_blade) = amount of guest memory allocation from host

Important: For metrics on memory and CPU support per blade model,
refer to the vCMP guest memory/CPU allocation matrix at
\sphinxurl{http://support.f5.com}.

The variables in this formula are defined as follows:
\begin{itemize}
\item {} 
total\_GB\_memory\_per\_blade

\end{itemize}

The total amount of memory in gigabytes that your specific blade
model provides (for all guests combined).
\begin{itemize}
\item {} 
cores\_per\_slot\_per\_guest

\end{itemize}

The estimated number of cores needed to provide the total amount of
memory that the guest requires.
\begin{itemize}
\item {} 
total\_cores\_per\_blade

\end{itemize}

The total number of cores that your specific blade model provides
(for all guests combined).

For example, if you have a VIPRION 2150 blade, which provides
approximately 32 GB memory through a maximum of eight cores, and you
estimate that the guest will need two cores to satisfy the guest’s total
memory requirement of 8 GB, the formula looks as follows:
\begin{itemize}
\item {} 
(32 GB - 3 GB) x (2 cores / 8 cores) = 7.25 GB memory that the host will allocate to the guest per slot

\end{itemize}

In this case, the formula shows that two cores will not provide
sufficient memory for the guest. If you specify four cores per slot
instead of two, the formula shows that the guest will have
sufficient memory:
\begin{itemize}
\item {} 
(32 GB - 3 GB) x (4 cores / 8 cores) = 14.5 GB memory that the host will allocate to the guest per slot

\end{itemize}

Note that except for single-core guests, the host always allocates
cores in increments of two. For example, for B2150 blade models, the
host allocates cores in increments of 2, 4, and 8.

Once you use this formula for each of the guests you plan to create on a
slot, you can create your guests so that the combined memory allocation
for all guests on a slot does not exceed the total amount of memory that
the blade model provides.

\sphinxstylestrong{About slot assignment for a guest}

On the vCMP system, the host assigns some number of slots to each guest
based on information you provide when you initially create the guest.
The key information that you provide for slot assignment is the maximum
and minimum number of slots that a host can allocate to the guest, as
well as the specific slots on which the guest is allowed to run. With
this information, the host determines the number of slots and the
specific slot numbers to assign to each guest.

As a best practice, you should configure every guest so that the guest
can span all slots in the cluster whenever possible. The more slots that
the host can assign to a guest, the lighter the load is on each blade
(that is, the fewer the number of connections that each blade must
process for that guest).

Note: In device service clustering (DSC) configurations, all guests in
the device group must have the same core allocation and module
provisioning, and the guests must match with respect to number of slots
and the exact slot numbers. Also, each guest in the device group must
run on the same blade and chassis models.

\sphinxstylestrong{About single-core guests}

On platforms with hard drives, the vCMP host always allocates cores on a
slot for a guest in increments of two cores. In the case of blades with
solid-state drives, however, the host can allocate a single core to a
guest, but only for a guest that requires one core only; the host never
allocates any other odd number of cores per slot for a guest (such as
three, five, or seven cores).

The illustration shows a possible configuration where the host has
allocated a single core to one of the guests.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p161}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

A vCMP configuration with a single-core guest

Because a single-core guest has a relatively small amount of CPU and
memory allocated to it, F5 supports only these products or
product combinations for a single-core guest:
\begin{itemize}
\item {} 
BIG-IP Local Traffic Manager (LTM) only

\item {} 
BIG-IP Local Traffic Manager (LTM) and BIG-IP Global Traffic Manager
(GTM) only

\item {} 
BIG-IP Global Traffic Manager (GTM) standalone only

\end{itemize}

\sphinxstylestrong{Resource allocation results}

This illustration shows an example of a system with three guests that
the vCMP host has distributed across slots in varying ways. The way that
the host distributes the guests depends on the way you configured guest
properties when you initially created each guest.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p171}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Three guests with varying amounts of core allocation and slot assignment

This illustration shows three guests configured on the system. For blade
model B2100, which provides approximately 2 GB of memory per core:
\begin{itemize}
\item {} 
The blue guest is configured with two cores per slot, providing a
total memory allocation of four GB per slot for the guest (2 cores x
2 GB). The guest spans four slots.

\item {} 
The red guest is configured with two cores per slot, providing a
total memory allocation of four GB per slot for the guest (2 cores x
2 GB). The guest spans two slots.

\item {} 
The green guest is configured with four cores per slot, providing a
total memory allocation of eight GB per slot for the guest (4 cores x
2 GB). The guest spans two slots.

\end{itemize}

\sphinxstyleemphasis{Important}: For an individual guest, the number of cores allocated to
one (not all) of the guest’s slots determines the guest’s total memory
allocation.

\sphinxstylestrong{Scalability considerations}

When managing a guest’s slot assignment, or when removing a blade from a
slot assigned to a guest, there are a few key concepts to consider.

\sphinxstylestrong{About initial slot assignment}

When you create a vCMP guest, the number of slots that you initially
allow the guest to run on determines the maximum total resource
allocation possible for that guest, even if you add blades later. For
example, in a four-slot VIPRION chassis that contains two blades, if you
allow a guest to run on two slots only and you later add a third blade,
the guest continues to run on two slots and does not automatically
expand to acquire additional resource from the third blade. However, if
you initially allow the guest to run on all slots in the cluster, the
guest will initially run on the two existing blades but will expand to
run on the third slot, acquiring additional traffic processing capacity,
if you add another blade.

Because each connection causes some amount of memory use, the fewer the
connections that the blade is processing, the lower the percentage of
memory that is used on the blade compared to the total amount of memory
allocated on that slot for the guest. Configuring each guest to span as
many slots as possible reduces the chance that memory use will exceed
the available memory on a blade when that blade must suddenly process
additional connections.

If you do not follow the best practice of instructing the host to assign
as many slots as possible for a guest, you should at least allow the
guest to run on enough slots to account for an increase in load per
blade if the number of blades is reduced for any reason.

In general, F5 strongly recommends that when you create a
guest, you assign the maximum number of available slots to the guest to
ensure that as few additional connections as possible are redistributed
to each blade, therefore resulting in as little increase in memory use
on each blade as possible.

\sphinxstylestrong{About changing slot assignments}

At any time, you can intentionally increase or decrease the number of
slots a guest runs on explicitly by re-configuring the number of slots
that you initially assigned to the guest. Note that you can do this
while a guest is processing traffic, to either increase the guest’s
resource allocation or to reclaim host resources.

When you increase the number of slots that a guest is assigned to, the
host attempts to assign the guest to those additional slots. The host
first chooses those slots with the greatest number of available cores.
The change is accepted as long as the guest is still assigned to at
least as many slots as dictated by its Minimum Number of Slotsvalue. If
the additional number of slots specified is not currently available, the
host waits until those additional slots become available and then
assigns the guest to these slots until the guest is assigned to the
desired total number of slots. If the guest is currently in a deployed
state, VMs are automatically created on the additional slots.

When you decrease the number of slots that a guest is assigned to, the
host removes the guest from the most populated slots until the guest is
assigned to the correct number of slots. The guest’s VMs on the removed
slots are deleted, although the virtual disks remain on those slots for
reassignment later to another guest. Note that the number of slots that
you assign to a guest can never be less than the minimum number of slots
configured for that guest.

\sphinxstylestrong{Effect of blade removal on a guest}

If a blade suddenly becomes unavailable, the total traffic processing
resource for guests on that blade is reduced and the host must
redistribute the load on that slot to the remaining assigned slots. This
increases the number of connections that each remaining blade must
process.

Fortunately, there is no reduction in memory allocation, given that when
you create a guest, you instruct the host to allocate the full amount of
required memory for that guest to every slot in the guest’s cluster
(through the guest’s Cores per Slot property). However, each connection
causes some amount of memory use, which means that when a blade becomes
unavailable and the host redistributes its connections to other blades,
the percentage of memory use on these remaining blades increases. In
some cases, the increased memory use could exceed the amount of memory
allocated to each of those slots.

For example, if a guest spans three slots which process 1,000,000
connections combined, each slot is processing a third of the connections
to the guest. If one of the blades becomes unavailable, reducing the
guest’s cluster to two slots, then the two remaining blades must each
process half of the guest’s connections (500,000), resulting in a memory
use per slot that could be higher than what is allocated for that slot.
Assigning as many slots as possible to each guest reduces this risk.

\sphinxstylestrong{Effect of blade re-insertion on a guest}

When you remove a blade from the chassis, the host remembers which
guests were allocated to that slot. If you then re-insert a blade into
that slot, the host automatically allocates cores from that blade to the
guests that were previously assigned to that slot.

Whenever the host assigns guests to a newly-inserted blade, those guests
that are below their Minimum Number of Slots threshold are given
priority; that is, the host assigns those guests to the slot before
guests that are already assigned to at least as many slots as their
Minimum Number of Slots value. Note that this is the only time when a
guest is allowed to be assigned to fewer slots than specified by its
Minimum Number of Slots value.

\sphinxstylestrong{About SSL and compression hardware}

On systems that include SSL and compression hardware processors, the
vCMP feature shares these hardware resources among all guests on the
system, in a round robin fashion.

When sharing SSL hardware, if all guests are using similar-sized keys,
then each guest receives an equal share of the SSL resource. Also, if
any guests are not using SSL keys, then other guests can take advantage
of the extra SSL resource.

\sphinxstylestrong{Guest states and resource allocation}

As a vCMP host administrator, you can control when the system allocates
or de-allocates system resources to a guest. You can do this at any
time, by setting a guest to one of three states: Configured,
Provisioned, or Deployed. These states affect resource allocation in
these ways:

\sphinxstylestrong{Configured}

This is the initial (and default) state for a newly-created guest. In
this state, the guest is not running, and no resources are allocated. If
you change a guest from another state to the Configured state, the vCMP
host does not delete any virtual disks that were previously attached to
that guest; instead, the guest’s virtual disks persist on the system.
The host does, however, automatically de-allocate other resources such
as CPU and memory. When the guest is in the Configured state, you cannot
configure the BIG-IP modules that are licensed to run within the guest;
instead, you must set the guest to the Deployed state to provision and
configure the BIG-IP modules within the guest.

\sphinxstylestrong{Provisioned}

When you change a guest state from Configured to Provisioned, the vCMP
host allocates system resources to the guest (CPU, memory, and any
unallocated virtual disks). If the guest is new, the host creates new
virtual disks for the guest and installs the selected ISO image on them.
A guest does not run while in the Provisioned state. When you change a
guest state from Deployed to Provisioned, the host shuts down the guest
but retains its current resource allocation.

\sphinxstylestrong{Deployed}

When you change a guest to the Deployed state, the vCMP host activates
the guest virtual machines (VMs), and the guest administrator can then
provision and configure the BIG-IP modules within the guest. For a guest
in this state, the vCMP host starts and maintains a VM on each slot for
which the guest has resources allocated. If you are a host administrator
and you reconfigure the properties of a guest after its initial
deployment, the host immediately propagates the changes to all of the
guest VMs and also propagates the list of allowed VLANs.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.11 - Understand that the vCMP guest license is inherited from the host}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/vcmp-administration-appliances-11-6-0/1.html?sr=42415298}

\sphinxstylestrong{BIG-IP license considerations for vCMP}

The BIG-IP system license authorizes you to provision the vCMP feature
and create guests with one or more BIG-IP system modules provisioned.
Note the following considerations:

Each guest inherits the license of the vCMP host.

The host license must include all BIG-IP modules that are to be
provisioned across all guest instances. Examples of BIG-IP modules are
BIG-IP Local Traffic Manager and BIG-IP Global Traffic Manager.

The license allows you to deploy the maximum number of guests that the
platform allows.

If the license includes the appliance mode feature, you cannot enable
appliance mode for individual guests; when licensed, appliance mode
applies to all guests and cannot be disabled.

You activate the BIG-IP system license when you initially set up the
vCMP host.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.11 - Describe how to deploy and/or upgrade vCMP guests and related dependency on host version}

\sphinxurl{https://support.f5.com/csp/article/K14088}

\sphinxstylestrong{Upgrading software on a vCMP system}

When you upgrade software on vCMP systems, keep the following
information in mind:
\begin{itemize}
\item {} 
When you upgrade a vCMP host, the guests go offline.

\item {} 
Upgrading the vCMP host does not upgrade individual guests.

\item {} 
To avoid excessive disk and CPU usage, upgrade only one vCMP guest at
a time.

\item {} 
Each guest inherits the license of the vCMP host, and the host
license includes all BIG-IP modules available for use with vCMP guest
instances. If you need to reactivate the license, you reactivate it
at the vCMP host only.

\item {} 
While not required, F5 recommends that you configure your vCMP host
to run the same BIG-IP version as the latest version used by any of
its vCMP guests.

\item {} 
F5 hardware platforms with multiple blades manage and share software
image ISO files between blades automatically. Starting in 11.6.0,
BIG-IP software images that are stored and managed on the vCMP host
are also available for vCMP guests to install.

\item {} 
Hosts and guests use unique UCS configuration files. For example,
virtual servers configured within a BIG-IP guest are not contained in
the UCS file created on the vCMP host.

\end{itemize}

For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K15930}{K15930: Overview of vCMP configuration
considerations}.

\sphinxurl{https://support.f5.com/csp/article/K14088}

\sphinxstylestrong{vCMP host and compatible guest version matrix}

Starting in BIG-IP 11.0.0, the BIG-IP system supports vCMP, a feature
that allows you to run multiple instances of the BIG-IP software on a
single hardware platform. The hypervisor allows you to allocate hardware
resources to each BIG-IP vCMP guest instance.

The vCMP host allows you to run a vCMP guest software version, which can
be either the same version or a different version than the host, which
is BIG-IP 11.0.0 and later. This functionality allows customers to run
multiple versions of BIG-IP code simultaneously for testing, migration
staging, or environment consolidation.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.12 Determine the appropriate LTM device security configuration to protect against a security threat}
\label{\detokenize{class5/modules/module2:objective-2-12-determine-the-appropriate-ltm-device-security-configuration-to-protect-against-a-security-threat}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - Explain the implications of SNAT and NAT on network promiscuity}

In a typical network, a host’s network adapter only receives frames that
are meant for it. If the Host’s network adapter supports promiscuous
mode, then placing it in promiscuous mode will allow it to receive all
frames passed on the switch that are allowed under the VLAN policy for
the associated port group. This can be useful for intrusion detection
monitoring or if a sniffer needs to analyze all traffic on the network
segment.

When the BIG-IP platform performs SNAT or NAT functions to the network
traffic that is traversing the system it rewrites the destination IP or
source IP address of the traffic depending on the function performed.
This can make troubleshooting captures of network traffic difficult
since with SNAT all traffic seems to have a source IP address of the
BIG-IP system, or with NAT the destination IP address is not the same on
each side of the communications of the BIG-IP.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - Explain the implications of forwarding virtual servers on the environment security}

\sphinxurl{https://support.f5.com/csp/article/K7595?sr=42401954}

\sphinxstylestrong{Forwarding Virtual Servers}

There are two different types of forwarding virtual server, the Layer2
forwarding and IP forwarding.

An IP forwarding virtual server accepts traffic that matches the virtual
server address and forwards it to the destination IP address that is
specified in the request rather than load balancing the traffic to a
pool. Address translation is disabled when you create an IP forwarding
virtual server, leaving the destination address in the packet unchanged.
When creating an IP forwarding virtual server, as with all virtual
servers, you can create either a host IP forwarding virtual server,
which forwards traffic for a single host address, or a network IP
forwarding virtual server, which forwards traffic for a subnet.

\sphinxstylestrong{Host IP forwarding virtual server}

A host IP forwarding virtual server forwards traffic to a single
destination host address. For example, the following configuration
defines a host IP forwarding virtual server that accepts any traffic
arriving on the Virtual Local Area Network (VLAN) named external whose
destination is 10.0.0.1 on any service port using any valid TCP/IP
protocol. The traffic is forwarded from the external VLAN to the
destination host at 10.0.0.1.

\sphinxstylestrong{Network IP forwarding virtual server}

A network IP forwarding virtual server forwards traffic to the
destination network. For example, the following configuration example
defines a network IP forwarding virtual server that accepts traffic from
any VLAN bound for any host on the 10.0.0.0/24 network, but only if it
arrives on TCP port 22. Matching traffic is forwarded from the
originating VLAN to the host specified in the client request.

Note: IP forwarding virtual servers are similar to Layer 2 forwarding
virtual servers in that neither one load balances traffic to pool
members, but instead forward directly to the destination address
requested by the client. For more information about Layer 2 forwarding
virtual servers, refer to K8082: Overview of TCP connection setup for
BIG-IP LTM virtual server types.

An IP forwarding virtual server is useful when you want to configure the
BIG-IP system to pass infrastructure-related traffic, such as Internet
Control Message Protocol (ICMP) traffic.

\sphinxstylestrong{Emulating stateless IP routing with BIG-IP LTM forwarding virtual servers}

The TMOS-based full-proxy model is stateful and connection-orientated by
nature, in contrast to the stateless IP forwarding typically provided by
L3 routers. The BIG-IP LTM system must be specifically configured to
more closely emulate a standard router’s stateless routing behavior by
adjusting the virtual server and protocol profile configurations to
match your requirements.

For the closest approximation of stateless IP forwarding, F5 recommends
that you create an IP forwarding wildcard virtual server. This
configuration accepts traffic and forwards it using the information
contained in the system routing table, regardless of whether it is
associated with an established connection.

Note: The VLANs on which you enable the forwarding virtual server may
vary depending on your routing requirements and restrictions. The
virtual server should be enabled on all VLANs from which it will accept
and route traffic.

The FastL4 profile determines how the system handles the connection
table entries. Enabling the Loose Initiation option allows the system to
initialize a connection when it receives any TCP packet, rather than
requiring a SYN packet for connection initiation. It also provides a
good alternative to the high overhead of connection mirroring. In the
event of a failover, with the Loose Initiation option enabled, the
standby BIG-IP system accepts connections mid-flow, and forwards, as
expected. The Loose Close option allows the system to remove a
connection when the system receives the first FIN packet from either the
client or the server. This will help trim connection table entries as
the connection entry can be removed as soon as the connection officially
closes, and the system does not need to maintain the connection table
entry.

Note: The Loose Close feature is optional, and may impact system
performance because it disables Packet Velocity ASIC (PVA) Acceleration
for the virtual server. For information about PVA Acceleration, refer to
K4832: Overview of PVA Acceleration. The Loose Close feature does not
impact ePVA acceleration. For information about ePVA acceleration, refer
to K12837: Overview of the ePVA feature.

Setting the Idle Timeout allows the system to remove connections from
the connection table when the connections are no longer active. F5
recommends that you use the default timeout of 300 seconds. If you
disable Reset on Timeout, the system removes connection entries from the
connection table once the idle timeout expires, but the system does not
reset the connection. This setting prevents the BIG-IP LTM system from
sending resets when closing an idle connection, it also reduces the need
to use long idle timeouts for long-lived TCP connections, which may go
idle for extended periods of time. For instance, if an application
allows for long periods of inactivity (greater than the configured Idle
Timeout) with no traffic being exchanged, then without this setting, the
BIG-IP LTM system would close both sides of the connection when the
timeout expired. The system would reject any subsequent packets that the
client or server sent in the same TCP connection, since the connection
is no longer valid on the BIG-IP LTM system. However, with Reset on
Timeout disabled, the BIG-IP LTM quietly removes the connection entry
and neither the client nor the server is aware that the communication
channel has timed out. When the client or server begins communicating
again, the Loose Initiation setting allows the BIG-IP LTM system to
re-add the connection to the connection table, and the newly-arrived
packets are forwarded, as expected.

Note: F5 does not recommend that you set the idle timeout for any
virtual server to immediate or indefinite. Setting the timeout to
immediate results in constant writing and deletion of connection entries
for each datagram, creating undesirable overhead. Setting the timeout to
indefinite (or to large values) results in a connection table that grows
until all available memory is consumed, and typically results in an
unplanned failover upon memory exhaustion.

Some protocols have different requirements than others. In which case, a
more specific virtual server allows you to control traffic handling for
specific protocols. A protocol-specific virtual server can help keep
connection table sizes down, and if Last Hop is still used, will help
reduce stale last hop information for short-lived connections. For
instance, User Datagram Protocol (UDP) is less stateful than TCP, and
does not typically require as long an idle timeout. To set a specific
timeout for UDP traffic, you can create the wildcard forwarding virtual
server described previously, and a protocol-specific forwarding virtual
server and profile. This virtual server listens for only UDP traffic.
All other IP protocols will be processed by the more general wildcard
forwarding virtual server defined previously.

\sphinxstylestrong{Forwarding Virtual Servers Security Concerns}

Since the forwarding virtual server is not processing traffic to a
specific pool resource traffic can be destined for any IP address in the
subnet that the BIG-IP system is listening on. This may allow traffic to
systems that you did not intend to pass.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - Explain how to set up and enable SNMP device traps on the LTM device}

\sphinxurl{https://support.f5.com/csp/article/K3727}

\sphinxstylestrong{SNMP trap configuration files}

Standard, pre-configured SNMP traps are contained in the
/etc/alertd/alert.conf file. F5 does not recommend, or support, the
addition or removal of traps or any other changes to the alert.conf
file.

Custom, user-defined SNMP traps should be defined in the
/config/user\_alert.conf file.

The BIG-IP system will process the alert notification specified in the
/config/user\_alert.conf file first, if the same alert definition exists
on both of the config files.

Prior to BIG-IP 10.1.0, when the alertd process starts, it creates a
dynamic configuration file by appending the /config/user\_alert.conf
file to the /etc/alertd/alert.conf file. The BIG-IP system searches the
dynamic configuration file sequentially for matches. After a match is
found, the trap is generated and no further matches are attempted.

Note: All files in the /config directory, including any customizations
to the /config/user\_alert.conf file, are automatically included in the
UCS archive by default. For more information, refer to K4422: Viewing
and modifying the files that are configured for inclusion in a UCS
archive.

Creating custom SNMP traps

Before you create a custom trap, you must determine the unique syslog
messages for which you want the system to send alerts. The message must
not match the matched\_message value of any other SNMP trap already
defined in the /etc/alertd/alert.conf file or the
/config/user\_alert.conf file.

Note: For information about how to determine which alerts are
pre-configured to trigger an SNMP trap, refer to K6414: Determining
which alerts are pre-configured to trigger an SNMP trap. You may also
examine the alerts from the /config/user\_alert.conf file in the same
manner.

To create a custom SNMP trap, perform the following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line.

\end{enumerate}

2. To back up your /config/user\_alert.conf file, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cp} \PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{user\PYGZus{}alert}\PYG{o}{.}\PYG{n}{conf} \PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{user\PYGZus{}alert}\PYG{o}{.}\PYG{n}{conf}\PYG{o}{.}\PYG{n}{SOL3727}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Edit the /config/user\_alert.conf file.

\end{enumerate}

4. Add a new SNMP trap using the following format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{alert} \PYG{o}{\PYGZlt{}}\PYG{n}{alert\PYGZus{}name}\PYG{o}{\PYGZgt{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZlt{}matched message\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{p}{\PYGZob{}}

\PYG{n}{snmptrap} \PYG{n}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{.1.3.6.1.4.1.3375.2.4.0.XXX}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Note: Replace \textless{}alert\_name\textgreater{} with a descriptive name. Do not use an
alert name that exactly matches one already used in the
/etc/alertd/alert.conf file or the /config/user\_alert.conf file.
Replace \textless{}matched\_message\textgreater{} with text that matches the syslog message
that triggers the custom trap. You can specify a portion of the
syslog message text or use a regular expression. F5 recommends that
you do not include the syslog prefix information, such as the date
stamp and process ID, in the match string. Including information of
a variable nature in the match string or regular expression may
result in unexpected false positives or result in no matches at all.
The syslog message you want to trap must not match the
matched\_message value of any other SNMP trap defined in the
/etc/alertd/alert.conf file or the /config/user\_alert.conf file.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Replace XXX with a number unique to this object ID.

\end{enumerate}

You can use any object ID that meets all of the following criteria:
\begin{itemize}
\item {} 
The object ID is in standard object identifier (OID) format, and within the following range:

\end{itemize}

.1.3.6.1.4.1.3375.2.4.0.300 through .1.3.6.1.4.1.3375.2.4.0.999

Note: If the OID value is outside the range listed above, a trap
will be sent with the OID specified, but it will not contain any
text within the trap body.
\begin{itemize}
\item {} 
The object ID is in a numeric range that can be processed by your trap receiving tool.

\item {} 
The object ID does not already exist in the /usr/share/snmp/mibs/F5-BIGIP-COMMON-MIB.txt management information base (MIB) file.

\item {} 
The object ID is not already used in another custom trap.

\end{itemize}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
Save the file and exit the editor.

\end{enumerate}

Note: If the alertd process fails to start, examine the newly added
entry to ensure it contains all of the required elements and
punctuation.

Note: To test the newly created trap, refer to K11127: Testing SNMP
traps on the BIG-IP system (9.4.x - 13.x).

Custom SNMP trap example

A message that appears similar to the following example is logged to the
/var/log/ltm file when switchboard failsafe is enabled:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Sep} \PYG{l+m+mi}{23} \PYG{l+m+mi}{11}\PYG{p}{:}\PYG{l+m+mi}{51}\PYG{p}{:}\PYG{l+m+mi}{40} \PYG{n}{bigip1}\PYG{o}{.}\PYG{n}{askf5}\PYG{o}{.}\PYG{n}{com} \PYG{n}{lacpd}\PYG{p}{[}\PYG{l+m+mi}{27753}\PYG{p}{]}\PYG{p}{:} \PYG{l+m+mi}{01160016}\PYG{p}{:}\PYG{l+m+mi}{6}\PYG{p}{:}
\PYG{n}{Switchboard} \PYG{n}{Failsafe} \PYG{n}{enabled}
\end{sphinxVerbatim}

To create a custom SNMP trap that is triggered whenever switchboard
failsafe status changes are logged, add the following trap definition to
the /config/user\_alert.conf file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{alert} \PYG{n}{SWITCHBOARD\PYGZus{}FAILSAFE\PYGZus{}STATUS} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Switchboard Failsafe (.}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{*)}\PYG{l+s+s2}{\PYGZdq{}} \PYG{p}{\PYGZob{}}

\PYG{n}{snmptrap} \PYG{n}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{.1.3.6.1.4.1.3375.2.4.0.500}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - Describe the implications of port lockdown settings}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/13.html}

\sphinxstylestrong{Port lockdown}

Each self IP address has a feature known as port lockdown. Port lockdown
is a security feature that allows you to specify particular UDP and TCP
protocols and services from which the self IP address can accept
traffic.

You can determine the supported protocols and services by using the tmsh
command tmsh list net self-allow defaults.

If you do not want to use the default setting (Allow None), you can
configure port lockdown to allow either all UDP and TCP protocols and
services (Allow All) or only those that you specify (Allow Custom).

Note: High availability-related traffic from configured peer devices in
a device group might not be subject to port lockdown settings.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/csp/article/K13250}

The port lockdown feature allows you to secure the BIG-IP system from
unwanted connection attempts by controlling the level of access to each
self IP address defined on the system. Each port lockdown list setting,
defined later in this document, specifies the protocols and services
from which a self IP can accept connections. The system refuses traffic
and connections made to a service or protocol port that is not on the
list.

Port lockdown exceptions
\begin{itemize}
\item {} 
TCP port 1028: In BIG-IP 11.0.0 - 11.3.0 redundant pair
configurations, the system allows \sphinxurl{tcp:1028} for connection and
persistence mirroring, regardless of the port lockdown settings.

\item {} 
TCP port 1029 - 1043: Beginning in BIG-IP 11.4.0, the BIG-IP system
maintains a separate mirroring channel for each traffic group. The
port range for each connection channel begins at TCP 1029 and
increments by one for each new traffic group and channel created. By
default, the BIG-IP system allows TCP ports 1029-1043. For more
information, refer to K14894: The BIG-IP system establishes a
separate mirroring channel for each traffic group.

\item {} 
TCP port 4353: When BIG-IP 11.0.0 and later devices are configured in
a synchronization group, peer devices communicate using Centralized
Management Infrastructure (CMI) on \sphinxurl{tcp:4353}, regardless of the port
lockdown settings.

\end{itemize}

Note: CMI uses the same port as iQuery \sphinxurl{tcp:4353}, but is independent
of iQuery and the port configuration options available for the port.
If you are using iQuery, you must allow port 4353 in your port
lockdown settings.
\begin{itemize}
\item {} 
ICMP: ICMP traffic to the self-IP address is not affected by the port
lockdown list and is implicitly allowed in all cases.

\end{itemize}

Note: In most cases, it is not possible to ping self IP addresses
across Virtual Local Area Networks (VLANs). For more information,
refer to K3475: The BIG-IP system may not respond to requests for a
self IP address.

\sphinxstylestrong{Port lockdown setting definitions:}

Allow Default

This option allows access to a pre-defined set of network protocols and
services that are typically required in a BIG-IP deployment.

The Allow Default setting specifies that connections to the self IP
address are allowed from the following protocols and services:

Allowed protocol Service Service definition


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Allowed protocol}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Service}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Service definition}
\\
\hline
OSPF
&
N/A
&
N/A
\\
\hline
TCP
&
4353
&
iQuery
\\
\hline
UDP
&
4353
&
iQuery
\\
\hline
TCP
&
443
&
HTTPS
\\
\hline
TCP
&
161
&
SNMP
\\
\hline
UDP
&
161
&
SNMP
\\
\hline
TCP
&
22
&
SSH
\\
\hline
TCP
&
53
&
DNS
\\
\hline
UDP
&
53
&
DNS
\\
\hline
UDP
&
520
&
RIP
\\
\hline
UDP
&
1026
&
network failover
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

You can also determine the default supported protocols and services by
using the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh} \PYG{n+nb}{list} \PYG{n}{net} \PYG{n+nb+bp}{self}\PYG{o}{\PYGZhy{}}\PYG{n}{allow}
\end{sphinxVerbatim}

The output appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{net} \PYG{n+nb+bp}{self}\PYG{o}{\PYGZhy{}}\PYG{n}{allow} \PYG{p}{\PYGZob{}}
\PYG{n}{defaults} \PYG{p}{\PYGZob{}}
\PYG{n}{ospf}\PYG{p}{:}\PYG{n+nb}{any}
\PYG{n}{tcp}\PYG{p}{:}\PYG{n}{domain}
\PYG{n}{tcp}\PYG{p}{:}\PYG{n}{f5}\PYG{o}{\PYGZhy{}}\PYG{n}{iquery}
\PYG{n}{tcp}\PYG{p}{:}\PYG{n}{https}
\PYG{n}{tcp}\PYG{p}{:}\PYG{n}{snmp}
\PYG{n}{tcp}\PYG{p}{:}\PYG{n}{ssh}
\PYG{n}{udp}\PYG{p}{:}\PYG{l+m+mi}{520}
\PYG{n}{udp}\PYG{p}{:}\PYG{n}{cap}
\PYG{n}{udp}\PYG{p}{:}\PYG{n}{domain}
\PYG{n}{udp}\PYG{p}{:}\PYG{n}{f5}\PYG{o}{\PYGZhy{}}\PYG{n}{iquery}
\PYG{n}{udp}\PYG{p}{:}\PYG{n}{snmp}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Allow All

\end{itemize}

This option specifies that all connections to the self IP address are
allowed, regardless of protocol or service.
\begin{itemize}
\item {} 
Allow None

\end{itemize}

This option specifies that no connections are allowed on the self IP
address, regardless of protocol or service. However, ICMP traffic is
always allowed, and if the BIG-IP systems are configured in a redundant
pair, ports that are listed as exceptions are always allowed from the
peer system.
\begin{itemize}
\item {} 
Allow Custom

\end{itemize}

This option allows you to specify the protocols and services for which
connections are allowed on the self IP address. However, ICMP traffic is
always allowed, and if the BIG-IP systems are configured in a redundant
pair, ports that are listed as exceptions are always allowed from the
peer system.

Important: A known issue prevents connections to the state mirroring
address when port \sphinxurl{tcp:1028} is explicitly allowed in the custom port
lockdown list. For more information, refer to K12932: The BIG-IP system
resets statemirror connections when port 1028 is configured in the Self
IP Port Lockdown list.

Default port lockdown setting

When creating self IP addresses using the Configuration utility, the
default port lockdown setting in BIG-IP 10.x through 11.5.2 is Allow
Default, and for BIG-IP 11.6.0 and later versions is Allow None.

When creating self IP addresses using the bigpipe or tmsh utilities, the
default port lockdown setting in BIG-IP 10.x is Allow None. For BIG-IP
11.0.0 - 11.5.2, the default port lockdown setting is Allow Default, and
for BIG-IP 11.5.3 and 11.6.0 and later versions, the default port
lockdown setting is Allow None.

Using the Configuration utility to modify port lockdown settings for a
specific self IP
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to Network \textgreater{} Self IPs.

\item {} 
Click the relevant self IP address.

\item {} 
From the Port Lockdown box, click the setting you want.

\item {} 
Click Update.

\end{enumerate}

Using the tmsh utility to modify port lockdown settings

1. Log in to the Traffic Management Shell (tmsh) by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tmsh}
\end{sphinxVerbatim}

2. To modify the port lockdown settings for a self IP address, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{modify} \PYG{o}{/}\PYG{n}{net} \PYG{n+nb+bp}{self} \PYG{o}{\PYGZlt{}}\PYG{n}{self\PYGZus{}IP}\PYG{o}{\PYGZgt{}} \PYG{n}{allow}\PYG{o}{\PYGZhy{}}\PYG{n}{service} \PYG{o}{\PYGZlt{}}\PYG{n}{option}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

For example, to change the port lockdown setting for self IP address
10.10.10.1 to default, you would type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{modify} \PYG{o}{/}\PYG{n}{net} \PYG{n+nb+bp}{self} \PYG{l+m+mf}{10.10}\PYG{o}{.}\PYG{l+m+mf}{10.1} \PYG{n}{allow}\PYG{o}{\PYGZhy{}}\PYG{n}{service} \PYG{n}{default}
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Save the change by typing the following command:

\end{enumerate}

BIG-IP 10.1.0 and later:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{save} \PYG{n}{sys} \PYG{n}{config}
\end{sphinxVerbatim}

\sphinxstylestrong{Recommendations}

For optimal security, F5 recommends that you use the port lockdown
feature to allow only the protocols or services required for a self IP
address.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - (Supplemental Example) Describe how to disable services}

\sphinxstylestrong{Making the BIG-IP Listen for a service}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/2.html\#conceptid}

The Big-IP platform is a default deny network platform. You have to
configure the BIG-IP to listen for traffic whether that is for
management or for production traffic. Virtual servers are the listeners
for application traffic services. Some listeners need to be built to
pass more than one type of traffic. And many times, the configuration
will allow either one port or all ports. If you want to restrict it to a
short list of ports, an iRule can be used that will allow the selective
list of ports.

Simply sending a TCP reset to a port scan can tell an intruder a lot
about your environment. By default, the TM.RejectUnmatched BigDB
variable is set to true, and the BIG-IP system sends a TCP RST packet in
response to a non-SYN packet that matches a virtual server address and
port or self IP address and port, but does not match an established
connection. The BIG-IP system also sends a TCP RST packet in response to
a packet that matches a virtual server address, or self IP address, but
specifies an invalid port. The TCP RST packet is sent on the client side
of the connection, and the source IP address of the reset is the
relevant BIG-IP LTM object address or self IP address for which the
packet was destined. If TM.RejectUnmatched is set to false, the system
silently drops unmatched packets.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - (Supplemental Example) Describe how to disable ARP}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-ip-routing-administration-11-5-0/5.html}

\sphinxstylestrong{Address Resolution Protocol on the BIG-IP system}

The BIG-IP system is a multi-layer network device, and as such, needs to
perform routing functions. To do this, the BIG-IP system must be able to
find destination MAC addresses on the network, based on known IP
addresses. The way that the BIG-IP system does this is by supporting
Address Resolution Protocol (ARP), an industry-standard Layer 3
protocol. Settings for ARP behaviors can be found on the Main tab, click
Network \textgreater{} ARP \textgreater{} Options. You can also see and manage the dynamic and
static ARP entries in ARP cache from the console or the GUI.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/2.html\#conceptid}

\sphinxstylestrong{Disabling ARP for A Virtual Server’s Address}

If you want to control how the BIG-IP handles ARP for a virtual server
you can make a change to the configuration of the virtual address of the
virtual server.

\sphinxstylestrong{What is a virtual address?}

A virtual address is the IP address with which you associate a virtual
server. For example, if a virtual server’s IP address and service are
10.10.10.2:80, then the IP address 10.10.10.2 is a virtual address.

You can create a many-to-one relationship between virtual servers and a
virtual address. For example, you can create the three virtual servers
10.10.10.2:80, 10.10.10.2:443, and 10.10.10.2:161 for the same virtual
address, 10.10.10.2.

You can enable and disable a virtual address. When you disable a virtual
address, none of the virtual servers associated with that address can
receive incoming network traffic.

You create a virtual address indirectly when you create a virtual
server. When this happens, Local Traffic Manager internally associates
the virtual address with a MAC address. This in turn causes the BIG-IP
system to respond to Address Resolution Protocol (ARP) requests for the
virtual address, and to send gratuitous ARP requests and responses with
respect to the virtual address. As an option, you can disable ARP
activity for virtual addresses, in the rare case that ARP activity
affects system performance. This most likely occurs only when you have a
large number of virtual addresses defined on the system.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - (Supplemental Example) Explain how to set up logging for security events on the LTM device}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-external-monitoring-implementations-11-5-0/6.html}

\sphinxstylestrong{Overview: Configuring DoS Protection event logging}

You can configure the BIG-IP system to log information about BIG-IP
system denial-of-service (DoS) events, and send the log messages to
remote high-speed log servers.

Important: The BIG-IP Advanced Firewall Manager (AFM) must be licensed
and provisioned before you can configure DoS Protection event logging.
Additionally, for high-volume logging requirements, such as DoS, ensure
that the BIG-IP system sends the event logs to a remote log server.

When configuring remote high-speed logging of DoS Protection event
logging, it is helpful to understand the objects you need to create and
why, as described here:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Object to create in implementation
&\sphinxstyletheadfamily 
Reason
\\
\hline
Pool of remote log servers
&
Create a pool of remote log servers to which the BIG-IP system can send log messages.
\\
\hline
Destination (unformatted)
&
Create a log destination of Remote High-Speed Log type that specifies a pool of remote log servers.
\\
\hline
Destination (formatted)
&
If your remote log servers are the ArcSight, Splunk, IPFIX, or Remote Syslog type, create an additional log destination to format the logs in the required format and forward the logs to a remote high-speed log destination.
\\
\hline
Publisher
&
Create a log publisher to send logs to a set of specified log destinations.
\\
\hline
Logging profile
&
Create a custom Logging profile to enable logging of user-specified data at a user-specified level, and associate a log publisher with the profile.
\\
\hline
LTM virtual server
&
Associate a custom Logging profile with a virtual server to define how the BIG-IP system logs security events on the traffic that the virtual server processes.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

This illustration shows the association of the configuration objects for
remote high-speed logging of DoS Protection events.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p181}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Association of remote high-speed logging configuration objects

\sphinxstylestrong{Task summary}

Perform these tasks to configure logging of DoS Protection events on the
BIG-IP system.

Note: Enabling logging impacts BIG-IP system performance.

\sphinxstylestrong{Creating a pool of remote logging servers}

Before creating a pool of log servers, gather the IP addresses of the
servers that you want to include in the pool. Ensure that the remote log
servers are configured to listen to and receive log messages from the
BIG-IP system.

Create a pool of remote log servers to which the BIG-IP system can send
log messages.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click DNS \textgreater{} Delivery \textgreater{} Load Balancing \textgreater{} Pools or Local Traffic \textgreater{} Pools. The Pool List screen opens.

\item {} 
Click Create. The New Pool screen opens.

\item {} 
In the Name field, type a unique name for the pool.

\item {} 
Using the New Members setting, add the IP address for each remote logging server that you want to include in the pool:
\begin{itemize}
\item {} 
Type an IP address in the Address field, or select a node address from the Node List.

\item {} 
Type a service number in the Service Port field, or select a service name from the list. Note: Typical remote logging servers require port 514.

\item {} 
Click Add.

\end{itemize}

\item {} 
Click Finished.

\end{enumerate}

\sphinxstylestrong{Creating a remote high-speed log destination}

Before creating a remote high-speed log destination, ensure that at
least one pool of remote log servers exists on the BIG-IP system. Create
a log destination of the Remote High-Speed Log type to specify that log
messages are sent to a pool of remote log servers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} Logs \textgreater{} Configuration \textgreater{} Log Destinations. The Log Destinations screen opens.

\item {} 
Click Create.

\item {} 
In the Name field, type a unique, identifiable name for this destination.

\item {} 
From the Type list, select Remote High-Speed Log.

\end{enumerate}

Important: If you use log servers such as Remote Syslog, Splunk,
or ArcSight, which require data be sent to the servers in a specific
format, you must create an additional log destination of the
required type, and associate it with a log destination of the Remote
High-Speed Log type. With this configuration, the BIG-IP system can
send data to the servers in the required format. The BIG-IP system
is configured to send an unformatted string of text to the log
servers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
From the Pool Name list, select the pool of remote log servers to
which you want the BIG-IP system to send log messages.

\item {} 
From the Protocol list, select the protocol used by the high-speed
logging pool members.

\item {} 
Click Finished.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Creating a formatted remote high-speed log destination}

Ensure that at least one remote high-speed log destination exists on the
BIG-IP system.

Create a formatted logging destination to specify that log messages are
sent to a pool of remote log servers, such as Remote Syslog, Splunk, or
ArcSight servers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} Logs \textgreater{} Configuration \textgreater{} Log Destinations. The Log Destinations screen opens.

\item {} 
Click Create.

\item {} 
In the Name field, type a unique, identifiable name for this destination.

\item {} 
From the Type list, select a formatted logging destination, such as IPFIX, Remote Syslog, Splunk, or ArcSight.

\end{enumerate}

Important: ArcSight formatting is only available for logs coming
from Advanced Firewall Manager (AFM), Application Security Manager
(ASM), and the Secure Web Gateway component of Access Policy Manager
(APM). IPFIX is not available for Secure Web Gateway. The BIG-IP
system is configured to send a formatted string of text to the log
servers.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If you selected Remote Syslog, from the Syslog Format list, select a format for the logs, and then from the High-Speed Log Destination list, select the destination that points to a pool of remote Syslog servers to which you want the BIG-IP system to send log messages.

\item {} 
If you selected Splunk or IPFIX, from the Forward To list, select the destination that points to a pool of high-speed log servers to which you want the BIG-IP system to send log messages.

\item {} 
Click Finished.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Creating a publisher}

Ensure that at least one destination associated with a pool of remote
log servers exists on the BIG-IP system. Create a publisher to specify
where the BIG-IP system sends log messages for specific resources.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} Logs \textgreater{} Configuration \textgreater{} Log Publishers. The Log Publishers screen opens.

\item {} 
Click Create.

\item {} 
In the Name field, type a unique, identifiable name for this publisher.

\item {} 
For the Destinations setting, select a destination from the Available list, and click \textless{}\textless{} to move the destination to the Selected list.

\end{enumerate}

Note: If you are using a formatted destination, select the
destination that matches your log servers, such as Remote Syslog,
Splunk, or ArcSight.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Click Finished.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Creating a custom DoS Protection Logging profile}

Create a custom Logging profile to log DoS Protection events and send
the log messages to a specific location.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Security \textgreater{} Event Logs \textgreater{} Logging Profiles. The Logging Profiles list screen opens.

\item {} 
Click Create. The New Logging Profile screen opens.

\item {} 
Select the DoS Protection check box.

\item {} 
In the DNS DoS Protection area, from the Publisher list, select the publisher that the BIG-IP system uses to log DNS DoS events. You can specify publishers for other DoS types in the same profile, for example, for SIP or Application DoS Protection.

\item {} 
Click Finished.

\end{enumerate}

Assign this custom DoS Protection Logging profile to a virtual server.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Configuring an LTM virtual server for DoS Protection event logging}

Ensure that at least one Log Publisher exists on the BIG-IP system.

Assign a custom DoS Protection Logging profile to a virtual server when
you want the BIG-IP system to log DoS Protection events on the traffic
the virtual server processes.

Note: This task applies only to LTM-provisioned systems.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Virtual Servers. The Virtual Server List screen opens.

\item {} 
Click the name of the virtual server you want to modify.

\item {} 
On the menu bar, click Security \textgreater{} Policies. The screen displays Policy settings and Inline Rules settings.

\item {} 
From the Log Profile list, select Enabled. Then, for the Profile setting, move the profiles that log specific events to specific locations from the Available list to the Selected list.

\item {} 
Click Update to save the changes.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Disabling logging}

Disable Network Firewall, Protocol Security, or DoS Protection event
logging when you no longer want the BIG-IP system to log specific events
on the traffic handled by specific resources.

Note: You can disable and re-enable logging for a specific resource
based on your network administration needs.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Virtual Servers. The Virtual Server List screen opens.

\item {} 
Click the name of the virtual server you want to modify.

\item {} 
On the menu bar, click Security \textgreater{} Policies. The screen displays Policy settings and Inline Rules settings.

\item {} 
From the Log Profile list, select Disabled.

\item {} 
Click Update to save the changes.

\end{enumerate}

The BIG-IP system does not log the events specified in this profile for
the resources to which this profile is assigned.

\sphinxstylestrong{Implementation result}

You now have an implementation in which the BIG-IP system logs specific
DoS Protection events and sends the logs to a specific location.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - (Supplemental Example) Explain how route domains can be used to enforce network segmentation}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-ip-routing-administration-11-5-0/2.html}

\sphinxstylestrong{What is a route domain?}

A route domain is a configuration object that isolates network traffic
for a particular application on the network.

Because route domains segment network traffic, you can assign the same
IP address or subnet to multiple nodes on a network, provided that each
instance of the IP address resides in a separate routing domain.

Note: Route domains are compatible with both IPv4 and IPv6 address
formats.

\sphinxstylestrong{Benefits of route domains}

Using the route domains feature of the BIG-IP system, you can provide
hosting service for multiple customers by isolating each type of
application traffic within a defined address space on the network.

With route domains, you can also use duplicate IP addresses on the
network, provided that each of the duplicate addresses resides in a
separate route domain and is isolated on the network through a separate
VLAN. For example, if you are processing traffic for two different
customers, you can create two separate route domains. The same node
address (such as 10.0.10.1) can reside in each route domain, in the same
pool or in different pools, and you can assign a different monitor to
each of the two corresponding pool members.

\sphinxstylestrong{Sample partitions with route domain objects}

This illustration shows two route domain objects on a BIG-IP system,
where each route domain corresponds to a separate customer, and thus
resides in its own partition. Within each partition, the customer
created the network objects and local traffic objects required for that
customer’s application (AppA or AppB).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p19}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Sample route domain deployment}

A good example of the use of route domains is a configuration for an ISP
that services multiple customers, where each customer deploys a
different application. In this case, the BIG-IP system isolates traffic
for two different applications into two separate route domains. The
routes for each application’s traffic cannot cross route domain
boundaries because cross-routing restrictions are enabled on the BIG-IP
system by default.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p20}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

About strict isolation

You can control the forwarding of traffic across route domain boundaries
by configuring the strict isolation feature of a route domain:

If strict isolation is enabled, the BIG-IP system allows traffic
forwarding from that route domain to the specified parent route domain
only. This is the default behavior. Note that for successful isolation,
you must enable the strict isolation feature on both the child and the
parent route domains.

If strict isolation is disabled, the BIG-IP system allows traffic
forwarding from that route domain to any route domain on the system,
without the need to define a parent-child relationship between route
domains. Note that in this case, for successful forwarding, you must
disable the strict isolation feature on both the forwarding route domain
and the target route domain (that is, the route domain to which the
traffic is being forwarded).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Conclusion}
\label{\detokenize{class5/modules/module2:conclusion}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

This document is intended as a study guide for the F5 301a \textendash{} LTM
Specialist: Architect, Set-Up \& Deploy exam version 2 - TMOS v11.5.0.
This study guide is not an all-inclusive document that will guarantee a
passing grade on the exam. It is intended to be a living doc and any feedback or material that you feel should be included, to help exam takers better prepare, can be sent to
\sphinxhref{mailto:F5CertGuides@f5.com}{F5CertGuides@f5.com}.

Thank you for using this study guide to prepare the 301a \textendash{} LTM
Specialist exam and good luck with your certification goals.

Thanks

\sphinxstylestrong{Eric Mitchell}

Sr. Systems Engineer - Global SI


\chapter{F5 301A - BIG-IP LTM Specialist Labs 11/01/19}
\label{\detokenize{class6/class6:f5-301a-big-ip-ltm-specialist-labs-11-01-19}}\label{\detokenize{class6/class6::doc}}
These exercises are design to reinforce the concepts outlined in the
\sphinxstylestrong{LTM Specialist: Architect, Setup, and Deploy} certification blueprint. F5
certifications exams are designed to required hands-on experience to pass the
test and these exercises will help you deal with exam questions requiring you
to interpret configuration and other outputs from the BIG-IP.

Exam blueprints and study guides can be found on the F5 Support site at:
\sphinxurl{https://support.f5.com/csp/article/K29900360}

This class covers the following topics:
- Basic Setup, TMSH and SNATs
- Profiles
- Application Visibilty and Reporting (AVR)
- Monitors and Status
- SSL
- Virtual Servers and Packet Processing Review
- Load Balancing and Pools
- Networking
- Roles and Partitions
- Device Service Clusters and High Availability
- Security and Securing the BIG-IP

Expected time to complete: \sphinxstylestrong{6-8 hours}


\section{Lab 1 - Basic Setup, TMSH and SNATs}
\label{\detokenize{class6/module01/module01:lab-1-basic-setup-tmsh-and-snats}}\label{\detokenize{class6/module01/module01::doc}}
In this section, you will provide the basic networking, create a virtual
server and pool to test your comfort level with basic set up. Try
doing much of this through \sphinxstylestrong{tmsh} commands to become familiar with
the basic syntax, which you may see on the exams. If you get stuck module
\sphinxstylestrong{3.12 TMOS commands} has the required commands. Finally you will work with
SNATs and NATs to solidify the concepts in the first exam objective.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.01}] \leavevmode\begin{itemize}
\item {} 
Given an expected traffic volume, determine the appropriate SNAT
configuration

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{Basic set up using TMSH}
\label{\detokenize{class6/module01/lab1:basic-set-up-using-tmsh}}\label{\detokenize{class6/module01/lab1::doc}}

\subsubsection{TMSH challenge}
\label{\detokenize{class6/module01/lab1:tmsh-challenge}}
Access your BIG-IP, perform a basic build of networking, pool and
virtual server and establish that your environment is working. \sphinxstylestrong{If you
are unfamiliar with TMSH this is a good opportunity to get a feel for it.}

For BIG-IP WebUI access open a browser and access \sphinxstylestrong{https://10.1.1.245}. Log into the BIG-IP VE system using the following credentials:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{admin}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{admin}
\end{sphinxVerbatim}

For BIG-IP terminal access, you have two options:
\begin{itemize}
\item {} 
SSH Access from a Linux terminal window. Open a terminal window and
type the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ssh} \PYG{n}{root}\PYG{o}{@}\PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.245}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{default}
\end{sphinxVerbatim}

\item {} 
Select the PuTTY icon on the bottom task bar and select \sphinxstylestrong{bigip01}

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
If you use PuTTY, your MIDDLE mouse button or \sphinxstylestrong{\textless{}shift\textgreater{} insert} allows you to paste into
the window
\end{sphinxadmonition}

Given the following information, network the BIG-IP and build a basic pool and
virtual server using SNAT automap.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline

VLANs
&
Name:
&
client\_vlan
&
server\_vlan
&\\
\hline&
Interface:
&
1.1
&
1.2
&\\
\hline
IP Addressing
&
Name:
&
client\_ip
&
server\_ip
&\\
\hline&
IP Address:
&
10.1.10.245
&
10.1.20.245
&\\
\hline&
Netmask:
&
255.255.255.0
&
255.255.255.0
&\\
\hline&
VLAN:
&
client\_vlan
&
server\_vlan
&\\
\hline&&&&\\
\hline
Pool
&
Name:
&
www\_pool
&&\\
\hline&
Members
&
10.1.20.11:80
&
10.1.20.12:80
&
10.1.20.13:80
\\
\hline
Virtual Server
&
Name:
&
www\_vs
&&\\
\hline&
Destination:
&
10.1.10.100:80
&&\\
\hline&
Pool
&
www\_pool
&&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Here are example TMSH command to help you:

Command examples for networking:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{n}{net} \PYG{n}{vlan} \PYG{o}{\PYGZlt{}}\PYG{n}{vlan}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{n}{interfaces} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{o}{\PYGZlt{}}\PYG{n}{interface}\PYG{o}{\PYGZgt{}} \PYG{p}{\PYGZob{}} \PYG{n}{untagged} \PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZcb{}}

\PYG{n}{create} \PYG{n}{net} \PYG{n+nb+bp}{self} \PYG{o}{\PYGZlt{}}\PYG{n}{ip\PYGZus{}name}\PYG{o}{\PYGZgt{}} \PYG{n}{address} \PYG{o}{\PYGZlt{}}\PYG{n}{ip}\PYG{o}{/}\PYG{n}{mask}\PYG{o}{\PYGZgt{}} \PYG{n}{vlan} \PYG{o}{\PYGZlt{}}\PYG{n}{vlan\PYGZus{}name}\PYG{o}{\PYGZgt{}}

\PYG{n}{create} \PYG{n}{net} \PYG{n}{route} \PYG{n}{def\PYGZus{}gw} \PYG{n}{network} \PYG{l+m+mf}{0.0}\PYG{o}{.}\PYG{l+m+mf}{0.0}\PYG{o}{/}\PYG{l+m+mi}{0} \PYG{n}{gw} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.1}
\end{sphinxVerbatim}

Command example for creating pool:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{n}{ltm} \PYG{n}{pool} \PYG{o}{\PYGZlt{}}\PYG{n}{pool} \PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{n}{members} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{o}{\PYGZlt{}}\PYG{n}{ip}\PYG{p}{:}\PYG{n}{port}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{ip}\PYG{p}{:}\PYG{n}{port}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{etc}\PYG{o}{\PYGZgt{}} \PYG{p}{\PYGZcb{}} \PYG{n}{monitor} \PYG{n}{http}
\end{sphinxVerbatim}

Command example for creating a standard virtual server:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{create} \PYG{n}{ltm} \PYG{n}{virtual} \PYG{o}{\PYGZlt{}}\PYG{n}{vs} \PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{n}{destination} \PYG{o}{\PYGZlt{}}\PYG{n}{ip}\PYG{p}{:}\PYG{n}{port}\PYG{o}{\PYGZgt{}} \PYG{n}{pool} \PYG{o}{\PYGZlt{}}\PYG{n}{pool} \PYG{n}{name}\PYG{o}{\PYGZgt{}} \PYG{n}{ip}\PYG{o}{\PYGZhy{}}\PYG{n}{protocol} \PYG{n}{tcp} \PYG{n}{source}\PYG{o}{\PYGZhy{}}\PYG{n}{address}\PYG{o}{\PYGZhy{}}\PYG{n}{translation} \PYG{p}{\PYGZob{}} \PYG{n+nb}{type} \PYG{n}{automap} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Write your configuration to disk and create an archive:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{save} \PYG{n}{sys} \PYG{n}{config}
\PYG{n}{save} \PYG{n}{sys} \PYG{n}{ucs} \PYG{n}{lab1}\PYG{o}{\PYGZhy{}}\PYG{n}{base}\PYG{o}{\PYGZhy{}}\PYG{n}{config}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The tmsh commands to build the base configuration can be found in \sphinxstylestrong{Module 3.12}.
\end{sphinxadmonition}

Log on to the BIG-IP WebUI and verify your virtual server is \sphinxstylestrong{Available} (green circle).

Using a new browser window (preferably a private browser window) access
the web site at \sphinxurl{http://10.1.10.100}

\sphinxstyleemphasis{Q1. In} \sphinxstylestrong{Request Detail} \sphinxstyleemphasis{at the top of the page, what is the client
IP address and why?}


\subsection{SNATs and NATs}
\label{\detokenize{class6/module01/lab1:snats-and-nats}}

\subsubsection{SNAT Pools}
\label{\detokenize{class6/module01/lab1:snat-pools}}
You will build a new FTP application, to take a closer look at SNATs and
SNAT Pools using the \sphinxstylestrong{tcpdump} tool and view the connection table.

When building the FTP application you will use the default
\sphinxstylestrong{FTP} profile and use \sphinxstylestrong{Auto Map} for the Source Translation address.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Pools} and create a new pool.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{40}{70}|\X{30}{70}|}
\hline

Name
&
\sphinxstylestrong{ftp\_pool}
\\
\hline
Health Monitor
&
\sphinxstylestrong{tcp}
\\
\hline
Address
&
\sphinxstylestrong{10.1.20.11}
\\
\hline
Service Port
&
\sphinxstylestrong{21}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Go to \sphinxstylestrong{Local Traffic \textgreater{} Virtual Servers} and create a new virtual server.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{40}{70}|\X{30}{70}|}
\hline

Name
&
\sphinxstylestrong{ftp\_vs}
\\
\hline
Destination Address
&
\sphinxstylestrong{10.1.10.100}
\\
\hline
Service Port
&
\sphinxstylestrong{21}
\\
\hline
FTP Profile
&
\sphinxstylestrong{ftp}
\\
\hline
Source Address Translation
&
\sphinxstylestrong{Auto Map}
\\
\hline
Default Pool
&
\sphinxstylestrong{ftp\_pool}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Verify your FTP virtual server and pool are \sphinxstylestrong{Available}.

Open up a terminal window and SSH to the BIG-IP:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ssh} \PYG{n}{root}\PYG{o}{@}\PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{1.245}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{default}
\end{sphinxVerbatim}

Or use PuTTY:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{root}
\PYG{n}{Passwood}\PYG{p}{:} \PYG{n}{default}
\end{sphinxVerbatim}

At the BIG-IP CLI prompt do a tcpdump of the server-side traffic and
watch the FTP pool member:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{nni} \PYG{n}{server\PYGZus{}vlan} \PYG{n}{host} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.11}
\end{sphinxVerbatim}

From a Linux terminal window FTP to 10.1.10.100. The logon credentials
are \sphinxstylestrong{root/default}. It may take 15-20 to connect.

\sphinxstyleemphasis{Q1. Do you see traffic destined for the for the FTP server? What is the source IP?}

Imagine a dozen virtual servers using
using Auto Map. It would be extremely difficult to watch for particular
client traffic from a particular virtual server. Not to mention a SNAT IP address can only handle 65535. SNAT pools can make
management and debugging a little easier and keep port exhaustion at bay.

Create a SNAT pool and assign it to the FTP server.

Go to \sphinxstylestrong{Address Translation} on the sidebar and select \sphinxstylestrong{SNAT Pool List}
and create a new SNAT pool named \sphinxstylestrong{SNATpool\_249} with \sphinxstylestrong{10.1.20.249}
as a member.

\sphinxstyleemphasis{Q2. Why might you require more than one IP address in the SNAT pool?}

Go to the \sphinxstylestrong{ftp\_vs} and change the \sphinxstylestrong{Source Address Translation} to
the \sphinxstylestrong{SNATpool\_249} pool.

Let’s tried the tcpdump we did earlier, but have it limited to the pool
member and SNAT pool IP:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{nni} \PYG{n}{server\PYGZus{}vlan} \PYG{n}{host} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.15} \PYG{o+ow}{and} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.249}
\end{sphinxVerbatim}

Now there is no extraneous traffic being seen. Open a terminal window
and ftp to \sphinxstylestrong{10.1.10.100} and log on to the ftp server. User: \sphinxstylestrong{root}
Password: \sphinxstylestrong{default}

\sphinxstyleemphasis{Q3. What is the client IP that shows up in the tcpdump?}

Open up another SSH session to the BIG-IP, go into \sphinxstylestrong{TMSH} and dump the
connection table:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{show} \PYG{n}{sys} \PYG{n}{connection}
\end{sphinxVerbatim}

Find the connection with your client IP 10.1.10.51 and the SNAT pool IP.

\sphinxstyleemphasis{Q4. What are the ephemeral port numbers on your client-side source IP
and server-side source IP?}


\subsubsection{More SNATs and NATs}
\label{\detokenize{class6/module01/lab1:more-snats-and-nats}}
Let’s take a look at using SNATs to allow internal resources to access
external resources more securely and the difference between a SNAT and
a NAT.

The LAMP server used for the internal server farm has a default gateway
of 10.1.20.240 and has no external access at this time, but you can SSH
to it via the out-of-band management network at \sphinxstylestrong{10.1.1.252}.

On the BIG-IP, add a new self IP address named \sphinxstylestrong{server\_gw} to the VLAN
\sphinxstylestrong{server\_vlan}, with an IP address of \sphinxstylestrong{10.1.20.240} and netmask of \sphinxstylestrong{255.255.255.0}

From the jumpbox, SSH to the LAMP server at \sphinxstylestrong{10.1.1.252}. You can open PuTTY, load the \sphinxstylestrong{LAMP} Server profile and SSH to the LAMP server or open a terminal window and \sphinxstylestrong{ssh root@10.1.1.252}.  The user credentials are \sphinxstylestrong{root/default}.

At the command prompt, attempt to hit the Google open DNS server:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dig} \PYG{o}{@}\PYG{l+m+mf}{8.8}\PYG{o}{.}\PYG{l+m+mf}{4.4}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q1. Did the command succeed?}

On the BIG-IP, open the \sphinxstylestrong{SNAT List} and select \sphinxstylestrong{Create}

Create a new SNAT translation Name: \sphinxstylestrong{server\_snat,} used the IP
address \sphinxstylestrong{10.1.10.248} for the Translation and limit the allowed
ingress traffic to VLAN \sphinxstylestrong{server\_vlan}.

In a BIG-IP terminal window, do a \sphinxstylestrong{tcpdump} on the \sphinxstylestrong{client\_vlan},
limited to the \sphinxstylestrong{10.1.20.248} and \sphinxstylestrong{8.8.4.4}.

From the LAMP server try the \sphinxstylestrong{dig} command again from the LAMP server.

\sphinxstyleemphasis{Q2. Did the dig work? What was the source IP?. Did the ping work? What
was the result?}

Stop the \sphinxstylestrong{tcpdump} and start a new one limited to the FTP port 21:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{i} \PYG{n}{client\PYGZus{}vlan} \PYG{n}{port} \PYG{l+m+mi}{21}
\end{sphinxVerbatim}

From from a command prompt on the jumpbox attempt to FTP to \sphinxstylestrong{10.1.10.248}.  Oh the Windows jumpbox hit \sphinxstylestrong{Start} and the select ** Command Prompt ** from the pop-up.

\sphinxstyleemphasis{Q3. What happened when you try to FTP to the SNAT address? What did the tcpdump show?}

Go to \sphinxstylestrong{Statistics \textgreater{}\textgreater{} Module Statistics \textgreater{}\textgreater{} Local Traffic} and select
\sphinxstylestrong{Statistics Type: SNAT Translations} and review the information.

Under \sphinxstylestrong{Address Translation} go to the \sphinxstylestrong{NAT List} and create a NAT
named \sphinxstylestrong{server\_15\_nat} with a \sphinxstylestrong{NAT Address} of \sphinxstylestrong{10.1.10.15} (outside) and
an \sphinxstylestrong{Origin Address} of \sphinxstylestrong{10.1.20.15} (inside).

Attempt to ping 10.1.10.15.Attempt to FTP to 10.1.10.15.

\sphinxstyleemphasis{Q4. When you attempted to FTP and ping 10.1.10.15 and access 10.1.20.15
behind the BIG-IP were you successful?}


\section{Lab 2 - Profiles}
\label{\detokenize{class6/module02/module02:lab-2-profiles}}\label{\detokenize{class6/module02/module02::doc}}
\textless{}enter description\textgreater{}
\begin{description}
\item[{301 Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.02 - 1.05}] \leavevmode\begin{itemize}
\item {} 
Given a scenario, determine the minimum profiles for an application

\item {} 
Given an application configuration, determine which functions can
be offloaded to the LTM device

\item {} 
Given iRule functionality, determine the profiles and
configuration options necessary to implement the iRule.

\item {} 
Given application requirements, determine the appropriate profile
and persistence settings.

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Working with Profiles}
\label{\detokenize{class6/module02/lab1:working-with-profiles}}\label{\detokenize{class6/module02/lab1::doc}}

\subsubsection{Working with profiles}
\label{\detokenize{class6/module02/lab1:id1}}
Create a new pool called \sphinxstylestrong{secure\_pool}, using the \sphinxstylestrong{https} default
monitor and add the following members, \sphinxstylestrong{10.1.20.11:443,
10.1.20.12:443} and \sphinxstylestrong{10.1.20.13.443.}

Create new virtual server \sphinxstylestrong{secure\_vs} at \sphinxstylestrong{10.1.10.115:443} with
\sphinxstylestrong{TCP} the profile using your new \sphinxstylestrong{secure\_pool}.

Open two separate PuTTy/Terminal windows to the BIG-IP and run the following
tcpdumps.

Window 1:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{nni} \PYG{n}{client\PYGZus{}vlan} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{o}{\PYGZhy{}}\PYG{n}{s0} \PYG{n}{host} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.51} \PYG{o+ow}{and} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.115}
\end{sphinxVerbatim}

Window 2:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{nni} \PYG{n}{server\PYGZus{}vlan} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{o}{\PYGZhy{}}\PYG{n}{s0} \PYG{n}{host} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.51}
\end{sphinxVerbatim}

Verify your virtual server is available and then browse to
\sphinxstylestrong{https://10.1.10.115}. View the TCPDUMPs.

\sphinxstyleemphasis{Q1. Did site work? Why didn’t you need to SNAT? Did you need SSL
profiles?}

\sphinxstyleemphasis{Q2. Could you use L7 iRules or profiles to view or modify the request or
response? Why or why not?}

Modify \sphinxstylestrong{secure\_vs} to use the HTTP (80) \sphinxstylestrong{www\_pool}. View the
TCPdumps

Verify your virtual server is available and then browse to
\sphinxstylestrong{https://10.1.10.115}.

\sphinxstyleemphasis{Q3. Did site work? Why or not?}

Change SSL Profile to include the default \sphinxstylestrong{clientssl} then update.

Browse to \sphinxstylestrong{https://10.1.10.115} and observe the tcpdump.

\sphinxstyleemphasis{Q4. Did site work? What did you observe in the tcpdumps? Did you need an
HTTP profile?}

On the \sphinxstylestrong{secure\_vs} in the virtual server \sphinxstylestrong{Resources} section enable
\sphinxstylestrong{cookies} as the \sphinxstylestrong{Default Persistence Profile} and then \sphinxstylestrong{Update}.

\sphinxstyleemphasis{Q5. Did it work? What was needed to add cookie persistence?}

Browse to \sphinxstylestrong{https://10.1.10.115/} scroll and select \sphinxstylestrong{Display Cookie} in
the \sphinxstylestrong{HTTP Request and Response Information} section on the web page.

\sphinxstyleemphasis{Q6. What nodes do the pictures come from? What is the name of the cookie
inserted begin with?}

Assign the \sphinxstylestrong{secure\_pool} to the \sphinxstylestrong{secure\_vs} once again. Browse to
\sphinxstylestrong{https://10.1.10.115}

\sphinxstyleemphasis{Q5. Did site work? Why or why not?}

Troubleshoot and fix.

\sphinxstyleemphasis{Q6. What profile was needed to correct the error?}


\subsection{Application Acceleration}
\label{\detokenize{class6/module02/lab2:application-acceleration}}\label{\detokenize{class6/module02/lab2::doc}}

\subsubsection{TCP Express}
\label{\detokenize{class6/module02/lab2:tcp-express}}
Set client-side and server-side TCP profiles on your virtual server
properties.

From the drop-down menus place the \sphinxstylestrong{tcp-wan-optimized} profile on the
client-side and the \sphinxstylestrong{tcp-lan-optimized} profile on the server-side.

Note the custom boxes in each of the TCP profiles you used.

\sphinxstyleemphasis{Q1. What is the idle timeout in each profile? Why might you want to
change it?}

\sphinxstyleemphasis{Q2. What is the Nagle selection in the default TCP, tcp-wan-optimized
and tcp-lan-optimized profiles? Why might you want to change it?}

\sphinxstyleemphasis{Q3. What happens if you increase the proxy buffer sizes?}


\subsubsection{HTTP Optimization - RamCache Lab}
\label{\detokenize{class6/module02/lab2:http-optimization-ramcache-lab}}
Go to your virtual server and refresh server times. Note the Source Node
for the pictures of the BIG-IPs. They change depending on where the
connection is coming from. The Source Node information is part of the
picture.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Profiles \textgreater{} Services \textgreater{} Web Acceleration} or
\sphinxstylestrong{Acceleration \textgreater{} Profiles \textgreater{} Web Acceleration}

Create a new profile named \sphinxstylestrong{www-opt-caching} using
\sphinxstylestrong{optimized-caching} as the Parent Profile.

Take all the defaults, no other changes are required.

\sphinxstyleemphasis{Q1. What resource would be consumed if you increased the} \sphinxstylestrong{Cache Size} \sphinxstyleemphasis{setting?}

Open up your \sphinxstylestrong{www\_vs} virtual server.

At the HTTP Profile drop down menu make sure http is selected.

Under \sphinxstylestrong{Acceleration} at \sphinxstylestrong{Web} \sphinxstylestrong{Acceleration} \sphinxstylestrong{Profile} select
your new caching profile; \sphinxstylestrong{www-opt-caching}

Clear the statistics on the \sphinxstylestrong{www\_pool}.

Browse to \sphinxstylestrong{http://10.1.10.100}. Refresh the main web page several times.

\sphinxstyleemphasis{Q2. The pictures do not change. Why do you think that is?}

\sphinxstyleemphasis{Q3. Go to your pool. Are all pool members taking connections?}

Now go to \sphinxstylestrong{Statistics \textgreater{} Module Statistics \textgreater{} Local Traffic} on the sidebar,
from the \sphinxstylestrong{Statistics Type} drop down menu select \sphinxstylestrong{Profiles Summary}
and select the \sphinxstylestrong{Web Acceleration} profile view link. Note the
information.

You can get more detailed information on Web Acceleration profils and cache entries at the
CLI level

Log onto the CLI of your BIG-IP via SSH using the root account (root/default).

At the CLI go into \sphinxstylestrong{tmsh} at the (tmos)\# prompt and enter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{show} \PYG{n}{ltm} \PYG{n}{profile} \PYG{n}{ramcache} \PYG{n}{www}\PYG{o}{\PYGZhy{}}\PYG{n}{opt}\PYG{o}{\PYGZhy{}}\PYG{n}{caching}
\end{sphinxVerbatim}


\subsection{HTTP Optimization - HTTP Compression Lab}
\label{\detokenize{class6/module02/lab2:http-optimization-http-compression-lab}}
Browse to \sphinxstylestrong{http://10.1.10.100}. On the web page under, \sphinxstylestrong{HTTP Request and
Response Information} select the \sphinxstylestrong{Request and Response Headers} link.

\sphinxstyleemphasis{Q1. Does the browser accept compression?}

Go to Local \sphinxstylestrong{Traffic \textgreater{} Profiles \textgreater{} Service \textgreater{} HTTP} \sphinxstylestrong{Compression} or
\sphinxstylestrong{Acceleration \textgreater{} Profiles \textgreater{} HTTP Compression}

Create a new profile, named \sphinxstylestrong{www-compress} using the
\sphinxstylestrong{wan-optimized-compression} default profile.

\sphinxstyleemphasis{Q2. At what point would the BIG-IP quit compressing responses?}

Open up your \sphinxstylestrong{www\_vs} virtual server.

At the \sphinxstylestrong{Web Acceleration} drop down menu select \sphinxstylestrong{None}

\begin{sphinxadmonition}{note}{Note:}
For purpose of this lab we don’t want caching interfering with our
response headers.
\end{sphinxadmonition}

At the \sphinxstylestrong{HTTP Compression} drop down menu select the HTTP compression
profile you just created.

Browse the virtual server web site and on the web page under \sphinxstylestrong{Content Examples
on This Host} select the \sphinxstylestrong{HTTP Compress Example} and \sphinxstylestrong{Plaintext
Compress Example} link.

Now off to \sphinxstylestrong{Statistics} on the sidebar, under the \sphinxstylestrong{Local Traffic}
drop down menu select \sphinxstylestrong{Profiles Summary}

Select the \sphinxstylestrong{View} link next to the \sphinxstylestrong{HTTP Compression} profile type

On the web page under, \sphinxstylestrong{HTTP Request and Response Information} select
the \sphinxstylestrong{Request and Response Headers} link. Notice you no longer see the
\sphinxstylestrong{Accept-Encoding} header in the \sphinxstylestrong{Request Headers Received} at the
Server section.

You can also browse to \sphinxstylestrong{https://10.1.10.115} and note what the
request/response looks like unchanged.


\subsection{Securing Web Applications}
\label{\detokenize{class6/module02/lab3:securing-web-applications}}\label{\detokenize{class6/module02/lab3::doc}}

\subsubsection{Securing web applications with the HTTP profile}
\label{\detokenize{class6/module02/lab3:securing-web-applications-with-the-http-profile}}
Here you are going to perform some custom profile alterations to help
secure the web site. You are going to make sure hackers cannot see error
codes returned, scrub the response headers of extraneous and potentially
dangerous information and encrypt the persistence cookie to prevent
tampering.

Obtain the cookie name and information by browsing to
\sphinxstylestrong{https://10.1.10.115/} and open the \sphinxstylestrong{Display Cookie}. The cookie name is
everything in front of the \sphinxstylestrong{=} sign. How BIG-IP creates cookies for
Cookie Insert persistence can be found at \sphinxurl{https://support.f5.com/csp/article/K6917}. After reading this article you could craft a cookie to hit a particular server.

\sphinxstyleemphasis{Q1. What is the cookie name? Note the information after the cookie.}

Let’s begin by creating a custom HTTP profile.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Name:
&\sphinxstyletheadfamily 
\sphinxstylestrong{secure-my-website}
&\sphinxstyletheadfamily \\
\hline
Set the Fallback Host
&
\sphinxstylestrong{http://www.f5.com}
&\\
\hline
Fallback on Error Codes
&
\sphinxstylestrong{404 500-505}
&
The fallback site if an error is received
\\
\hline
Response Headers Allowed
&
\sphinxstylestrong{Content-Type Set-Cookie Location}
&\\
\hline
Encrypt Cookies
&
\sphinxstylestrong{\textless{}cookie name you obtained earlier\textgreater{}}
&\\
\hline
Cookie Encryption Passphrase
&
\sphinxstylestrong{xcookie}
&\\
\hline
Confirm Cookie Encryption Passphrase
&
\sphinxstylestrong{xcookie}
&\\
\hline
Insert XForwarded For
&
\sphinxstylestrong{Enable}
&
Example of modify headers
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstyleemphasis{Q2. What is in the X-Forwarded-For header? Why might you want to enable
it?}

Attach your new HTTP Profile to your \sphinxstylestrong{secure\_vs} virtual server

Browse to \sphinxstylestrong{https://10.1.10.115}.

Do the web pages appear normal? On the web page under, \sphinxstylestrong{HTTP Request
and Response Information} select the \sphinxstylestrong{Request and Response Headers}
link.

Open a new browser to \sphinxstylestrong{http://10.1.10.100}. On the web page under, \sphinxstylestrong{HTTP
Request and Response Information} select the \sphinxstylestrong{Request and Response
Headers} link.

\sphinxstyleemphasis{Q3. Are they the same? What is different?}

Now browse to a bad page.

For example, \sphinxstylestrong{https://10.1.10.115/badpage}

\sphinxstyleemphasis{Q4. What is the result?}

Under, \sphinxstylestrong{HTTP Request and Response Information} select the \sphinxstylestrong{Display
Cookie} link.

\sphinxstyleemphasis{Q5. What is different from the cookie at the start of the task?}

\begin{sphinxadmonition}{note}{Note:}
Even though the data is encrypted between your browser and the
virtual server, the LTM can still modify the data (i.e. resource
cloaking) because the data is unencrypted and decompressed within TMOS.
\end{sphinxadmonition}


\subsubsection{Using iRules}
\label{\detokenize{class6/module02/lab3:using-irules}}
By now you should be thoroughly sick of trying to remember to type \sphinxurl{https://} in
every time you want to access your secure web site. Not only is that
easily rectify on the BIG-IP, but it is much more secure than opening up
port 80 on your secure web servers, so that they can perform a redirect.

While it would be easy to write your own redirect iRule, you note F5 has
one prebuilt that you can use.

Example of simple redirect iRule:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{when} \PYG{n}{HTTP\PYGZus{}REQUEST} \PYG{p}{\PYGZob{}}
   \PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{redirect} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{p}{[}\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{host}\PYG{p}{]}\PYG{p}{[}\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{uri}\PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Go to \sphinxstylestrong{Local Traffic \textgreater{} iRules}

In the search box at the top of the list of iRules, type \sphinxstylestrong{redirect}
and hit \sphinxstylestrong{Search}.

Open the iRule and take a quick look. This is a F5 Verified and F5
supported iRule.

Create your HTTP-to-HTTPS redirect virtual server.

Go to Local \sphinxstylestrong{Traffic \textgreater{} Virtual Servers} and create a new virtual
server.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
redirect\_to\_secure\_vs
\\
\hline
Destination
&
\textless{}same IP as secure\_vs\textgreater{}
\\
\hline
Service Port
&
80 (HTTP)
\\
\hline
Source Address Translation
&
None \textless{}you don’t need this, this traffic is going nowhere\textgreater{}
\\
\hline
iRule
&
\_sys\_https\_redirect
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Hit \sphinxstylestrong{Finished}

WOW! That didn’t go too far did it. You just got an error. If you are
going to redirect the HTTP request you need the HOST and URI information
and that requires the HTTP protocol.

Test your new virtual by going to \sphinxstylestrong{http://10.1.10.115}.

You should be redirected to the HTTPS virtual server.

As you can see very small iRules can make a very big difference. On the
exam, you may be asked to identify the iRule that would best solve an
issue. So, you should be familiar with basic iRules syntax.


\section{Lab 3 - Application Visibilty and Reporting (AVR)}
\label{\detokenize{class6/module03/module03:lab-3-application-visibilty-and-reporting-avr}}\label{\detokenize{class6/module03/module03::doc}}
You will use iApps templates, iRules and an analytics profile to build
new virtual servers that will be used to test Application Visibility and
Reporting (aka Analytics). In interest of time and to avoid typing
errors the iRules and Data Groups have been predefined.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.06 - 1.07}] \leavevmode\begin{itemize}
\item {} 
Explain the steps necessary to configure AVR

\item {} 
Given a set of reporting requirements, determine the AVR metrics and entities to    collect

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Working with Analytics (AVR)}
\label{\detokenize{class6/module03/lab1:working-with-analytics-avr}}\label{\detokenize{class6/module03/lab1::doc}}

\subsubsection{AVR Lab Setup - Verify provisioning, iRules and Data Group}
\label{\detokenize{class6/module03/lab1:avr-lab-setup-verify-provisioning-irules-and-data-group}}
In this task you prep the BIG-IP for the Application Visibility and
Reporting (AVR) lab. In the interest of time AVR has already been
provisioned, a data group has been built and two iRules have been
prepopulated on the BIG-IP.

AVR is \sphinxstylestrong{NOT} provisioned by default, but should be already be
provisioned on this BIG-IP. You can verify this by going to \sphinxstylestrong{System \textgreater{}\textgreater{}
Resource Provisioning}. Application Visibility and Reporting should be
set to Nominal.

\sphinxstyleemphasis{Q1. What resources does AVR require to be provisioned?}

Go to \sphinxstylestrong{Local Traffic \textgreater{} iRules \textgreater{} iRules List} and select \sphinxstylestrong{Data Group
List} from the top-bar

A \sphinxstylestrong{Data Group} named \sphinxstylestrong{user\_agents} has already been created for
you.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{String}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Value}
\\
\hline
agent
&
IE9
\\
\hline
agent1
&
IE11
\\
\hline
agent2
&
IE11
\\
\hline
agent3
&
Chrome
\\
\hline
agent4
&
Firefox
\\
\hline
agent5
&
Safari
\\
\hline
agent6
&
iPhone5
\\
\hline
agent7
&
iPhone6
\\
\hline
agent8
&
iPhone6
\\
\hline
agent9
&
Android
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

To save time and typing errors, the iRules required for this lab have
already been configured on the BIG-IP. Find the iRules below under
\sphinxstylestrong{Local Traffic \textgreater{} iRules \textgreater{} iRule List} and verify the iRules exist.
We use these iRules to modify traffic and give Analytics something
interesting to see.

\sphinxstylestrong{random\_client\_ip} - randomizes the client IPs and user agents using
the data group you built:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when CLIENT\PYGZus{}ACCEPTED \PYGZob{}
\PYGZsh{} Create a random IP address and use it to replace the client IP to simulate many clients
\PYGZsh{} going through the virtual
   snat [expr int(rand()*255)].[expr int(rand()*255)].[expr int(rand()*255)].[expr int(rand()*254)]
   virtual avr\PYGZus{}virtual2
\PYGZcb{}
when HTTP\PYGZus{}REQUEST \PYGZob{}
\PYGZsh{} When the HTTP request comes in, select a random user agents and put that agent
\PYGZsh{} in the user\PYGZhy{}agent HTTP header to simulate many different user agents
   set my\PYGZus{}index [expr int(rand()*10)]
   set user\PYGZus{}agent [class element \PYGZhy{}value \PYGZdl{}my\PYGZus{}index user\PYGZus{}agents]
      HTTP::header replace user\PYGZhy{}Agent \PYGZdl{}user\PYGZus{}agent
\PYGZcb{}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q2. Review the iRule, what profiles are required on the virtual server?}

\sphinxstylestrong{delay\_server} - introduces delay into server-side traffic:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{when} \PYG{n}{LB\PYGZus{}SELECTED} \PYG{p}{\PYGZob{}}
\PYG{c+c1}{\PYGZsh{} After a member has been selected by the load balancing algorithm introduce delay}
\PYG{c+c1}{\PYGZsh{} (in milliseconds) on the specified URL or server}
   \PYG{k}{if} \PYG{p}{\PYGZob{}}\PYG{p}{(}\PYG{p}{[}\PYG{n}{LB}\PYG{p}{:}\PYG{p}{:}\PYG{n}{server} \PYG{n}{addr}\PYG{p}{]} \PYG{n}{equals} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{10.128.20.13}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{o+ow}{and} \PYG{p}{(}\PYG{p}{[}\PYG{n}{HTTP}\PYG{p}{:}\PYG{p}{:}\PYG{n}{uri}\PYG{p}{]} \PYG{n}{equals} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/welcome.php}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}} \PYG{n}{after} \PYG{l+m+mi}{10}\PYG{p}{\PYGZcb{}}

   \PYG{k}{if} \PYG{p}{\PYGZob{}}\PYG{p}{[}\PYG{n}{LB}\PYG{p}{:}\PYG{p}{:}\PYG{n}{server} \PYG{n}{addr}\PYG{p}{]} \PYG{n}{equals} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{10.128.20.13}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZob{}}\PYG{n}{after} \PYG{l+m+mi}{20}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q3. Review the iRule, what profiles are required on the virtual server?}


\subsubsection{Create an Analytics Profile}
\label{\detokenize{class6/module03/lab1:create-an-analytics-profile}}
Create an analytics profile that will be used with a virtual server.

In the Configuration Utility, open the \sphinxstylestrong{Local Traffic \textgreater{} Profiles \textgreater{}
Analytics} page, and then click \sphinxstylestrong{Create}.

Create an analytics profile using the following information, and then
click \sphinxstylestrong{Finished}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Profile Name}
&\sphinxstyletheadfamily 
custom\_analytics
\\
\hline
\sphinxstylestrong{Collected Metrics}
&
Max TPS

Throughput

Page Load Time
\\
\hline
\sphinxstylestrong{Collected Entities}
&
URLs

Countries

Client IP Addresses

Client Subnets

Response Codes

User Agents

Methods
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Create a Web Application}
\label{\detokenize{class6/module03/lab1:create-a-web-application}}
\begin{sphinxadmonition}{note}{Note:}
The \sphinxstylestrong{avr\_virtual2} destination address is the default gateway of the web servers.
\end{sphinxadmonition}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{40}{70}|\X{30}{70}|}
\hline

Name
&
\sphinxstylestrong{avr\_virtual2}
\\
\hline
Destination Address
&
\sphinxstylestrong{10.1.20.240}
\\
\hline
Service Port
&
\sphinxstylestrong{80 (HTTP)}
\\
\hline
Configuration
&
\sphinxstylestrong{Advanced}
\\
\hline
HTTP Profile
&
\sphinxstylestrong{http}
\\
\hline
Source Address Translation
&
\sphinxstylestrong{Auto Map}
\\
\hline
Analytics Profile
&
\sphinxstylestrong{custom\_analytics}
\\
\hline
iRules
&
\sphinxstylestrong{delay\_server}
\\
\hline
Default Pool
&
\sphinxstylestrong{www\_pool}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

Create another virtual server using the following information, and then
click Finished.

\begin{sphinxadmonition}{note}{Note:}
Within the iRule attached to this virtual you are pointing traffic to the virtual server you created above, so avr\_virtual2 had to be created first.
\end{sphinxadmonition}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{40}{70}|\X{30}{70}|}
\hline

Name
&
\sphinxstylestrong{avr\_virtual1}
\\
\hline
Destination Address
&
\sphinxstylestrong{10.1.10.90}
\\
\hline
Service Port
&
\sphinxstylestrong{80 (HTTP)}
\\
\hline
HTTP Profile
&
\sphinxstylestrong{http}
\\
\hline
iRules
&
\sphinxstylestrong{random\_client\_ip}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Visit the Web Site to Generate AVR Data}
\label{\detokenize{class6/module03/lab1:visit-the-web-site-to-generate-avr-data}}
Use a web browser to access the virtual server, and then view the
\sphinxstylestrong{Analytics} statistics.

Use a new tab to access \sphinxstylestrong{http://10.1.10.90}. It is recommended you use
private browsing.

Type \sphinxstylestrong{\textless{}Ctrl\textgreater{}F5} several times to refresh the page. Do this for each of
the next steps.

Click the \sphinxstylestrong{Welcome} link, and then click the banner at the top of the
page to return to the home page.

Click the \sphinxstylestrong{Stream Profile Example} link. Click the banner at the top
to return to the home page.

Click on the \sphinxstylestrong{Multiple Stream Example} link. Click the banner at the
top of the page to return home.

Click the \sphinxstylestrong{Request and Response Headers} link. Click the banner at the
top of the page to return home.

Close the F5 vLab Test Web Site tab.

Open the \sphinxstylestrong{Statistics \textgreater{} Analytics \textgreater{} HTTP \textgreater{} Overview page}.

\begin{sphinxadmonition}{hint}{Hint:}
If you don’t see anything, set your Auto Refresh to 1 minute. It may
take up to 5 minutes for analytics data to load.
\end{sphinxadmonition}


\subsubsection{View the Analytics Reports}
\label{\detokenize{class6/module03/lab1:view-the-analytics-reports}}
Use the \sphinxstylestrong{Analytics} page to view statistics information on the BIG-IP
system.

In the Configuration Utility, refresh the \sphinxstylestrong{Statistics \textgreater{} Analytics \textgreater{}
HTTP \textgreater{} Overview} page until you see statistics.

Once you have data set the \sphinxstylestrong{Override} time range to list box, select
\sphinxstylestrong{Last Hour}.

Open the \sphinxstylestrong{Transactions} page from the top bar. Let’s review some of
the various data compiled.

From the \sphinxstylestrong{View By} list box, select \sphinxstylestrong{Pool Members}.

From the \sphinxstylestrong{View By} list box, select \sphinxstylestrong{URLs}.

From the \sphinxstylestrong{View By} list box, select \sphinxstylestrong{Response Codes}.

Users are complaining of intermittent slow responses.

Open the \sphinxstylestrong{Latency \textgreater{} Server Latency} page, and then from the \sphinxstylestrong{View
By} list box, select \sphinxstylestrong{Pool Members}.

\sphinxstyleemphasis{Q1. Does a particular pool member seem to be an issue?}

In the \sphinxstylestrong{Details} section, click \sphinxstylestrong{10.1.20.13:80}, and then from the
\sphinxstylestrong{View By} list box, select \sphinxstylestrong{URLs}.

Go to \sphinxstylestrong{Transactions}.

\sphinxstyleemphasis{Q2. What country has the most transactions?}

\sphinxstyleemphasis{Q3. What are the top two User Agents?}


\section{Lab 4 - Monitors and Status}
\label{\detokenize{class6/module04/module04:lab-4-monitors-and-status}}\label{\detokenize{class6/module04/module04::doc}}
In this section you will configure and apply monitors and interpret the results.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.08-1.10}] \leavevmode\begin{itemize}
\item {} 
Given a scenario, determine the appropriate monitor type and
parameters to use

\item {} 
Given a set of parameters, predict an outcome of a monitor status
on other LTM device objects

\item {} 
Given a health monitor configuration and pool member response
predict the resulting status of the pool member

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Basic Monitoring}
\label{\detokenize{class6/module04/lab1:basic-monitoring}}\label{\detokenize{class6/module04/lab1::doc}}

\subsubsection{Default Monitors}
\label{\detokenize{class6/module04/lab1:default-monitors}}
You will be setting up a default monitor to test any node created. You
can also choose to use custom monitors and monitor on a per node basis.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Nodes}, note the status nodes.

As you can see the nodes in this table, even though they were never
specifically configured in the Node portion of the GUI. Each time a unique IP
address is placed in a pool a corresponding node entry is added and
assigned the default monitor, if configured.

Also note, the node status is currently a blue square (\sphinxstylestrong{Unchecked}).

\sphinxstyleemphasis{Q1. What would happen if a node failed?}

Select the \sphinxstylestrong{Default Monitors} tab.

Notice you have several options, for nodes you want a generic monitor,
so we will choose \sphinxstyleemphasis{icmp}.

Select \sphinxstylestrong{icmp} from \sphinxstylestrong{Available} and place it in \sphinxstylestrong{Active}.

Select \sphinxstylestrong{Node List} or \sphinxstylestrong{Statistics} from the top tab.

\sphinxstyleemphasis{Q2. What are your node statuses?}

Select \sphinxstylestrong{Statistics \textgreater{} Module Statistics \textgreater{} Local Traffic}

\sphinxstyleemphasis{Q3. What are the statuses of your nodes, pool and virtual server?}


\subsubsection{Content Monitors}
\label{\detokenize{class6/module04/lab1:content-monitors}}
The default monitor simply tells us the IP address is accessible, but we
really don’t know the status of the particular application the node
supports. We are now going to create a monitor to specifically test the
application we are interested in. We are going to check our web site and
its basic authentication capabilities.

Browse to \sphinxstylestrong{http://10.1.10.100} virtual server and select the \sphinxstylestrong{Basic
Authentication} link under \sphinxstylestrong{Authentication Examples}. Log on with the
credentials \sphinxstylestrong{user.1/password}.

\begin{sphinxadmonition}{hint}{Hint:}
You may have to scroll down the page to find the link.
\end{sphinxadmonition}

You could use text from this page or text within the source code to test
for availability. You could also use HTTP statuses or header
information. You will be looking for the HTTP status \sphinxstylestrong{200 OK} as
the receive string to determine availability.

Note the URI is \sphinxstylestrong{/basic/}. You will need this for your monitor.

Select \sphinxstylestrong{Local Traffic \textgreater{} Monitor} on the side-bar and create and new
HTTP monitor called \sphinxstylestrong{www\_test}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{40}{140}|\X{100}{140}|}
\hline

Name
&
\sphinxstylestrong{www\_test}
\\
\hline
Type
&
\sphinxstylestrong{http}
\\
\hline
Send String
&
\sphinxstylestrong{GET /basic/ HTTP/1.1 \textbackslash{}r\textbackslash{}n\textbackslash{}r\textbackslash{}n}
\\
\hline
Receive String
&
\sphinxstylestrong{200 OK}
\\
\hline
User Name
&
\sphinxstylestrong{user.1}
\\
\hline
Password
&
\sphinxstylestrong{password}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{sphinxadmonition}{note}{Note:}
In case you were wondering, the receive string is NOT case sensitive.

An excellent reference for crafting HTTP monitors can be found on ASK F5 at \sphinxurl{https://support.f5.com/csp/article/K2167}.
\end{sphinxadmonition}

Click \sphinxstylestrong{Finish} and you will be taken back to \sphinxstylestrong{Local Traffic \textgreater{} Monitors}

Do you see your new Monitor?

\begin{sphinxadmonition}{hint}{Hint:}
Check the lower right hand corner of the Monitors list, here you
can go to the next page or view all Monitors. You can change the number of records
displayed per page in \sphinxstylestrong{System \textgreater{} Preferences}.
\end{sphinxadmonition}

Go to \sphinxstylestrong{www\_pool} and replace the default \sphinxstylestrong{http} monitor with your
\sphinxstylestrong{www\_test} monitor.

\sphinxstyleemphasis{Q1. What is the status of the pool and its members?}

\sphinxstyleemphasis{Q2. Go to} \sphinxstylestrong{Virtual Servers} \sphinxstyleemphasis{or} \sphinxstylestrong{Network Map} \sphinxstyleemphasis{, what is the status of
your virtual server?}

Just for fun \sphinxstylestrong{Reverse} the monitor. Now when \sphinxstylestrong{200 OK} is returned it
indicates the server is not responding successfully.

\sphinxstyleemphasis{Q3. What is status of your pool and virtual server now?}

You can see where this would be useful if you were looking for a 404
(bad page) or 50x (server error) response and pulling the failed member
out of the pool.

\begin{sphinxadmonition}{warning}{Warning:}
Be sure to un-reverse your monitor before continuing.
\end{sphinxadmonition}


\subsection{Virtual Server Status}
\label{\detokenize{class6/module04/lab2:virtual-server-status}}\label{\detokenize{class6/module04/lab2::doc}}

\subsubsection{Test Disabled Virtual Servers}
\label{\detokenize{class6/module04/lab2:test-disabled-virtual-servers}}
In this task, you will disable and enable various virtual servers and
note the behavior.

Make sure you have two SSH sessions opened to the BIG-IP.
\begin{itemize}
\item {} 
In window 1, have a tcpdump watching traffic to the \sphinxstylestrong{www\_vs} virtual (\sphinxstylestrong{10.1.10.100})

\item {} 
In window 2, go into TMSH

\end{itemize}

Disable \sphinxstylestrong{www\_vs} from the \sphinxstylestrong{Virtual Server List} or from within the
\sphinxstylestrong{www\_vs} GUI interface.

Open \sphinxstylestrong{Local} \sphinxstylestrong{Traffic \textgreater{} Virtual Servers} and hover over status icons.

From window 2 (TMSH) type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{show} \PYG{n}{ltm} \PYG{n}{virtual}
\PYG{n}{show} \PYG{n}{ltm} \PYG{n}{virtual} \PYG{n}{www\PYGZus{}vs}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q1. What is the Availability of} \sphinxstylestrong{www\_vs}\sphinxstyleemphasis{? What is the State?}

\sphinxstyleemphasis{Q2. What symbol is used to represent} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{status?}

\sphinxstyleemphasis{Q3. Would you expect browsing to} \sphinxstylestrong{http://10.1.10.100} \sphinxstyleemphasis{to work?}

\sphinxstyleemphasis{Q4. Can you ping the virtual IP?}

Clear virtual server stats and browse to \sphinxstylestrong{http://10.1.10.100}

Observe the tcpdump (window 1) and connection statistics in the Virtual
Server statics GUI interface.

\sphinxstyleemphasis{Q5. Did the site work? What did the tcpdump show?}

\sphinxstyleemphasis{Q6. Did statistics counters for any virtual server increment?}

Establish ftp connection to \sphinxstylestrong{10.1.10.100} and ensure successful login.
\begin{itemize}
\item {} 
Logon credentials are \sphinxstylestrong{root/default}

\end{itemize}

Disable \sphinxstylestrong{ftp\_vs}.

\sphinxstyleemphasis{Q10. Does ftp session still work? Why?}

Open another window and establish ftp connection to \sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q11. Did new ftp session establish connection? Why not?}

\begin{sphinxadmonition}{warning}{Warning:}
Make sure all virtual servers are \sphinxstylestrong{Enabled} before continuing.
\end{sphinxadmonition}


\subsubsection{Virtual Server Connection Limits and Status}
\label{\detokenize{class6/module04/lab2:virtual-server-connection-limits-and-status}}
In this task, you will set the connection limit for the FTP virtual
server to 1 and note the status and behavior of different connection
scenarios.

Modify \sphinxstylestrong{ftp\_vs} for connection limit of \sphinxstylestrong{1}. The \sphinxstylestrong{Connection Limit}
option can be found under the \sphinxstylestrong{Advanced} virtual server menu.

Establish ftp connection to \sphinxstylestrong{10.1.10.100} and hold the logon open.

\sphinxstyleemphasis{Q1. Does FTP session work?}

\sphinxstyleemphasis{Q2. What is the virtual server symbol and status of} \sphinxstylestrong{ftp\_vs}\sphinxstylestrong{?}

Open another window and establish a second ftp connection to \sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q3. Did new ftp session establish connection? Why not?}

\sphinxstyleemphasis{Q4. Did tcpdump capture a connection reset?}

\sphinxstyleemphasis{Q5 Quit all FTP sessions and note} \sphinxstylestrong{ftp\_vs} \sphinxstyleemphasis{status.}


\subsection{Pool Member and Virtual Servers}
\label{\detokenize{class6/module04/lab3:pool-member-and-virtual-servers}}\label{\detokenize{class6/module04/lab3::doc}}

\subsubsection{Create a new monitor}
\label{\detokenize{class6/module04/lab3:create-a-new-monitor}}
In this task, you will determine the effects of monitors on the status
of pools members.

Create \sphinxstylestrong{mysql} monitor for testing.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Monitors} and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
mysql\_monitor
\\
\hline
\sphinxstylestrong{Parent Monitor}
&
mysql
\\
\hline
\sphinxstylestrong{Interval}
&
15
\\
\hline
\sphinxstylestrong{Timeout}
&
46
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\paragraph{Effects of Monitors on Members, Pools and Virtual Servers}
\label{\detokenize{class6/module04/lab3:effects-of-monitors-on-members-pools-and-virtual-servers}}
Go to \sphinxstylestrong{Local Traffic \textgreater{} Pools \textgreater{} www\_pool} and assign \sphinxstylestrong{mysql\_monitor} to the pool.

Observe Availability Status of \sphinxstylestrong{www\_pool.} The pool status
momentarily changes to \sphinxstylestrong{Unknown}.

\sphinxstyleemphasis{Q1. Since the} \sphinxstylestrong{mysql\_monitor} \sphinxstyleemphasis{will fail, how long will it take to
mark the pool offline?}

Go to \sphinxstylestrong{Local Traffic \textgreater{} Pool \textgreater{} www\_pool} and then \sphinxstylestrong{Member} from the
top bar and open member \sphinxstylestrong{10.1.20.13:80} and note the status of the
monitors.

Open \sphinxstylestrong{Local Traffic \textgreater{} Network Map \textgreater{} Show Map}

\sphinxstyleemphasis{Q2. What is the icon and status of} \sphinxstylestrong{www\_vs}?

\sphinxstyleemphasis{Q3. What is the icon and status of} \sphinxstylestrong{www\_pool}?

\sphinxstyleemphasis{Q4. What is the icon and status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members?}

\sphinxstyleemphasis{Q5. How does the status of the pool configuration effect the virtual
server status?}

Clear the virtual server statistics.

Browse to \sphinxstylestrong{http://10.1.10.100} and note the browser results,
statistics and tcpdump.

Disable \sphinxstylestrong{www\_vs} and clear the statistics and ping the virtual
server.

\sphinxstyleemphasis{Q6. What is the icon and status of} \sphinxstylestrong{www\_vs}?

Browse to \sphinxstylestrong{http://10.1.10.100} and note the browser results,
statistics and tcpdump.

\sphinxstyleemphasis{Q7. Did traffic counters increment for} \sphinxstylestrong{www\_vs}?

\sphinxstyleemphasis{Q8. What is the difference in the tcpdumps between Offline (Disabled) vs
Offline (Enabled)?}

\begin{sphinxadmonition}{warning}{Warning:}
Make sure all virtual servers, pools and pool members are \sphinxstylestrong{Available} before continuing.
\end{sphinxadmonition}


\paragraph{More on status and member specific monitors}
\label{\detokenize{class6/module04/lab3:more-on-status-and-member-specific-monitors}}
Go to \sphinxstylestrong{Local Traffic \textgreater{} Pool \textgreater{} www\_pool} and then \sphinxstylestrong{Member} from the
top bar and open member \sphinxstylestrong{10.1.20.13:80.} Enable the \sphinxstylestrong{Configuration:
Advanced} menus.

\sphinxstyleemphasis{Q1. What is the status of the Pool Member and the monitors assigned to
it?}

In \sphinxstylestrong{Health Monitors} select \sphinxstylestrong{Member Specific} and assign the
\sphinxstylestrong{http} monitor and \sphinxstylestrong{Update.}

Go to the \sphinxstylestrong{Network Map}.

\sphinxstyleemphasis{Q2. What is the status of} \sphinxstylestrong{www\_vs}, \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and the pool
members? Why?}

Browse to \sphinxstylestrong{http://10.1.10.100} and note results of browser and
tcpdump.

\sphinxstyleemphasis{Q3. Did the site work?}

\sphinxstyleemphasis{Q4. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}


\subsection{Extended Application Verification (EAV)}
\label{\detokenize{class6/module04/lab4:extended-application-verification-eav}}\label{\detokenize{class6/module04/lab4::doc}}

\subsubsection{Create an EAV monitor}
\label{\detokenize{class6/module04/lab4:create-an-eav-monitor}}
Log on to the F5 DevCentral site \sphinxstylestrong{http://devcentral.f5.com} and go to the
following link:

\sphinxurl{https://devcentral.f5.com/codeshare/http-monitor-curl-basic-get}

If you don’t have an account then create one. You’ll be glad you did.

This monitor is also in \sphinxstylestrong{Module 3.14} of this document, but working from
F5 DevCentral is more appropriate.

You will be using this monitor as your new external monitor, a copy of
the code is on your desktop in a plain text file called
\sphinxstylestrong{eav-http-monitor}.

A copy of this monitor is also in the \sphinxstylestrong{/root} directory on the BIG-IP. To
get a feel of how it works go to the BIG-IP CLI and test it against once
of the \sphinxstylestrong{www\_pool} members:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cd} \PYG{o}{/}\PYG{n}{root}
\PYG{o}{/}\PYG{n+nb}{bin}\PYG{o}{/}\PYG{n}{sh} \PYG{n}{eav}\PYG{o}{\PYGZhy{}}\PYG{n}{http}\PYG{o}{\PYGZhy{}}\PYG{n}{monitor} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.11} \PYG{l+m+mi}{80}
\end{sphinxVerbatim}

The first two parameters of an EAV are always IP address and Port. When using an
External monitor on a pool, the pool supplies these. Here you have to supply them.

\sphinxstyleemphasis{Q1. What was the stdout output? Did this indicate the member was
Available?}

Go to \sphinxstylestrong{System \textgreater{} File Management \textgreater{} External Monitor Program File List} and
select \sphinxstylestrong{Import}

\sphinxstylestrong{Choose File} to find the \sphinxstylestrong{eav-http-monitor} on your desktop, name
it \sphinxstylestrong{eav-http-monitor} and select \sphinxstylestrong{Import}

Create a monitor named \sphinxstylestrong{eav-http-monitor}, select type \sphinxstylestrong{External}
and \sphinxstylestrong{eav-http-monitor} as your \sphinxstylestrong{External Program}.

Apply the \sphinxstylestrong{eav-http-monitor} monitor to \sphinxstylestrong{www\_pool}. Remove all
other monitors.

\sphinxstyleemphasis{Q2. Are your members up? What would happen if the external monitor returned} \sphinxstylestrong{DOWN}\sphinxstyleemphasis{?}


\subsection{Inband Monitors}
\label{\detokenize{class6/module04/lab5:inband-monitors}}\label{\detokenize{class6/module04/lab5::doc}}
In this exercise, you need to limited the amount of monitor traffic to
your back in servers. You will use the basic inband monitor, but you
would like the servers to come up faster than default of 5 minutes.
You will combine Inband and Active monitors to accomplish this.


\subsubsection{Create an Inband monitor and Active monitor with an Up Interval}
\label{\detokenize{class6/module04/lab5:create-an-inband-monitor-and-active-monitor-with-an-up-interval}}
Create an inband monitor named \sphinxstylestrong{my\_inband}.  Use all the defaults.

Note the 300 second retry timer, after 3 failures in a 30 second period the
BIG-IP will mark the member down and will not check the member again for
5 minutes.

Create a new custom monitor as the active monitor. Make the monitor an \sphinxstylestrong{http} monitor called \sphinxstylestrong{active\_http}, with an \sphinxstylestrong{Up Interval} of \sphinxstylestrong{60} seconds and a \sphinxstylestrong{Time Until Up} of \sphinxstylestrong{30} second and a \sphinxstylestrong{Receive String} of \sphinxstylestrong{200 OK}.


\subsubsection{Assign the Inband monitor to a pool and test}
\label{\detokenize{class6/module04/lab5:assign-the-inband-monitor-to-a-pool-and-test}}
You are going to begin by removing the current monitors for the
\sphinxstylestrong{www\_pool} and replacing them with the \sphinxstylestrong{my\_inband} monitor only.

Go to the \sphinxstylestrong{www\_pool} and remove all monitors and \sphinxstylestrong{Update}. Your
pool members show now be \sphinxstylestrong{Unchecked}.

\sphinxstyleemphasis{Q1. What is the status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and} \sphinxstylestrong{www\_vs}
\sphinxstyleemphasis{configuration objects? Is the web site accessible? Why?}

Add the \sphinxstylestrong{my\_inband} monitor to the \sphinxstylestrong{www\_pool}.

\sphinxstyleemphasis{Q2. What are the status of} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and} \sphinxstylestrong{www\_vs}? \sphinxstyleemphasis{Can you access
the web site?}

Let’s simulate a failure. Open a new browser tab to
\sphinxstylestrong{https://10.1.1.252:10000} this will bring you to \sphinxstylestrong{Webmin} on the
back-end server:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Username}\PYG{p}{:} \PYG{n}{root}
\PYG{n}{Password}\PYG{p}{:} \PYG{n}{default}
\end{sphinxVerbatim}

Under \sphinxstylestrong{Servers} on the side-bar, select the \sphinxstylestrong{Apache Webserver} link.
In the upper right corner select the \sphinxstylestrong{Stop Apache} link. This will
effectively bring the web sites down.

Go to your pool statistics. After 30 seconds what is the status of the
\sphinxstylestrong{secure\_pool} and \sphinxstylestrong{www\_pool?}

\sphinxstyleemphasis{Q3. Why is the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{still showing up?}

Attempt to access \sphinxstylestrong{http://10.1.10.100} and refresh several times.

\sphinxstyleemphasis{Q4. What is the status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{now?}

In the \sphinxstylestrong{Webmin} tab, in the upper right corner, select \sphinxstylestrong{Start Apache}.

Once Apache is started, refresh you pool statistics page. Then try to
browse to \sphinxstylestrong{http://10.1.10.100/}

\sphinxstyleemphasis{Q5. What are the pool statuses and why?}

It will be 300 seconds before the BIG-IP attempts to send any traffic to
the offline pool members.

Go to the \sphinxstylestrong{www\_pool} and add the \sphinxstylestrong{active\_http} monitor to the
pool.

Open a terminal window to BIG-IP and run the following tcpdump:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tcpdump} \PYG{o}{\PYGZhy{}}\PYG{n}{nni} \PYG{l+m+mf}{1.2} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{o}{\PYGZhy{}}\PYG{n}{s0} \PYG{n}{port} \PYG{l+m+mi}{80}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q6. How often to you see monitor traffic to the} \sphinxstylestrong{www\_pool}?

In the \sphinxstylestrong{Webmin} tab, \sphinxstylestrong{Stop Apache} again and attempt to browse
\sphinxstylestrong{http://10.1.10.100} and refresh several times. Check the status of your
pools. The \sphinxstylestrong{secure\_pool} and \sphinxstylestrong{www\_pool} should be offline.

\sphinxstyleemphasis{Q7. How often to you see monitor traffic to the} \sphinxstylestrong{www\_pool}?

In the \sphinxstylestrong{Webmin} tab \sphinxstylestrong{Start Apache}.

\sphinxstyleemphasis{Q8. Did the www\_pool come up within 30 seconds without client traffic?
What did the tcpdump show?}


\section{Lab 5 - SSL}
\label{\detokenize{class6/module05/module05:lab-5-ssl}}\label{\detokenize{class6/module05/module05::doc}}
In this module, you will go over the basics of importing/creating certificates and building virtual servers that can encrypt and decrypt traffic.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.11-1.12}] \leavevmode\begin{itemize}
\item {} 
Given a set of application SSL requirements, determine the
appropriate profiles and profile options

\item {} 
Given a scenario determine the steps required to maintain SSL
certificates

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{SSL Certificates and Profiles}
\label{\detokenize{class6/module05/lab1:ssl-certificates-and-profiles}}\label{\detokenize{class6/module05/lab1::doc}}

\subsubsection{Creating and Importing Certs and Key}
\label{\detokenize{class6/module05/lab1:creating-and-importing-certs-and-key}}
You want the highest levels of encryption between the BIG-IP and the
client, but you do not require the same levels of encryption between the
BIG-IP and the server and you would like to save server processing
power. You are going to create new SSL certificates with 2048 bit keys
for client-side SSL and import a certificate you own that has a 1024 bit
keys for the server-side SSL processing.

Create the client-side SSL certificate and key.

Go to \sphinxstylestrong{System \textgreater{}\textgreater{} File Management \textgreater{}\textgreater{} SSL Certificate List} and select
\sphinxstylestrong{Create} and enter the following information\sphinxstylestrong{.}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
\sphinxstylestrong{new\_ssl\_cert}
\\
\hline
Issuer
&
\sphinxstylestrong{Self}
\\
\hline
Common Name
&
\sphinxstylestrong{ltm301a.f5demo.com}
\\
\hline
Division
&
\sphinxstylestrong{Training}
\\
\hline
Organization
&
\sphinxstylestrong{F5}
\\
\hline
Locality
&
\sphinxstylestrong{Lab}
\\
\hline
Country
&
\sphinxstylestrong{United States}
\\
\hline
State
&
\sphinxstylestrong{Washington}
\\
\hline
Email
&
\sphinxstylestrong{example@f5demo.com}
\\
\hline
Subject Alternative Name
&
\sphinxstylestrong{\textless{}leave this blank\textgreater{}}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

By default, a self-sign certificate starts with a Lifetime of 365 days
and the key type is 2048 bit RSA.

Import the SSL certificate and key below to the BIG-IP to be used for
server-side encryption by selecting \sphinxstylestrong{Import}.

You can find the cert and key under the \sphinxstylestrong{Lab Guides} link on your
browser bookmark bar. Look for the \sphinxstylestrong{Cert 301a LTM Architect.txt}
file/link. Open the link and the certificate and key are in there under
\sphinxstylestrong{LAB 5 - SSL}

You may want to import the Key first, as it will validate certificate if
your naming both the same. If you were to import the certificate first
and then import a Key with the same name you could technically attached
an invalid key to the certificate.

Import the \sphinxstylestrong{Key} (Type), named \sphinxstylestrong{import\_ssl\_cert}, leave the
\sphinxstylestrong{Password} blank.

\sphinxstylestrong{RSA Private Key}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{BEGIN} \PYG{n}{RSA} \PYG{n}{PRIVATE} \PYG{n}{KEY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{n}{MIICXQIBAAKBgQCobsrka60VT1TLfQsamdtQCbvfnGC9ibiTtPjaHXRBpNV70prY}
\PYG{n}{rihQqj3pBNlE4dvK0ucF49gGF5HXpKZDqZWXai3AnJhia248FRyT}\PYG{o}{/}\PYG{n}{ezxAjVqamFh}
\PYG{n}{c3Lhx5ykSIxWzzw}\PYG{o}{+}\PYG{n}{VBuwTIvg2MS3aE3P}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{n}{CQ8MI02}\PYG{o}{/}\PYG{n}{uiLsya0eydw3EyiQIDAQAB}
\PYG{n}{AoGBAKPN3BP5hALNfDHKEhp0tw1H6ia19n9eiNtdjQbSzlVo8RXS5DUGar7IUh1k}
\PYG{n}{UcjjvtWp9nOL}\PYG{o}{+}\PYG{n}{nMySOvnfKshKhDbB}\PYG{o}{/}\PYG{l+m+mi}{73}\PYG{n}{NRg7VZ1eZL6K}\PYG{o}{/}\PYG{l+m+mi}{0}\PYG{n}{vv37KbDSU8KTQssSb3}
\PYG{n}{myKxrRVMbxxpPujpUNT3gd6XqdUXyPjWuJOkCGLgVfGhANHhAkEA2ssfpYXgID2a}
\PYG{l+m+mi}{0}\PYG{n}{B}\PYG{o}{+}\PYG{n}{VC}\PYG{o}{+}\PYG{n}{FaAB0GBg5P}\PYG{o}{/}\PYG{n}{oQF3mTPSj460totqGWeXi7beuYXgFYLbn5BNHCsDeVclZMy}
\PYG{n}{ws7k4SZiiwJBAMUTSRX3rjeZBpl0zF6xr}\PYG{o}{/}\PYG{n}{JFfw0Fd4lgKDO}\PYG{o}{+}\PYG{n}{hFZvrbhDUYIU9D08}
\PYG{n}{ROyH}\PYG{o}{+}\PYG{n}{FViQ0IoV2BtW9IZDtN}\PYG{o}{/}\PYG{n}{GzoroLE}\PYG{o}{/}\PYG{n}{hbsCQQCG5cwaSwOX}\PYG{o}{/}\PYG{n}{UOxZHeJ}\PYG{o}{/}\PYG{n}{qR2A28O}
\PYG{n}{Vs69dvsDVpZ0CRBNppWWCSlummdaS}\PYG{o}{/}\PYG{n}{lbeDHOK2vagEmku7CszDf04ok9xGPnAkAl}
\PYG{l+m+mi}{5}\PYG{n}{rubmfLLhoaaZLgZThsEgREaM}\PYG{o}{/}\PYG{l+m+mi}{71}\PYG{n}{UKTqrq1M4lWKpoe6eMUwMbMfulasNSWyR4fm}
\PYG{n}{Z6HNGjybuEpIObPB4vGZAkBo1LKCZXas}\PYG{o}{+}\PYG{n}{mxRfZeucfzPLOx5a8XmwtV57br}\PYG{o}{+}\PYG{n}{ivnK}
\PYG{n}{n0OIrSExckYHeeWb4sFl8Y}\PYG{o}{/}\PYG{n}{S85yyBqHS5q5v9s}\PYG{o}{/}\PYG{n}{x2fvp}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{END} \PYG{n}{RSA} \PYG{n}{PRIVATE} \PYG{n}{KEY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\end{sphinxVerbatim}

Import the certificate.  Type \sphinxstylestrong{Certificate} and named \sphinxstylestrong{import\_ssl\_cert}

\sphinxstylestrong{Certificate}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{BEGIN} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{n}{MIIBuzCCASQCCQCTVAeV4noavTANBgkqhkiG9w0BAQUFADAiMSAwHgYDVQQDExds}
\PYG{n}{aW51eDMyc2VydmVyMS5mNXNlLmNvbTAeFw0xMDA2MTkyMTI2NTZaFw0yMDA2MTYy}
\PYG{n}{MTI2NTZaMCIxIDAeBgNVBAMTF2xpbnV4MzJzZXJ2ZXIxLmY1c2UuY29tMIGfMA0G}
\PYG{n}{CSqGSIb3DQEBAQUAA4GNADCBiQKBgQCobsrka60VT1TLfQsamdtQCbvfnGC9ibiT}
\PYG{n}{tPjaHXRBpNV70prYrihQqj3pBNlE4dvK0ucF49gGF5HXpKZDqZWXai3AnJhia248}
\PYG{n}{FRyT}\PYG{o}{/}\PYG{n}{ezxAjVqamFhc3Lhx5ykSIxWzzw}\PYG{o}{+}\PYG{n}{VBuwTIvg2MS3aE3P}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{n}{CQ8MI02}\PYG{o}{/}\PYG{n}{uiLsya}
\PYG{l+m+mi}{0}\PYG{n}{eydw3EyiQIDAQABMA0GCSqGSIb3DQEBBQUAA4GBAH1e}\PYG{o}{+}\PYG{n}{FXvNOnKlP5RO5wKVjG0}
\PYG{n}{C8F4Xww462beL2LeYZvV3ZjDoTUU0CNkkOnOKMbLkaiTICpBdd836sIiloAyV8M1}
\PYG{l+m+mi}{2}\PYG{n}{YZwxgwP}\PYG{o}{/}\PYG{n}{fV4ycTjHUnloEBmmmBVmW3M5DzLGA1k9cB1dUly5koIoRE9mYRWm9V2}
\PYG{n}{ZzYkbZf96KMh8zH47R4y}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{END} \PYG{n}{CERTIFICATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q1. What is the common name of your imported certificate and when does
it expire?}


\subsubsection{SSL Profile and Virtual Servers}
\label{\detokenize{class6/module05/lab1:ssl-profile-and-virtual-servers}}
Now you will create a custom client and server side SSL profiles using
your new certificates and key and attach them to you \sphinxstylestrong{secure\_vs} and
test.

Create a custom client SSL profile using your \sphinxstylestrong{new\_ssl\_cert}
certificate, by going to \sphinxstylestrong{Profiles \textgreater{} SSL \textgreater{} Client}.

Name you new profile \sphinxstylestrong{my-client-ssl} and place \sphinxstylestrong{new\_ssl\_cert} in
the \sphinxstylestrong{Certificate} and \sphinxstylestrong{Key} drop-downs.

Make sure you \sphinxstylestrong{Add} the certificate and key before you Finish.

Go to the SSL Server profiles and create a new profile named
\sphinxstylestrong{my-server-ssl} with your \sphinxstylestrong{import-ssl-cert} certificate and key.

Replace the current default client-side and server-side SSL profiles
with your new SSL profiles.

Browse to \sphinxstylestrong{http://10.1.10.115}.

\sphinxstyleemphasis{Q1. Did it work?}


\section{Lab 6 - Virtual Servers and Packet Processing Review}
\label{\detokenize{class6/module06/module06:lab-6-virtual-servers-and-packet-processing-review}}\label{\detokenize{class6/module06/module06::doc}}
This is a review (but an important one) of virtual server and packet processing from
the 201 certification lab and adds a lab on forwarding virtual servers.

These concepts are vital to passing the 301a.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.13-15}] \leavevmode\begin{itemize}
\item {} 
Given a set of application requirements, determine the appropriate
virtual server type to use

\item {} 
Given a set of application requirements, determine the appropriate
virtual server configuration settings

\item {} 
Given a set of application requirements, determine the appropriate
virtual server configuration settings

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Packet Processing}
\label{\detokenize{class6/module06/lab1:packet-processing}}\label{\detokenize{class6/module06/lab1::doc}}

\subsubsection{Open BIG-IP TMSH and TCPDump session}
\label{\detokenize{class6/module06/lab1:open-big-ip-tmsh-and-tcpdump-session}}
In this task, you will open two SSH sessions to the BIG-IP. One for TMSH
commands and the other for tcpdump of the client-side network.

Open PuTTY/terminal window (window1) to BIG-IP from the shortcut bar at the
bottom of the jumpbox.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ssh root@10.1.1.245
password: default
\end{sphinxVerbatim}

Use tcpdump to monitor traffic from the client (10.1.10.51) destined to
\sphinxstylestrong{ftp\_vs} (10.1.10.100)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}nni client\PYGZus{}vlan host \PYG{l+m}{10}.1.10.51 and \PYG{l+m}{10}.1.10.100
\end{sphinxVerbatim}

Open a second PuTTY/terminal window (window2) to BIG-IP and use \sphinxstylestrong{tmsh} to display the
connection table.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ssh root@10.1.1.245
password: default

tmsh
\end{sphinxVerbatim}

At the TMOS prompt \sphinxstylestrong{(tmos)\#}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
show sys connection
\end{sphinxVerbatim}

Do you see any connections from the jumpbox 10.1.1.51 to 10.1.1.245:22?

\sphinxstyleemphasis{Q1. Why are the ssh management sessions not displayed in connection
table?}


\subsubsection{Establish ftp connection}
\label{\detokenize{class6/module06/lab1:establish-ftp-connection}}
In this task you will open a third terminal window and establish an FTP
session through the \sphinxstylestrong{ftp\_vs} virtual server. With the connection
remaining open you will view the results in window1 (tcpdump) and
window2 (tmsh).

Open a third command/terminal window (window3).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ftp \PYG{l+m}{10}.1.10.100
\end{sphinxVerbatim}

It may take 15 to 20 seconds for the logon on prompt, just leave it at
prompt to hold the connection open.

In window 1 you should see something similar to the tcpdump captured
below.

\noindent\sphinxincludegraphics{{201ex211t2a-tcpdump}.png}

\sphinxstyleemphasis{Q1. In the tcpdump above, what is client IP address and port and the
server IP address port?}

In window2 (tmsh) run the \sphinxstylestrong{show sys conn} again, but strain out the
noise of other connections (mirrored and selfIP) by just looking at
connections from your jumpbox.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
sho sys conn cs\PYGZhy{}client\PYGZhy{}addr \PYG{l+m}{10}.1.10.51
\end{sphinxVerbatim}

The connection table on window2 will show the client-side and
server-side connection similar to below:

\noindent\sphinxincludegraphics{{201ex211t2b-shsysconn}.png}

\sphinxstyleemphasis{Q2. What is source ip and port as seen by ftp server in the example
above?}

\sphinxstyleemphasis{Q3. What happened to the original client IP address and where did
10.1.20.249 come from?}

\begin{sphinxadmonition}{hint}{Hint:}
You may have to review the configuration of \sphinxstylestrong{ftp\_vs} to determine
the answer to question 3.
\end{sphinxadmonition}


\subsection{Packet Filter Lab}
\label{\detokenize{class6/module06/lab2:packet-filter-lab}}\label{\detokenize{class6/module06/lab2::doc}}
You are going to test how packet filters impact packet processing by
creating a packet filter to block ftp connections to 10.1.10.100.


\subsubsection{Create a packet filter}
\label{\detokenize{class6/module06/lab2:create-a-packet-filter}}
Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} Rules} and \sphinxstylestrong{Create} a filter using
the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Name}
&
block\_ftp
\\
\hline
\sphinxstylestrong{Order}
&
First
\\
\hline
\sphinxstylestrong{Action}
&
Discard
\\
\hline
\sphinxstylestrong{Destination Hosts and Networks}
&
10.1.10.100
\\
\hline
\sphinxstylestrong{Destination Port List}
&
21 (FTP)
\\
\hline
\sphinxstylestrong{Logging}
&
Enabled
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Make sure you select \sphinxstylestrong{Finish} after entering a host/network or a port.


\subsubsection{Test the FTP packet filter}
\label{\detokenize{class6/module06/lab2:test-the-ftp-packet-filter}}
Ensure ftp connection is currently established to \sphinxstylestrong{10.1.10.100}.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} General} and select \sphinxstylestrong{Enable} and
then \sphinxstylestrong{Update}.

\sphinxstyleemphasis{Q1. Was the existing ftp connection in the connection table affected?   Why?}

Quit ftp and clear virtual server statistics by going to \sphinxstylestrong{Local Traffic
\textgreater{} Virtual Servers \textgreater{} Statistic}, select the virtual server and hit
\sphinxstylestrong{Reset}.

Attempt to establish an ftp connection to 10.1.10.100.
Watch tcpdump capture you built in Window1.

\sphinxstyleemphasis{Q2. Was ftp connection successful? Why?}

\sphinxstyleemphasis{Q3. What did tcpdump reveal? Did the connection timeout or reset?}

\sphinxstyleemphasis{Q4. What did virtual server statistics for} \sphinxstylestrong{ftp\_vs} \sphinxstyleemphasis{reveal? Why are
counters not incrementing?}

\sphinxstyleemphasis{Q5. Prioritize the packet processing order below from 1-7:}

Virtual Server\_\_\_ SNAT\_\_\_ AFM/Pkt Filter\_\_\_ NAT\_\_\_ Existing
Connections\_\_\_ Self IP\_\_\_ Drop \_\_\_

Review the Packet Filter Logs and Packet Filter Statistics, then disable
the Packet Filters.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} Statistics} and review the
information.

Go to \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Packet Filters} and review the information.

Go to \sphinxstylestrong{Network \textgreater{} Packet Filters \textgreater{} General} and select \sphinxstylestrong{Disable} and
then \sphinxstylestrong{Update}


\subsection{Virtual Server Packet Processing}
\label{\detokenize{class6/module06/lab3:virtual-server-packet-processing}}\label{\detokenize{class6/module06/lab3::doc}}
In this task you will create a wildcard virtual server and pool, test and observe various types of traffic under different configurations to determine how virtual servers
process new inbound connections. You will be using tcpdump from window1,
virtual server statistics, as well as a browser to determine behavior.


\subsubsection{Create additional Virtual Servers}
\label{\detokenize{class6/module06/lab3:create-additional-virtual-servers}}
Create \sphinxstylestrong{wildcard\_vs} \sphinxstylestrong{10.1.10.100:*} with a \sphinxstylestrong{TCP} profile, \sphinxstylestrong{Automap} and a
pool named \sphinxstylestrong{wildcard\_pool} with the following member \sphinxstylestrong{10.1.20.11:*}

To create the wildcard pool, go to \sphinxstylestrong{Local Traffic \textgreater{} Pools \textgreater{} Pool List}
and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
wildcard\_pool
\\
\hline
\sphinxstylestrong{Address}
&
10.1.20.11
\\
\hline
\sphinxstylestrong{Port}
&
*
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{sphinxadmonition}{hint}{Hint:}
Don’t forget to \sphinxstylestrong{Add} the pool member to the \sphinxstylestrong{New Members} box
before you hit \sphinxstylestrong{Finished.}
\end{sphinxadmonition}

To create the wildcard virtual server, go to \sphinxstylestrong{Local Traffic \textgreater{} Virtual
Server} and select \sphinxstylestrong{Create}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
\sphinxstylestrong{wildcard\_vs}
\\
\hline
\sphinxstylestrong{Destination}
&
10.1.10.100
\\
\hline
\sphinxstylestrong{Service Port}
&
*
\\
\hline
\sphinxstylestrong{Source Address Translation}
&
Automap
\\
\hline
\sphinxstylestrong{Default Pool}
&
wildcard\_pool
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Don’t forget to hit \sphinxstylestrong{Finished.}

You were not required to enter the source addresses allowed. Go to your new virtual
server and look at the \sphinxstylestrong{Source} configuration to see what the default is for
source addresses allowed.


\subsubsection{Testing Virtual Server Packet Processing Behavior}
\label{\detokenize{class6/module06/lab3:testing-virtual-server-packet-processing-behavior}}
Many of your virtual servers have the same virtual address. You will now
test various behaviors.

Clear virtual server stats.

Observe connection statistics (VS stats) after each of the following tasks.

Browse to \sphinxurl{http://10.1.10.100:8080}

\sphinxstyleemphasis{Q1. Which VS is used for web traffic over port 8080?}

FTP to 10.1.10.100

\sphinxstyleemphasis{Q2. Which VS is used for FTP traffic?}

Browse to \sphinxurl{http://10.1.10.100}

\sphinxstyleemphasis{Q3. Which VS is used for this web traffic the default HTTP port? What
port was used?}

Clear virtual server stats.

Modify the \sphinxstylestrong{wildcard\_vs} to only allow connections from a \sphinxstylestrong{Source}
of 10.1.10.0/24.

\begin{sphinxadmonition}{note}{Note:}
The source address your jumpbox should be connecting from is 10.1.10.51
\end{sphinxadmonition}

Browse to \sphinxurl{http://10.1.10.100}

Observe connection statistics (VS stats)

\sphinxstyleemphasis{Q4. Which VS is used for web traffic?}

Clean up your modifications

Clear virtual server stats.

Modify \sphinxstylestrong{wildcard\_vs} to include the default \sphinxstylestrong{Source} of 0.0.0.0/0.


\subsection{Forwarding Virtual Servers}
\label{\detokenize{class6/module06/lab4:forwarding-virtual-servers}}\label{\detokenize{class6/module06/lab4::doc}}
Our web administrators would like to access the back-end server network.
They all access from the same 10.1.10.0/24 subnet. Let’s create a
virtual server that allows them and only them to get to the backend
network. REMEMBER somewhere a router must have the route to the backend
network inserted.


\subsubsection{IP Forwarding Virtual Server}
\label{\detokenize{class6/module06/lab4:ip-forwarding-virtual-server}}
Create a new \sphinxstylestrong{Forward (IP)} type of virtual server named
\sphinxstylestrong{forward-to-servernet} that only allows \sphinxstylestrong{Source} IPs from the
\sphinxstylestrong{10.1.10.0/24}, to the destination \sphinxstylestrong{Network} \sphinxstylestrong{10.1.20.0/24}, all
ports should be allowed and all protocols should be allowed.

\sphinxstyleemphasis{Q1. What happens if we don’t change the Protocol from TCP?}

\sphinxstyleemphasis{Q2. What is the status of your new virtual server? Why?}

Of course we are not going anywhere unless we install a route to the
\sphinxstylestrong{10.1.20.0/24} network. From a command/terminal window on your jumpbox enter the
add route command.

Windows requires elevated priveleges, click on \sphinxstylestrong{Start}, right click on \sphinxstylestrong{Command Prompt},
select \sphinxstylestrong{Run as Administrator}, select \sphinxstylestrong{Yes} at the pop-up:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{route} \PYG{n}{add} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.0} \PYG{n}{mask} \PYG{l+m+mf}{255.255}\PYG{o}{.}\PYG{l+m+mf}{255.0} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.245}
\end{sphinxVerbatim}

Linux (enter the user password when prompted):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sudo} \PYG{n}{route} \PYG{n}{add} \PYG{o}{\PYGZhy{}}\PYG{n}{net} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.0}\PYG{o}{/}\PYG{l+m+mi}{24} \PYG{n}{gw} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.245}
\end{sphinxVerbatim}

Verifiy your route has been added (works for Windows and Linux):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{netstat} \PYG{o}{\PYGZhy{}}\PYG{n}{r}
\end{sphinxVerbatim}

Open up statistics for \sphinxstylestrong{forward-to-servernet} and from the jumpbox terminal window test access to the
10.1.20.0/24 subnet:
\begin{itemize}
\item {} 
ping 10.1.20.11

\item {} 
nslookup hackzon.f5demo.com 10.1.20.12 (windows) or dig @10.1.20.12 hackazon.f5demo.com (linux)

\item {} 
\sphinxurl{http://10.1.20.13} (from a browser) or curl 10.1.20.13 (linux)

\end{itemize}

By the way, if you take a look at the iApp templates you will find one
for building IP Forwarding virtual servers.


\subsubsection{More on Transparent Virtual Servers}
\label{\detokenize{class6/module06/lab4:more-on-transparent-virtual-servers}}
You have a pool of servers running multiple applications (FTP, HTTP,
SSH, etc) and you don’t want to create a virtual server for each
application. In this case a transparent virtual server that doesn’t
translate the port would work best.

Build your transparent pool and virtual server

Create a new pool called \sphinxstylestrong{transparent-pool}, use the \sphinxstylestrong{gateway\_icmp}
monitor with the member \sphinxstylestrong{10.1.20.14:}\sphinxstylestrong{*} and \sphinxstylestrong{10.1.20.15:}\sphinxstylestrong{*},
wildcard \sphinxcode{\sphinxupquote{*}} for the port.

\sphinxstyleemphasis{Q1. Why did we use gateway\_icmp? What other kind of monitor could we
have used?}

Create a virtual server called \sphinxstylestrong{transparent-vs} with a IP address of
\sphinxstylestrong{10.1.10.95} with with the wildcard port \sphinxcode{\sphinxupquote{*}}, since we can’t put any L7
profiles on this virtual server a virtual server type of \sphinxstylestrong{Performance (Layer 4)} will
be more efficient, Finally configure \sphinxstylestrong{transparent-pool} as the virtual server pool.

\begin{sphinxadmonition}{note}{Note:}
Open the Advanced menu and notice that Address Translation is still enabled, but
Port Translation is not.
\end{sphinxadmonition}

Test your virtual server.

Browse to \sphinxstylestrong{http://10.1.10.95}.

\sphinxstyleemphasis{Q2. Did it work? What were the image results?}

Browse to \sphinxstylestrong{https://10.1.10.95}.

\sphinxstyleemphasis{Q3. Did it work?}

DNS is running to the LAMP server.  SSH or PuTTY to 10.1.1.252 (LAMP server).
In the LAMP terminal window:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dig} \PYG{o}{@}\PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.95} \PYG{n}{hackazon}\PYG{o}{.}\PYG{n}{f5demo}\PYG{o}{.}\PYG{n}{com}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q4. Did it work? Why not and how would you fix it?}


\section{Lab 7 - Load Balancing and Pools}
\label{\detokenize{class6/module07/module07:lab-7-load-balancing-and-pools}}\label{\detokenize{class6/module07/module07::doc}}
In this module you will look at the effects of load balancing methods and configuration parameters on connection distribution to the pool members.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{1.16}] \leavevmode\begin{itemize}
\item {} 
Explain the effect of LTM device configuration parameters on load balancing
decisions

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{Load Balancing}
\label{\detokenize{class6/module07/lab1:load-balancing}}\label{\detokenize{class6/module07/lab1::doc}}

\subsubsection{Ratio Load Balancing}
\label{\detokenize{class6/module07/lab1:ratio-load-balancing}}
Go to Local \sphinxstylestrong{Traffic \textgreater{} Pools} and select \sphinxstylestrong{www\_pool} and then
\sphinxstylestrong{Members} from the top bar or you could click on the \sphinxstylestrong{Members} link
in the \sphinxstylestrong{Pool List} screen.

\begin{sphinxadmonition}{hint}{Hint:}
When we created the pool, we performed all our configuration on
one page, but when we modify a pool the Resource information is under
the Members tab
\end{sphinxadmonition}

Under \sphinxstylestrong{Load Balancing} section change the \sphinxstylestrong{Load Balancing Method} to \sphinxstylestrong{Ratio (Member)}

In drop-down menu, notice most load balancing methods have two options, \sphinxstylestrong{(Node)} or \sphinxstylestrong{(Member)}.

\sphinxstyleemphasis{Q1. What is the difference between Node and Member?}

Select the first member in the pool \sphinxstylestrong{10.1.20.11:80} and change the
\sphinxstylestrong{Ratio} of the member to \sphinxstylestrong{3}

Open the pool statistics and reset the statistics for \sphinxstylestrong{www\_pool}.

Browse to \sphinxstylestrong{http://10.1.10.100} and refresh the browser screen several
times.

\sphinxstyleemphasis{Q2. How many Total connections has each member taken? Is the ratio of
connections correct?}

Now go back and put the pool back to \sphinxstylestrong{Round Robin} Load Balancing
Method

Reset the pool statistics and refresh the virtual server page several
times.

\sphinxstyleemphasis{Q3. Does the ratio setting have any impact now?}


\subsubsection{Priority Groups Lab}
\label{\detokenize{class6/module07/lab1:priority-groups-lab}}
Let’s look at priority groups. In this scenario we will treat the 10.1.20.13
server as if it was is in a disaster recovery site that can be reached
over a backhaul. You want to maintain at least two members in the pool for
redundancy and load.  You would traffic to be distributed t0 10.1.20.13 only during maintenance of one on the two primary servers or if one to the two other pool members fails.

\begin{sphinxadmonition}{note}{Note:}
Remove any caching profiles from the www\_vs virtual server (10.1.10.100).
\end{sphinxadmonition}

Go to the \sphinxstylestrong{www\_pool} \sphinxstylestrong{Members} section. Make sure the load
balancing method is \sphinxstylestrong{Round Robin}.

Set the \sphinxstylestrong{Priority Group Activation} to less than \sphinxstylestrong{2} Available
Members.

Select the pool members \sphinxstylestrong{10.1.20.11} and \sphinxstylestrong{10.1.20.12} and set their
\sphinxstylestrong{Priority Group} to \sphinxstylestrong{10}.

Review your settings and let’s see how load balancing reacts now.

Select the \sphinxstylestrong{Statistics} tab, reset the pool statistics, browse to
\sphinxstylestrong{http://10.1.10.100} and refresh several times.

\sphinxstyleemphasis{Q1. Are all members taking connections? Which member isn’t taking
connections?}

Let’s simulate a maintenance window or an outage by disabling a pool
member \sphinxstylestrong{10.1.20.11:80} in the highest priority group. This should
cause low priority group to be activated, since number of active members
in our high priority group has dropped below 2.

\sphinxstyleemphasis{Q2. Is the lower priority group activated and taking connections?}

Select a member in the \sphinxstylestrong{Priority Group} 10 and \sphinxstylestrong{Disable} that pool
member.

Once again, select \sphinxstylestrong{Statistics}, reset the pool statistics, browse to the
virtual server and see which pool members are taking hits now.

\begin{sphinxadmonition}{important}{Important:}
Once you are done testing re-enable your disabled pool member.
\end{sphinxadmonition}


\subsection{Simple (Source Address) Persistence}
\label{\detokenize{class6/module07/lab1:simple-source-address-persistence}}
You have already seen cookie persistence at work, but if the client or
application (ie. ftp) does not support cookies you must use and
alternate method. The most common is Simple Persistence which is based
on the source IP address/network.

Verify your \sphinxstylestrong{www\_pool} is using \sphinxstylestrong{Round Robin} load balancing and the
priority groups are disabled.

Browse to \sphinxstylestrong{http://10.1.10.100} and refresh several times. You should see
all 3 servers respond.

Go to \sphinxstylestrong{Local Traffic \textgreater{} Profiles} and select the \sphinxstylestrong{Persistence} tab and
from the \sphinxstylestrong{Persistence} \sphinxstylestrong{Profiles} screen select the \sphinxstylestrong{Create}
button.

Create a new persistence profile named \sphinxstylestrong{my-src-persist} with a
\sphinxstylestrong{Persistence Type} of \sphinxstylestrong{Source Address Affinity} and set the
\sphinxstylestrong{Timeout} to \sphinxstylestrong{120} seconds and leave \sphinxstylestrong{Mask: None}

\begin{sphinxadmonition}{note}{Note:}
The \sphinxstylestrong{Mask: None} defaults to \sphinxstylestrong{255.255.255.255} which means each new IP address will create a new
persistence record.
\end{sphinxadmonition}

Now let’s attach the new persistence profile to the \sphinxstylestrong{www\_vs} virtual
server.

\begin{sphinxadmonition}{hint}{Hint:}
When you create a Virtual Server everything is on a single page,
when you return to modified the Virtual Server the Properties and
Resources are on different pages.
\end{sphinxadmonition}

Set the \sphinxstylestrong{Default Persistence Profile} to \sphinxstylestrong{my-src-persist}.

Test your Source Address Affinity persistence profile.

At this point you may want to open a second browser window to the BIG-IP
GUI.

Go to \sphinxstylestrong{Statistics \textgreater{} Module Statistic \textgreater{} Local Traffic} and select
\sphinxstylestrong{Persistence Records} from the \sphinxstylestrong{Statistics Type} menu.

In this window, you can watch you persistence records. You may want to
set \sphinxstylestrong{Auto Refresh} to 20 seconds.

In another BIG-IP GUI window go to \sphinxstylestrong{www\_pool} and clear the member
statistics.

Browser to \sphinxstylestrong{http://10.1.10.100} and refresh several times.

\sphinxstyleemphasis{Q1. How many members are taking traffic?}

\sphinxstyleemphasis{Q2. Check you Persists Records window, are the any persistence records?}

\sphinxstyleemphasis{Q3. Refresh you web page prior to the Age column reaching 120. What
happens?}

While the persistence recorded is still active \sphinxstylestrong{Disable} the member
you are persisted too and refresh the browser page.

\sphinxstyleemphasis{Q4. Could you access the web site? Why?}

While the persistence recorded is still active, go the member specific
menu of the member you are persisted too and do a \sphinxstylestrong{Force Offline} and
refresh the browser page.

\sphinxstyleemphasis{Q5. Could you access the web site? Why?}

\begin{sphinxadmonition}{important}{Important:}
Re-enable the pool members before continuing.
\end{sphinxadmonition}


\section{Lab 8 - Networking}
\label{\detokenize{class6/module08/module08:lab-8-networking}}\label{\detokenize{class6/module08/module08::doc}}
You have already done a number of labs around networks and there are
only so many things we can do in the lab environment. Will take a moment
to do a couple of simple exercises that will help set up later labs.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{2.01-2.02}] \leavevmode\begin{itemize}
\item {} 
Distinguish between the management interface configuration and application
traffic interface configuration

\item {} 
Given a network diagram, determine the appropriate network and system
settings (i.e., VLANs, self-IPs, trunks, routes, NTP servers, DNS servers,
SNMP receivers and syslog servers)

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{Self IP Port Lockdown and more}
\label{\detokenize{class6/module08/lab1:self-ip-port-lockdown-and-more}}\label{\detokenize{class6/module08/lab1::doc}}

\subsubsection{Effects of Port Lockdown}
\label{\detokenize{class6/module08/lab1:effects-of-port-lockdown}}
In the exercise, you will do some basic configuration of DNS and NTP and
work with port lockdown.

Working with port lockdown on self IPs.

Ping \sphinxstylestrong{10.1.10.245}

\sphinxstyleemphasis{Q1. Was echo response received?}

SSH to \sphinxstylestrong{10.1.10.245}

\sphinxstyleemphasis{Q2. Was ssh successful? Why not?}

Open \sphinxstylestrong{Network \textgreater{} Self IPs \textgreater{} 10.1.10.245} and change \sphinxstylestrong{Port Lockdown}
to \sphinxstylestrong{Allow Defaults}

SSH to \sphinxstylestrong{10.1.10.245}

Browse to \sphinxstylestrong{https://10.1.10.245}

\sphinxstyleemphasis{Q3. Did SSH work? Did browsing work?}

\sphinxstyleemphasis{Q4. What other ports are opened when you select} \sphinxstylestrong{Allow Defaults}.

Open \sphinxstylestrong{Network \textgreater{} Self IPs \textgreater{} 10.1.10.245} and change Port Lockdown to
\sphinxstylestrong{Allow Custom} and add \sphinxstylestrong{TCP} port \sphinxstylestrong{22}

SSH to \sphinxstylestrong{10.1.10.245}

Browse to \sphinxstylestrong{https://10.1.10.245}

\sphinxstyleemphasis{Q5. Did SSH work? Did browsing work?}


\subsubsection{Configure DNS and NTP}
\label{\detokenize{class6/module08/lab1:configure-dns-and-ntp}}
NTP is essential for a number of BIG-IP functions, in particular, when
creating Device Service Clusters. DNS configured on the BIG-IP can also
be of value.

Configure DNS and NTP.

\begin{sphinxadmonition}{note}{Note:}
The BIG-IP DNS has been preconfigured in the UDF environment
\end{sphinxadmonition}

Go to \sphinxstylestrong{System \textgreater{} Configuration \textgreater{} Device \textgreater{} DNS}

Configure BIG-IP to use \sphinxstylestrong{8.8.8.8} as the first DNS server in the \sphinxstylestrong{DNS Lookup Server List}.
Use the \sphinxstylestrong{Up} and \sphinxstylestrong{Down} buttons to set the priority.  In BIG-IP command line terminal
window test DNS from the CLI or TMSH enter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dig} \PYG{n}{pool}\PYG{o}{.}\PYG{n}{ntp}\PYG{o}{.}\PYG{n}{org}
\end{sphinxVerbatim}

Note the IP addresses returned and the DNS server used.

Now that you’ve configured DNS, configure NTP using \sphinxstylestrong{pool.ntp.org}.


\subsubsection{VLAN Tagging}
\label{\detokenize{class6/module08/lab1:vlan-tagging}}
Here you will set up multiple VLANs on the same interface and assign IP
addressing. You will be using one of these VLANs when you do the High
Availability lab.

Go to \sphinxstylestrong{VLANs} and create two \sphinxstylestrong{tagged} VLANs on interface \sphinxstylestrong{1.3}.

The first VLAN will be named \sphinxstylestrong{vlan-30} have a
tag of \sphinxstylestrong{30} and on interface \sphinxstylestrong{1.3} will be placed in the \sphinxstylestrong{Tagged} box.

The second tagged VLAN will be named \sphinxstylestrong{vlan-40} on interface \sphinxstylestrong{1.3} and have
a tag of \sphinxstylestrong{40}.

Make sure you place the interface into correct box.

Create a new self IP named \sphinxstylestrong{HA-IP} and \sphinxstylestrong{10.1.30.245/24} and assign
it to vlan \sphinxstylestrong{vlan-30}.

You will be using this IP address for building a device service cluster
in a later lab.


\section{Lab 9 - Roles and Partitions}
\label{\detokenize{class6/module09/module09:lab-9-roles-and-partitions}}\label{\detokenize{class6/module09/module09::doc}}
In this module you will learn more about user roles and how configuring partitions restricts
access to portions of the configuration based on user role.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{2.04-2.05}] \leavevmode\begin{itemize}
\item {} 
Explain how to configure remote authentication and multiple administration
roles on the LTM device

\item {} 
Explain the uses of administrative partitions

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{Roles and Partitions}
\label{\detokenize{class6/module09/lab1:roles-and-partitions}}\label{\detokenize{class6/module09/lab1::doc}}

\subsubsection{Create a partition}
\label{\detokenize{class6/module09/lab1:create-a-partition}}
Partitions are basically configuration containers. Users assigned to a
partition can only view their partition configuration and configuration items in the \sphinxstylestrong{Common} partition. Depending on their role a user may modify and create configuration items within their partition and use (but not modify) configuration items in
the common partition.

To create a new partition, go to \sphinxstylestrong{System \textgreater{} Users \textgreater{} Partition List} and
select create

Create a new partition named \sphinxstylestrong{my\_partition}. There is really not a
whole lot to it.


\subsubsection{Create and place a user in a partition}
\label{\detokenize{class6/module09/lab1:create-and-place-a-user-in-a-partition}}
Create a new local user by going to \sphinxstylestrong{System \textgreater{} Users \textgreater{} User List} and
selecting create.

Create a new user \sphinxstylestrong{testuser} with \sphinxstylestrong{testpass} as the password and set
their \sphinxstylestrong{Role} to \sphinxstylestrong{Manager}, assign them to the \sphinxstylestrong{test\_partition}
partition and give them \sphinxstylestrong{tmsh Terminal Access}

Open a new private browser to the BIG-IP, or log out and log back in
under your current browser as the new user \sphinxstylestrong{testuser/testpass}.

\sphinxstyleemphasis{Q1. In the upper right of the BIG-IP WebUI what partition are you in?}

Look at the virtual servers. You can see these because they were all
built in the Common partition, but you cannot modify them. If you go
into a virtual server you will see the selections greyed out.

As you can see, you can view but not change things in common. But you
can use things in the \sphinxstylestrong{Common} partition to build your own configuration.

Build a new HTTP virtual server named \sphinxstylestrong{test\_vs}, with a destination
IP of \sphinxstylestrong{10.1.10.120} and used the \sphinxstylestrong{www\_pool} in the \sphinxstylestrong{/Common}
partition as the default pool.

In this case we are taking advantage of the \sphinxstylestrong{Common} partition nodes and
pools to build are virtual server.

Log out and log in as \sphinxstylestrong{admin} (or go to your other browser window that is
logged in as admin)

Go to the \sphinxstylestrong{Virtual Server List}.

\sphinxstyleemphasis{Q2. Do you see the} \sphinxstylestrong{test\_vs} \sphinxstyleemphasis{just created?}

Go to the upper right-hand corner and select \sphinxstylestrong{test\_partition}. You
can now see the \sphinxstylestrong{test\_vs} virtual server. Since you are an admin you
can also modify the virtual server as necessary

SSH to your BIG-IP and log in with the new user name and password.  You should be
taken directly into the \sphinxstylestrong{tmsh}.

Note the prompt, your partition name is there.

Now let’s make a change to the test\_vs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mod} \PYG{n}{ltm} \PYG{n}{virtual} \PYG{n}{test}\PYGZbs{}\PYG{n}{\PYGZus{}vs} \PYG{n}{description} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Partition Testing}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

In the BIG-IP WebUI go to your \sphinxstylestrong{test\_vs} virtual server.

\sphinxstyleemphasis{Q3. Do you see your change? Is your change permanent?}

\begin{sphinxadmonition}{note}{Note:}
\sphinxstylestrong{The following lab portion is probably not on the 301, but as I have you playing with
partitions this is something if feel you should know.}
\end{sphinxadmonition}

SSH to the BIG-IP and log in as \sphinxstylestrong{root}. \sphinxstylestrong{cat} or \sphinxstylestrong{more} bigip.conf
and look for you \sphinxstylestrong{test\_vs} virtual:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cat} \PYG{n}{bigip}\PYG{o}{.}\PYG{n}{conf}
\PYG{n}{more} \PYG{n}{bigip}\PYG{o}{.}\PYG{n}{conf}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q4. Did you find it in /config/bigip.conf?}

Each partition gets its own “folder” where its configuration is stored
under the \sphinxstylestrong{partitions} directory in the \sphinxstylestrong{/config} directory. At the
BIG-IP CLI prompt:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cd} \PYG{o}{/}\PYG{n}{config}\PYG{o}{/}\PYG{n}{partitions}\PYG{o}{/}\PYG{n}{test\PYGZus{}partition}
\PYG{n}{ls}
\PYG{n}{cat} \PYG{n}{bigip}\PYG{o}{.}\PYG{n}{conf}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q5. Did you find your virtual server? Is the tmsh change you made in
there?}

As \sphinxstylestrong{testuser} at the tmsh prompt type: \sphinxstylestrong{save sys config}

Look at your \sphinxstylestrong{bigip.conf} in the \sphinxstylestrong{test\_partition}.

\sphinxstylestrong{Q6. Do you see the change now?}

Attempt to exit tmsh to get to the Linux CLI.

\sphinxstyleemphasis{Q7. Where you able to?}


\subsection{Remote Authentication}
\label{\detokenize{class6/module09/lab2:remote-authentication}}\label{\detokenize{class6/module09/lab2::doc}}

\subsubsection{Authenticate against LDAP}
\label{\detokenize{class6/module09/lab2:authenticate-against-ldap}}
Go to \sphinxstylestrong{System \textgreater{} Users \textgreater{} Authentication} and select \sphinxstylestrong{Change} under \sphinxstylestrong{User
Directory}.

Now select \sphinxstylestrong{LDAP} from the \sphinxstylestrong{User Directory} drop-down and enter the
following


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Host
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{3}}
10.1.20.252
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
Remote Directory Tree
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{3}}
dc=f5demo,dc=com
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
Bind DN:
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{3}}
cn=Directory Manager
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
Bind Password/Confirm
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{3}}
default
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
Role
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{3}}
Administrator
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Open a new private browser window to \sphinxstylestrong{bigip01} at \sphinxstylestrong{https://10.1.1.4} and
logon using the LDAP account \sphinxstylestrong{adminuser/password}.

\sphinxstyleemphasis{Q1. Were you successful?}

Try logging with the local account \sphinxstylestrong{testuser/testpass}.

\sphinxstyleemphasis{Q2. Were you successful?}


\section{Lab 10 - Device Service Clusters and High Availability}
\label{\detokenize{class6/module10/module10:lab-10-device-service-clusters-and-high-availability}}\label{\detokenize{class6/module10/module10::doc}}
In this module you will configure BIG-IPs for high availability.  Device Service Clusters (DSCs) are a series of BIG-IPs (up to 8) that and support each other and failover applications.
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{2.05-2.07}] \leavevmode\begin{itemize}
\item {} 
Given a scenario, determine an appropriate high availability
configuration (i.e., failsafe, failover and timers)

\item {} 
Given a scenario, describe the steps necessary to set up a device
group, traffic group and HA group

\item {} 
Predict the behavior of an LTM device group or traffic groups in a
given failure scenario

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{45 minutes}


\subsection{Building a DSC (Device Service Cluster)}
\label{\detokenize{class6/module10/lab1:building-a-dsc-device-service-cluster}}\label{\detokenize{class6/module10/lab1::doc}}

\subsubsection{Base Networking and HA VLAN}
\label{\detokenize{class6/module10/lab1:base-networking-and-ha-vlan}}
You will be creating a high availability cluster using the second BIG-IP
(bigip2.f5demo.com) in your lab.  You’ll begin by prepping \sphinxstylestrong{bigip01.f5demo.com} ( your current BIG-IP by creating a high availability VLAN that you will use to pass network polling, configuration changes and mirroring information between the two BIG-IPs.

\begin{sphinxadmonition}{warning}{Warning:}
If you haven’t already \sphinxstylestrong{archived} your work \sphinxstylestrong{DO IT NOW!}
\end{sphinxadmonition}

Begin by making sure the base network configuration is created on both
devices.


\paragraph{Prepare bigip01}
\label{\detokenize{class6/module10/lab1:prepare-bigip01}}
On \sphinxstylestrong{bigip01.f5demo.com} (10.1.1.245), this should already have been
accomplished. You will be using interface 1.3 VLAN 30 and IP 10.1.30.245
for Network Failover and ConfigSync and Mirroring.

High availability requires certain ports to be open on the Self IP; TCP port 4353 for
ConfigSync and TCP port 1026 for Network Failover and TCP port 6699 for
the Master Control Program.

Go to you \sphinxstylestrong{10.1.30.245} self IP and set \sphinxstylestrong{Port Lockdown} to \sphinxstylestrong{Allow
Defaults}. This will ensure the ports we require are open.

Go to \sphinxstylestrong{https://10.1.1.246} which is \sphinxstylestrong{bigip02.f5demo.com} and login with
\sphinxstylestrong{admin/admin}.


\paragraph{Prepare bigip02}
\label{\detokenize{class6/module10/lab1:prepare-bigip02}}
Your second BIG-IP, \sphinxstylestrong{bigip02,} has already been licensed and the basic
setup completed. You need to make sure the BIG-IPs are provisioned the
same \sphinxstylestrong{(LTM and AVR)} and set up the base networking on \sphinxstylestrong{bigip02}.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Interface
&\sphinxstyletheadfamily 
VLAN name
&\sphinxstyletheadfamily 
Tag (blank untagged)
&\sphinxstyletheadfamily 
Self IP Name
&\sphinxstyletheadfamily 
Self IP
&\sphinxstyletheadfamily 
Mask
&\sphinxstyletheadfamily 
Port Lockdown
&\sphinxstyletheadfamily \\
\hline
1.1
&
client\_vlan
&&
client\_ip
&
10.1.10.246
&
255.255.255.0
&
None
&\\
\hline
1.2
&
server\_vlan
&&
server\_ip
&
10.1.20.246
&
255.255.255.0
&
None
&\\
\hline
1.3
&
vlan-30
&
30
&
HA\_IP
&
10.1.30.246
&
255.255.255.0
&
Allow Defaults
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstyleemphasis{Q1. What is the status your BIG-IPs?}

\begin{sphinxadmonition}{note}{Note:}
Check the upper left-hand corner next to the F5 ball.
\end{sphinxadmonition}


\subsubsection{Prepare each BIG-IP for High Availability}
\label{\detokenize{class6/module10/lab1:prepare-each-big-ip-for-high-availability}}
On each BIG-IP you will update the device and device trust certificate
and configured the failover IPs for each device.

On \sphinxstylestrong{EACH} BIG-IP, prior to building the Device Trust it is
recommended, but not mandatory, that you renew the BIG-IP self-signed
certificate with valid information and re-generate the local Device
Trust certificate.

Under \sphinxstylestrong{System \textgreater{} Device Certificate \textgreater{} Device Certificate} select the
\sphinxstylestrong{Renew} button.

\sphinxstylestrong{Common Name:} \textless{}the Hostname of the BIG-IP in the upper left corner\textgreater{}

\sphinxstylestrong{Country:} United States (or your country of preference)

\sphinxstylestrong{Lifetime:} 3650

\begin{sphinxadmonition}{important}{Important:}
Lifetime is important, when your certificate expires your HA setup will FAIL.
You should always make sure you device certificate has a long lifetime.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Because you have changed the device certificate you may be required to log back
into the BIG-IP to establish a secure connection with the new certificate.
\end{sphinxadmonition}

Select \sphinxstylestrong{Finished}. Your browser will ask to exchange certs with the BIG-IP again.

Under \sphinxstylestrong{Device Management \textgreater{} Device Trust \textgreater{} Local Domain} select \sphinxstylestrong{Reset Device Trust}

In the \sphinxstylestrong{Certificate Signing Authority} select \sphinxstylestrong{Generate New Self-Signed Authority}.

On each BIG-IP configure the device object failover parameters the
BIG-IP will send to other BIG-IPs that want to be a part of a sync-only
or sync-failover group.

Under \sphinxstylestrong{Device Management \textgreater{} Device}, select the local BIG-IP. It will
have the \sphinxstylestrong{(Self)} suffix.
\begin{description}
\item[{Under \sphinxstylestrong{Device Connectivity}:}] \leavevmode\begin{itemize}
\item {} 
On the top bar select \sphinxstylestrong{ConfigSync} and use the \sphinxstylestrong{HA-IP} for your \sphinxstylestrong{Local Address}.

\end{itemize}

\item[{Under \sphinxstylestrong{Network Failover}:}] \leavevmode\begin{itemize}
\item {} 
In the \sphinxstylestrong{Failover Unicast Configuration} section select the \sphinxstylestrong{Add} button

\item {} 
Use the Self IP address the \sphinxstylestrong{HA VLAN} for your Address

\item {} 
Leave the \sphinxstylestrong{Port} at the default setting of \sphinxstylestrong{1026}.

\end{itemize}

\end{description}

\sphinxstyleemphasis{Q1. If you were to add multiple IP address to the Failover Unicast, when
would the BIG-IP failover?}

\begin{sphinxadmonition}{note}{Note:}
Multicast is for Viprion chasses only.
\end{sphinxadmonition}
\begin{description}
\item[{Under \sphinxstylestrong{Mirroring}:}] \leavevmode\begin{itemize}
\item {} 
Primary Local Mirror Address: \sphinxstylestrong{\textless{}use the HA-IP\textgreater{}}

\item {} 
Secondary Local Mirror Address: \sphinxstylestrong{None}

\end{itemize}

\end{description}

\begin{sphinxadmonition}{important}{Important:}
On each BIG-IP archive your work in a UCS called: \sphinxstylestrong{lab11\_ha\_prep}
\end{sphinxadmonition}


\subsubsection{Build the Device Trust and Device Group}
\label{\detokenize{class6/module10/lab1:build-the-device-trust-and-device-group}}
In the task you will build a trust between bigip01 and bigip02. Once the
trust between the devices is built you will be build a Sync-Failover
device group and place the BIG-IPs in the new group. You will build this
from bigip01 and sync its good configuration to bigip02.

On \sphinxstylestrong{bigip01.f5demo.com}, under \sphinxstylestrong{Device Management \textgreater{} Device Trust \textgreater{}
Peer List} and select \sphinxstylestrong{Add}

\sphinxstylestrong{Device IP Address:} \textless{}management IP address of the BIG-IP to add\textgreater{}

\begin{sphinxadmonition}{note}{Note:}
You could use any Self IP if the out-of-band management interface is not
configured and you have the appropriate ports (22 and 443) open as you build the trust.
\end{sphinxadmonition}

Enter the \sphinxstylestrong{Administrator} username and password of the BIG-IP you are
trusting.

Select \sphinxstylestrong{Retrieve Device Information}

The certificate information and name from the other BIG-IP should appear

On each BIG-IP check the other BIG-IP in the Peer Authorities list.

\sphinxstyleemphasis{Q1. Is all the information there?}

\begin{sphinxadmonition}{warning}{Warning:}
Occasionally some of the information is missing due to configuration errors or other failures.  If any of the
information is missing delete the trust, correct the problem and try again.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q2. What are the statuses of your BIG-IPs now?}

You might think they should be \sphinxstylestrong{In Sync}. \sphinxcode{\sphinxupquote{But wait!}} We haven’t even created a device
group! Remember the Device Trust creates a \sphinxstylestrong{Sync-Only} group for the
certificates under the covers (device-trust-group) for the trust.  It is the \sphinxstylestrong{device-trust-group} that is in sync.

On \sphinxstylestrong{bigip01.f5demo.com} create a new \sphinxstylestrong{Sync-Failover} device group

Under \sphinxstylestrong{Device Management \textgreater{} Device Group} create a new device group
named \sphinxstylestrong{my\_device\_group} with a type of \sphinxstylestrong{Sync-Failover}

Add the members of the group (bigip01 and bigip02) to the \sphinxstylestrong{Includes}
box and check the \sphinxstylestrong{Network Failover} setting for the group.

Check \sphinxstylestrong{Device Groups} on each BIG-IP.

\sphinxstyleemphasis{Q3. Did you have to create the Device Group on the other BIG-IP?}

\sphinxstyleemphasis{Q4. Is the full configuration synchronized yet?}

\sphinxstyleemphasis{Q5. What is the status and sync status on the BIG-IPs?}

On your configured BIG-IP (bigip01), click on the sync status
(\sphinxstylestrong{Awaiting Initial Sync}) or go to \sphinxstylestrong{Device Management \textgreater{} Overview}.

\begin{sphinxadmonition}{warning}{Warning:}
Click the device with the configuration you want to
synchronize to the other BIG-IPs (that would be bigip01). The Sync
Options should appear.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
You can push or pull a configuration from the device the cluster or the cluster to a device.  The warning above applies.  \sphinxstylestrong{Always} understand what BIG-IP you are on and which direction you are syncing.
\end{sphinxadmonition}

\sphinxstylestrong{Sync Device to Group}. It could take up to 30 seconds for
synchronization to complete.

\begin{sphinxadmonition}{warning}{Warning:}
During the \sphinxstylestrong{Awaiting Initial Sync} phase either BIG-IP can perform the synchronization and the other BIG-IP will be overwritten.
\end{sphinxadmonition}

Check each BIG-IP \sphinxstylestrong{Device Management \textgreater{} Overview}.

\sphinxstyleemphasis{Q6. Did the configuration synchronize? What, if any, errors do you see?}

You ended up with an error because of configuration dependencies with
\sphinxstylestrong{avr2\_virtual}. This is why building you device service cluster early
is a good idea, but you can’t always do that. You could have a device
cluster pair that you are adding a third BIG-IP. You are going to have
to correct the error, synchronize and the re-add \sphinxstylestrong{avr\_virtual.}

On \sphinxstylestrong{bigip01} delete the virtual server \sphinxstylestrong{avr\_virtual2.}

\sphinxstyleemphasis{Q7. Any issue with that?}

Maybe the easier route is to remove the iRule from \sphinxstylestrong{avr\_virtual1}
(which references \sphinxstylestrong{avr\_virtual2}), synchronize and then add it back.

\sphinxstyleemphasis{Q8. What is the sync status of bigip02 once you made the change?}

Sync \sphinxstylestrong{bigip01} to the group.

\sphinxstyleemphasis{Q9. Are the BIG-IPs In Sync? Are the configurations the same?}

Browse to \sphinxstylestrong{http://10.1.10.100}

\sphinxstyleemphasis{Q10. Could you access the site? Which BIG-IP passed the traffic?}

Place the \sphinxstylestrong{random\_client\_ip} iRule back on \sphinxstylestrong{avr\_virtual2} and
synchronize the changes.


\subsection{Failover and Mirroring}
\label{\detokenize{class6/module10/lab2:failover-and-mirroring}}\label{\detokenize{class6/module10/lab2::doc}}

\subsubsection{Testing Failover}
\label{\detokenize{class6/module10/lab2:testing-failover}}
Now that you have created your HA environment let’s play with it. In
this lab, you will set up mirroring and perform failover and
synchronization of updates.

Ensure \sphinxstylestrong{bigip02} is the \sphinxstylestrong{Active} BIG-IP. If \sphinxstylestrong{bigip01} is the
\sphinxstylestrong{Active} BIG-IP then go to \sphinxstylestrong{Device Management \textgreater{}\textgreater{} Traffic Groups}.
Select \sphinxstylestrong{traffic-group-1} and hit the \sphinxstylestrong{Force to Standby} button.

Browse to \sphinxstylestrong{http://10.1.10.100}?

\sphinxstyleemphasis{Q1. What is the source IP in the} \sphinxstylestrong{Request Details}?

Browse to \sphinxstylestrong{http://10.1.10.115}?

\sphinxstyleemphasis{Q2. What happened? Why?}

The default gateway for the servers in the \sphinxstylestrong{secure\_pool} is
\sphinxstylestrong{10.1.20.240}. This IP is currently assigned to
\sphinxstylestrong{traffic-group-local-only} in \sphinxstylestrong{bigip01} and resides in the
\sphinxstylestrong{bigip\_base.conf}. We need this IP address to float to the active
BIG-IP upon failover. Because we are changing this from a base IP to a
floating IP you will encounter an error when trying to sync the configuration. Incremental updates are the default sync method, but sometimes a full overwrite is required.

On \sphinxstylestrong{bigip01}, open the self IP \sphinxstylestrong{server\_gw} (10.1.20.240) and
assign it to the default floating traffic group \sphinxstylestrong{traffic-group-1.}
Select \sphinxstylestrong{Changes Pending} or \sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Oveview}.

From the \sphinxstylestrong{Overview} page, select \sphinxstylestrong{bigip01.f5demo.com}, select \sphinxstylestrong{Sync Device to
Group}, select \sphinxstylestrong{Overwrite Configure} and select \sphinxstylestrong{Sync}.

Browse to \sphinxstylestrong{http://10.1.10.115}.

\sphinxstyleemphasis{Q3. Did the site work? What was the client IP?}

Browse to \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q4. What was the client IP address that the server saw (under} \sphinxstylestrong{Request
Details} \sphinxstyleemphasis{on the main page)? Why?}

Failover the active BIG-IP by going to \sphinxstylestrong{Device Management  \textgreater{} Devices
\textgreater{}} \sphinxstylestrong{\textless{}device name\textgreater{} (self)} and at the bottom of the page select
\sphinxstylestrong{Force to Standby}. This is how a system level failover is performed.

\sphinxstyleemphasis{Q5. Does http://10.1.10.115 still work? What is the client IP?}


\subsubsection{Mirroring}
\label{\detokenize{class6/module10/lab2:mirroring}}
Once you place a BIG-IP in a device group, mirroring selections will
show up for SNAT objects, persistence profiles and connection mirroring
on virtual servers. The BIG-IP will only mirror records created after
mirroring is enabled. Let’s see how mirroring persistence works, as an
example.

Go to your \sphinxstylestrong{Active} BIG-IP.

Open you \sphinxstylestrong{www\_vs} virtual server and add \sphinxstylestrong{my-src-persist} as your
\sphinxstylestrong{Persistence Profile}.

On each BIG-IP go to \sphinxstylestrong{Module Statistics \textgreater{} Local Traffic} and bring up
the \sphinxstylestrong{Persistence Record} statistics.

Browse to \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q1. Do you have a persistence record on each BIG-IP? What would happen
if you did a failover?}

Go to your persistence profile \sphinxstylestrong{my-src-persist} and check the \sphinxstylestrong{Mirror
Persistence} box.

Synchronize your changes.

On each BIG-IP go to \sphinxstylestrong{Module Statistics \textgreater{} Local Traffic} and bring up
the \sphinxstylestrong{Persistence Record} statistics.

SSH to your active BIG-IP and view your persistence records. In TMSH run
the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{show} \PYG{o}{/}\PYG{n}{ltm} \PYG{n}{persistence} \PYG{n}{persistence}\PYG{o}{\PYGZhy{}}\PYG{n}{records}
\end{sphinxVerbatim}

Note the CLI/TMSH prompt, you can find the sync status and the BIG-IP
state.

For this lab, if you have any persistence records delete them:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{delete} \PYG{o}{/}\PYG{n}{ltm} \PYG{n}{persistence} \PYG{n}{persistence}\PYG{o}{\PYGZhy{}}\PYG{n}{records}
\end{sphinxVerbatim}

Browse to \sphinxstylestrong{http://10.1.10.100} and refresh the page few times.

Check the persistence records on each of your BIG-IPs, you should see
the records are mirrored on each device.

\sphinxstyleemphasis{Q2. If you had persistence records existing prior to mirroring would
they appear on the standby box?}

Go to \sphinxstylestrong{Device Management \textgreater{} Traffic Groups}. Select the default traffic
group \sphinxstylestrong{traffic-group-1} and check out the \sphinxstylestrong{Next Active Device}.

Refresh the web page at \sphinxstylestrong{http://10.1.10.100}, and in \sphinxstylestrong{traffic-group-1},
select \sphinxstylestrong{Force to Standby}.

Browse or refresh \sphinxstylestrong{http://10.1.10.100}.

\sphinxstyleemphasis{Q3. Did you persist to the correct pool member? What is the client IP?}


\subsection{Traffic Groups}
\label{\detokenize{class6/module10/lab3:traffic-groups}}\label{\detokenize{class6/module10/lab3::doc}}

\subsubsection{Build a New Traffic Group.}
\label{\detokenize{class6/module10/lab3:build-a-new-traffic-group}}
You are now going to build an active-active cluster by creating a new
traffic-group and forcing that traffic group to run on the Standby
BIG-IP.

On your \sphinxstylestrong{Active} BIG-IP, go to \sphinxstylestrong{Device Management \textgreater{} Traffic Groups} and
create a new traffic group called \sphinxstylestrong{tg-2}.

Place the \sphinxstylestrong{www\_vs} in the new \sphinxstylestrong{tg-2} traffic group.

Remember you place virtual address, not virtual servers, in a traffic
group.

Go the \sphinxstylestrong{Virtual Server List}, note the IP address of \sphinxstylestrong{www\_vs} and
select \sphinxstylestrong{Virtual Address} from the top bar.

Under the \sphinxstylestrong{Virtual Address} select the traffic group you want to
assign it to, \sphinxstylestrong{tg-2}.

\sphinxstyleemphasis{Q1. When you did this, what other virtual servers were assign to tg-2?}

On the \sphinxstylestrong{Active} BIG-IP, under \sphinxstylestrong{Device Management} select \sphinxstylestrong{tg-2}
note the \sphinxstylestrong{Next Active Device} and \sphinxstylestrong{Force to Standby}.

\sphinxstyleemphasis{Q2. What are the states of you BIG-IPs?}

Browse to \sphinxstylestrong{http://10.1.10.100} and ftp to \sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q3. Did the web site work? What was the client IP? Did ftp work? Why or
why not?}

It is important to get all the listeners that support an application
into the same traffic group.

Go to your ftp SNAT pool and note the address, then go to the \sphinxstylestrong{SNAT
Translation List} select the IP and place it in \sphinxstylestrong{tg-2}.

FTP to \sphinxstylestrong{10.1.10.100}.

\sphinxstyleemphasis{Q4. Did it work now?}


\section{Lab 11 - Security and Securing the BIG-IP}
\label{\detokenize{class6/module11/module11:lab-11-security-and-securing-the-big-ip}}\label{\detokenize{class6/module11/module11::doc}}
You have seen numerous security features already, but logging can be
just as important to securing the BIG-IP. In the lab you will set up
audit logging and log BIG-IP LTM message to a remote syslog-ng server.
You will also learn to about additional logging and security
features you can implement.,
\begin{description}
\item[{301a Objectives covered:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{2.12}] \leavevmode\begin{itemize}
\item {} 
Determine the appropriate LTM device security configuration to protect
against a security threat

\end{itemize}

\end{description}

\end{itemize}

\end{description}

Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{More Security Features}
\label{\detokenize{class6/module11/lab1:more-security-features}}\label{\detokenize{class6/module11/lab1::doc}}

\subsubsection{Configure Audit Logging}
\label{\detokenize{class6/module11/lab1:configure-audit-logging}}
Audit logging allows you to log changes made by BIG-IP administrators
and other users.

Audit logging is disabled by default. \sphinxstylestrong{Go to System \textgreater{} Logs \textgreater{} Configuration}.

Notice you can determine by role who is allowed to view the audit logs.

Audit Logging is toward the bottom of the page. \sphinxstylestrong{Enable} Audit Logging

In a private browser window, log on to the BIG-IP as \sphinxstylestrong{adminuser/password}.

Make a change to the \sphinxstylestrong{Description} of the FTP virtual server \sphinxstylestrong{ftp\_vs}.

Review the audit log at \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Audit}. In the \sphinxstylestrong{Search}
box type \sphinxstylestrong{adminuser} and hit \sphinxstylestrong{Search}.

\sphinxstyleemphasis{Q1. Do you see when adminuser logged on? Do you see the change made in
the audit log?}


\subsubsection{Limiting SSH access to the BIG-IP}
\label{\detokenize{class6/module11/lab1:limiting-ssh-access-to-the-big-ip}}
The jumpbox has two IPs, 10.1.1.51 on the management network, 10.1.10.51
on the client-side network.

Open \sphinxstylestrong{System \textgreater{} Platform} and in \sphinxstylestrong{SSH IP Allow} \textgreater{} \sphinxstylestrong{Specify Range}
of \sphinxstylestrong{10.1.20.0/24}

\sphinxstyleemphasis{Q1. Does existing an SSH window still work? Does a new SSH work?}

Change the \sphinxstylestrong{Specify Range} to the management network only \sphinxstylestrong{10.1.1.0/24}.

Open new SSH sessions to \sphinxstylestrong{10.1.1.245} and \sphinxstylestrong{10.1.10.245}.

\sphinxstyleemphasis{Q2. Were new ssh sessions established?}


\subsection{BIG-IP Remote Logging}
\label{\detokenize{class6/module11/lab2:big-ip-remote-logging}}\label{\detokenize{class6/module11/lab2::doc}}
Your customer would like to integrate BIG-IP system messages with
their central logging system, to be processed by their correlation
software. They would like you to send mcpd informational messages (to external logging server(s)).


\subsubsection{Configuring a logging pool}
\label{\detokenize{class6/module11/lab2:configuring-a-logging-pool}}
Create a pool with the logging server(s). This will be the destination for
high speed logging. You will be logging to \sphinxstylestrong{syslog\_ng} over TCP port \sphinxstylestrong{514}.
You will be using a combination of an inband monitor and an active
monitor to determine the log server’s availability. This monitor will
combination will reduce network activity and superfluous log messages to
the syslog server.

Configure the \sphinxstylestrong{Logging Pool}.

Because the syslog server is using the TCP protocol, we can use inband monitors.  Create an \sphinxstylestrong{inband} monitor named \sphinxstylestrong{syslog\_inband} and use the default configuration.

Create an active \sphinxstylestrong{TCP} monitor named \sphinxstylestrong{syslog\_active} and set the
\sphinxstylestrong{Up Interval} to \sphinxstylestrong{180} seconds.

This monitor will poll the syslog server every three minutes while the inband
monitor is showing the server available. If the server goes down, it
will be polled every 5 seconds.

\begin{sphinxadmonition}{note}{Note:}
The purpose of the monitors is to reduce logging to the syslog server, which will
log the monitor request as they come in.  The inband monitor will use message traffic the monitor the syslog server without generating message traffic, but if the syslog server goes down the active monitor will return it to service much faster than the default inband timeout.
\end{sphinxadmonition}

Create a logging pool named \sphinxstylestrong{logging\_pool}, with the
\sphinxstylestrong{syslog\_inband}, \sphinxstylestrong{syslog\_active} monitors and the member
\sphinxstylestrong{10.1.20.252:514}.


\subsubsection{Configure the logging destinations}
\label{\detokenize{class6/module11/lab2:configure-the-logging-destinations}}
Remember at least two log destinations need to be created. The first one
will be the High Speed Logging (HSL) Destination where the messages will
be sent (the Logging\_Pool you just created) and the protocol that will be
used, TCP or UDP. The second Log Destination created will specify the
message format and the HSL Destination where formatted messages go too.


\paragraph{High Speed Logging (HSL) Log Destination}
\label{\detokenize{class6/module11/lab2:high-speed-logging-hsl-log-destination}}
First you will create a Log Destination to tell the BIG-IP where to send
the log messages and the protocol to use.

\begin{sphinxadmonition}{note}{Note:}
The reason we have to define an HSL destination is because the is no way to assign a protocol to a pool.
\end{sphinxadmonition}

Go to \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Configurations \textgreater{} Log Destinations} and create a
HSL destination named \sphinxstylestrong{hsl\_logging\_dest} of a type \sphinxstylestrong{Remote
High-Speed Log} and the pool name is \sphinxstylestrong{logging\_pool}


\paragraph{Formatted Log Destination}
\label{\detokenize{class6/module11/lab2:formatted-log-destination}}
This log destination will be used to format the log output. You are
sending the messages to a syslogng server, so you will want them in a
syslog format. You will send the formatted log events to the HSL Log
Destination you created earlier.

\sphinxstylestrong{In Logging Destinations} select \sphinxstylestrong{Create} and build a formatted
destination named \sphinxstylestrong{formatted\_dest} with a type of \sphinxstylestrong{Remote Syslog}
and with the \sphinxstylestrong{Syslog Format} of \sphinxstylestrong{Syslog} and the \sphinxstylestrong{High Speed Log
Destination} set to \sphinxstylestrong{hsl\_logging\_dest.}


\subsubsection{Log Publisher and Filtering Messages}
\label{\detokenize{class6/module11/lab2:log-publisher-and-filtering-messages}}
The log publisher is a way to associate individual or multiple log
destinations to a logging profile. In this case, any messages through
this publisher will go to local log files and the remote logs via
formatted\_dest.

Go to \sphinxstylestrong{System \textgreater{} Logs \textgreater{} Configurations \textgreater{} Log Publishers} and select
\sphinxstylestrong{Create}.

Name: \sphinxstylestrong{logging\_pub}

Destinations: Move \sphinxstylestrong{formatted\_dest} and \sphinxstylestrong{local-syslog} to the
\sphinxstylestrong{Selected} box.

Select \sphinxstylestrong{Finished} when done.

This step created a log publisher that will send Syslog formatted events
to a remote server, the local database, and the local syslog. Normally
you wouldn’t want to go to all three, but this is one way to show how BIG-IP can
send to multiple destinations for demonstration purposes. And while you can log everything off the BIG-IP you will probably want some local logging available, so you can log on to the BIG-IP and check events without going through the syslog server.


\paragraph{System Logging Filter}
\label{\detokenize{class6/module11/lab2:system-logging-filter}}
Now you will create a system logging filter. This will demonstrate how
we can log systems events off box, as well as on box. We do NOT want to
take the defaults as logging down to the debug level would cause the
BIG-IP to drop log messages and could fill up the log files to the point
where the BIG-IP runs out of disk space. You are going to send
informational messages from the MCPd daemon to the published
destinations.
\begin{description}
\item[{Go to \sphinxstylestrong{System \textgreater{} Log \textgreater{} Configuration \textgreater{} Log Filters} and select Create}] \leavevmode\begin{itemize}
\item {} 
Name: \sphinxstylestrong{my-mcpd-filter}

\item {} 
Severity: \sphinxstylestrong{Informational}

\item {} 
Source: \sphinxstylestrong{mcpd}

\item {} 
Log Publisher: \sphinxstylestrong{logging\_pub}

\end{itemize}

\end{description}


\subsubsection{Test your logging configuration}
\label{\detokenize{class6/module11/lab2:test-your-logging-configuration}}
Generate and view a \sphinxstylestrong{mcpd} event.

SSH to the syslog-ng server at \sphinxstylestrong{10.1.1.252} (credentials are \sphinxstylestrong{root/default})..

Watch the \sphinxstylestrong{bigip.log} syslog file for your events:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tail} \PYG{o}{\PYGZhy{}}\PYG{n}{f} \PYG{o}{/}\PYG{n}{var}\PYG{o}{/}\PYG{n}{log}\PYG{o}{/}\PYG{n}{syslog} \PYG{o}{\textbar{}} \PYG{n}{grep} \PYG{n}{bigip}
\end{sphinxVerbatim}

Go to \sphinxstylestrong{Local Traffic \textgreater{} Pools} and select the \sphinxstylestrong{www\_pool}. Disable
one of the pool members.

\sphinxstyleemphasis{Q1. Did you see messages on the syslog servers?}


\section{Appendix I - ANSWER KEY}
\label{\detokenize{class6/module12/module12:appendix-i-answer-key}}\label{\detokenize{class6/module12/module12::doc}}
The answer to life, the universe and everything:  42

The answers to the lab questions are below:


\subsection{Module - Basic Setup, TMSH and SNATs}
\label{\detokenize{class6/module12/lab1:module-basic-setup-tmsh-and-snats}}\label{\detokenize{class6/module12/lab1::doc}}

\subsubsection{Basic set up using TMSH}
\label{\detokenize{class6/module12/lab1:basic-set-up-using-tmsh}}

\paragraph{Open BIG-IP TMSH and TCPDump session}
\label{\detokenize{class6/module12/lab1:open-big-ip-tmsh-and-tcpdump-session}}
\sphinxstyleemphasis{Q1. In the} \sphinxstylestrong{Request Detail} \sphinxstyleemphasis{at the top of the page, what is the client
IP address and why?}

10.1.20.245, because you applied SNAT Auto Map to the www\_vs virtual
server and that is the self IP address on the server VLAN


\paragraph{SNAT Pools}
\label{\detokenize{class6/module12/lab1:snat-pools}}
\sphinxstyleemphasis{Q1. Do you see traffic destined for the FTP server? What is the source IP?}

Yes, monitor traffic is hitting the FTP server at 10.1.20.15 from source
IP 10.1.20.245 because monitors are serviced from the self IPs.

\sphinxstyleemphasis{Q2. Why might you require more than one IP address in the SNAT pool?}

When you have more than 65535 simultaneous connections. You should have
one IP address for every 65000 simultaneous connections or you may run
into port exhaustion.

\sphinxstyleemphasis{Q3. What is the client IP?}

10.1.20.249

\sphinxstyleemphasis{Q4. What are the ephemeral port numbers on your client-side source IP
and server-side source IP?}

They are the same ephemeral port numbers on your client-side source IP
and server-side source IP. BIG-IP will attempt to keep them the same if
the port is not already in use.


\paragraph{SNATs and NATs}
\label{\detokenize{class6/module12/lab1:snats-and-nats}}
\sphinxstyleemphasis{Q1. Did the command succeed?}

No, the LAMP sent the request to the BIG-IP, but has no access to the
client-side network.

\sphinxstyleemphasis{Q2. Did the dig work? What was the source IP?. Did the ping work? What
was the result?}

Yes, the source IP was 10.1.20.248. The ping did not work, Destination
Net Prohibited

\sphinxstyleemphasis{Q3. What happened when you try to FTP to the SNAT address?}

The BIG-IP sends a reset.

\sphinxstyleemphasis{Q4. When you attempted to FTP and ping 10.1.10.15 and access 10.1.20.15
behind the BIG-IP were you successful?}

Yes, you should be able to FTP and ping to 10.1.20.15.


\subsection{Module - Profiles}
\label{\detokenize{class6/module12/lab1:module-profiles}}

\subsubsection{Working with Profiles}
\label{\detokenize{class6/module12/lab1:working-with-profiles}}

\paragraph{Working with profiles}
\label{\detokenize{class6/module12/lab1:id1}}
\sphinxstyleemphasis{Q1. Did site work? Why didn’t you need to SNAT? Did you need SSL
profiles?}

Yes, you didn’t need to SNAT because you put the servers default gateway
on the BIG-IP (routed mode), you didn’t need SSL profiles because the
client created an SSL session directly with the backend server.

\sphinxstyleemphasis{Q2. Could you use L7 iRules or profiles to view or modify the request or
response? Why or why not?}

No, because the session was encrypted through the proxy. Had this been
unencrypted you would have seen the HTTP request and response in the
tcpdumps.

\sphinxstyleemphasis{Q3. Did site work? Why not?}

SSL connection error, you could not establish a SSL session directly to
the backend servers because they don’t support HTTPS.

\sphinxstyleemphasis{Q4. Did site work? What did you observe in the TCPDUMPs? Did you need an
HTTP profile?}

Yes, the tcpdumps show the client-side connection was encrypted and the
serve-side connection was not encrypted. The HTTP profile is not
required for SSL profiles to work, their at a different layer in the
stack.

\sphinxstyleemphasis{Q5. Did it work? What was needed to add cookie persistence?}

Yes, after you added the http profile to break out the http (L7)
request/response sequence.

\sphinxstyleemphasis{Q6. What nodes do the pictures come from? What is the name of the cookie
inserted begin with?}

All the images came from the same node. The cookie starts with
BIGipServerwww\_pool

\sphinxstyleemphasis{Q5. Did site work?}

No, the BIG-IP was sending unencrypted request to encrypted servers.

\sphinxstyleemphasis{Q6. What profile was needed to correct the error?}

Server side ssl profile


\subsubsection{Application Acceleration}
\label{\detokenize{class6/module12/lab1:application-acceleration}}

\paragraph{TCP Express}
\label{\detokenize{class6/module12/lab1:tcp-express}}
\sphinxstyleemphasis{Q1. What is the idle timeout in each profile? Why might you want to
change it?}

300 second, for long term connections, such as telnet, ssh or ftp

\sphinxstyleemphasis{Q2. What is the Nagle selection in the tcp-wan-optimized? Why might you
want to change it?}

Nagle combines smaller packets into a larger packet for efficiency. It
the application relays on small packets for connection information,
Nagle may cause connection delays.

\sphinxstyleemphasis{Q3. What happens if you increase the proxy buffer sizes?}

You will use more memory per connection, for all connections using that
TCP profile.


\paragraph{HTTP Optimization - RamCache Lab}
\label{\detokenize{class6/module12/lab1:http-optimization-ramcache-lab}}
\sphinxstyleemphasis{Q1. What resource would be consumed if you increased the} \sphinxstylestrong{Cache Size}
\sphinxstyleemphasis{setting?}

More memory, per virtual server the caching profile was attached too.

\sphinxstyleemphasis{Q2. The pictures do not change. Why do you think that is?}

They are being pulled from cache.

\sphinxstyleemphasis{Q3. Go to your pool. Are all pool members taking connections?}

Yes, there are still uncacheable items to be retrieved.


\paragraph{HTTP Optimization - HTTP Compression Lab}
\label{\detokenize{class6/module12/lab1:http-optimization-http-compression-lab}}
\sphinxstyleemphasis{Q1. Does the browser accept compression?}

Yes, in the Request Headers you find Accept-Encoding: gzip, deflate.

\sphinxstyleemphasis{Q2. At what point would the BIG-IP quit compressing responses?}

When it hits 90\% CPU


\paragraph{Securing web applications with the HTTP profile}
\label{\detokenize{class6/module12/lab1:securing-web-applications-with-the-http-profile}}
\sphinxstyleemphasis{Q1. What is the cookie name? Note the information after the cookie.}

BIGipServerwww\_pool

\sphinxstyleemphasis{Q2. What is in the X-Forwarded-For header? Why might you want to enable it?}

It place the original client IP in the HTTP header. It is useful for
virtual servers with SNAT if the original client IP is needed for
logging or other purposes.

\sphinxstyleemphasis{Q3. Are they the same? What is different?}

No, the server information has be removed from the response coming from
the secure\_vs

\sphinxstyleemphasis{Q4. What is the result?}

Redirected to www.f5.com.

\sphinxstyleemphasis{Q5. What is different from the cookie at the start of the task?}

Everything after the = sign as been encrytped


\subsection{Module - Application Visibilty and Reporting (AVR)}
\label{\detokenize{class6/module12/lab1:module-application-visibilty-and-reporting-avr}}

\subsubsection{Working with Analytics (AVR)}
\label{\detokenize{class6/module12/lab1:working-with-analytics-avr}}

\paragraph{AVR Lab Setup - Verify provisioning, iRules and Data Group}
\label{\detokenize{class6/module12/lab1:avr-lab-setup-verify-provisioning-irules-and-data-group}}
\sphinxstyleemphasis{Q1. What resources does AVR require to be provisioned?}

16 gb of disks outside of the boot volume and 448mb of memory

\sphinxstyleemphasis{Q2. Review the iRule, what profiles are required on the virtual server?}

tcp and http

\sphinxstyleemphasis{Q3. Review the iRule, what profiles are required on the virtual server?}

tcp and http


\paragraph{View the Analytics Reports}
\label{\detokenize{class6/module12/lab1:view-the-analytics-reports}}
\sphinxstyleemphasis{Q1. What country has the most transactions?}

Usually the majority of the requests are coming from the United States.

\sphinxstyleemphasis{Q2. What are the top two User Agents?}

A majority of the requests should be from Internet Explorer v11 and
iPhone6 users, but it’s not guaranteed due to the randomness of the
iRule.


\subsection{Module - Monitors and Status}
\label{\detokenize{class6/module12/lab1:module-monitors-and-status}}

\subsubsection{Basic Monitoring}
\label{\detokenize{class6/module12/lab1:basic-monitoring}}

\paragraph{Default Monitors}
\label{\detokenize{class6/module12/lab1:default-monitors}}
\sphinxstyleemphasis{Q1. What would happen if a node failed?}

The pool members with the node IP address would be marked offline.

\sphinxstyleemphasis{Q2. What are your node statuses?}

Available


\paragraph{Task 2 - Content Monitors}
\label{\detokenize{class6/module12/lab1:task-2-content-monitors}}
\sphinxstyleemphasis{Q1. What is the status of the pool and its members?}

Available

\sphinxstyleemphasis{Q2. Go to} \sphinxstylestrong{Virtual Servers} \sphinxstyleemphasis{or} \sphinxstylestrong{Network Map} \sphinxstyleemphasis{, what is the status of
your virtual server?}

Available

\sphinxstyleemphasis{Q3. What is status of your pool and virtual server now?}

Both the pool and virtual servers dependent on the pool are mark
offline.


\subsubsection{Virtual Server Status}
\label{\detokenize{class6/module12/lab1:virtual-server-status}}

\paragraph{Test Disabled Virtual Servers}
\label{\detokenize{class6/module12/lab1:test-disabled-virtual-servers}}
\sphinxstyleemphasis{Q1. What is the Availability of} \sphinxstylestrong{www\_vs}? \sphinxstyleemphasis{What is the State?}

Availability: available, State: disabled

\sphinxstyleemphasis{Q2. What symbol is used to represent} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{status?}

Black Circle

\sphinxstyleemphasis{Q3. Would you expect browsing to http://10.1.10.100 to work?}

no

\sphinxstyleemphasis{Q4. Can you ping the virtual IP?}

Yes, the virtual address still responds to pings

\sphinxstyleemphasis{Q5. Did the site work? What did the tcpdump show?}

No, the tcpdump showed the virtual server 10.1.10.100:80 responding to
SYNs with Resets

\sphinxstyleemphasis{Q6. Did statistics counters for any virtual increment?}

No

\sphinxstyleemphasis{Q7. Why do you think the} \sphinxstylestrong{wildcard\_vs} \sphinxstyleemphasis{didn’t pick up the packets?}

www\_vs was the most specific virtual server so it responded. That
response was to reset the connection.

\sphinxstyleemphasis{Q8. What symbol is used to represent} \sphinxstylestrong{wildcard\_vs}? \sphinxstyleemphasis{Why is symbol a
square?}

The status symbol is a black square. Black because the virtual server
was administratively disabled and square because there is no monitor and
the state is Unknown

\sphinxstyleemphasis{Q9. What is the Reason given for current state?}

The children pool member(s) either don’t have service checking enabled,
or service check results are not available yet. Availability: unknown
State: disabled

\sphinxstyleemphasis{Q10. Does ftp session still work? Why?}

Disabling a configuration item (node, pool or virtual server) does not
affect existing connections.

\sphinxstyleemphasis{Q11. Did new ftp session establish connection? Why not?}

No, a disabled virtual server will not process new connections.


\paragraph{Virtual Server Connection Limits and Status}
\label{\detokenize{class6/module12/lab1:virtual-server-connection-limits-and-status}}
\sphinxstyleemphasis{Q1. Does ftp session work?}

Yes

\sphinxstyleemphasis{Q2. What is the virtual server status of} \sphinxstylestrong{ftp\_vs}?

Yellow Triangle - Availability: unavailable - State: enabled

\sphinxstyleemphasis{Q3. Did new ftp session establish connection? Why not?}

No, the virtual server’s connection limit has been reached.

\sphinxstyleemphasis{Q4. Did tcpdump capture a connection reset?}

Yes, tcpdump had \sphinxstylestrong{R} resets returning from the virtual server.


\subsubsection{Pool Member and Virtual Servers}
\label{\detokenize{class6/module12/lab1:pool-member-and-virtual-servers}}

\paragraph{Effects of Monitors on Members, Pools and Virtual Servers}
\label{\detokenize{class6/module12/lab1:effects-of-monitors-on-members-pools-and-virtual-servers}}
\sphinxstyleemphasis{Q1. Since the} \sphinxstylestrong{mysql\_monitor} \sphinxstyleemphasis{will fail, how long will it take to
mark the pool offline?}

60 seconds, the monitor will have to fail 4 times at 15 second intervals
before it exceeds the 46 second timeout value.

\sphinxstyleemphasis{Q2. What is the icon and status of} \sphinxstylestrong{www\_vs}?

Red Diamond - Availability: offline - State: enabled - The children pool
member(s) are down

\sphinxstyleemphasis{Q3. What is the icon and status of} \sphinxstylestrong{www\_pool}?

Red Diamond - Availability: offline - State: enabled - The children pool
member(s) are down

\sphinxstyleemphasis{Q4. What is the icon and status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members?}

Red Diamond - Availability: offline - State: enabled - Pool member has
been marked down by a monitor

\sphinxstyleemphasis{Q5. Does pool configuration have an effect on virtual server status?}

Yes, the status of the pool members can affect the status of the virtual
server.

\sphinxstyleemphasis{Q6. What is the icon and status of www\_vs?}

Black Diamond - Availability: offline - State: disabled - The children
pool member(s) are down

\sphinxstyleemphasis{Q7. Did traffic counters increment for} \sphinxstylestrong{www\_vs}?

No

\sphinxstyleemphasis{Q8. What is the difference in the tcpdumps between Offline (Disabled) vs
Offline (Enabled)?}

Offline (Disabled) - immediate connection reset, you will see no virtual
server statistics.

Offline (Enabled) - initial connection accepted then reset - vs stats
incremented


\paragraph{More on status and member specific monitors}
\label{\detokenize{class6/module12/lab1:more-on-status-and-member-specific-monitors}}
\sphinxstyleemphasis{Q1. What is the status of the Pool Member and the monitors assigned to it?}

Red Diamond - Red Diamond - Availability: offline - State: enabled -
Pool member has been marked down by a monitor

http - Green Circle, mysql\_monitor - Red Diamond

\sphinxstyleemphasis{Q2. What is the status of} \sphinxstylestrong{www\_vs}, \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and the pool
members? Why?}

Green, Green, Red, Red, Green. One pool member available, marks the pool
available and since the pool is available, the virtual server is
available

\sphinxstyleemphasis{Q3. Did the site work?}

Yes

\sphinxstyleemphasis{Q4. Which} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{members was traffic sent to?}

Traffic was distributed to available pool members.


\subsubsection{Extended Application Verification (EAV)}
\label{\detokenize{class6/module12/lab1:extended-application-verification-eav}}

\paragraph{Create an EAV monitor}
\label{\detokenize{class6/module12/lab1:create-an-eav-monitor}}
\sphinxstyleemphasis{Q1. What was the stdout output? Did this indicate the member was Available?}

UP, indicating the member was Availble

\sphinxstyleemphasis{Q2. Are your members up? What would happen if the external monitor
returned “DOWN”}

Yes, the same would be true if DOWN was returned, any stdout output is
consider good status


\subsubsection{Inband Monitors}
\label{\detokenize{class6/module12/lab1:inband-monitors}}
\sphinxstyleemphasis{Q1. What is the status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and} \sphinxstylestrong{www\_vs} \sphinxstyleemphasis{objects? Is
the web site accessible? Why?}

Unchecked (blue square), Yes, because Uncheck simply mean the status in
unknown and is always assumed to be availale.

\sphinxstyleemphasis{Q2. What are the status of} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{and} \sphinxstylestrong{www\_vs}? \sphinxstyleemphasis{Can you access
the web site?}

Available, Yes

\sphinxstyleemphasis{Q3. Why is the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{still showing up?}

Because there hasn’t been any client traffic to trigger the inband
monitor.

\sphinxstyleemphasis{Q4. What is the status of the} \sphinxstylestrong{www\_pool} \sphinxstyleemphasis{now?}

Offline

\sphinxstyleemphasis{Q5. What are the pool statuses and why?}

Offline, regardless of client traffic the BIG-IP will not attempt a
connection to the offline pool members for 300 seconds

\sphinxstyleemphasis{Q6. How often to you see monitor traffic to the} \sphinxstylestrong{www\_pool}?

Once a minute

\sphinxstyleemphasis{Q7. How often to you see monitor traffic to the} \sphinxstylestrong{www\_pool}?

Every 5 seconds

\sphinxstyleemphasis{Q8. Did the www\_pool come up within 30 seconds without client traffic?
What did the tcpdump show?}

Yes, the active monitor marked the pool up after 6 consecutive
successful monitor attempts.

The tcpdump show the monitor executing every 5 seconds until the members
were marked Available then it slowed to every 60 seconds.


\subsection{Module - SSL}
\label{\detokenize{class6/module12/lab1:module-ssl}}

\subsubsection{SSL Certificates and Profiles}
\label{\detokenize{class6/module12/lab1:ssl-certificates-and-profiles}}

\paragraph{Importing Certs and Key}
\label{\detokenize{class6/module12/lab1:importing-certs-and-key}}
\sphinxstyleemphasis{Q1. What is the common name of your imported certificate and when does
it expire?}

Linux32server1.f5se.com, Jun 16, 2020


\paragraph{SSL Profile and Virtual Servers}
\label{\detokenize{class6/module12/lab1:ssl-profile-and-virtual-servers}}
\sphinxstyleemphasis{Q1. Did it work?}

Yes


\subsection{Module - Virtual Servers and Packet Processing Review}
\label{\detokenize{class6/module12/lab1:module-virtual-servers-and-packet-processing-review}}

\subsubsection{Lab Preparation and Packet Processing}
\label{\detokenize{class6/module12/lab1:lab-preparation-and-packet-processing}}

\paragraph{Open BIG-IP TMSH and TCPDump session}
\label{\detokenize{class6/module12/lab1:id2}}
\sphinxstyleemphasis{Q1. Why are ssh sessions not displayed in connection table?}

\sphinxstylestrong{tmsh show sys connections} displays connections on the TMOS data plane.
SSH connections are established to out-of-band management interface and
thus not seen.


\paragraph{Establish ftp connection}
\label{\detokenize{class6/module12/lab1:establish-ftp-connection}}
\sphinxstyleemphasis{Q1. In the tcpdump above, what is client IP address and port and the
server IP address port?}

10.1.10.51:60603 and 10.1.10.20:21 (FTP)

\begin{sphinxadmonition}{note}{Note:}
60603 is an ephemeral port, your port will probably be differenr.  BIG-IP will attempt to use the same ephemeral port on the server-side connection, if the port is available.
\end{sphinxadmonition}

\sphinxstyleemphasis{Q2. What is source ip and port as seen by ftp server in the example
above?}

Source IP: 10.1.20.249 Source Port: \textless{}it should be the same as the client ephemeral port\textgreater{}

\sphinxstyleemphasis{Q3. What happened to the original client IP address and where did
10.1.20.249 come from?}

The virtual server was configured to do source address translation using
the SNAT Pool, SNAT249\_pool. Reviewing the configuration of
SNAT249\_pool shows it was configured with IP address 10.1.20.249.


\subsubsection{Packet Filters}
\label{\detokenize{class6/module12/lab1:packet-filters}}

\paragraph{Test the FTP packet filter}
\label{\detokenize{class6/module12/lab1:test-the-ftp-packet-filter}}
\sphinxstyleemphasis{Q1. Was the existing ftp connection in the connection table affected?
Why?}

The FTP connection is not affected because adding packet filter does not
impact established connections.

\sphinxstyleemphasis{Q2. Was ftp connection successful? Why?}

The attempt to establish a new FTP connection was blocked, because the
packet filter rule applies to all new connection attempts

\sphinxstyleemphasis{Q3. What did tcpdump reveal? Connection timeout or reset?}

Tcpdump revealed multiple “S” (syn) attempts without receiving ack or reset. This
is indicating a connection timeout.

\sphinxstyleemphasis{Q4. What did virtual server statistics for ftp20\_vs reveal? Why are
counters not incrementing?}

VS stats shows no new connection attempts because Filter is applied
before VS in order of processing

\sphinxstyleemphasis{Q5. Prioritize the packet processing order:}

Virtual Server \sphinxstylestrong{3} SNAT \sphinxstylestrong{4} AFM/Pkt Filter \sphinxstylestrong{2} NAT \sphinxstylestrong{5} Existing
Connections \sphinxstylestrong{1} Self IP \sphinxstylestrong{6} Drop \sphinxstylestrong{7}


\subsubsection{Virtual Server Packet Processing}
\label{\detokenize{class6/module12/lab1:virtual-server-packet-processing}}

\paragraph{Testing Virtual Server Packet Processing Behavior}
\label{\detokenize{class6/module12/lab1:testing-virtual-server-packet-processing-behavior}}
\sphinxstyleemphasis{Q1. Which VS is used for web traffic over port 8080?}

wildcard\_vs

\sphinxstyleemphasis{Q2. Which VS is used for ftp traffic?}

ftp\_vs

\sphinxstyleemphasis{Q3. Which VS is used for web traffic over the default HTTP port? Which
port was used?}

www\_vs port 80

\sphinxstyleemphasis{Q4. Which VS is used for web traffic?}

\sphinxstylestrong{wildcard\_vs}


\subsubsection{IP Forwarding Virtual Servers}
\label{\detokenize{class6/module12/lab1:ip-forwarding-virtual-servers}}

\paragraph{Forwarding Virtual Server}
\label{\detokenize{class6/module12/lab1:forwarding-virtual-server}}
\sphinxstyleemphasis{Q1. What happens if we don’t change the Protocol from TCP?}

Only TCP will be allowed through, things like ICMP and UDP will be
blocked

\sphinxstyleemphasis{Q2. What is the status of your new virtual server? Why?}

Unchecked (blue square) because there is nothing to monitor.


\paragraph{More on Transparent Virtual Servers}
\label{\detokenize{class6/module12/lab1:more-on-transparent-virtual-servers}}
\sphinxstyleemphasis{Q1. Why did we use gateway\_icmp? What other kind of monitor could we
have used?}

Because there isn’t a port on the pool member, you could have used a
transparent monitor to assign a L7 content monitor to check a specific
port.

\sphinxstyleemphasis{Q2. Did it work? What were the image results?}

Yes, images came from nodes 4 and 5.

\sphinxstyleemphasis{Q3. Did it work?}

dig @10.1.20.12 hackazon.f5demo.com

\sphinxstyleemphasis{Q4. Did it work? Why not and how would you fix it?}

No, because it is a UDP protocol and a TCP profile is on the virtual
server. You could do a wildcard for the protocols and then it would work
or create a UDP transparent virtual.


\subsection{Module - Load Balancing and Pools}
\label{\detokenize{class6/module12/lab1:module-load-balancing-and-pools}}

\subsubsection{Load Balancing}
\label{\detokenize{class6/module12/lab1:load-balancing}}

\paragraph{Ratio Load Balancing}
\label{\detokenize{class6/module12/lab1:ratio-load-balancing}}
\sphinxstyleemphasis{Q1. What is the difference between Node and Member?}

Member is based on the connections for each pool member within a single
pool only, while Node takes into account all the connections an IP
address has across all pools it is a member of.

\sphinxstyleemphasis{Q2. How many Total connections has each member taken? Is the ratio of
connections correct?}

Yes, the pool member with a Ratio of 3 took 3 times the number of
connections

\sphinxstyleemphasis{Q3. Does the ratio setting have any impact now?}

No, the pool member ratios only have an effect if Ratio load balancing
is selected.


\paragraph{Priority Groups Lab}
\label{\detokenize{class6/module12/lab1:priority-groups-lab}}
\sphinxstyleemphasis{Q1. Are all members taking connections? Which member isnt taking
connections?}

No, 10.1.20.13:80 in the low priority group is not taking connections.

\sphinxstyleemphasis{Q2. Is the lower priority group activated and taking connections?}

Yes, 10.1.20.13:80 in the low priority group is now taking connections.


\subsubsection{Simple (Source Address) Persistence}
\label{\detokenize{class6/module12/lab1:simple-source-address-persistence}}
\sphinxstyleemphasis{Q1. How many members are taking traffic?}

Only, one member is taking traffic

\sphinxstyleemphasis{Q2. Check you Persists Records window, are the any persistence records?}

Yes

\sphinxstyleemphasis{Q3. Refresh you web page prior to the Age column reaching 120. What
happens?}

The timer resets.

\sphinxstyleemphasis{Q4. Could you access the web site? Why?}

Yes, when a member is disabled, new connections can still be built to
it, if it there is a persist record pointing to it.

\sphinxstyleemphasis{Q5. Could you access the web site? Why?}

Force Offline only allows existing connections to be maintain, regardless
of persistence records.


\subsection{Module - Networking}
\label{\detokenize{class6/module12/lab1:module-networking}}

\subsubsection{Self IP Port Lockdown and more}
\label{\detokenize{class6/module12/lab1:self-ip-port-lockdown-and-more}}

\paragraph{Effects of Port Lockdown}
\label{\detokenize{class6/module12/lab1:effects-of-port-lockdown}}
\sphinxstyleemphasis{Q1. Was echo response received?}

Ping reply successful

\sphinxstyleemphasis{Q2. Was ssh successful? Why not?}

No. Port lockdown set to \sphinxstylestrong{Allow None} by default

\sphinxstyleemphasis{Q3. Did SSH work? Did browsing work?}

Yes to SSH and No to browsing.

\sphinxstyleemphasis{Q4. What other ports are opened when you select} \sphinxstylestrong{Allow Defaults}?

From the bigip.conf:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ospf}
\PYG{n}{tcp} \PYG{o}{\PYGZhy{}} \PYG{n}{snmp} \PYG{p}{(}\PYG{l+m+mi}{161}\PYG{p}{)}\PYG{p}{,} \PYG{n}{ssh} \PYG{p}{(}\PYG{l+m+mi}{22}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{4353} \PYG{p}{(}\PYG{n}{iquery}\PYG{o}{/}\PYG{n}{configsync}\PYG{p}{)}\PYG{p}{,} \PYG{n}{https} \PYG{p}{(}\PYG{l+m+mi}{443}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dns} \PYG{p}{(}\PYG{l+m+mi}{53}\PYG{p}{)}
\PYG{n}{udp} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{1026} \PYG{p}{(}\PYG{n}{Network} \PYG{n}{failover}\PYG{p}{)}\PYG{p}{,} \PYG{n}{snmp} \PYG{p}{(}\PYG{l+m+mi}{161}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{4353} \PYG{p}{(}\PYG{n}{iquery}\PYG{o}{/}\PYG{n}{configsync}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{520}\PYG{p}{,} \PYG{n}{dns} \PYG{p}{(}\PYG{l+m+mi}{53}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Q5. Did SSH work? Did browsing work?}

Yes to SSH and No to browsing.


\subsection{Module - Roles and Partitions}
\label{\detokenize{class6/module12/lab1:module-roles-and-partitions}}

\subsubsection{Roles and Partitions}
\label{\detokenize{class6/module12/lab1:roles-and-partitions}}

\paragraph{Create and place a user in a partition}
\label{\detokenize{class6/module12/lab1:create-and-place-a-user-in-a-partition}}
\sphinxstyleemphasis{Q1. In the upper right of the BIG-IP WebUI what partition are you in?}

test\_partition

\sphinxstyleemphasis{Q2. Do you see the} \sphinxstylestrong{test\_vs} \sphinxstyleemphasis{just created?}

No

\sphinxstyleemphasis{Q3. Do you see your change? Is your change permanent?}

Yes, but configuration changes made in tmsh are not permanent until
written to disk (save sys config) or a change is made in the GUI.
Changes made in the GUI are push into memory and written to disk.

\sphinxstyleemphasis{Q4. Did you find it in /config/bigip.conf?}

No

\sphinxstyleemphasis{Q5. Did you find your virtual server? Is the tmsh change you made in
there?}

Yes, but the new description isn’t there.

\sphinxstyleemphasis{Q6. Do you see the change now?}

Yes

\sphinxstyleemphasis{Q7. Where you able to?}

No, you were kicked off the BIG-IP SSH session


\subsubsection{Remote Authentication}
\label{\detokenize{class6/module12/lab1:remote-authentication}}

\paragraph{Authenticate against LDAP}
\label{\detokenize{class6/module12/lab1:authenticate-against-ldap}}
\sphinxstyleemphasis{Q1. Were you successful?}

Yes, well at least you should have been.

\sphinxstyleemphasis{Q2. Were you successful?}

No, local accounts aside admin are disabled when using remote
authentication.


\subsection{Module - Device Service Clusters and High Availability}
\label{\detokenize{class6/module12/lab1:module-device-service-clusters-and-high-availability}}

\subsubsection{Building a DSC (Device Service Cluster)}
\label{\detokenize{class6/module12/lab1:building-a-dsc-device-service-cluster}}

\paragraph{Base Networking and HA VLAN}
\label{\detokenize{class6/module12/lab1:base-networking-and-ha-vlan}}
\sphinxstyleemphasis{Q1. What is the status your BIG-IPs?}

Both are Active


\paragraph{Prepare each BIG-IP for High Availability}
\label{\detokenize{class6/module12/lab1:prepare-each-big-ip-for-high-availability}}
\sphinxstyleemphasis{Q1. If you were to add multiple IP addresses to the Failover Unicast, when
would the BIG-IP failover?}

Only after the network polls for all the IP addresses failed.


\paragraph{Build the Device Trust and Device Group}
\label{\detokenize{class6/module12/lab1:build-the-device-trust-and-device-group}}
\sphinxstyleemphasis{Q1. Is all the information there?}

Yes

\sphinxstyleemphasis{Q2. What are the statuses of your BIG-IPs now?}

Active In Sync

\sphinxstyleemphasis{Q3. Did you have to create the Device Group on the other BIG-IP?}

No, It was created automatically

\sphinxstyleemphasis{Q4. Is the full configuration synchronized yet?}

No. Only the Device Group is synced

\sphinxstyleemphasis{Q5. What is the status and sync status on the BIG-IPs?}

It should be Awaiting Initial Sync. Once BIG-IP is Active, the other is
Standby. There is no guarantee which BIG-IP will be the Active BIG-IP
when the device group is created.

\sphinxstyleemphasis{Q6. Did the configuration synchronize? What, if any, errors do you see?}

No, there was an error message on bigip02 indicating it could not load
avr\_virtual2 because of iRule dependencies. Which was why you created
that virtual first in the AVR lab.

\sphinxstyleemphasis{Q7. Any issue with that?}

Yes, avr\_virtual2 has dependencies.

\sphinxstyleemphasis{Q8. What is the sync status of bigip02 once you made the change?}

Changes Pending

\sphinxstyleemphasis{Q9. Are the BIG-IPs In Sync? Are the configurations the same?}

Yes and Yes

Browse to \sphinxurl{http://10.1.10.100}

\sphinxstyleemphasis{Q10. Could you access the site? Which BIG-IP passed the traffic?}

Yes, the Active BIG-IP. You can tell because the virtual server is using SNAT Auto
Map and the source IP is selfIP address of the active device.


\subsubsection{Failover and Mirroring}
\label{\detokenize{class6/module12/lab1:failover-and-mirroring}}

\paragraph{Testing Failover}
\label{\detokenize{class6/module12/lab1:testing-failover}}
\sphinxstyleemphasis{Q1. What is the source IP in the} \sphinxstylestrong{Request Details}?

10.1.20.246

\sphinxstyleemphasis{Q2. What happened? Why?}

Site couldn’t be reached. The secure\_vs server does not use SNATs. The
secure\_pool servers use the default gateway, 10.1.20.240, you built as
a self IP on bigip01.

\sphinxstyleemphasis{Q3. Did the site work? What was the client IP? Why?}

Yes, 10.1.10.51 because SNAT Auto Map is not configured on this virtual server and the pool member uses the floating IP as a default gateway.

\sphinxstyleemphasis{Q4. What was the client IP address that the server saw (under} \sphinxstylestrong{Request
Details} \sphinxstyleemphasis{on the main page)? Why?}

It should be 10.1.20.240. www\_vs uses SNAT automap. The BIG-IP will
always use the floating IP for the SNAT if available. If you exceed
64000 simultaneous connection, the BIG-IP then uses the non-floating self
IP, but you probably should have created a SNAT pool, since you cannot mirror
SNAT connections on non-floating self IPs.

\sphinxstyleemphasis{Q5. Does http://10.1.10.115 still work? What is the client IP?}

Yes, 10.1.10.51


\paragraph{Mirroring}
\label{\detokenize{class6/module12/lab1:mirroring}}
\sphinxstyleemphasis{Q1. Do you have a persistence record on each BIG-IP? What would happen
if you did a failover?}

No, only the Active unit had persistence records, upon failover
persistence would be lost.

\sphinxstyleemphasis{Q2. If you had persistence records existing prior to mirroring would
they appear on the standby box?}

No, BIG-IP only mirrors records created after mirroring is enabled.
Also, upon failover, the new Active BIG-IP will only mirror records
created after it became active.

\sphinxstyleemphasis{Q3. Did you persist to the correct pool member? What is the client IP?}

Yes, 10.1.10.240


\subsubsection{Traffic Groups}
\label{\detokenize{class6/module12/lab1:traffic-groups}}

\paragraph{Build a New Traffic Group}
\label{\detokenize{class6/module12/lab1:build-a-new-traffic-group}}
\sphinxstyleemphasis{Q1. When you did this, what other virtual servers were assign to tg-2?}

ftp\_vs

\sphinxstyleemphasis{Q2. What are the states of you BIG-IPs?}

Active-Active

\sphinxstyleemphasis{Q3. Did the web site work? What was the client IP? Did ftp work? Why or
why not?}

Yes the web site work, the client IP was 10.1.20.245 SNAT because the
10.1.20.240 address is not part of the tg-2. The ftp site did NOT work
because it’s SNAT pool IP is not part of the tg-2 traffic group

\sphinxstyleemphasis{Q4. Did it work now?}

Yes, if you made the change on the active device for tg-2. If not,
synchronize and try again


\subsection{Module - Security and Securing the BIG-IP}
\label{\detokenize{class6/module12/lab1:module-security-and-securing-the-big-ip}}

\subsubsection{More Security Features}
\label{\detokenize{class6/module12/lab1:more-security-features}}

\paragraph{Configure Audit Logging}
\label{\detokenize{class6/module12/lab1:configure-audit-logging}}
\sphinxstyleemphasis{Q1. Do you see when adminuser logged on? Do you see the change made in
the audit log?}

Yes, to both.


\paragraph{Limiting SSH access to the BIG-IP}
\label{\detokenize{class6/module12/lab1:limiting-ssh-access-to-the-big-ip}}
\sphinxstyleemphasis{Q1. Does existing an SSH window still work? Does a new SSH work?}

Existing SSH session worked. New ssh sessions could not be establish for
the jumpbox source IPs.

\sphinxstyleemphasis{Q2. Were new ssh sessions established?}

Yes, to 10.1.1.245, No, to 10.1.10.245 (the source IP for that would be
10.1.10.51)


\subsubsection{BIG-IP Remote Logging}
\label{\detokenize{class6/module12/lab1:big-ip-remote-logging}}

\paragraph{Test your logging configuration}
\label{\detokenize{class6/module12/lab1:test-your-logging-configuration}}
\sphinxstyleemphasis{Q1. Did you see messages on the syslog servers?}

You saw and audit message and in the bigip.log:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{bigip01}\PYG{o}{.}\PYG{n}{f5demo}\PYG{o}{.}\PYG{n}{com} \PYG{n}{mcpd}\PYG{p}{[}\PYG{l+m+mi}{7702}\PYG{p}{]} \PYG{n}{Pool} \PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{n}{www\PYGZus{}pool} \PYG{n}{member}\PYG{o}{/}\PYG{n}{Common}\PYG{o}{/}\PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.13}\PYG{p}{:}\PYG{l+m+mi}{80} \PYG{n}{session}   \PYG{n}{status} \PYG{n}{forced} \PYG{n}{disable}
\end{sphinxVerbatim}


\section{Appendix II - TMSH commands for Module 3.1}
\label{\detokenize{class6/module13/module13:appendix-ii-tmsh-commands-for-module-3-1}}\label{\detokenize{class6/module13/module13::doc}}
Estimated completion time: \sphinxstylestrong{30 minutes}


\subsection{TMSH Commands}
\label{\detokenize{class6/module13/lab1:tmsh-commands}}\label{\detokenize{class6/module13/lab1::doc}}
Cut and paste these commands at the TMSH prompt \sphinxstylestrong{(tmos)\#}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} bigip01}
\PYG{c+c1}{\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{} Client\PYGZhy{}side networking}
\PYG{n}{create} \PYG{n}{net} \PYG{n}{vlan} \PYG{n}{client\PYGZus{}vlan} \PYG{n}{interfaces} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mf}{1.1} \PYG{p}{\PYGZob{}} \PYG{n}{untagged} \PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZcb{}}
\PYG{n}{create} \PYG{n}{net} \PYG{n+nb+bp}{self} \PYG{n}{client\PYGZus{}ip} \PYG{n}{address} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.245}\PYG{o}{/}\PYG{l+m+mi}{24} \PYG{n}{vlan} \PYG{n}{client\PYGZus{}vlan}

\PYG{c+c1}{\PYGZsh{} Server\PYGZhy{}side networking}
\PYG{n}{create} \PYG{n}{net} \PYG{n}{vlan} \PYG{n}{server\PYGZus{}vlan} \PYG{n}{interfaces} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mf}{1.2} \PYG{p}{\PYGZob{}} \PYG{n}{untagged} \PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZcb{}}
\PYG{n}{create} \PYG{n}{net} \PYG{n+nb+bp}{self} \PYG{n}{server\PYGZus{}ip} \PYG{n}{address} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.245}\PYG{o}{/}\PYG{l+m+mi}{24} \PYG{n}{vlan} \PYG{n}{server\PYGZus{}vlan}

\PYG{c+c1}{\PYGZsh{} Default route}
\PYG{n}{create} \PYG{n}{net} \PYG{n}{route} \PYG{n}{def\PYGZus{}gw} \PYG{n}{network} \PYG{l+m+mf}{0.0}\PYG{o}{.}\PYG{l+m+mf}{0.0}\PYG{o}{/}\PYG{l+m+mi}{0} \PYG{n}{gw} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.1}

\PYG{c+c1}{\PYGZsh{} Pool and Virtual Server v11.5.3}
\PYG{n}{create} \PYG{n}{ltm} \PYG{n}{pool} \PYG{n}{www\PYGZus{}pool} \PYG{n}{members} \PYG{n}{add} \PYG{p}{\PYGZob{}} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.11}\PYG{p}{:}\PYG{l+m+mi}{80} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.12}\PYG{p}{:}\PYG{l+m+mi}{80} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{20.13}\PYG{p}{:}\PYG{l+m+mi}{80} \PYG{p}{\PYGZcb{}} \PYG{n}{monitor} \PYG{n}{http}
\PYG{n}{create} \PYG{n}{ltm} \PYG{n}{virtual} \PYG{n}{www\PYGZus{}vs} \PYG{n}{destination} \PYG{l+m+mf}{10.1}\PYG{o}{.}\PYG{l+m+mf}{10.100}\PYG{p}{:}\PYG{l+m+mi}{80} \PYG{n}{pool} \PYG{n}{www\PYGZus{}pool} \PYG{n}{ip}\PYG{o}{\PYGZhy{}}\PYG{n}{protocol} \PYG{n}{tcp} \PYG{n}{source}\PYG{o}{\PYGZhy{}}\PYG{n}{address}\PYG{o}{\PYGZhy{}}\PYG{n}{translation} \PYG{p}{\PYGZob{}} \PYG{n+nb}{type} \PYG{n}{automap} \PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Write changes to disk}
\PYG{n}{save} \PYG{n}{sys} \PYG{n}{config}

\PYG{c+c1}{\PYGZsh{} Archive your change}
\PYG{n}{save} \PYG{n}{sys} \PYG{n}{ucs} \PYG{n}{lab1}\PYG{o}{\PYGZhy{}}\PYG{n}{base}\PYG{o}{\PYGZhy{}}\PYG{n}{config}
\end{sphinxVerbatim}


\section{Appendix III - EAV Monitor from DevCentral}
\label{\detokenize{class6/module14/module14:appendix-iii-eav-monitor-from-devcentral}}\label{\detokenize{class6/module14/module14::doc}}

\subsection{EAV Monitor - HTTP Monitor cURL Basic GET}
\label{\detokenize{class6/module14/lab1:eav-monitor-http-monitor-curl-basic-get}}\label{\detokenize{class6/module14/lab1::doc}}
Code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}!/bin/sh
\PYGZsh{}
\PYGZsh{} (c) Copyright 1996\PYGZhy{}2007 F5 Networks, Inc.
\PYGZsh{}
\PYGZsh{} This software is confidential and may contain trade secrets that are the
\PYGZsh{} property of F5 Networks, Inc. No part of the software may be disclosed
\PYGZsh{} to other parties without the express written consent of F5 Networks, Inc.
\PYGZsh{} It is against the law to copy the software. No part of the software may
\PYGZsh{} be reproduced, transmitted, or distributed in any form or by any means,
\PYGZsh{} electronic or mechanical, including photocopying, recording, or information
\PYGZsh{} storage and retrieval systems, for any purpose without the express written
\PYGZsh{} permission of F5 Networks, Inc. Our services are only available for legal
\PYGZsh{} users of the program, for instance in the event that we extend our services
\PYGZsh{} by offering the updating of files via the Internet.
\PYGZsh{}
\PYGZsh{} @(\PYGZsh{}) \PYGZdl{}Id: http\PYGZbs{}\PYGZus{}monitor\PYGZbs{}\PYGZus{}cURL+GET,v 1.0 2007/06/28 16:10:15 deb Exp \PYGZdl{}
\PYGZsh{} (based on sample\PYGZbs{}\PYGZus{}monitor,v 1.3 2005/02/04 18:47:17 saxon)
\PYGZsh{}
\PYGZsh{} these arguments supplied automatically for all external monitors:
\PYGZsh{} \PYGZdl{}1 = IP (IPv6 notation. IPv4 addresses are passed in the form
\PYGZsh{} ::ffff:w.x.y.z
\PYGZsh{} where \PYGZdq{}w.x.y.z\PYGZdq{} is the IPv4 address)
\PYGZsh{} \PYGZdl{}2 = port (decimal, host byte order)
\PYGZsh{}
\PYGZsh{} Additional command line arguments (\PYGZdl{}3 and higher) may be specified inthe monitor template
\PYGZsh{} This example does not expect any additional command line arguments
\PYGZsh{}
\PYGZsh{} Name/Value pairs may also be specified in the monitor template
\PYGZsh{} This example expects the following Name/Vaule pairs:
\PYGZsh{} URI = the URI to request from the server
\PYGZsh{} RECV = the expected response (not case sensitive)
\PYGZsh{}

\PYGZsh{} remove IPv6/IPv4 compatibility prefix (LTM passes addresses in IPv6 format)
IP=\PYGZbs{}{}`echo \PYGZdl{}\PYGZob{}1\PYGZcb{} \PYGZbs{}\textbar{} sed \PYGZsq{}s/::ffff://\PYGZsq{}\PYGZbs{}{}`
PORT=\PYGZdl{}\PYGZob{}2\PYGZcb{}

PIDFILE=\PYGZdq{}/var/run/\PYGZbs{}{}`basename \PYGZdl{}\PYGZob{}0\PYGZcb{}\PYGZbs{}{}`.\PYGZdl{}\PYGZob{}IP\PYGZcb{}\PYGZbs{}\PYGZus{}\PYGZdl{}\PYGZob{}PORT\PYGZcb{}.pid\PYGZdq{}
\PYGZsh{} kill of the last instance of this monitor if hung and log current pid
if [ \PYGZhy{}f \PYGZdl{}PIDFILE ]
then

   echo \PYGZdq{}EAV exceeded runtime needed to kill \PYGZdl{}\PYGZob{}IP\PYGZcb{}:\PYGZdl{}\PYGZob{}PORT\PYGZcb{}\PYGZdq{} \PYGZbs{}\textbar{} logger \PYGZhy{}p
   local0.error
   kill \PYGZhy{}9 \PYGZbs{}{}`cat \PYGZdl{}PIDFILE\PYGZbs{}{}` \PYGZgt{} /dev/null 2\PYGZgt{}\PYGZam{}1

fi

echo \PYGZdq{}\PYGZdl{}\PYGZdl{}\PYGZdq{} \PYGZgt{} \PYGZdl{}PIDFILE

\PYGZsh{} send request \PYGZam{} check for expected response
curl \PYGZhy{}fNs http://\PYGZdl{}\PYGZob{}IP\PYGZcb{}:\PYGZdl{}\PYGZob{}PORT\PYGZcb{}\PYGZdl{}\PYGZob{}URI\PYGZcb{} \PYGZbs{}\textbar{} grep \PYGZhy{}i \PYGZdq{}\PYGZdl{}\PYGZob{}RECV\PYGZcb{}\PYGZdq{} 2\PYGZgt{}\PYGZam{}1 \PYGZgt{} /dev/null

\PYGZsh{} mark node UP if expected response was received
   if [ \PYGZdl{}? \PYGZhy{}eq 0 ]
then
   rm \PYGZhy{}f \PYGZdl{}PIDFILE
   echo \PYGZdq{}UP\PYGZdq{}
else
   rm \PYGZhy{}f \PYGZdl{}PIDFILE
fi

exit
\end{sphinxVerbatim}


\chapter{F5 301B - BIG-IP LTM Specialist: Maintain and Troubleshoot Study Guide 11/01/19}
\label{\detokenize{class7/class7:f5-301b-big-ip-ltm-specialist-maintain-and-troubleshoot-study-guide-11-01-19}}\label{\detokenize{class7/class7::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 301B - LTM Specialist: Maintain and Troubleshoot}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Welcome to the 301b - LTM Specialist compiled Study Guide. The purpose of this
guide is to help you prepare for the F5 301b - LTM Specialist exam. The
contents of this document are based on the 301b - LTM Specialist Exam Blueprint
for TMOS v11.5.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled
from F5 sources that are located on Internet. All of the information
locations are referenced at the top of each topic instead of in an
Appendix of this document. This was done to help the reader access the
reference the linked information easier without having to search through
a formal appendix. This guide may also reference the same books as the
exam Resource Guide for each topic when applicable for consistency.

F5 provides the 301b - LTM Specialist Resource Guide as a study
guide. The Resource Guide is a list of reading material that will help
any student build a broad base of general knowledge that can assist in
not only their exam success but in becoming a well rounded systems
engineer. The Resource Guide will be available to the candidate once
they are qualified for the 301b - LTM Specialist exam.

Taking certified F5 LTM training, such as Administering BIG-IP v11 and
Configuring BIG-IP LTM v11, will surely help with the topics of this
exam but does not teach directly to the exam content. Hands on
administrative experience with the BIG-IP platform licensed with LTM
will reinforce many of the topics contained in the 301b - LTM Specialist
exam.

The F5 301a - Local Traffic Manager Specialist: Architect, Setup and
Deploy, stand as a pre-requisite to this exam.

This guide was prepared by an F5 employee but is not an official F5
document and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}


\bigskip\hrule\bigskip


\sphinxstylestrong{Printed References}

These reference books are important and should be considered basic
reading material for this exam. However, these reading materials are not
available for purchase. You can only gain access to the books by
attending the associated F5 training class. These official F5
classes are now being offered in v12 and v13. So, if you have the newer
copy of the material that is fine, be aware that the exam is based on
the 11.5 version and content could have changed. It is possible that an
ATC for F5  may still offer older 11.5 training, but this is not
guaranteed.

(Ref:1) Configuring BIG-IP Local Traffic Manager v11.5, v11.5.0 Edition.
F5 Training Course Manual.

(Ref:2) Administering BIG-IP v11.5, v11.5.0 Edition.
F5 Training Course Manual.

(Ref:3) Troubleshooting BIG-IP v11.5, v11.5.0 Edition.
F5 Training Course Manual.

(Ref:4) Developing iRules for BIG-IP v11.5, v11.5.0 Edition.
F5 Training Course Manual.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{F5 301b Introduction}
\label{\detokenize{class7/modules/module1:f5-301b-introduction}}\label{\detokenize{class7/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{F5 \textendash{} 301b Local Traffic Manager Specialist Exam}

The F5 BIG-IP Local Traffic Manager (LTM) increases an application’s
operational efficiency and ensures peak network performance by providing
a flexible, high-performance application delivery system. With its
application-centric perspective, LTM optimizes your network
infrastructure to deliver availability, security, and performance for
critical business applications. Although the Exam Blueprint is not
written in a structure that presents topics in an educational order, it
does provide many of the necessary building blocks. The Certified LTM
Training classes from F5 will help with many of the scenario-based
topics on the test. An LTM Specialist must be proficient with all
aspects of maintaining and troubleshooting the LTM within a network.

\sphinxstylestrong{Traffic Management Shell}

Although it is not mentioned in the blueprint as a requirement, a
candidate should not focus only on the GUI interface for management of
the LTM platform. Some test questions will refer to the command line
interface (CLI) TMSH commands. You should take time to understand where
in the CLI that common commands are issued so you can not only correctly
answer the questions presented on the exam but also have enough
knowledge of the CLI structure to eliminate bad commands from your
question’s answer choices.

Try building your vLab environment from command line to gain CLI
proficiency. Hands-on experience is the key to passing this exam.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 1 \textendash{} Troubleshoot Basic Virtual Server Connectivity Issues}
\label{\detokenize{class7/modules/module1:section-1-troubleshoot-basic-virtual-server-connectivity-issues}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.01 - Given a scenario, determine the appropriate profile setting modifications}
\label{\detokenize{class7/modules/module1:objective-1-01-given-a-scenario-determine-the-appropriate-profile-setting-modifications}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 \textendash{} Given a scenario of client or server side buffer issues, packet
loss, or congestion, select the appropriate TCP or UDP profile to
correct the issue}

\sphinxurl{https://support.f5.com/csp/article/K13924148}

\sphinxstylestrong{Congestion Control}

The default TCP Profile has the following settings related to congestion
control.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{3}{\X{1}{3}|}}
\hline

\sphinxstylestrong{Setting}
&
\sphinxstylestrong{Default Value}
&
\sphinxstylestrong{Description}
\\
\hline
Appropriate Byte Counting (\sphinxhref{http://datatracker.ietf.org/doc/rfc3465/}{RFC 3465})
&
Enabled
&
This setting increases the congestion window by basing the increase amount on the number of previously-unacknowledged bytes that each ACK covers.
\\
\hline
Congestion Metrics Cache
&
Enabled
&
This setting specifies that the system uses a cache for storing congestion metrics.
\\
\hline
Congestion Control
&
High Speed
&
This setting specifies the congestion control mechanism that the BIG-IP system uses.

Available options:
\begin{itemize}
\item {} 
\sphinxstylestrong{None}: No congestion control algorithm implemented.

\item {} 
\sphinxstylestrong{High Speed}: A more aggressive, loss-based algorithm. For more information, refer to \sphinxhref{http://datatracker.ietf.org/doc/rfc3649/}{RFC 3649}: HighSpeed TCP for Large Congestion Windows.

\item {} 
\sphinxstylestrong{New Reno}: A modification to the Reno algorithm that responds to partial acknowledgments when selective acknowledgments (SACK) are unavailable. For more information, refer to \sphinxhref{http://datatracker.ietf.org/doc/rfc2582/}{RFC 2582}: The NewReno Modification to TCP’s Fast Recovery Algorithm.

\item {} 
\sphinxstylestrong{Reno}: An implementation of the TCP Fast Recovery algorithm, based on the implementation in the BSD Reno release. For more information, refer to \sphinxhref{http://datatracker.ietf.org/doc/rfc2581/}{RFC 2581}: TCP Congestion Control.

\item {} 
\sphinxstylestrong{Scalable}: A TCP algorithm modification that adds a scalable, delay-based and loss-based component into the Reno algorithm. This option is used in conjunction with the \sphinxstylestrong{Appropriate Byte Counting} setting.

\item {} 
\sphinxstylestrong{CUBIC} (11.6.0 and later): Specifies that the system uses a TCP algorithm that is optimized for high bandwidth, high delay networks.

\item {} 
\sphinxstylestrong{Westwood+} (11.6.0 and later): Specifies that the system uses a TCP algorithm based on a bandwidth estimation metric.

\item {} 
\sphinxstylestrong{CAIA Delay Gradient (CDG)} (11.5.0 and later): Specifies that the system uses a delay based TCP that senses onset of congestion by variations in round trip time (RTT).

\item {} 
\sphinxstylestrong{CAIA Hamilton Delay (CHD)} (11.5.0 and later): Specifies that the system uses a TCP algorithm that aims to keep network queuing delays below a particular threshold (queue\_threshold) and decides to reduce the congestion window (cwnd) probabilistically based on its estimate of the network queuing delay.

\item {} 
\sphinxstylestrong{Illinois} (11.5.0 and later): Specifies that the system uses a TCP algorithm that is especially targeted at high-speed, long-distance networks.

\item {} 
\sphinxstylestrong{Vegas} (11.5.0 and later): Specifies that the system uses a TCP algorithm modification that adds a delay-based and loss-based component into the Reno algorithm.

\item {} 
\sphinxstylestrong{Woodside} (11.5.0 and later): Specifies that the system uses a TCP algorithm that is especially targeted at high-speed, long-distance networks with enhanced congestion recovery.

\end{itemize}
\\
\hline
Delay Window Control
&
Disabled
&
When enabled, this setting specifies that the system uses an estimate of queuing delay as a measure of congestion to control the amount of data sent (in addition to the normal loss-based control).
\\
\hline
Explicit Congestion Notification
&
Disabled
&
When enabled, this setting specifies that the system uses the TCP flags CWR (Congestion Window Reduced) and ECE (ECN-Echo, used to indicate that the TCP peer is Explicit Congestion Notification capable during the three-way handshake) to notify its peer of congestion and congestion counter-measures.

\sphinxstylestrong{*Note}: When this setting is enabled, it is used only when two hosts signal that they want to use it. This setting allows a host to set the ECN bit within the IP header to notify the transmitter that the link is congested.*
\\
\hline
Initial Congestion Window Size
&
0 MSS units
&
This setting specifies the initial congestion window size for connections to this destination. Actual window size is this value multiplied by the MSS for the same connection. The default value is 0 (zero), meaning that the system uses the values specified in \sphinxhref{http://datatracker.ietf.org/doc/rfc2414/}{RFC 2414}. Valid values range from 0 to 16.
\\
\hline
Packet Loss Ignore Burst
&
0 packet count
&
This setting specifies the probability of performing congestion control when multiple packets are lost, even if the \sphinxstylestrong{Packet Loss Ignore Rate} value was not exceeded. Valid values range from 0 to 32. The default value is 0, meaning that the system performs congestion control if any packets are lost. Higher values decrease the chance of performing congestion control.
\\
\hline
Packet Loss Ignore Rate
&
0 packets lost per million
&
This setting specifies the threshold of packets lost per million at which the system performs congestion control. Valid values range from 0 to 1,000,000. The default value is 0, meaning the system performs congestion control if any packet loss occurs. If you set the ignore rate to 10 and packet loss for a TCP connection is greater than 10 per million, congestion control occurs.
\\
\hline
Rate Pace

(11.5.0 and later)
&
Disabled
&
The system paces the egress packets to avoid dropping packets, allowing for optimum goodput. This option mitigates bursty behavior in mobile networks.
\\
\hline
Slow Start
&
Enabled
&
This setting specifies that the system uses larger initial window sizes, as specified in  \sphinxhref{http://datatracker.ietf.org/doc/rfc3390/}{RFC 3390}: Increasing TCP’s Initial Window, to help reduce round trip times. TCP slow-start congestion avoidance is a method of converging on the right amount of data to put on the link without overloading the link in order to prevent packets from being dropped.
\\
\hline
Timestamps Extension for High Performance (\sphinxhref{http://datatracker.ietf.org/doc/rfc1323/}{RFC 1323})

(11.4.0 and later)
&
Enabled
&
This setting specifies that the system uses the timestamp extensions for TCP, as specified in  \sphinxhref{http://datatracker.ietf.org/doc/rfc1323/}{RFC 1323}, to enhance high-speed network performance. The timestamp option allows for accurate RTT measurement, in addition to simplifying window calculations for the sender.
\begin{quote}

\sphinxstylestrong{Note:} Beginning in BIG-IP 11.4.0, the window scale functionality is built into the TCP profile and cannot be manually disabled or enabled. The functionality will be negotiated if the send or receive buffer is larger than 65535 bytes. This option only controls the Timestamp functionality.
\end{quote}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Virtual Server Layer4 Protocol Settings}

The BIG-IP system provides a variety of Layer4 profiles that have been
modified to optimize traffic processing for a number of popular network
environments. Choosing an optimized TCP profile may greatly improve
performance compared to using the default TCP profile.


\bigskip\hrule\bigskip


\sphinxstylestrong{Using optimized TCP profiles}

\sphinxurl{https://support.f5.com/csp/article/K76314423}

\sphinxstylestrong{tcp-mobile-optimized}

Introduced in BIG-IP 11.5.0, the tcp-mobile-optimized profile is a
modified TCP protocol profile for use when the BIG-IP system is load
balancing traffic from 3G and 4G cellular networks.

If you use a standard virtual server with a TCP profile to process
strictly 3G and/or 4G cellular based traffic, you can configure your
virtual server to use the tcp-mobile-optimized profile to enhance
cell-based traffic processing. When the BIG-IP system proxies cellular
traffic, client side connections to the virtual server are generally
slower than the server side connections to pool members, resulting in a
greater amount of data the BIG-IP must buffer. Increasing buffer sizes
allows the BIG-IP system to accept more data and better manage the
disparity in connection speeds also known as content spooling. For more
information on content spooling, refer to K3422: Overview of content
spooling. Additionally, the tcp-mobile-optimized profile increases the
Initial Congestion Window size to reduce round trip times (RTT) and
enables Nagle’s Algorithm to reduce the number of smaller TCP packets on
the network.

Modified options in the tcp-mobile-optimized profile

The tcp-mobile-optimized profile contains the following modifications to
the default TCP profile:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Setting
&
Value
&
Description
\\
\hline
Proxy Buffer Low
&
131072 bytes
&
Specifies the proxy buffer level at which the receive window was opened.

This value is increased to accommodate larger bandwidth links and content spooling that may occur.
\\
\hline
Proxy Buffer High
&
131072 bytes
&
Specifies the proxy buffer level at which the receive window is no longer advanced.

This value is increased to accommodate larger bandwidth links and content spooling that may occur.
\\
\hline
Send Buffer
&
131072 bytes
&
Specifies the BIG-IP system’s send buffer size in bytes.

This value is increased to allow the BIG-IP to send more data.
\\
\hline
Receive Window
&
131072 bytes
&
Specifies the BIG-IP system’s receive window size in bytes.

This value is increased to allow the BIG-IP to receive more data.
\\
\hline
Reset on Timeout
&
Disabled
&
Specifies that the system sends a reset packet (RST) in addition to deleting the connection, when a connection exceeds the idle timeout value.
\\
\hline
Delayed ACKs
&
Disabled
&
Specifies if the BIG-IP system can send fewer than one ACK (acknowledgment) packet per data packet received.

Enabling Delayed ACK and Nagle’s Algorithm may cause latency when single small packets are sent or received.
\\
\hline
Appropriate Byte Counting (ABC)
&
Disabled
&
Specifies if the BIG-IP system increases the congestion window by basing the increase amount on the number of previously unacknowledged bytes that each ACK covers.

Disabled as ABC may not perform optimally when applications send small amounts of data.
\\
\hline
Initial Congestion Window Size
&
16
&
Specifies the initial congestion window size for connections to this destination. Actual window size is this value multiplied by the MSS (Maximum Segment Size) for the same connection.

Larger initial congestion windows may improve performance of TCP connections over satellite channels.
\\
\hline
Explicit Congestion Notification (ECN)
&
Enabled
&
Specifies that the BIG-IP system uses the TCP flags Congestion Window Reduced (CWR) and ECN-Echo (ECE) to notify peers of impending congestion.

Instead of dropping packets an ECN-aware peer will reduce the packet transmission rate.
\\
\hline
Nagle’s Algorithm
&
Enabled
&
Specifies that the BIG-IP system uses Nagle’s algorithm to reduce the number of short segments on the network by holding data until the peer system acknowledges outstanding segments. This helps to reduce congestion by creating fewer packets on the network.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K7405}

\sphinxstylestrong{tcp-wan-optimized}

The tcp-wan-optimized profile is a pre-configured profile type. In cases
where the BIG-IP system is load balancing traffic over a WAN link, you
can enhance the performance of your wide-area TCP traffic by using the
tcp-wan-optimized profile.

If the traffic profile is strictly WAN-based, and a standard virtual
server with a TCP profile is required, you can configure your virtual
server to use the tcp-wan-optimized profile to enhance WAN-based
traffic. For example, in many cases, the client connects to the BIG-IP
virtual server over a WAN link, which is generally slower than the
connection between the BIG-IP system and the pool member servers. As a
result, the BIG-IP system can accept the data more quickly, allowing
resources on the pool member servers to remain available. By configuring
your virtual server to use the tcp-wan-optimized profile, you can
increase the amount of data the BIG-IP system will buffer while waiting
for a remote client to accept it. Additionally, you can increase network
throughput by reducing the number of short TCP segments the BIG-IP
system sends on the network.

Optimized settings and definitions in the tcp-wan-optimized profile

The following table describes settings of the tcp-wan-optimized profile
that may differ from the parent default TCP profile in order to optimize
WAN traffic.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Setting
&
Value
&
Description
\\
\hline
Proxy Buffer Low
&
131072
&
This setting specifies the proxy buffer level at which the receive window was opened. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K3422}{K3422: Overview of content spooling}.
\\
\hline
Proxy Buffer High
&
131072
&
This setting specifies the proxy buffer level at which the receive window is no longer advanced. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K3422}{K3422: Overview of content spooling}.
\\
\hline
Send Buffer
&
65535
&
This setting causes the BIG-IP system to send the buffer size in bytes. To optimize LAN-based traffic, this setting should be at least 64 K in order to allow the BIG-IP system to output more data at a time, if it is allowed by the congestion window.
\\
\hline
Receive Window
&
65535
&
This setting causes the BIG-IP system to receive the window size in bytes. If this setting is set too low in a LAN environment it can cause delays, as some systems inhibit data transfers if the receive window is too small.
\\
\hline
Selective ACKs
&
Enabled
&
When this setting is enabled, the BIG-IP system can inform the data sender about all segments that it has received, allowing the sender to retransmit only the segments that have been lost.
\\
\hline
Nagle’s Algorithm
&
Enabled
&
When this setting is enabled, the BIG-IP system applies Nagle’s algorithm to reduce the number of short segments on the network by holding data until the peer system acknowledges outstanding segments.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

To display all tcp-wan-optimized profile settings and values for your
specific version, you can use the following Traffic Management Shell
(tmsh) command:

tmsh list ltm profile tcp tcp-wan-optimized all-properties


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K7406}

\sphinxstylestrong{tcp-lan-optimized}

The tcp-lan-optimized profile is a preconfigured profile type that can
be associated with a virtual server. In cases where the BIG-IP virtual
server is load balancing LAN-based or interactive traffic, you can
enhance the performance of your local-area TCP traffic by using the
tcp-lan-optimized profile.

If the traffic profile is strictly LAN-based, or highly interactive, and
a standard virtual server with a TCP profile is required, you can
configure your virtual server to use the tcp-lan-optimized profile to
enhance LAN-based or interactive traffic. For example, applications
producing an interactive TCP data flow such as secure shell (SSH) and
TELNET, normally generate a TCP packet for each keystroke. A TCP profile
setting such as Slow Start or Nagle’s Algorithm can introduce latency
when this type of traffic is being processed. By configuring your
virtual server to use the tcp-lan-optimized profile, you can ensure that
LAN-based or interactive traffic is delivered without delay.

Settings and definitions in the tcp-lan-optimized profile

The following table describes settings of the tcp-lan-optimized profile
that may differ from the parent default TCP profile in order to optimize
LAN traffic.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

Setting
&
Value
&
Description
\\
\hline
Proxy Buffer Low
&
98304
&
This setting specifies the proxy buffer level at which the receive window was opened. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K3422}{K3422: Overview of content spooling}.
\\
\hline
Proxy Buffer High
&
131072
&
This setting specifies the proxy buffer level at which the receive window is no longer advanced. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K3422}{K3422: Overview of content spooling}.
\\
\hline
Send Buffer
&
65535
&
This setting causes the BIG-IP system to send the buffer size in bytes. To optimize LAN-based traffic, this setting should be at least 64K in order to allow the BIG-IP system to output more data at a time, if allowed by the congestion window.
\\
\hline
Receive Window
&
65535
&
This setting causes the BIG-IP system to receive the window size in bytes. If this setting is set too low in a LAN environment it can cause delays, as some systems inhibit data transfers if the receive window is too small.
\\
\hline
Slow Start
&
Disabled
&
When enabled (selected), this setting specifies that the system uses larger initial window sizes (as specified in \sphinxhref{ftp://ftp.rfc-editor.org/in-notes/rfc3390.txt}{Internet Engineering Task Force (RFC 3390)}) to help reduce round trip times.
\\
\hline
Bandwidth Delay
&
Disabled
&
When this setting is enabled, the system attempts to calculate the optimal bandwidth to use to the client, based on throughput and round-trip time, without exceeding the available bandwidth. This setting should be disabled in the following cases: the traffic profile is interactive; the client exhibits stretch ACKs; or the acknowledgment packets cover more than two segments of previously unacknowledged data. \sphinxstyleemphasis{Note: This setting is deprecated and no longer appears in BIG-IP 11.2.1 and later versions.}
\\
\hline
Nagle’s Algorithm
&
Disabled
&
When this setting is enabled, the BIG-IP system applies Nagle’s algorithm to reduce the number of short segments on the network by holding data until the peer system acknowledges outstanding segments.
\\
\hline
Acknowledge on Push
&
Enabled
&
When this setting is enabled it improves performance to Windows and MacOS peers who produce a small send buffer.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K7535}

\sphinxstylestrong{UDP}

Even though UDP is a connectionless protocol, the F5 BIG-IP is a full
proxy device and can accept the UDP traffic and will keep an inbound
connection in the state table. The most important setting in the UDP
profile for network performance issues is the idle timeout setting.

Settings and definitions in the UDP profile are defined in the following
table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{3}{\X{1}{3}|}}
\hline

\sphinxstylestrong{Setting}
&
\sphinxstylestrong{Default value}
&
\sphinxstylestrong{Description}
\\
\hline
Proxy Maximum Segment
&
Disabled (Not Selected)
&
When enabled, this setting specifies that the system advertises the same maximum segment size (MSS) to the server as that of the client. This option is available in BIG-IP LTM 11.0.0 and later.
\\
\hline
Idle Timeout
&
Specify: 60 seconds
&
This setting specifies the length of time that a connection is idle before the connection is eligible for deletion. The Idle Timeout setting allows the BIG-IP LTM to create a connection entry. UDP is a connectionless protocol and does not behave in the same manner as TCP. By default, the BIG-IP LTM treats UDP packets from the same source and port as part of a connection.

Available options:
\begin{itemize}
\item {} 
Specify: User specified amount of time (in seconds) the UDP connection can remain idle before it can be deleted

\item {} 
Immediate: Specifies that you do not want the UDP connection to remain idle and that it is immediately eligible for deletion

\item {} 
Indefinite: Specifies that the UDP connection can remain idle indefinitely

\end{itemize}

\sphinxstyleemphasis{Note: Specifying an indefinite idle timeout for connectionless protocols such as UDP can lead to stalled connections and resource shortages.}
\\
\hline
IP ToS
&
0
&
This setting specifies the Layer 3 (L3) Type of Service (ToS) level that the system inserts in the UDP datagrams destined for clients. The IP ToS is part of the TCP/IP protocol and is primarily used for ToS Application Routing, which is supported by OSPF and IS-IS. It allows the administrator to specify the importance and routing preference the packet should be given on a supported network. For more information regarding ToS Precedence values and a description of ToS Application Routing, refer to the following RFC’s:
\begin{itemize}
\item {} 
RFC 791: INTERNET PROTOCOL

\item {} 
RFC 1583: OSPF Version 2

\item {} 
RFC 2474: Definition of the Differentiated Services Field (DS Field) in the IPv4 and IPv6 Headers

\end{itemize}
\\
\hline
Link QoS
&
0
&
This setting specifies the Layer 2 (L2) Quality of Service (QoS) level that the system inserts in the TCP packets destined for clients. The Link QoS is used to specify the QoS level that the system assigns to the UDP datagrams when sending to a client. These values are similar to IP ToS, but are applied to the link layer or L2. For more information regarding QoS, refer to the following RFCs:
\begin{itemize}
\item {} 
RFC 2474: Definition of the Differentiated Services Field (DS Field) in the IPv4 and IPv6 Headers

\item {} 
RFC 2697: A Single Rate Three Color Marker

\item {} 
RFC 2597: Assured Forwarding PHB Group

\item {} 
RFC 2598: An Expedited Forwarding PHB

\end{itemize}
\\
\hline
Datagram LB
&
Disabled (Not Selected)
&
The Datagram LB option, which is disabled by default, specifies that the system load balances UDP traffic packet-by-packet and does not treat UDP packets from the same source and port as part of a connection. This setting overrides the default behavior of the UDP profile.
\\
\hline
Allow No Payload
&
Disabled (Not Selected)
&
Allows UDP datagrams that have no payload (Contains only the UDP header) through the system.
\\
\hline
TTL Mode1
&
Proxy
&
This setting specifies the outgoing UDP packet’s Time-to-live (TTL) mode.

Available options:
\begin{itemize}
\item {} 
\sphinxstylestrong{Proxy}: Sets the IP TTL of IPv4 to the default value of 255, and IPv6 to the default value of 64.

\item {} 
\sphinxstylestrong{Preserve}: Sets the IP TTL to the original packet TTL value.

\item {} 
\sphinxstylestrong{Decrement}: Sets the IP TTL to the original packet TTL value minus 1.

\item {} 
\sphinxstylestrong{Set}: Sets the IP TTL to the values specified in TTL IPv4 and TTL IPv6.

\end{itemize}

\sphinxstylestrong{*Note}: The \sphinxstylestrong{Set} value is available in 12.1.0 and later.*
\\
\hline
Don’t Fragment Mode2
&
PMTU
&
This setting controls the Don’t Fragment (DF) bit in the outgoing UDP packet.

Available options:
\begin{itemize}
\item {} 
\sphinxstylestrong{PMTU}: Sets the outgoing UDP packet DF bit based on the IP Path Maximum Transmission Unit (PMTU) setting.

\item {} 
\sphinxstylestrong{Preserve}: Preserve the incoming UDP packet DF bit for the outgoing UDP packet.

\item {} 
\sphinxstylestrong{Enable}: Sets the outgoing UDP packet DF bit.

\item {} 
\sphinxstylestrong{Disable}: Clear the outgoing UDP packet DF bit.

\end{itemize}

\sphinxstylestrong{*Note}: In \sphinxstylestrong{PMTU}, the  \sphinxstylestrong{TM.PathMTUDiscovery} database variable controls the \sphinxstylestrong{PMTU} setting.*
\\
\hline
Max Buffer Bytes3
&
655350 (bytes)
&
This setting specifies ingress buffer byte limit. Maximum allowed value is 16777215. This option is available in BIG-IP LTM 13.0.0 and later.
\\
\hline
Max Buffer Packets3
&
0
&
This setting specifies ingress buffer packet limit. Maximum allowed value is 255.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.01 \textendash{} Given a scenario determine when an application would benefit from HTTP Compression and/or Web Acceleration profile}

\sphinxstylestrong{Compression}

Even though the internet speed is increasing, there are users that still
have slow internet access and adding compression to a website can speed
up performance for them. The BIG-IP can provide simple Compression or
Caching of data that can help with this need.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K15434}

When you configure an HTTP Compression profile and assign it to a
virtual server, the BIG-IP system reads the Accept-Encoding header of a
client request and determines what content encoding method the client
prefers. The BIG-IP system then removes the Accept-Encoding header from
the request and passes the request to the server. Upon receiving the
server response, the BIG-IP system inserts the Content-Encoding header,
specifying either the gzip or deflate, based on the compression method
that the client specifies in the Accept-Encoding header.

Note: Compression of data can cause latency so tuning may be necessary
to find the best configuration for each environment.


\bigskip\hrule\bigskip


\sphinxstylestrong{Web Acceleration profile}

\sphinxurl{https://support.f5.com/csp/article/K14903}

The Web Acceleration profile provides settings to configure HTTP caching
for the BIG-IP system. HTTP caching allows the BIG-IP system to store
frequently requested web objects in memory for reuse by subsequent
connections.

You can enable HTTP caching on the BIG-IP system by associating a Web
Acceleration profile with a virtual server. An HTTP cache is a
collection of HTTP objects stored in the BIG-IP system’s memory that
subsequent connections can reuse to reduce traffic load on the origin
web servers. The goal of caching is to reduce the need to send frequent
requests for the same object and eliminate the need to send full
responses in many cases.

\sphinxstylestrong{Cacheable content}

You can configure the BIG-IP cache feature to cache the following
content types:
\begin{itemize}
\item {} 
200, 203, 300, 301, and 410 HTTP responses

\item {} 
Responses to HTTP GET requests

\item {} 
Other HTTP methods for URIs specified for inclusion in cached
content, or specified in an iRule

\item {} 
Content based on the User-Agent and Accept-Encoding values. The cache
feature holds different content for Vary headers.

\end{itemize}

The default cache configuration caches only responses to HTTP GET
requests. However, you can configure the Web Acceleration profile to
cache other requests, including non-HTTP requests. To do this, you can
specify a URI in the URI Include Override List or Pin List within a Web
Acceleration profile, or write an iRule.

\sphinxstylestrong{Non-cacheable content}

The cache feature does not cache the following items:
\begin{itemize}
\item {} 
Data specified by the following Cache-Control headers: private,
no-store, no-cache

\item {} 
Action-oriented HTTP methods such as HEAD, PUT, DELETE, TRACE, and
CONNECT

\end{itemize}

\sphinxstylestrong{Recommendations}

When you configure the Web Acceleration profile for a virtual server,
you should consider the following factors:
\begin{itemize}
\item {} 
Caching is useful for frequently-requested content; for example,
caching can be used if the site has periods of high demand for
specific content. When you configure a Web Acceleration profile for a
virtual server, the content server only has to serve the content to
the BIG-IP system once per expiration period.

\item {} 
Caching is useful if a site contains a large amount of static content
such as CSS files, JavaScript files, or images.

\item {} 
For compressible data, the cache feature can store data for clients
that accept compressed data. When used with the compression feature
on the BIG-IP system, the cache takes stress off of the BIG-IP system
and the content servers.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.02 - Given a sub-set of an LTM configuration, determine which objects to remove or consolidate to simplify the LTM configuration}
\label{\detokenize{class7/modules/module1:objective-1-02-given-a-sub-set-of-an-ltm-configuration-determine-which-objects-to-remove-or-consolidate-to-simplify-the-ltm-configuration}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Evaluate which iRules can be replaced with a profile or policy setting}

\sphinxurl{https://support.f5.com/csp/article/K15085}

\sphinxstylestrong{Interpret Configuration}

The Local Traffic Policies comprise a prioritized list of rules that
match defined conditions and run specific actions, which you can assign
to a virtual server that directs traffic accordingly. For example, you
might create a policy that determines whether a client’s browser is a
Chrome browser and adds an Alternative-Protocols attribute to the
header, so that subsequent requests from the Chrome browser are directed
to a SPDY virtual server. Or you might create a policy that determines
whether a client is using a mobile device, and then redirects its
requests to the applicable mobile web site’s URL.


\bigskip\hrule\bigskip


\sphinxurl{https://devcentral.f5.com/articles/ltm-policy}

iRules are an important and long-standing part of the BIG-IP
architecture, and pervasive throughout the product. There is some
overlap between what can be controlled by LTM Policy and iRules, not
surprisingly that most of the overlap is in the realm of HTTP traffic
handling. And just about anything that is possible in LTM Policy can
also be written as an iRule.

LTM Policy is a structured, data-driven collection of rules. iRules and
Tcl are more of a general purpose programming language which provide
lots of power and flexibility, but also require some programming skills.
Because policies are structured and can be created by populating tables
in a web UI, it is more approachable for those with limited programming
skills.

So, when to use LTM Policy and when to use iRules? As a general rule,
where there is identical functionality, LTM Policy should be able to
offer better performance. There are situations where LTM Policy may be a
better choice.
\begin{itemize}
\item {} 
when rules need to span different events, (e.g. a rule that considers
both request and response)

\item {} 
dealing with HTTP headers and cookies (e.g. LTM Policy has more
direct access to internal HTTP state)

\item {} 
when there are large number of conditions (pre-compiled internal
decision trees can evaluate conditions in parallel)

\item {} 
when conditions have a lot of commonality

\end{itemize}

For supported events (such as HTTP\_REQUEST or HTTP\_RESPONSE), LTM
Policy evaluation occurs before iRule evaluation. This means that it is
possible to write an iRule to override an LTM Policy decision.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.02 - Evaluate which host virtual servers would be better consolidated into a network virtual server}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/2.html}

\sphinxstylestrong{Host Virtual Server}

A host virtual server represents a specific site, such as an Internet
web site or an FTP site, and it load balances traffic targeted to
content servers that are members of a pool.

The IP address that you assign to a host virtual server should match the
IP address that Domain Name System (DNS) associates with the site’s
domain name. When the BIG-IP system receives a connection request for
that site, Local Traffic Manager recognizes that the client’s
destination IP address matches the IP address of the virtual server, and
subsequently forwards the client request to one of the content servers
that the virtual server load balances.

\sphinxstylestrong{Network Virtual Server}

A network virtual server is a virtual server whose IP address has no
bits set in the host portion of the IP address (that is, the host
portion of its IP address is 0). There are two kinds of network virtual
servers: those that direct client traffic based on a range of
destination IP addresses, and those that direct client traffic based on
specific destination IP addresses that the BIG-IP system does not
recognize.

When you have a range of destination IP addresses

With an IP address whose host bit is set to 0, a virtual server can
direct client connections that are destined for an entire range of IP
addresses, rather than for a single destination IP address (as is the
case for a host virtual server). Thus, when any client connection
targets a destination IP address that is in the network specified by the
virtual server IP address, Local Traffic Manager (LTM) can direct that
connection to one or more pools associated with the network virtual
server.

For example, the virtual server can direct client traffic that is
destined for any of the nodes on the 192.168.1.0 network to a specific
load balancing pool such as ingress-firewalls. Or, a virtual server
could direct a web connection destined to any address within the subnet
192.168.1.0/24, to the pool default\_webservers.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.03 - Given a set of LTM device statistics, determine which objects to remove or consolidate to simplify the LTM configuration}
\label{\detokenize{class7/modules/module1:objective-1-03-given-a-set-of-ltm-device-statistics-determine-which-objects-to-remove-or-consolidate-to-simplify-the-ltm-configuration}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Identify redundant and/or unused objects}

\sphinxurl{https://support.f5.com/csp/article/K15335}

\sphinxstylestrong{Orphaned Configuration Objects}

Over the course of a system’s operation, various configuration objects
may become orphaned as they are created and then abandoned to
accommodate changing business or application needs.

While orphaned configuration objects do not initially cause problems, if
allowed to accumulate, you can eventually encounter some of the
following issues:
\begin{itemize}
\item {} 
Performance degradation when saving or loading the configuration.

\item {} 
Increased memory and CPU utilization from monitoring unused pools and
pool members.

Note: CPU utilization is increased when monitors repeatedly mark pool
members or nodes down.

\item {} 
Hindered administration from unnecessarily large configurations that
can result in configuration conflicts such as IP address or object
name conflicts.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Identify unnecessary monitoring}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxstylestrong{Simple Monitoring}

Simple monitoring determines whether the status of a resource is up or
down. The system contains three simple monitors, Gateway ICMP, ICMP, and
TCP\_ECHO.

Simple monitors work well when you only need to determine the up or down
status of the following:
\begin{itemize}
\item {} 
A Local Traffic Manager node

\item {} 
A Global Traffic Manager or Link Controller server, virtual server,
pool, pool member, or link

\end{itemize}

\sphinxstylestrong{Active Monitoring}

Active monitoring checks the status of a pool member or node on an
ongoing basis as specified. If a pool member or node does not respond
within a specified timeout period, or the status of a node indicates
that performance is degraded, the BIG-IP system can redirect the traffic
to another pool member or node. There are many active monitors. Each
active monitor checks the status of a particular protocol, service, or
application. For example, one active monitor is HTTP. An HTTP monitor
allows you to monitor the availability of the HTTP service on a pool,
pool member, or node. A WMI monitor allows you to monitor the
performance of a node that is running the Windows Management
Instrumentation (WMI) software. Active monitors fall into two
categories: Extended Content Verification (ECV) monitors for content
checks, and Extended Application Verification (EAV) monitors for service
checks, path checks, and application checks.

An active monitor can check for specific responses and run with or
without client traffic.

Note: An active monitor also creates additional network traffic beyond
the client request and server response and can be slow to mark a pool
member as down.

\sphinxstylestrong{Passive monitoring}

Passive monitoring occurs as part of a client request. This kind of
monitoring checks the health of a pool member based on a specified
number of connection attempts or data request attempts that occur within
a specified time period. If, after the specified number of attempts
within the defined interval, the system cannot connect to the server or
receive a response, or if the system receives a bad response, the system
marks the pool member as down. There is only one passive monitor, called
an Inband monitor.

A passive monitor creates no additional network traffic beyond the
client request and server response. It can mark a pool member as down
quickly, as long as there is some amount of network traffic.

Note: A passive monitor cannot check for specific responses and can
potentially be slow to mark a pool member as up.

\sphinxstylestrong{Unnecessary Monitoring}

Monitors can be layered (meaning more than one monitor on a
configuration object) and assigned to different configuration objects
that makeup or represent an application. If you are checking the state
of a web application with an HTTP monitor on the Pool member and it is
working, it may be redundant to check the node with ICMP. It is logical
that if you can get a response back from the server at the application
level you don’t need to ping the server that is sending you the HTTP
response to know if it is up.

Example: If there is an HTTP monitor assigned to the Pool Member and it
is working, then assigning a TCP monitor checking port 80 on that Pool
Member is redundant.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Interpret configuration and performance statistics}

\sphinxstylestrong{Interpreting configuration and performance statistics}

It can be difficult when looking for configuration objects that are no
longer used in a BIG-IP configuration. One way to confirm if a
configuration object is actively being used is to look in the network
map and see all of the object on the map and where they are assigned.

\noindent\sphinxincludegraphics{{p01}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

You can also look in Statistics/Module Statistics/Local Traffic and look
at the objects in the lists to see if they are actively receiving
traffic.

\noindent\sphinxincludegraphics{{p02}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.03 - Explain the effect of removing functions from the LTM device configuration}

\sphinxurl{https://support.f5.com/csp/article/K15335}

\sphinxstylestrong{Configuration removal}

F5 recommends that you periodically audit your configuration for any
orphaned objects that can be removed from the configuration.

Impact of recommendation: You should not delete any objects until a
thorough configuration review is performed to ensure the configuration
object to be deleted is not referenced by another configuration object.
Additionally, you should save a backup of your configuration before
deleting any objects.

For example, you should review your configuration for any orphaned
configuration objects similar to the following:
\begin{itemize}
\item {} 
Virtual server that has no pools, httpclass, policy, or iRules
attached to it, and is not a Reject or Forwarding type (Layer 2 or
IP), or referenced by an iRule.

\item {} 
Custom policy that is not attached to any virtual server or
referenced by any iRule. (11.4.0 and later)

\item {} 
Custom httpclass that is not attached to any virtual server or
referenced by any iRule. (11.0.0 - 11.3.0)

\item {} 
Custom profile that is not attached to any virtual server.

\item {} 
Custom iRule that is not attached to any virtual server.

\item {} 
Pool that is not attached to any virtual server, route, httpclass,
policy, or referenced by any iRule.

\item {} 
Node that is not a member of any pool, not attached to any policy,
and is not referenced by any iRule.

\item {} 
Custom monitor that is not attached to any pool or node, and is not
the Node Default Monitor.

\end{itemize}

You can use the BIG-IP iHealth website to monitor the health and proper
operation of your BIG-IP system. Additionally, BIG-IP iHealth can
discover and report a number of orphaned objects. After uploading your
qkview file, click Config Explorer on the left of the iHealth page and
search for the Unassigned Objects entry. The number of orphaned objects
will be listed and can be viewed by clicking the down arrow on the far
right.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.04 - Given a scenario, determine the appropriate upgrade and recovery steps required to restore functionality to LTM devices}
\label{\detokenize{class7/modules/module1:objective-1-04-given-a-scenario-determine-the-appropriate-upgrade-and-recovery-steps-required-to-restore-functionality-to-ltm-devices}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify the appropriate methods for a clean install}

\sphinxurl{https://support.f5.com/csp/article/K13117}

\sphinxstylestrong{Clean Install}

On rare occasions, you may be required to perform a clean installation
of BIG-IP 11.x through 14.x. During a clean installation, you wipe all
mass-storage devices, thereby restoring the BIG-IP or Enterprise Manager
system to its factory defaults.

If your device is no longer able to boot from any of the defined boot
locations, you need to perform the clean installation using one of the
following methods.
\begin{itemize}
\item {} 
Install the software using an installation image saved on the system

\item {} 
Install the software using a USB DVD or USB thumb drive

\item {} 
Install the software using a PXE server

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify the TMSH sys software install options required to install a new version}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-tmsh-11-5-0.html}

\sphinxstylestrong{sys software module}

You can use the image component to install images onto a volume, view
information about available images, or delete unwanted images.

Before you begin installing an image, you must download the image file
into the /shared/images directory. You can find new software images at
\sphinxurl{http://downloads.f5.com}. We recommend downloading both the .iso file and
the .md5 file. Download the file (or files) to your local machine, then
transfer it to the /shared/images directory on the BIG-IP. Use the
Manager (GUI) interface to make this transfer, or quit tmsh to the Unix
command line and use scp or a similar Unix command.

If you downloaded the .md5 file, you can use the Unix md5sum command to
check the MD5 hash of the .iso file, and you can compare it to the
contents of the .md5 file. They should match. If they do not, retry the
download and/or transfer of the .iso file.

From tmsh, you can use show sys software status to see all of the
available disk volumes where you can install the .iso file. You can
install the .iso file in any volume that is not active.

Then use the install command with this component to install the .iso
file to an unused volume. You can use the create-volume option if you
want to create a new volume. The installation takes some time; you can
use show sys software status repetitively to watch the progress of the
installation. To put the .iso file into active service, use the reboot
option in the install command, or use the reboot volume vol-name command
after the install command completes.

Confirming an Image Installation

You can use show sys version to confirm that the system is running the
new software version. If this is a new module for the current system,
you may need to use show sys license and/or install sys license to
update your license. For a new module, you may also need to provision
CPU, memory, and disk space for the module with the sys provision
component.

Examples:

install image BIGIP-10.0.0.5376.0.iso volume HD1.1 reboot

Attempts to install the specified image, BIGIP-10.0.0.5376.0.iso, onto
HD1.1. Note: If the installation is successful, the machine reboots into
the newly installed image.

list image BIGIP-10.0.0.5376.0.iso

Displays information about the specified image, build 5376.0 of BIG-IP
version 10.0.0.

list image */1

Displays information about all of the images located on the first slot.

Command Options:
\begin{itemize}
\item {} 
build

\end{itemize}

Displays the build number of the image.
\begin{itemize}
\item {} 
build-date

\end{itemize}

Displays the date on which the image was built.
\begin{itemize}
\item {} 
checksum

\end{itemize}

Displays the checksum of the image. You can use this option to verify the integrity of the image.
\begin{itemize}
\item {} 
create-volume

\end{itemize}

Creates a new volume using the name specified with the volume option. Mirrored volume names must begin with the prefix MD1.. Mirrored volumes are available only on systems that support RAID, see sys raid.
\begin{itemize}
\item {} 
file-size

\end{itemize}

Displays the size of the image file in megabytes.
\begin{itemize}
\item {} 
glob

\end{itemize}

Displays the items that match the glob expression. See help glob for a description of glob expression syntax.
\begin{itemize}
\item {} 
last-modified

\end{itemize}

Displays the date the file was last modified.
\begin{itemize}
\item {} 
name

\end{itemize}

Specifies the name of the image that you want to install or delete.
\begin{itemize}
\item {} 
product

\end{itemize}

Displays the F5 product the image contains.
\begin{itemize}
\item {} 
reboot

\end{itemize}

Specifies that the system reboots immediately after a successful installation.
\begin{itemize}
\item {} 
regex

\end{itemize}

Displays the items that match the regular expression. The regular expression must be preceded by an at sign (@{[}regular expression{]}) to indicate that the identifier is a regular expression. See help regex for a description of regular expression syntax.
\begin{itemize}
\item {} 
verified

\end{itemize}

When set to yes, indicates that the image is authentic.
\begin{itemize}
\item {} 
version

\end{itemize}

Displays the version number of the product this image contains.
\begin{itemize}
\item {} 
volume

\end{itemize}

Specifies the name of the volume on which you want to install the image, or from which you want to delete the image.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/14000/000/sol14088.html}

\sphinxstylestrong{Installing A Software Image}

Installing a software image, point release, or hotfix

Once the software image, point release, or hotfix is imported, you can
install it on a boot location. When installing to a new boot location,
the new boot location is created when performing the software
installation.

Note: You can install a software image over an existing software image,
provided the boot location is not active.

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.

Using tmsh
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to tmsh by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To install a software image, point release, or software hotfix, use
the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
install /sys software \PYGZlt{}hotfix \PYG{p}{\textbar{}} image\PYGZgt{} \PYGZlt{}software\PYGZgt{}.iso volume \PYGZlt{}volume\PYGZus{}number\PYGZgt{}
\end{sphinxVerbatim}

For example, to install BIG-IP 12.0.0 to new volume HD1.5, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
install /sys software image BIGIP\PYGZhy{}12.0.0.0.0.606.iso volume HD1.5 create\PYGZhy{}volume
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
You can use tab completion in tmsh. To see the available
images for installation, press the Tab key after you type the
install sys software image command.
\end{sphinxadmonition}

\item {} 
To verify the software installation progress, type the following
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
show /sys software status
\end{sphinxVerbatim}

The command output appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Sys::Software Status

Volume Product Version Build Active Status

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

HD1.1 BIG\PYGZhy{}IP \PYG{l+m}{10}.2.4 \PYG{l+m}{577}.0 no \PYG{n+nb}{complete}

HD1.2 BIG\PYGZhy{}IP \PYG{l+m}{11}.5.2 \PYG{l+m}{0}.0.141 no \PYG{n+nb}{complete}

HD1.3 BIG\PYGZhy{}IP \PYG{l+m}{11}.5.3 \PYG{l+m}{0}.0.163 no \PYG{n+nb}{complete}

HD1.4 BIG\PYGZhy{}IP \PYG{l+m}{12}.0.0 \PYG{l+m}{0}.0.606 yes \PYG{n+nb}{complete}

HD1.5 BIG\PYGZhy{}IP \PYG{l+m}{12}.0.0 \PYG{l+m}{0}.0.606 no installing \PYG{l+m}{10}.000 pct
\end{sphinxVerbatim}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify the steps required to upgrade the LTM device such as:
license renewal, validation of upgrade path, review release notes,
etc.}

\sphinxurl{https://support.f5.com/csp/article/K84554955\#prepare}

\sphinxstylestrong{Upgrade}

Preparing for a software upgrade

Before you perform your software upgrade, F5 recommends that you make
the following preparations:
\begin{itemize}
\item {} 
When you have planned the date for the upgrade, you have the option
to open a proactive service request to reduce the time needed to
speak with a Support Engineer, should you encounter any technical
issues during the upgrade procedure. For more information, refer to
K16022: Opening a proactive service request with F5 Technical
Support.

Note: If you want F5 to provide full planning assistance during your
upgrade, you can contact Professional Services. F5 Technical Support
will answer specific questions regarding your upgrade but cannot
provide start-to-finish upgrade assistance. For more information,
refer to Scope of Support.

\item {} 
Confirm your running BIG-IP software version using the TMOS Shell
(tmsh) show /sys software status command. Note the Volume name in
case you decide to boot a previous version at a later time (HD1.1 in
the below example).

For example, the command and output on a system running BIG-IP
12.1.2 appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh show /sys software status
Sys::Software Status

Volume Product Version Build Active Status
HD1.1 BIG\PYGZhy{}IP \PYG{l+m}{12}.1.2 \PYG{l+m}{0}.0.249 yes \PYG{n+nb}{complete}
\end{sphinxVerbatim}

\item {} 
For BIG-IP 10.x systems, confirm that you are using the volume’s
disk-formatting scheme. For more information, refer to the following
two articles:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K10817}{K10817: Determining the disk-formatting scheme used by a BIG-IP
version 10.x system}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K15459}{K15459: BIG-IP systems that use partition disk style cannot be
upgraded to versions 11.0.0 or
later}

\end{itemize}

\item {} 
Check the integrity of the running configuration. For BIG-IP 11.x and
later use the tmsh load /sys config verify command. For BIG-IP 10.x
and earlier, use bigpipe verify load. The system should not return
any errors.

Note: Warnings may not hinder a software upgrade but if possible,
you should correct them before you proceed with the upgrade.

\item {} 
Reactivate the system license. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K7727}{K7727:
License activation may be required prior to a software upgrade for
the BIG-IP or Enterprise Manager
system}.

\item {} 
Verify that the BIG-IP device certificate has not expired. For more
information, refer to \sphinxhref{https://support.f5.com/csp/article/K6353}{K6353: Updating an SSL device certificate on a
BIG-IP system}.

\item {} 
For high availability (HA) BIG-IP systems, verify that all systems in
the device group are in sync. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K13920}{K13920:
Performing a ConfigSync using the Configuration
utility}.

\item {} 
Note your local admin and root user passwords in case you need them
for troubleshooting.

\item {} 
Generate a qkview diagnostics file and upload to BIG-IP iHealth to
look for any triggered upgrade-related heuristics in the Diagnostics
and Upgrade Advisor tabs. For more information about:
\begin{itemize}
\item {} 
Qkview diagnostics, refer to \sphinxhref{https://support.f5.com/csp/article/K12878}{K12878: Generating diagnostic data
using the qkview
utility}.

\item {} 
BIG-IP iHealth, refer to the \sphinxhref{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/related/bigip\_ihealth\_user\_guide.html}{BIG-IP iHealth User
Guide}.

\end{itemize}

\item {} 
Create a user configuration set (UCS) archive of the BIG-IP
configuration and save it to a secure remote location in case it is
needed for recovery purposes. Retain a UCS archive from every BIG-IP
system in your network on a remote file store to aid disaster
recovery. Even if the archive has aged and does not contain all
configuration objects, it will provide faster recovery time than if
you completely reconfigure the BIG-IP system. For more archive
information, refer to the following articles:

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K4423}{K4423: Overview of UCS archives}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K12880}{K2880: Configuring a replacement BIG-IP device after a Return Materials Authorization}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K13551}{K13551: Configuring a replacement BIG-IP device after an RMA when no UCS archive is available}

\item {} 
Beginning in 11.6.3, 12.1.3, and 13.1.0, BIG-IP software no longer
uses cumulative hotfixes. Product defects and security fixes are now
included in a full release referred to as a point release. Point
releases are identified by a fourth version element. If you intend to
install these BIG-IP versions or later versions, you should download
the point release that you plan to install from the F5
\sphinxhref{https://downloads.f5.com/}{Downloads} site. If you intend to
install versions that support hotfixes, you should download the base
BIG-IP version that you plan to install from the F5
\sphinxhref{https://downloads.f5.com/}{Downloads} site, including the latest
hotfix, if available. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K167}{K167: Downloading software and firmware from F5}.

\item {} 
Verify the integrity of the downloaded software images using the MD5
checksum utility. For more information, refer to \sphinxhref{https://support.f5.com/csp/article/K8337}{K8337: Verifying the MD5 checksum for the downloaded F5 software file}.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify how to copy a config to a previously installed boot location or slot}

\sphinxurl{https://support.f5.com/csp/article/K14724}

\sphinxstylestrong{Copying config to different boot location}

The cpcfg command allows you to copy a configuration from a specified
source boot location to another specified target boot location. The
cpcfg command uses the following syntax:

cpcfg \textless{}options\textgreater{} \textless{}destination\_location\textgreater{}

You can use the options in the following table to add functionality to
the cpcfg command.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option syntax}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Function}
\\
\hline
\textendash{}source = SLOT
&
Get configuration from specified slot (for example: HD1.1)
\\
\hline
\textendash{}verbose
&
Increase verbose level (cumulative)
\\
\hline
\textendash{}reboot
&
Immediately switch to target location after transferring configuration
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Note: The —reboot option is available only in BIG-IP 10.2.4 and BIG-IP 11.2.0 and later.

The cpcfg command has the following restrictions:
\begin{itemize}
\item {} 
The BIG-IP version of the target boot location must be the same or
later than the version of the source boot location.

If the specified target boot location is an earlier version than the
source boot location, the command fails with an error message
similar to the following example:

info: New version (11.4.0) is not \textgreater{}= originating version (11.4.1);
configuration is not compatible.

configuration roll-forward desired but not compatible.

\item {} 
You cannot specify the currently-active boot location as the target
boot location.

If the specified target boot location is the active boot location,
the command fails with an error message similar to the following
example:

Copy to active location (HD1.6) is not supported.

\item {} 
On VIPRION systems, you must run the cpcfg command with the cluster
shell (clsh) command on the primary blade.

\item {} 
If you omit the \textendash{}source=SLOT option from the command, the system
uses the currently active boot location as the source configuration.

\end{itemize}

Prerequisites

You must meet the following prerequisites to use these procedures:
\begin{itemize}
\item {} 
You must have command line access on the BIG-IP system.

\item {} 
The BIG-IP system must have multiple boot locations (volumes).

\end{itemize}

Procedures

Copying a configuration from one boot location to another

You can use the cpcfg command to copy the configuration from one boot
location to another boot location. To do so, perform the following
procedure:

Impact of procedure: The system overwrites the configuration on the
specified target boot location with the configuration of the specified
source boot location.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the BIG-IP command line.

\item {} 
Display the available boot locations by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh show sys software
\end{sphinxVerbatim}

The command output appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

Sys::Software Status

Volume Product Version Build Active Status

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

HD1.1 BIG\PYGZhy{}IP \PYG{l+m}{10}.2.4 \PYG{l+m}{577}.0 no \PYG{n+nb}{complete}

HD1.2 BIG\PYGZhy{}IP \PYG{l+m}{11}.3.0 \PYG{l+m}{2806}.0 yes \PYG{n+nb}{complete}

HD1.3 BIG\PYGZhy{}IP \PYG{l+m}{11}.4.0 \PYG{l+m}{2384}.0 no \PYG{n+nb}{complete}
\end{sphinxVerbatim}

\item {} 
Copy the configuration from the source boot location to the target
boot location using the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cpcfg \PYGZhy{}\PYGZhy{}source\PYG{o}{=}SLOT \PYGZlt{}destination\PYGZus{}location\PYGZgt{}
\end{sphinxVerbatim}

For example, to copy the configuration from boot location HD1.2 (11.3.0) to boot location HD1.3 (11.4.0) you would type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cpcfg \PYGZhy{}\PYGZhy{}source\PYG{o}{=}HD1.2 HD1.3
\end{sphinxVerbatim}

On a VIPRION system, ensure that each blade receives the updated configuration by running the cpcfg command with the cluster shell (clsh) utility on the primary blade.

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
clsh cpcfg \PYGZhy{}\PYGZhy{}source\PYG{o}{=}HD1.2 HD1.3
\end{sphinxVerbatim}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.04 - Identify valid rollback steps for a given upgrade scenario}

\sphinxstylestrong{Rollback installation}

The upgrade process will only install the new version of software to a
new volume and then copy the config forward from the current running
boot location. Since Big-IP forces you to install to a software volume
which is not currently in-use, you are able to boot back to the original
volume should there be a problem.

\sphinxurl{https://support.f5.com/csp/article/K84554955\#backout}

Backing out your software upgrade

If a BIG-IP system fails to upgrade and you cannot perform further
troubleshooting due to time constraints, complete the following steps
before reverting to the previous BIG-IP version.

Note: If you do not perform troubleshooting before reverting changes, it
may be difficult to determine a root cause for failure. If possible,
contact F5 Technical Support while the issue is occurring so you can
perform relevant data gathering, such as creating a fresh qkview file.

Gathering troubleshooting information
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
To determine what may be causing the configuration load error, run
the tmsh load /sys config command.

\item {} 
Create a qkview file.

\end{enumerate}

Using the Configuration utility to reboot
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility with administrative privileges.

\item {} 
Navigate to System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
Click the Boot Location for the previous software version.

\item {} 
Click Activate.

\item {} 
To close the confirmation message, click OK.

\end{enumerate}

Rebooting from the command line
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line.

\item {} 
To reboot to the previous software version, use the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh reboot volume \PYGZlt{}volume name\PYGZgt{}
\end{sphinxVerbatim}

For example, to reboot to volume HD1.1, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh reboot volume HD1.1
\end{sphinxVerbatim}

note:: The previously described backout procedures do not apply if you
have already reset the BIG-IP system to its default settings.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.05 - Given a scenario, determine the appropriate upgrade steps required to minimize application outages}
\label{\detokenize{class7/modules/module1:objective-1-05-given-a-scenario-determine-the-appropriate-upgrade-steps-required-to-minimize-application-outages}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Explain how to upgrade an LTM device from the GUI}

\sphinxurl{https://support.f5.com/csp/article/K84554955\#upgrade}

\sphinxstylestrong{Performing a software upgrade on a BIG-IP system}

Impact of procedure: You can upgrade the active BIG-IP system in an HA
configuration before you reboot into the new software volume. However,
if the BIG-IP system serves high volume traffic, you can perform the
upgrade during a maintenance window to lessen the impact on a busy
system. Optionally, you can perform the upgrade on the standby systems
in an HA configuration before the maintenance window to shorten the
required duration of the maintenance window.

Note: Ensure that your system is already booted into the software volume
that contains the configuration you are planning to upgrade. If the
system is not already booted into that volume, reboot your system to
that software volume before you begin the following procedure.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility with administrative privileges.

\item {} 
To upload the necessary ISO files, navigate to System \textgreater{} Software Management.

\item {} 
Click Import.

\item {} 
Click Browse to select the file to upload from your local computer.

\item {} 
Click Import.

Notes:
\begin{itemize}
\item {} 
Alternatively, you can use the Secure Copy (SCP) protocol from a
remote device to transfer images to the /shared/images/ directory on
the BIG-IP. For more information, refer to K175: Transferring files
to or from an F5 system.

\item {} 
Images automatically appear in the Configuration utility when the
system completes the upload and verifies the internal checksum.

\end{itemize}

\item {} 
If you are installing a point release, navigate to System \textgreater{} Software
Management \textgreater{} Image list. If you are installing a hotfix, navigate to
System \textgreater{} Software Management \textgreater{} Hotfix list.

Note: The BIG-IP system automatically installs the base image before
installing the hotfix to the new software volume.

\item {} 
Select the box next to the point release image or the hotfix image you want to install.

\item {} 
Click Install.

\item {} 
Select an available disk from the Select Disk menu.

\item {} 
Select an empty volume set from the Volume Set Name menu, or type a new volume set name.

Note: You can use any combination of lowercase alphanumeric
characters (a-z, 0-9) and the hyphen character. The volume set name
can be from 1 to 32 characters in length but cannot be only one 0
(zero) character (for example HD1.0 or MD1.0). For instance, if the
HD1 disk is active and you type Development into Volume set name,
the system creates a volume set named HD1.Development and installs
the specified software to the new volume set.

\item {} 
Click Install.

Note: If the string you type does not match an existing volume set,
the system creates the volume set and installs the software.

To see the installation progress, view the Install Status column of
the Installed Images section of the page.

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.05 - Describe the effect of performing an upgrade in an environment with device groups and traffic groups}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-11x-software-upgrade-11-5-0/1.html}

\sphinxstylestrong{Upgrade of device groups and traffic groups}

Preparing BIG-IP device groups for an upgrade

The following prerequisites apply when you upgrade BIG-IP device groups
from version 11.x to the new version.
\begin{itemize}
\item {} 
The BIG-IP systems (Device A, Device B, and Device C) are configured
as a device group.

\item {} 
Each BIG-IP device is running the same version of 11.x software.

\item {} 
The BIG-IP version 11.x devices are the same model of hardware.

\end{itemize}

When you upgrade a BIG-IP device group from version 11.x to the new
version, you begin by preparing the devices.

Note: If you prefer to closely observe the upgrade of each device, you
can optionally connect to the serial console port of the device that you
are upgrading.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
For each device, complete the following steps to prepare the
configuration and settings.
\begin{itemize}
\item {} 
Examine the Release Notes for specific configuration requirements,
and reconfigure the systems, as necessary.

\item {} 
Examine the Release Notes for specific changes to settings that occur
when upgrading from version 11.x to the new version, and complete any
in-process settings.

\end{itemize}

\item {} 
From the device that is running the latest configuration, synchronize
the configuration to the devices in the device group.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
For version 11.3, and later.
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Overview}. A message appears for the Status Message.

\item {} 
In the Devices area of the screen, in the Sync Status column, click the device that shows a sync status of Changes Pending.

\item {} 
Click  \sphinxstylestrong{Synchronize Device to Group}.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
For each device, create a QKView file, and upload it to iHealth.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} Support. The Support screen opens.

\item {} 
Select the QKView check box.

\item {} 
Click Start. The BIG-IP system creates a QKView file.

\item {} 
Click Download Snapshot File, and click Save. The BIG-IP system
downloads the QKView file, named
case\_number\_\#\#\#\_support\_file.qkview, into the browser’s download
folder.

\item {} 
Rename the QKView file to include a case number and an identifier. An
example of a renamed file is: c123456\_A\_support\_file.qkview.

\item {} 
Go to \sphinxurl{https://ihealth.f5.com}, and log in using your F5 WebSupport
credentials.

\item {} 
Click Upload.

\item {} 
Click Browse, navigate to the QKView file in the download folder, and
then click Open.

\item {} 
Click Upload QKView(s).

\end{itemize}

\item {} 
For each device, create a backup file.
\begin{itemize}
\item {} 
Access the tmsh command line utility.

\item {} 
At the prompt, type save /sys ucs /shared/filename.ucs.

\item {} 
Copy the backup file to a safe location on your network.

\end{itemize}

Note: For additional support information about backing up and
restoring BIG-IP system configuration files, refer to SOL11318 on
www.askf5.com.

\item {} 
Download either the latest BIG-IP system hotfix image file, if
available, or the new version software image file from the AskF5
downloads web site (\sphinxurl{http://support.f5.com/kb/en-us.htm}) to a
preferred location.

Note: Using a tool or utility that computes an md5 checksum, you can
verify the integrity of the BIG-IP system latest hotfix .iso file or
new version .iso file in the preferred location.

\item {} 
Import either the latest BIG-IP system hotfix image file, if
available, or the new version software image file to each device.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Import the latest BIG-IP system hotfix image file
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Hotfix List \textgreater{} Import.

\item {} 
Click Browse, locate and click the image file, click Open, and click Import.

\item {} 
When the hotfix image file completes uploading to the BIG-IP device, click OK. A link to the image file appears in the Software Image list.

\end{enumerate}
\\
\hline
Import the new version software image file
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Image List \textgreater{} Import.

\item {} 
Click Browse, locate and click the image file, click Open, and click Import.

\item {} 
When the software image file completes uploading to the BIG-IP device, click OK. A link to the image file appears in the Software Image list.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{6}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), the HSM client software must be available for
reinstallation.

Important: Make sure that the available version of HSM client
software supports the new version of BIG-IP software.

\end{enumerate}

The BIG-IP devices are prepared to install the latest hotfix or new
version software.

\sphinxstylestrong{Upgrading the Device A system}

The following prerequisites apply for this task.
\begin{itemize}
\item {} 
Each device must be prepared to upgrade Device A with the new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\end{itemize}

After you prepare each device for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software onto Device A.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device A to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device A. The device properties screen opens.

\item {} 
Click Force Offline. Device A changes to offline state.

\end{itemize}

Important: Once Device A changes to offline state, ensure that
traffic passes normally for all active traffic groups on the other
devices.

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP
addresses are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\end{itemize}

\item {} 
Install either the latest hotfix image, if available, or the new
version software.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Install the latest hotfix image
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Hotfix List.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click Install. The Install Software Hotfix popup screen opens.

\item {} 
From the Volume set name list, select the location of the new version software volume to install the hotfix image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
Install the new version software
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Image List.

\item {} 
In the Available Images area, select the check box for the new version software image, and click Install. The Install Software Image popup screen opens.

\item {} 
From the Volume set name list, select a location to install the image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot the device to the location of the installed new software
image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Reboot from version 11.4.0, or later
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the Install Configuration list, select Yes. The Source Volume list appears.

\item {} 
From the Source Volume list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting HD1.2:11.6.0 installs the version 11.6.0 configuration.

\item {} 
Click Activate. Device A reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), reinstall and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device before upgrading another device in the device group, to
ensure that traffic groups using the network HSM function properly.

\item {} 
Release Device A from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device A. The device properties screen opens.

\item {} 
Click Release Offline. Device A changes to standby state.

\end{itemize}

\end{enumerate}

The new version of BIG-IP software is installed on Device A, with all
traffic groups in standby state.

\sphinxstylestrong{Upgrading the Device B system}

The following prerequisites apply in upgrading Device B.
\begin{itemize}
\item {} 
Device B must be prepared to upgrade the software to new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), you must reinstall network HSM client software on
Device A before upgrading Device B, to ensure that traffic groups
using the network HSM function properly.

\item {} 
Device A (the new version BIG-IP device) is in standby state.

\end{itemize}

After you prepare Device B for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device B to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device B. The device properties screen opens.

\item {} 
Click Force Offline. Device B changes to offline state.

\end{itemize}

Important: Once Device B changes to offline state, ensure that Device A
passes traffic normally for all active traffic groups.

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP addresses
are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\end{itemize}

\item {} 
Install either the latest hotfix image, if available, or the new
version software.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Install the latest hotfix image
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Hotfix List.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click Install. The Install Software Hotfix popup screen opens.

\item {} 
From the Volume set name list, select the location of the new version software volume to install the hotfix image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
Install the new version software
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Image List.

\item {} 
In the Available Images area, select the check box for the new version software image, and click Install. The Install Software Image popup screen opens.

\item {} 
From the Volume set name list, select a location to install the image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot the Device B to the location of the installed new software
image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Reboot from version 11.4.0, or later
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the Install Configuration list, select Yes. The Source Volume list appears.

\item {} 
From the Source Volume list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting HD1.2:11.6.0 installs the version 11.6.0 configuration.

\item {} 
Click Activate. Device A reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network HSM, reinstall
and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device before upgrading another device in the device group, to
ensure that traffic groups using the network HSM function properly.

\item {} 
Release Device B from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device B. The device properties screen opens.

\item {} 
Click Release Offline. Device B changes to standby state.

\end{itemize}

\end{enumerate}

The new version of BIG-IP software is installed on Device B with
configured traffic groups in standby state.

\sphinxstylestrong{Upgrading the Device C system}

The following prerequisites apply in upgrading Device C.
\begin{itemize}
\item {} 
Device C must be prepared to upgrade the software to new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), you must reinstall network HSM client software on
Device B before upgrading Device C, to ensure that traffic groups
using the network HSM function properly.

\item {} 
Device C is in active state.

\end{itemize}

After you prepare Device C for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device C to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device C. The device properties screen opens.

\item {} 
Click Force Offline. Device C changes to offline state.

\end{itemize}

Important: Once Device C changes to offline state, ensure that the
other devices pass traffic normally for all active traffic group

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP
addresses are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\end{itemize}

\item {} 
Install either the latest hotfix image, if available, or the new
version software.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Install the latest hotfix image
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Hotfix List.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click Install. The Install Software Hotfix popup screen opens.

\item {} 
From the Volume set name list, select the location of the new version software volume to install the hotfix image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
Install the new version software
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Image List.

\item {} 
In the Available Images area, select the check box for the new version software image, and click Install. The Install Software Image popup screen opens.

\item {} 
From the Volume set name list, select a location to install the image, and click Install.

Important: In the Install Status list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot the Device B to the location of the installed new software image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Reboot from version 11.4.0, or later
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the Install Configuration list, select Yes. The Source Volume list appears.

\item {} 
From the Source Volume list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting HD1.2:11.6.0 installs the version 11.6.0 configuration.

\item {} 
Click Activate. Device A reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), reinstall and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device, to ensure that traffic groups using the network HSM function
properly.

\item {} 
Release Device C from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device C. The device properties screen opens.

\item {} 
Click Release Offline. Device C changes to standby state.

\end{itemize}

\item {} 
On the Main tab, click Device Management \textgreater{} Overview.

\item {} 
In the Devices area of the screen, in the Sync Status column, select
the device that shows a sync status of Changes Pending.

\item {} 
In the Sync Options area of the screen, select Sync Device to Group.

\item {} 
Click Sync.

\end{enumerate}

The new version of BIG-IP software is installed on Device C with
configured traffic groups in standby state.

\sphinxstylestrong{Changing states of the traffic groups}

Manually configuring active state traffic groups across devices within a
device group involves forcing an active state traffic group on a device
to standby state, and retargeting that active state traffic group to a
different device. Completing these tasks results in active state traffic
groups on the appropriate devices in a device group.

\sphinxstylestrong{Viewing a list of traffic groups for a device}

You can view a list of traffic groups for the device group. Using this
list, you can add floating IP addresses to a traffic group, force a
traffic group into a Standby state, and view information such as the
current and next-active devices for a traffic group and its HA load
factor.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, view the names of the traffic groups on the local
device.

\end{enumerate}

\sphinxstylestrong{Forcing a traffic group to a standby state}

You perform this task when you want the selected traffic group on the
local device to fail over to another device (that is, switch to a
Standby state). Users typically perform this task when no automated
method is configured for a traffic group, such as auto-failback or an HA
group. By forcing the traffic group into a Standby state, the traffic
group becomes active on another device in the device group. For device
groups with more than two members, you can choose the specific device to
which the traffic group fails over.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the device on which the traffic group is currently active.

\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, locate the name of the traffic group that you
want to run on the peer device.

\item {} 
Select the check box to the left of the traffic group name. If the
check box is unavailable, the traffic group is not active on the
device to which you are currently logged in. Perform this task on the
device on which the traffic group is active.

\item {} 
Click Force to Standby. This displays target device options.

\item {} 
Choose one of these actions:
\begin{itemize}
\item {} 
If the device group has two members only, click Force to Standby. This displays the
list of traffic groups for the device group and causes the local device to appear in
the Next Active Device column.

\item {} 
If the device group has more than two members, then from the Target Device list,
select a value and click Force to Standby.

\end{itemize}

\end{enumerate}

The selected traffic group is now in a standby state on the local device
and active on another device in the device group.

\sphinxstylestrong{Verifying a BIG-IP device group upgrade}

When you have completed upgrading the BIG-IP device group from version
11.x to the new version, you should verify that the upgraded
configuration is working properly.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Verify the Platform configuration for each device.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} Platform.

\item {} 
For the Root Folder Device Group setting, verify that the device
group is identical on each device.

\item {} 
From the Root Folder Traffic Group list, verify that the correct
traffic group (traffic-group-1) is selected.

\end{itemize}

\item {} 
Verify the configuration for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Verify the following information for the device and the peer devices.
\begin{itemize}
\item {} 
active-standby status

\item {} 
device name

\item {} 
management IP address

\item {} 
hostname

\item {} 
TMOS version

\end{itemize}

\item {} 
On the Main menu, click Device Management \textgreater{} Device Trust \textgreater{} Peer List.

\item {} 
Verify that the peer devices are specified as Peer Authority Devices.

Note: Ensure that all information for each peer device appears
correctly and completely.

\end{itemize}

\item {} 
Verify the traffic groups for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Traffic Groups.

\item {} 
From the Name list, click a traffic group.

\item {} 
If you configured MAC Masquerade addresses for VLANs on the devices,
verify that the traffic-group-1 includes an address in the MAC
Masquerade Address field.

\item {} 
Verify that the floating traffic group is correct.

\item {} 
Verify that the failover objects are correct.

\end{itemize}

\item {} 
Verify the Current ConfigSync State for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Overview.

\item {} 
In the Devices area of the screen, in the Sync Status column, verify
that each device shows a sync status of green.

\end{itemize}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-11x-software-upgrade-11-5-0/1.html}

\sphinxstylestrong{Introduction to upgrading version 11.x BIG-IP software}

Version 11.x BIG-IP systems are typically configured to employ the
functionality of a device group. When you upgrade version 11.x BIG-IP
software for a BIG-IP system device group, to the new version software,
you can use a simple sequence of steps to successfully upgrade each
device within the device group. The following steps enable you to
prepare for a software upgrade, perform the upgrade, and then verify
that the upgrade successfully completed.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Preparing BIG-IP modules for an upgrade

\item {} 
Preparing BIG-IP device groups for an upgrade

\item {} 
Upgrading each device within the device group

\item {} 
Changing states of the traffic groups

\item {} 
Configuring HA groups (if applicable)

\item {} 
Configuring module-specific settings

\item {} 
Verifying the software upgrade for the device group

\end{enumerate}

\sphinxstylestrong{Overview: Upgrading a version 11.x BIG-IP device group}

A BIG-IP system device group for version 11.x includes two or more
BIG-IP systems, with one or more traffic groups operating in active
state. In this example, a version 11.x device group includes one BIG-IP
system with traffic-group-1 operating in active state (Device A), one
BIG-IP system with traffic-group-2 operating in active state (Device B),
and one BIG-IP system with traffic-group-3 operating in active state
(Device C).

Important: If your version 11.x device group includes HA groups, note
that an HA group applies to the respective device in version 11.0
through 11.4.x, whereas an HA group applies to a traffic group on the
device in version 11.5, and later.

\noindent\sphinxincludegraphics{{p03}.png}


\bigskip\hrule\bigskip


\sphinxstylestrong{A version 11.x device group}

When upgrading an 11.x device group to the new version software, you
first need to prepare your devices. After preparing the devices, you
force Device A to offline state, and install the new version software
onto Device A. When you finish the installation of the new version
software onto Device A, the traffic groups remain in standby state on
Device A, and in active state on Device B and Device C.

Important: Once Device A reboots, if the BIG-IP system is configured to
use a network hardware security module (HSM), you must reinstall network
HSM client software on Device A before upgrading Device B, to ensure
that traffic groups using the network HSM function properly.

\noindent\sphinxincludegraphics{{p04}.png}


\bigskip\hrule\bigskip


A device group with Device A upgraded to the new version software, and
traffic groups in standby state

With the new version software installed on Device A and all traffic
groups in standby state, you force Device B to offline state, changing
the traffic groups on Device A to active state so that they can pass
traffic. You can then install the new version software onto Device B,
and reboot Device B to the location of the new version software image.

Important: Once Device B reboots, if the BIG-IP system is configured to
use a network HSM, you must reinstall network HSM client software on
Device B before upgrading Device C, to ensure that traffic groups using
the network HSM function properly.

\noindent\sphinxincludegraphics{{p05}.png}


\bigskip\hrule\bigskip


\sphinxstylestrong{A device group with Device B upgraded to the new version software, and traffic groups in standby state}

Once Device B reboots, you can force Device C to offline state, making
traffic-group-3 active on Device B. When you complete upgrading Device C
to the new version software and reboot Device C, the BIG-IP
configuration includes traffic-group-1 and traffic-group-2 in active
state on Device A, traffic-group-3 in active state on Device B, and a
device group that includes all devices. If you use HA groups, observe
that the HA group on Device A, Device B, and Device C applies to each
traffic group.

Important: Once Device C reboots, if the BIG-IP system is configured to
use a network HSM, you must reinstall network HSM client software on
Device C, to ensure that traffic groups using the network HSM function
properly.

\noindent\sphinxincludegraphics{{p06}.png}


\bigskip\hrule\bigskip


\sphinxstylestrong{A device group with all devices upgraded to the new version software}

Once each device is upgraded to the new version software, you can
reconfigure the traffic groups to become active on the devices that you
want by forcing the active traffic group on a device to standby state.
When forcing the traffic group to standby state, you can target the
device upon which you want that traffic group to run in active state.
For example, you can force traffic-group-2 on Device A into standby
state, and into active state on Device B, and then force traffic-group-3
on Device B into standby state, and into active state on Device C.
Additionally, if you use HA groups, you can create a unique HA group for
each traffic group on each device.

\noindent\sphinxincludegraphics{{p07}.png}

A device group with an active traffic group on each device


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Task}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Preparing the devices in the device group
&
In preparing to upgrade the BIG-IP systems to the new version software, you need to understand any specific configuration or functional changes from the previous version, and prepare the systems. You also download the new version of software from the AskF5 web site (\sphinxurl{http://support.f5.com/kb/en-us.html}) and import the files onto each device.
\\
\hline
Upgrading Device A
&
When you complete preparation of Device A, you can force that device to offline state, changing those traffic groups to active state on another device in the traffic group, and then upgrade the software on Device A.

Important:  Once Device A reboots, if the BIG-IP system is configured to use a network HSM, you must reinstall network HSM client software on Device A before upgrading Device B, to ensure that traffic groups using the network HSM function properly.
\\
\hline
Upgrading Device B
&
When you complete preparation of Device B, you can force that device to offline state, changing those traffic groups to active state on another device in the traffic group, and then upgrade the software on Device B.

Important: Once Device B reboots, if the BIG-IP system is configured to use a network HSM, you must reinstall network HSM client software on Device B before upgrading Device C, to ensure that traffic groups using the network HSM function properly.
\\
\hline
Upgrading Device C
&
When you complete preparation of Device C, you can force that device to offline state, changing those traffic groups to active state on another device in the traffic group, and then upgrade the software on Device C.

Important: Once Device C reboots, if the BIG-IP system is configured to use a network HSM, you must reinstall network HSM client software on Device C to ensure that traffic groups using the network HSM function properly.
\\
\hline
Changing states of traffic groups
&
When you finish upgrading all of the devices, you can restore the configuration of active traffic groups on each device.
\\
\hline
Verifying the upgrade
&
Finally, you should verify that the BIG-IP device group is functioning properly.
\\
\hline
Configuring HA groups
&
When you finish upgrading a device, the HA group on the device (in version 11.5, and later) applies to a traffic group, as opposed to the device. You can create a unique HA group for each traffic group on each device, as necessary.
\\
\hline
Configuring module-specific settings
&
According to your understanding of the configuration and functional changes from the previous version, you can reconfigure any customized module settings.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\sphinxstylestrong{DSC components}

Device service clustering (DSC) is based on a few key components.

Devices

A device is a physical or virtual BIG-IP system, as well as a member
of a local trust domain and a device group. Each device member has a
set of unique identification properties that the BIG-IP system
generates. For device groups configured for failover, it is
important that the device with the smallest capacity has the
capacity to process all traffic groups. This ensures application
availability in the event that all but one device in the device
group become unavailable for any reason.

Device groups

A device group is a collection of BIG-IP devices that trust each
other and can synchronize, and sometimes fail over, their BIG-IP
configuration data. You can create two types of devices groups: A
Sync-Failover device group contains devices that synchronize
configuration data and support traffic groups for failover purposes
when a device becomes unavailable. A Sync-Only device group contains
devices that synchronize configuration data, such as policy data,
but do not synchronize failover objects. The BIG-IP system supports
either homogeneous or heterogeneous hardware platforms within a
device group.

Important: BIG-IP module provisioning must be equivalent on all
devices within a device group. For example, module provisioning is
equivalent when all device group members are provisioned to run
BIG-IP Local Traffic Manager (LTM) and BIG-IP Application Security
Manager (ASM) only. Maintaining equivalent module provisioning on
all devices ensures that any device in the device group can process
module-specific application traffic in the event of failover from
another device.

Traffic groups

A traffic group is a collection of related configuration objects
(such as a virtual IP address and a self IP address) that run on a
BIG-IP device and process a particular type of application traffic.
When a BIG-IP device becomes unavailable, a traffic group can float
to another device in a device group to ensure that application
traffic continues to be processed with little to no interruption in
service.

Device trust and trust domains

Underlying the success of device groups and traffic groups is a
feature known as device trust. Device trust establishes trust
relationships between BIG-IP devices on the network, through mutual
certificate-based authentication. A trust domain is a collection of
BIG-IP devices that trust one another and can therefore synchronize
and fail over their BIG-IP configuration data, as well as exchange
status and failover messages on a regular basis. A local trust
domain is a trust domain that includes the local device, that is,
the device you are currently logged in to.

Folders

Folders are containers for the configuration objects on a BIG-IP
device. For every administrative partition on the BIG-IP system,
there is a high-level folder. At the highest level of the folder
hierarchy is a folder named root. The BIG-IP system uses folders to
affect the level of granularity to which it synchronizes
configuration data to other devices in the device group.

\sphinxstylestrong{About traffic groups}

A traffic group is a collection of related configuration objects, such
as a floating self IP address, a virtual IP address, and a SNAT
translation address, that run on a BIG-IP device. Together, these
objects process a particular type of application traffic on that device.
When a BIG-IP device becomes unavailable, a traffic group floats (that
is, fails over) to another device in a device group to ensure that
application traffic continues to be processed with little to no
interruption in service. In general, a traffic group ensures that when a
device becomes unavailable, all of the failover objects in the traffic
group fail over to any one of the available devices in the device group.

A traffic group is initially active on the device on which you create
it, until the traffic group fails over to another device. For example,
if you initially create three traffic groups on Device A, these traffic
groups remain active on Device A until one or more traffic groups fail
over to another device. If you want an active traffic group to become
active on a different device in the device group when failover has not
occurred, you can intentionally force the traffic group to switch to a
standby state, thereby causing failover to another device.

Only objects with floating IP addresses can be members of a floating
traffic group.

An example of a set of objects in a traffic group is an iApps
application service. If a device with this traffic group is a member of
a device group, and the device becomes unavailable, the traffic group
floats to another member of the device group, and that member becomes
the device that processes the application traffic.

Note: A Sync-Failover device group can support a maximum of 15 floating
traffic groups.

\sphinxstylestrong{About forcing a device offline}

You can force a BIG-IP device into an offline state, which stops that
device from processing or responding to local traffic connections. When
the device is in offline state, you can upgrade the software on that
device or perform maintenance on that device.

When the BIG-IP system is forced offline, it terminates existing
connections to local traffic objects, such as virtual servers, SNATs,
and so on. In the forced offline state, the BIG-IP system does not allow
new connections.

For BIG-IP systems running software version 11.1.0 and later, the Force
Offline status persists through system reboots and upgrades. For BIG-IP
systems running software versions earlier than 11.1.0, the Force Offline
status does not persist through system reboots.

The BIG-IP system allows administrative connections to the management
address to continue, but handles administrative connections to self IP
addresses differently, depending on the platform:

On appliance systems, the system maintains connections to self IP
addresses.

On VIPRION systems, the system terminates connections to self IP
addresses, and does not allow new connections.

Note: When you force a chassis system offline, the Traffic Management
Microkernel (TMM) interfaces remain configured until the unit is
rebooted. If the chassis is rebooted while Force Offline is enabled, the
system marks all TMM interfaces as Uninitialized or Missing. This
behavior is by design. The system will not attempt to initialize and
bring up TMM interfaces while the system is in the offline state.

When you force VIPRION platforms offline, make sure to manage the system
by using the management port or console. The system terminates
connections to self IP addresses when you force the platform offline.

You will want to force the standby devices offline before you change the
redundancy state (such as resetting the device trust for a device
group). Forcing standby devices into offline state prevents a standby
device from unexpectedly becoming active.

\sphinxstylestrong{Task summary}

The upgrade process involves preparation of the BIG-IP devices (Device
A, Device B, and Device C) configured in device group, followed by the
installation and verification of the new version software on each
device. When you upgrade each device, you perform several tasks.
Completing these tasks results in a successful upgrade to the new
version software on all BIG-IP devices, with the device group configured
properly.

\sphinxstylestrong{Local Traffic Manager system preparation}

The BIG-IP Local Traffic Manager (LTM) system does not require specific
preparation when upgrading from version 11.x to the new version
software. No additional configuration is required after completing the
upgrade to the new version software.

\sphinxstylestrong{HTTP Class profiles}

F5 replaced the HTTP Class profile in BIG-IP version 11.4.0,
and later, with the introduction of the Local Traffic Policies feature.
During an upgrade to BIG-IP version 11.4.0, if your configuration
contains an HTTP Class profile, the BIG-IP system attempts to migrate
the HTTP Class profile to an equivalent local traffic policy. For
additional support information regarding the change of HTTP Class
profiles to Local Traffic Policies, refer to SOL14409 on www.askf5.com.

\sphinxstylestrong{Policy Enforcement Manager system preparation}

The BIG-IP Policy Enforcement Manager (PEM) system does not require
specific preparation when upgrading from version 11.x to the new version
software. No additional configuration is required after completing the
upgrade to the new version software.

\sphinxstylestrong{Preparing BIG-IP device groups for an upgrade}

The following prerequisites apply when you upgrade BIG-IP device groups
from version 11.x to the new version.
\begin{itemize}
\item {} 
The BIG-IP systems (Device A, Device B, and Device C) are configured
as a device group.

\item {} 
Each BIG-IP device is running the same version of 11.x software.

\item {} 
The BIG-IP version 11.x devices are the same model of hardware.

\end{itemize}

When you upgrade a BIG-IP device group from version 11.x to the new
version, you begin by preparing the devices.

Note: If you prefer to closely observe the upgrade of each device, you
can optionally connect to the serial console port of the device that you
are upgrading.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
For each device, complete the following steps to prepare the
configuration and settings.

\end{enumerate}
\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Examine the Release Notes for specific configuration requirements,
and reconfigure the systems, as necessary.

\item {} 
Examine the Release Notes for specific changes to settings that occur
when upgrading from version 11.x to the new version, and complete any
in-process settings.

\end{enumerate}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
From the device that is running the latest configuration, synchronize
the configuration to the devices in the device group.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{For version 11.2, and earlier.}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Device Groups}. A list of device groups appears.

\item {} 
In the Group Name column, click the name of a device group.

\item {} 
On the menu bar, click  \sphinxstylestrong{ConfigSync}.

\item {} 
Click  \sphinxstylestrong{Synchronize To Group}.

\end{enumerate}
\\
\hline
\sphinxstylestrong{For version 11.3, and later.}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Overview}. A message appears for the Status Message.

\item {} 
In the Devices area of the screen, in the Sync Status column, click the device that shows a sync status of Changes Pending.

\item {} 
Click  \sphinxstylestrong{Synchronize Device to Group}.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
For each device, create a QKView file, and upload it to iHealth.
\begin{itemize}
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Support}. The Support screen opens.

\item {} 
Select the  \sphinxstylestrong{QKView} check box.

\item {} 
Click  \sphinxstylestrong{Start}. The BIG-IP system creates a QKView file.

\item {} 
Click  \sphinxstylestrong{Download Snapshot File}, and click  \sphinxstylestrong{Save}. The
BIG-IP system downloads the QKView file,
namedcase\_number\_\#\#\#\_support\_file.qkview, into the browser’s
download folder.

\item {} 
Rename the QKView file to include a case number and an
identifier. An example of a renamed file
is:c123456\_A\_support\_file.qkview.

\item {} 
Go to \sphinxurl{https://ihealth.f5.com}, and log in using your F5 WebSupport
credentials.

\item {} 
Click  \sphinxstylestrong{Upload}.

\item {} 
Click  \sphinxstylestrong{Browse}, navigate to the QKView file in the download
folder, and then click  \sphinxstylestrong{Open}.

\item {} 
Click  \sphinxstylestrong{Upload QKView(s)}.

\end{itemize}

\item {} 
For each device, create a backup file.
\begin{itemize}
\item {} 
Access the  \sphinxstylestrong{tmsh} command line utility.

\item {} 
At the prompt, type  \sphinxstylestrong{save /sys ucs /shared/filename.ucs}.

\item {} 
Copy the backup file to a safe location on your network.

\end{itemize}

Note: For additional support information about backing up and
restoring BIG-IP system configuration files, refer to SOL11318
on www.askf5.com.

\item {} 
Download either the latest BIG-IP system hotfix image file, if
available, or the new version software image file from the AskF5
downloads web site (\sphinxurl{http://support.f5.com/kb/en-us.htm}) to a
preferred location.

Note: Using a tool or utility that computes an md5 checksum,
you can verify the integrity of the BIG-IP system latest
hotfix .isofile or new version .iso file in the preferred location.

\item {} 
Import either the latest BIG-IP system hotfix image file, if
available, or the new version software image file to each device.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Import the latest BIG-IP system hotfix image file}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Hotfix List} \textgreater{} \sphinxstylestrong{Import}.

\item {} 
Click  \sphinxstylestrong{Browse}, locate and click the image file, click  \sphinxstylestrong{Open}, and click  \sphinxstylestrong{Import}.

\item {} 
When the hotfix image file completes uploading to the BIG-IP device, click  \sphinxstylestrong{OK}. A link to the image file appears in the Software Image list.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Import the new version software image file}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Image List} \textgreater{} \sphinxstylestrong{Import}.

\item {} 
Click  \sphinxstylestrong{Browse}, locate and click the image file, click  \sphinxstylestrong{Open}, and click  \sphinxstylestrong{Import}.

\item {} 
When the software image file completes uploading to the BIG-IP device, click  \sphinxstylestrong{OK}. A link to the image file appears in the Software Image list.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{6}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), the HSM client software must be available for
reinstallation.

\end{enumerate}

Important: Make sure that the available version of HSM client software
supports the new version of BIG-IP software.

The BIG-IP devices are prepared to install the latest hotfix or new
version software.

\sphinxstylestrong{Upgrading the Device A system}

The following prerequisites apply for this task.
\begin{itemize}
\item {} 
Each device must be prepared to upgrade Device A with the new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\end{itemize}

After you prepare each device for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software onto Device A.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device A to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device A. The device properties screen opens.

\item {} 
Click Force Offline. Device A changes to offline state.

\end{itemize}

Important: Once Device A changes to offline state, ensure that
traffic passes normally for all active traffic groups on the other
devices.

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP
addresses are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\item {} 
Install either the latest hotfix image, if available, or the new
version software.

\end{itemize}

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Install the latest hotfix image}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Hotfix List}.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click \sphinxstylestrong{Install}. The Install Software Hotfix popup screen opens.

\item {} 
From the \sphinxstylestrong{Volume set name} list, select the location of the new version software volume to install the hotfix image, and click \sphinxstylestrong{Install}.

Important: In the \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Install the new version software}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Image List}.

\item {} 
In the Available Images area, select the check box for the new version software image, and click \sphinxstylestrong{Install}. The Install Software Image popup screen opens.

\item {} 
From the \sphinxstylestrong{Volume set name} list, select a location to install the image, and click \sphinxstylestrong{Install}.

Important: In the \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot the device to the location of the installed new software
image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Reboot from version 11.3.0, or earlier}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
Note: Upgrading from version 11.3.0, or earlier, automatically installs the configuration of that version to the new boot location.

\item {} 
Click Activate. Device A reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Reboot from version 11.4.0, or later}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click System \textgreater{} Software Management \textgreater{} Boot Locations.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the Install Configuration list, select Yes. The Source Volume list appears.

\item {} 
From the Source Volume list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting HD1.2:11.6.0 installs the version 11.6.0 configuration.

\item {} 
Click Activate. Device A reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), reinstall and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device before upgrading another device in the device group, to
ensure that traffic groups using the network HSM function properly.

\item {} 
Release Device A from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device A. The device properties screen opens.

\item {} 
Click Release Offline. Device A changes to standby state.

\end{itemize}

\end{enumerate}

The new version of BIG-IP software is installed on Device A, with all
traffic groups in standby state.

\sphinxstylestrong{Upgrading the Device B system}

The following prerequisites apply in upgrading Device B.
\begin{itemize}
\item {} 
Device B must be prepared to upgrade the software to new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), you must reinstall network HSM client software on
Device A before upgrading Device B, to ensure that traffic groups
using the network HSM function properly.

\item {} 
Device A (the new version BIG-IP device) is in standby state.

\end{itemize}

After you prepare Device B for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device B to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device B. The device properties screen opens.

\item {} 
Click Force Offline. Device B changes to offline state.

\end{itemize}

Important: Once Device B changes to offline state, ensure that
Device A passes traffic normally for all active traffic groups.

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP
addresses are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\end{itemize}

\item {} 
Install either the latest hotfix image, if available, or the new version software.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Install the latest hotfix image}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Hotfix List}.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click  \sphinxstylestrong{Install}. The Install Software Hotfix popup screen opens.

\item {} 
From the  \sphinxstylestrong{Volume set name} list, select the location of the new version software volume to install the hotfix image, and click  \sphinxstylestrong{Install}.

Important: In the  \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Install the new version software}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Image List}.

\item {} 
In the Available Images area, select the check box for the new version software image, and click \sphinxstylestrong{Install}. The Install Software Image popup screen opens.

\item {} 
From the  \sphinxstylestrong{Volume set name} list, select a location to install the image, and click  \sphinxstylestrong{Install}.

Important: In the  \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot the Device B to the location of the installed new software image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Reboot from version 11.3.0, or earlier}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Boot Locations}.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

Note: Upgrading from version 11.3.0, or earlier, automatically installs the configuration of that version to the new boot location.

\end{enumerate}
\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Click  \sphinxstylestrong{Activate}. Device B reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Reboot from version 11.4.0, or later}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Boot Locations}.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the  \sphinxstylestrong{Install Configuration} list, select  \sphinxstylestrong{Yes}. The  \sphinxstylestrong{Source Volume} list appears.

\item {} 
From the  \sphinxstylestrong{Source Volume} list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting  \sphinxstylestrong{HD1.2:11.6.0} installs a version 11.6.0 configuration.

\item {} 
Click  \sphinxstylestrong{Activate}. Device B reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network HSM, reinstall
and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device before upgrading another device in the device group, to
ensure that traffic groups using the network HSM function properly.

\item {} 
Release Device B from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device B. The device properties screen opens.

\item {} 
Click Release Offline. Device B changes to standby state.

\end{itemize}

\end{enumerate}

The new version of BIG-IP software is installed on Device B with
configured traffic groups in standby state.

\sphinxstylestrong{Upgrading the Device C system}

The following prerequisites apply in upgrading Device C.
\begin{itemize}
\item {} 
Device C must be prepared to upgrade the software to new version
software.

\item {} 
Either the latest hotfix image file, if available, or the new version
software image file is downloaded and accessible.

\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), you must reinstall network HSM client software on
Device B before upgrading Device C, to ensure that traffic groups
using the network HSM function properly.

\item {} 
Device C is in active state.

\end{itemize}

After you prepare Device C for upgrading the software, you force the
device offline, reactivate the software license, and install the new
version software.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Force Device C to offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device C. The device properties screen opens.

\item {} 
Click Force Offline. Device C changes to offline state.

\end{itemize}

Important: Once Device C changes to offline state, ensure that the
other devices pass traffic normally for all active traffic groups.

Note: When Force Offline is enabled, make sure to manage the system
using the management port or console. Connections to self IP
addresses are terminated when Force Offline is enabled.

\item {} 
Reactivate the software license.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} License.

\item {} 
Click Re-activate.

\item {} 
For the Activation Method setting, select the Automatic (requires
outbound connectivity) option.

\item {} 
Click Next. The BIG-IP software license renews automatically.

\item {} 
Click Continue.

\end{itemize}

\item {} 
Install either the latest hotfix image, if available, or the new version software.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Install the latest hotfix image}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Hotfix List}.

\item {} 
In the Available Images area, select the check box for the hotfix image, and click  \sphinxstylestrong{Install}. The Install Software Hotfix popup screen opens.

\item {} 
From the  \sphinxstylestrong{Volume set name} list, select the location of the new version software volume to install the hotfix image, and click  \sphinxstylestrong{Install}.

Important: In the  \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Install the new version software}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Image List}.

\item {} 
In the Available Images area, select the check box for the new version software image, and click \sphinxstylestrong{Install}. The Install Software Image popup screen opens.

\item {} 
From the  \sphinxstylestrong{Volume set name} list, select a location to install the image, and click  \sphinxstylestrong{Install}.

Important: In the  \sphinxstylestrong{Install Status} list for the specified location, a progress bar indicates the status of the installation. Ensure that installation successfully completes, as indicated by the progress bar, before proceeding.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Reboot Device C to the location of the installed new software image.

\end{enumerate}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Reboot from version 11.3.0, or earlier}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Boot Locations}.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

Note: Upgrading from version 11.3.0, or earlier, automatically installs the configuration of that version to the new boot location.

\end{enumerate}
\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Click  \sphinxstylestrong{Activate}. Device C reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\sphinxstylestrong{Reboot from version 11.4.0, or later}
&\begin{enumerate}
\def\theenumi{\alph{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main menu, click  \sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management} \textgreater{} \sphinxstylestrong{Boot Locations}.

\item {} 
In the Boot Location list, click the boot location of the installed new software image.

\item {} 
From the  \sphinxstylestrong{Install Configuration} list, select  \sphinxstylestrong{Yes}. The  \sphinxstylestrong{Source Volume} list appears.

\item {} 
From the  \sphinxstylestrong{Source Volume} list, select the location of the configuration to install when activating the boot location of the new software image. For example, for an installation of a new software image on HD1.3, selecting  \sphinxstylestrong{HD1.2:11.6.0} installs a version 11.6.0 configuration.

\item {} 
Click  \sphinxstylestrong{Activate}. Device C reboots to the new software image boot location in offline state.

Note: If the device appears to be taking a long time to reboot, do not cycle the power off and on. Instead, verify the status of the device by connecting to its serial console port. The device might be performing firmware upgrades.

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
If the BIG-IP system is configured to use a network hardware security
module (HSM), reinstall and configure the HSM client software.

Important: You must reinstall network HSM client software on this
device, to ensure that traffic groups using the network HSM function
properly.

\item {} 
Release Device C from offline state.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Click the name of Device C. The device properties screen opens.

\item {} 
Click Release Offline. Device C changes to standby state.

\item {} 
On the Main tab, click Device Management \textgreater{} Overview.

\end{itemize}

\end{enumerate}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{7}
\item {} 
In the Devices area of the screen, in the Sync Status column, select
the device that shows a sync status of Changes Pending.

\item {} 
In the Sync Options area of the screen, select Sync Device to Group.

\item {} 
Click Sync.

\end{enumerate}

The new version of BIG-IP software is installed on Device C with
configured traffic groups in standby state.

\sphinxstylestrong{Changing states of the traffic groups}

Manually configuring active state traffic groups across devices within a
device group involves forcing an active state traffic group on a device
to standby state, and retargeting that active state traffic group to a
different device. Completing these tasks results in active state traffic
groups on the appropriate devices in a device group.

\sphinxstylestrong{Viewing a list of traffic groups for a device}

You can view a list of traffic groups for the device group. Using this
list, you can add floating IP addresses to a traffic group, force a
traffic group into a Standby state, and view information such as the
current and next-active devices for a traffic group and its HA load
factor.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, view the names of the traffic groups on the local
device.

\end{enumerate}

\sphinxstylestrong{Forcing a traffic group to a standby state}

You perform this task when you want the selected traffic group on the
local device to fail over to another device (that is, switch to a
Standby state). Users typically perform this task when no automated
method is configured for a traffic group, such as auto-failback or an HA
group. By forcing the traffic group into a Standby state, the traffic
group becomes active on another device in the device group. For device
groups with more than two members, you can choose the specific device to
which the traffic group fails over.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the device on which the traffic group is currently active.

\item {} 
On the Main tab, click Device Management \textgreater{} Traffic Groups.

\item {} 
In the Name column, locate the name of the traffic group that you
want to run on the peer device.

\item {} 
Select the check box to the left of the traffic group name. If the
check box is unavailable, the traffic group is not active on the
device to which you are currently logged in. Perform this task on the
device on which the traffic group is active.

\item {} 
Click Force to Standby. This displays target device options.

\item {} 
Choose one of these actions:

\end{enumerate}
\begin{itemize}
\item {} 
If the device group has two members only, click Force to Standby.
This displays the list of traffic groups for the device group and
causes the local device to appear in the Next Active Device column.

\item {} 
If the device group has more than two members, then from the Target
Device list, select a value and click Force to Standby.

\end{itemize}

The selected traffic group is now in a standby state on the local device
and active on another device in the device group.

\sphinxstylestrong{Verifying a BIG-IP device group upgrade}

When you have completed upgrading the BIG-IP device group from version
11.x to the new version, you should verify that the upgraded
configuration is working properly.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Verify the Platform configuration for each device.
\begin{itemize}
\item {} 
On the Main menu, click System \textgreater{} Platform.

\item {} 
For the Root Folder Device Group setting, verify that the device
group is identical on each device.

\item {} 
From the Root Folder Traffic Group list, verify that the correct
traffic group (traffic-group-1) is selected.

\end{itemize}

\item {} 
Verify the configuration for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Devices.

\item {} 
Verify the following information for the device and the peer devices.
\begin{itemize}
\item {} 
active-standby status

\item {} 
device name

\item {} 
management IP address

\item {} 
hostname

\item {} 
TMOS version

\end{itemize}

\item {} 
On the Main menu, click Device Management \textgreater{} Device Trust \textgreater{} Peer List.

\item {} 
Verify that the peer devices are specified as Peer Authority Devices.

\end{itemize}

Note: Ensure that all information for each peer device appears
correctly and completely.

\item {} 
Verify the traffic groups for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Traffic Groups.

\item {} 
From the Name list, click a traffic group.

\item {} 
If you configured MAC Masquerade addresses for VLANs on the devices,
verify that the traffic-group-1 includes an address in the MAC
Masquerade Address field.

\item {} 
Verify that the floating traffic group is correct.

\item {} 
Verify that the failover objects are correct.

\end{itemize}

\item {} 
Verify the Current ConfigSync State for each device.
\begin{itemize}
\item {} 
On the Main menu, click Device Management \textgreater{} Overview.

\item {} 
In the Devices area of the screen, in the Sync Status column, verify
that each device shows a sync status of green.

\end{itemize}

\end{enumerate}

\sphinxstylestrong{Implementation result}

Your upgrade of the BIG-IP device group from version 11.x to the new
version software is now complete. The new version software configuration
includes a device group with three devices (Device A, Device B, and
Device C) and three traffic groups (traffic-group-1, traffic-group-2,
and traffic-group-3), with a traffic group on each device in active
state.

\noindent\sphinxincludegraphics{{p08}.png}

An upgraded device group


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.06 - Describe the benefits of custom alerting within an LTM environment}
\label{\detokenize{class7/modules/module1:objective-1-06-describe-the-benefits-of-custom-alerting-within-an-ltm-environment}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Describe how to specify the OIDs for alerting}

\sphinxurl{https://support.f5.com/csp/article/K3727}

\sphinxstylestrong{Creating custom SNMP traps}

Before you create a custom trap, you must determine the unique syslog
messages for which you want the system to send alerts. The message must
not match the matched\_message value of any other SNMP trap already
defined in the /etc/alertd/alert.conf file or the
/config/user\_alert.conf file.

Note: For information about how to determine which alerts are
pre-configured to trigger an SNMP trap, refer to K6414: Determining
which alerts are pre-configured to trigger an SNMP trap. You may also
examine the alerts from the /config/user\_alert.conf file in the same
manner.

To create a custom SNMP trap, perform the following procedure:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line.

\item {} 
To back up your /config/user\_alert.conf file, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cp /config/user\PYGZus{}alert.conf /config/user\PYGZus{}alert.conf.SOL3727
\end{sphinxVerbatim}

\item {} 
Edit the /config/user\_alert.conf file.

\item {} 
Add a new SNMP trap using the following format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
alert \PYGZlt{}alert\PYGZus{}name\PYGZgt{} \PYG{l+s+s2}{\PYGZdq{}\PYGZlt{}matched message\PYGZgt{}\PYGZdq{}} \PYG{o}{\PYGZob{}}

snmptrap \PYG{n+nv}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}.1.3.6.1.4.1.3375.2.4.0.XXX\PYGZdq{}}

\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Replace \textless{}alert\_name\textgreater{} with a descriptive name. Do not use an alert name that
exactly matches one already used in the /etc/alertd/alert.conf file or the
/config/user\_alert.conf file. Replace \textless{}matched\_message\textgreater{} with text that matches the
syslog messagethat triggers the custom trap. You can specify a portion of the syslog
message text or use a regular expression. F5 recommends that you do not include the
syslog prefix information, such as the date stamp and process ID, in the match string.
Including information of a variable nature in the match string or regular expression
may result in unexpected false positives or result in no matches at all. The syslog
message you want to trap must not match the matched\_message value of any other SNMP
trap defined in the /etc/alertd/alert.conf file or the /config/user\_alert.conf file.
\end{sphinxadmonition}

\item {} 
Replace XXX with a number unique to this object ID.

You can use any object ID that meets all of the following criteria:
\begin{itemize}
\item {} 
The object ID is in standard object identifier (OID) format, and
within the following range:

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
.1.3.6.1.4.1.3375.2.4.0.300 through .1.3.6.1.4.1.3375.2.4.0.999
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
If the OID value is outside the range listed above, a trap
will be sent with the OID specified, but it will not contain any
text within the trap body.
\end{sphinxadmonition}
\begin{itemize}
\item {} 
The object ID is in a numeric range that can be processed by your
trap receiving tool.

\item {} 
The object ID does not already exist in the
/usr/share/snmp/mibs/F5-BIGIP-COMMON-MIB.txt management information
base (MIB) file.

\item {} 
The object ID is not already used in another custom trap.

\end{itemize}

\item {} 
Save the file and exit the editor.

\begin{sphinxadmonition}{note}{Note:}
If the alertd process fails to start, examine the newly added
entry to ensure it contains all of the required elements and
punctuation.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Note: To test the newly created trap, refer to K11127: Testing SNMP
traps on the BIG-IP system (9.4.x - 13.x).
\end{sphinxadmonition}

\end{enumerate}

\sphinxstylestrong{Custom SNMP trap example}

A message that appears similar to the following example is logged to the
/var/log/ltm file when switchboard failsafe is enabled:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Sep \PYG{l+m}{23} \PYG{l+m}{11}:51:40 bigip1.askf5.com lacpd\PYG{o}{[}\PYG{l+m}{27753}\PYG{o}{]}: \PYG{l+m}{01160016}:6: Switchboard
Failsafe enabled
\end{sphinxVerbatim}

To create a custom SNMP trap that is triggered whenever switchboard
failsafe status changes are logged, add the following trap definition to
the /config/user\_alert.conf file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
alert SWITCHBOARD\PYGZus{}FAILSAFE\PYGZus{}STATUS \PYG{l+s+s2}{\PYGZdq{}Switchboard Failsafe (.*)\PYGZdq{}} \PYG{o}{\PYGZob{}}

snmptrap \PYG{n+nv}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}.1.3.6.1.4.1.3375.2.4.0.500\PYGZdq{}}

\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Explain how to log different levels of local traffic message logs}

\sphinxurl{https://support.f5.com/csp/article/K5532}

\sphinxstylestrong{Log levels related to Traffic Management events}

Traffic Management events use levels to distinguish the severity of the
event. Traffic Management uses these severity levels when designating
log levels. Log levels set the threshold at which Traffic Management
event messages start accruing in the log files. Traffic Management event
messages equal to and greater than the specified log level are written
to the log file. For example, if you specify a log level of Warning, the
system writes events classified as Warning, Error, Critical, Alert, and
Emergency to the log file.

For information about how to specify which events are logged, refer to
the Configuring log levels for Traffic Management Events section of this
article.

Important: Use caution when changing a log level from its default
setting. Refer to the event mapping files in the /etc/alertd/ directory
to determine which Traffic Management event messages are associated with
each log level. Repeat this procedure after each upgrade, as some
Traffic Management event messages and their associated log levels may
differ between software releases.

\sphinxstylestrong{Configuring log levels for Traffic Management Events}

You can configure log levels for Traffic Management events from the
Configuration utility or the command line. To do so, perform one of the
following procedures:

Impact of procedure: An overloaded BIG-IP system may experience
performance degradation if the logging intensity is high.

Using the Configuration utility to configure log levels for Traffic
Management events
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to System \textgreater{} Logs \textgreater{} Configuration \textgreater{} Options.

\item {} 
Select the desired log levels from the menu of the Local Traffic
Logging event or Audit Logging event.

\item {} 
Click Update.

\end{enumerate}

Using tmsh to configure log levels for Traffic Management events
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to tmsh by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To modify the log level of the desired event, use the following
command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
modify /sys db \PYGZlt{}name\PYGZgt{} \PYGZlt{}string\PYGZgt{}

For example, to \PYG{n+nb}{set} the log level \PYG{k}{for} MCP events to debug, you would
\PYG{n+nb}{type} the following command:

modify /sys db log.mcpd.level value debug

To \PYG{n+nb}{enable} audit logging \PYG{k}{for} user\PYGZhy{}initiated configuration changes and
configuration loads, you would \PYG{n+nb}{type} the following command:

modify /sys db config.auditing value verbose
\end{sphinxVerbatim}

\item {} 
Save the change by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
save sys config
\end{sphinxVerbatim}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.06 - Explain how to trigger custom alerts for testing purposes}

\sphinxurl{https://support.f5.com/csp/article/K11127}

\sphinxstylestrong{Using the logger utility to test SNMP traps}

To test SNMP traps using the logger utility, perform the following
procedure:

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
While remaining logged in to the BIG-IP command line, construct your
logger command with the information you extracted using the following
syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
logger \PYGZhy{}p \PYGZlt{}facility\PYGZgt{}.\PYGZlt{}level\PYGZgt{} \PYG{l+s+s2}{\PYGZdq{}\PYGZlt{}alert code\PYGZgt{}:\PYGZlt{}log level\PYGZgt{}: \PYGZlt{}descriptive message\PYGZgt{}\PYGZdq{}}
\end{sphinxVerbatim}

In the previous syntax, note the following:
\begin{itemize}
\item {} 
\textless{}facility\textgreater{} is the syslog-ng facility as listed in the
/var/run/bigip\_error\_maps.dat file.

\item {} 
\textless{}level\textgreater{} is the facility log level, which can include one of any eight
available log levels.

\item {} 
\textless{}alert code\textgreater{} is the alert code as indicated in the *\_maps.h file
entry.

\item {} 
\textless{}log level\textgreater{} is the alert log level. This level corresponds with the
following values:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Log level}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Corresponding syslog level}
\\
\hline
0
&
System is unusable
&
emerg
\\
\hline
1
&
Action must be taken immediately
&
alert
\\
\hline
2
&
Critical conditions
&
crit
\\
\hline
3
&
Error conditions
&
err
\\
\hline
4
&
Warning conditions
&
warning
\\
\hline
5
&
Normal but significant condition
&
notice
\\
\hline
6
&
Informational
&
info
\\
\hline
7
&
Debug-level messages
&
debug
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\item {} 
\textless{}descriptive message\textgreater{} is the descriptive message string format used
to describe the alert. Note that \%s in the example will match any
string.

\end{itemize}

For example, using the information extracted in step 6 of the
previous procedure, you could create the following logger command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
logger \PYGZhy{}p local0.notice \PYG{l+s+s2}{\PYGZdq{}01070640:5: Node 10.10.64.14 monitor status down.\PYGZdq{}}
\end{sphinxVerbatim}

This command will output a syslog-ng message to the local0.notice
facility (the default destination of which is the /var/log/ltm file)
and generate an SNMP trap for this message.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 1.07 - Describe how to set up custom alerting for an LTM device}
\label{\detokenize{class7/modules/module1:objective-1-07-describe-how-to-set-up-custom-alerting-for-an-ltm-device}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - List and describe custom alerts: SNMP, email and Remote Syslog}

\sphinxurl{https://support.f5.com/csp/article/K3667}

\sphinxstylestrong{Custom Alerts}

SNMP traps provide a means of notification through external network
management systems when certain events occur on the BIG-IP system. In
addition to the external network management systems notification system,
you can also configure the BIG-IP system to send email messages
directly.

The /etc/alertd/alert.conf and the /config/user\_alert.conf files on the
BIG-IP system define monitored events and the corresponding actions (for
example, sending an SNMP trap or an email notification) when certain
events occur. The /etc/alertd/alert.conf file defines standard system
alerts, and the /config/user\_alert.conf file defines custom settings.
You should edit only the /config/user\_alert.conf file. When the alertd
process starts, the BIG-IP system creates a dynamic configuration file
by appending the /config/user\_alert.conf file to the /etc/alertd/alert.conf file.

Configuring SNMP trap alerts to send an email notification

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line.

\item {} 
To back up the /config/user\_alert.conf file, type the following
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cp /config/user\PYGZus{}alert.conf /config/user\PYGZus{}alert.conf.SOL3667
\end{sphinxVerbatim}

\item {} 
To modify the permissions on the user\_alert.conf file to include
write access, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
chmod \PYG{l+m}{644} /config/user\PYGZus{}alert.conf
\end{sphinxVerbatim}

\item {} 
Using a text editor, edit the /config/user\_alert.conf file to create
a custom alert definition according to the following format:

\begin{sphinxadmonition}{note}{Note:}
For more information about configuring custom alerts, refer to
K3727: Configuring custom SNMP traps.
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
alert \PYGZlt{}ALERT\PYGZus{}NAME\PYGZgt{} \PYG{o}{\PYGZob{}}

snmptrap \PYG{n+nv}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZlt{}OID\PYGZgt{}\PYGZdq{}}

\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

The alert definitions may appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
alert BIGIP\PYGZus{}SHELL\PYGZus{}BP\PYGZus{}CONFIGURATION\PYGZus{}LOADED \PYG{o}{\PYGZob{}}

snmptrap \PYG{n+nv}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}.1.3.6.1.4.1.3375.2.4.0.28\PYGZdq{}}

\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

For each alert definition for which you want to receive email
notification, add a semicolon (;) to the end of the existing
snmptrap line, and then add the following lines between the snmptrap
line and the terminating curly brace:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
email \PYG{n+nv}{toaddress}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}

\PYG{n+nv}{fromaddress}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}

\PYG{n+nv}{body}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}
\end{sphinxVerbatim}

For example, the following alert definition sends an email
notification using the configured email toaddress, fromaddress, and
body options:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
alert BIGIP\PYGZus{}SHELL\PYGZus{}BP\PYGZus{}CONFIGURATION\PYGZus{}LOADED \PYG{o}{\PYGZob{}}

snmptrap \PYG{n+nv}{OID}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}.1.3.6.1.4.1.3375.2.4.0.28\PYGZdq{}}\PYG{p}{;}

email \PYG{n+nv}{toaddress}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}demo@askf5.com\PYGZdq{}}

\PYG{n+nv}{fromaddress}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}root\PYGZdq{}}

\PYG{n+nv}{body}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}The test of this Solution worked!\PYGZdq{}}

\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{important}{Important:}
To configure the “fromaddress” to use a custom address,
refer to K27540405: The tmsh command now supports the RewriteDomain
and FromLineOverride SSMTP configuration and K13180: Configuring the
BIG-IP system to deliver locally generated email messages (11.x -
13.x).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
You can send the email notifications to multiple recipients by
separating the email addresses specified in the email toaddress
option with a comma (,), as shown in the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
email \PYG{n+nv}{toaddress}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}demo@askf5.com,demo2@askf5.com\PYGZdq{}}
\end{sphinxVerbatim}
\end{sphinxadmonition}

\item {} 
Save and exit the file.

\item {} 
To restore the permissions on the user\_alert.conf file, type the
following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
chmod \PYG{l+m}{444} /config/user\PYGZus{}alert.conf
\end{sphinxVerbatim}

\item {} 
To restart the alertd process, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh restart /sys service alertd
\end{sphinxVerbatim}

When the alert is triggered, the BIG-IP system will send an email
notification that appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}Original Message\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

From: root@bigip1.askf5.com

Sent: Monday, December \PYG{l+m}{25}, \PYG{l+m}{2007} \PYG{l+m}{12}:10 PM

To: demo@askf5.com

Subject: 010a0043:5: The configuration was successfully loaded.

The \PYG{n+nb}{test} of this Solution worked!

\PYGZhy{}\PYGZhy{}\PYGZhy{}END\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}

\end{enumerate}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K13080}

\sphinxstylestrong{Configuring a remote syslog server}

The Configuration utility provides a basic means of configuring the
syslog configurations, such as defining the log levels. To configure
extensive syslog-ng customizations, you must use the command line.
Examples of syslog-ng customizations include, but are not limited to,
the following:
\begin{itemize}
\item {} 
Single remote syslog server

\item {} 
Multiple remote syslog servers

\item {} 
Remote syslog server port

\item {} 
Local IP address for BIG-IP syslog to bind to when sending logs to
remote syslog server

\item {} 
Log to remote syslog server using the TCP protocol

\end{itemize}

Adding a remote syslog server using the Configuration utility

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.

Note: Adding remote syslog servers using the Configuration utility is
available in BIG-IP 11.1.0 and later.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log on to the Configuration utility.

\item {} 
Navigate to System \textgreater{} Logs \textgreater{} Configuration \textgreater{} Remote Logging.

\item {} 
Enter the destination syslog server IP address in the Remote IP text
box.

\item {} 
Enter the remote syslog server UDP port (default is 514) in the
Remote Port text box.

\item {} 
Enter the local IP address of the BIG-IP system in the Local IP text
box (optional).

Note: For BIG-IP systems in a high availability (HA) configuration,
the non-floating self IP address is recommended if using a Traffic
Management Microkernel (TMM) based IP address.

\item {} 
Click Add.

\item {} 
Click Update.

\item {} 
For BIG-IP systems in a high availability (HA) configuration, repeat
all previous steps for each device in the device group.

\end{enumerate}

Adding a single remote syslog server

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the TMOS Shell (tmsh) by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To add a single remote syslog server, use the following command
syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
modify /sys syslog remote\PYGZhy{}servers add \PYG{o}{\PYGZob{}} \PYGZlt{}name\PYGZgt{} \PYG{o}{\PYGZob{}} host \PYGZlt{}IP address\PYGZgt{} remote\PYGZhy{}port \PYGZlt{}port\PYGZgt{} \PYG{o}{\PYGZcb{}}\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

For example, to add remote syslog server 172.28.31.40 with port 514
and name mysyslog, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
modify /sys syslog remote\PYGZhy{}servers add \PYG{o}{\PYGZob{}} mysyslog \PYG{o}{\PYGZob{}} host \PYG{l+m}{172}.28.31.40 remote\PYGZhy{}port \PYG{l+m}{514} \PYG{o}{\PYGZcb{}}\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

\item {} 
To save the configuration, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
save /sys config
\end{sphinxVerbatim}

\item {} 
For BIG-IP systems in a HA configuration, repeat all previous steps
for each device in the device group.

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Identify the location of custom alert configuration files}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/3000/700/sol3727.html?sr=46108087}

\sphinxstylestrong{SNMP trap configuration files}

Important: Modifications to the /config/user\_alert.conf file may
not be preserved after system upgrades or hotfix installations. For
example, this file is not preserved when upgrading from BIG-IP 10.x
to 11.0.0. F5 Technical Support recommends that you create an
updated user configuration set (UCS) archive immediately preceding
an upgrade operation if you want to maintain the customizations in
the file.

Important: Beginning in BIG-IP 11.0.0, the configuration
synchronization (ConfigSync) process between BIG-IP devices does not
include the /config/user\_alert.conf configuration file. If you
require the peer device to send custom SNMP traps, you must perform
the following procedures on each peer device.

Standard, pre-configured SNMP traps are contained in the
/etc/alertd/alert.conf file. F5 does not recommend, or support, the
addition or removal of traps or any other changes to the alert.conf
file.

Custom, user-defined SNMP traps should be defined in the
/config/user\_alert.conf file.

The BIG-IP system will process the alert notification specified in the
/config/user\_alert.conf file first, if the same alert definition exists
on both of the config files.

Prior to BIG-IP 10.1.0, when the alertd process starts, it creates a
dynamic configuration file by appending the /config/user\_alert.conf
file to the /etc/alertd/alert.conf file. The BIG-IP system searches the
dynamic configuration file sequentially for matches. After a match is
found, the trap is generated and no further matches are attempted.

Note: All files in the /config directory, including any
customizations to the /config/user\_alert.conf file, are
automatically included in the UCS archive by default. For more
information, refer to K4422: Viewing and modifying the files that
are configured for inclusion in a UCS archive.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/100/sol13180.html?sr=46626450}

\sphinxstylestrong{SMTP configuration}

In BIG-IP 11.0.0 and later, you can use ssmtp to configure the system to
send locally generated email messages to a configured Simple Mail
Transfer Protocol (SMTP) mail hub. The ssmtp program accepts a mail
stream on standard input with email recipients specified on the command
line.

Note: In versions prior to BIG-IP 11.0.0, you can use the Postfix
software to deliver locally generated email messages. Starting in BIG-IP
11.0.0, F5 removed Postfix from BIG-IP software. For more information,
refer to K13182: Postfix has been removed from BIG-IP software.

\sphinxstylestrong{Procedures}

You can configure the BIG-IP system to deliver locally-generated email
messages using ssmtp by performing one of the following procedures,
depending on the BIG-IP version.

\sphinxstylestrong{Configuring ssmtp to send locally generated email messages using the
tmsh utility (11.5.0 and later)}

Beginning in 11.5.0, you can use the Traffic Management Shell (tmsh) to
configure an SMTP mail hub. BIG-IP 11.5.0 through 12.1.2 do not support
advanced SMTP options using the tmsh utility.

Note: Due to a known issue, the BIG-IP system does not automatically
configure a domain name in the email From: line. For more information
about and how to work around the issue, refer to K15188934: Emails
generated by the BIG-IP system may fail after upgrading to version
13.0.0.

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Traffic Management Shell (tmsh) by typing the following
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To configure the system to send locally generated email messages, use
the following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
  modify /sys outbound\PYGZhy{}smtp mailhub \PYGZlt{}mail\PYGZus{}server\PYGZgt{}:\PYGZlt{}port\PYGZgt{}

For example, to configure the system to send locally generated email
messages to host mail.mydomain.com using port \PYG{l+m}{587}, you \PYG{n+nb}{type} the
following command:

modify /sys outbound\PYGZhy{}smtp mailhub mail.mydomain.com:587
\end{sphinxVerbatim}

\item {} 
To save the configuration, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
save /sys config
\end{sphinxVerbatim}

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{1.07 - Identify the available levels for local traffic logging}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/tmos-concepts-11-5-0/11.html}

\sphinxstylestrong{Log level settings for BIG-IP system events}

For each type of system-level process, such as bigdb configuration
events or events related to HTTP compression, you can set a minimum log
level. The minimum log level indicates the minimum severity level at
which the BIG-IP system logs that type of event. There are many
different types of local traffic or global traffic events for which you
can set a minimum log level.

The log levels that you can set on certain types of events, ordered from
highest severity to lowest severity, are:
\begin{itemize}
\item {} 
Emergency

\item {} 
Alert

\item {} 
Critical

\item {} 
Error

\item {} 
Warning

\item {} 
Notice

\item {} 
Informational

\item {} 
Debug

\end{itemize}

For example, if you set the minimum log level for bigdb events to Error,
then the system only logs messages that have a severity of Error or
higher for those events.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 2 - Identify and Resolve Application Issues}
\label{\detokenize{class7/modules/module2:section-2-identify-and-resolve-application-issues}}\label{\detokenize{class7/modules/module2::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.01 Determine which iRule to use to resolve an application issue}
\label{\detokenize{class7/modules/module2:objective-2-01-determine-which-irule-to-use-to-resolve-an-application-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Determine which iRule events and commands to use}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/18.html}

\sphinxstylestrong{iRule Events and Commands}

An iRule is a powerful and flexible feature within the BIG-IP operating
system that you can use to manage your network traffic. The iRules
feature not only allows you to select pools based on header data, but
also allows you to direct traffic by searching on any type of content
data that you define. Thus, the iRules feature significantly enhances
your ability to customize your content switching to suit your exact
needs.

Important: For complete and detailed information on iRules syntax, see
the F5 DevCentral web site, \sphinxurl{http://devcentral.f5.com}. Note that
iRules must conform to standard Tcl grammar rules; therefore, for more
information on Tcl syntax, see
\sphinxurl{http://tmml.sourceforge.net/doc/tcl/index.html}.

An iRule is a script that you write if you want individual connections
to target a pool other than the default pool defined for a virtual
server. iRules allow you to more directly specify the destinations to
which you want traffic to be directed. Using iRules, you can send
traffic not only to pools, but also to individual pool members, ports,
or URIs. The iRules you create can be simple or sophisticated, depending
on your content-switching needs.

Events

iRules are event-driven, which means that the LTM system triggers an
iRule based on an event that you specify in the iRule. An event
declaration is the specification of an event within an iRule that causes
the LTM system to trigger that iRule whenever that event occurs.

In a basic system configuration where no iRule exists, Local Traffic
Manager directs incoming traffic to the default pool assigned to the
virtual server that receives that traffic. However, you might want Local
Traffic Manager to direct certain kinds of connections to other
destinations. The way to do this is to write an iRule that directs
traffic to that other destination, contingent on a certain type of event
occurring. Otherwise, traffic continues to go to the default pool
assigned to the virtual server.

iRules are therefore evaluated whenever an event occurs that you have
specified in the iRule. For example, if an iRule includes the event
declaration CLIENT\_ACCEPTED, then the iRule is triggered whenever Local
Traffic Manager accepts a client connection. Local Traffic Manager then
follows the directions in the remainder of the iRule to determine the
destination of the packet.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when CLIENT\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}ACCEPTED \PYG{o}{\PYGZob{}}
  \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{o}{[}IP::addr \PYG{o}{[}IP::client\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}addr\PYG{o}{]} equals \PYG{l+m}{10}.10.10.10\PYG{o}{]} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}
    pool my\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

This iRule is triggered when a client-side connection has been accepted,
causing Local Traffic Manager to send the packet to the pool my\_pool,
if the client’s address matches 10.10.10.10.

For a full list of possible events see the following link:

\sphinxurl{https://devcentral.f5.com/wiki/irules.Events.ashx}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.01 - Given a specific iRule event determine what commands are available}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/18.html}

\sphinxstylestrong{iRule Commands}

An iRule command within an iRule causes Local Traffic Manager to take
some action, such as querying for data, manipulating data, or specifying
a traffic destination. The types of commands that you can include within
iRules are:

Statement commands

These commands cause actions such as selecting a traffic destination or
assigning a SNAT translation address. An example of a statement command
is pool \textless{}name\textgreater{}, which directs traffic to the named load balancing pool.

Commands that query or manipulate data

Some commands search for header and content data, while others perform
data manipulation such as inserting headers into HTTP requests. An
example of a query command is IP::remote\_addr, which searches for and
returns the remote IP address of a connection. An example of a data
manipulation command is HTTP::header remove \textless{}name\textgreater{}, which removes the
last occurrence of the named header from a request or response.

Utility commands

These commands are functions that are useful for parsing and
manipulating content. An example of a utility command is decode\_uri
\textless{}string\textgreater{}, which decodes the named string using HTTP URI encoding and
returns the result.

For a full list of possible commands see the following link:

\sphinxurl{https://devcentral.f5.com/wiki/iRules.Commands.ashx}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.02 Explain the functionality of a given iRule}
\label{\detokenize{class7/modules/module2:objective-2-02-explain-the-functionality-of-a-given-irule}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Interpret information in iRule logs to determine the iRule and iRule events where they occurred}

\sphinxurl{https://devcentral.f5.com/articles/irules-101-09-debugging}

\sphinxstylestrong{Logging with iRules}

The first tool you will want to arm yourself with is the iRules “log” command.
The syntax for the log is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
log \PYG{o}{[}\PYGZlt{}facility\PYGZgt{}.\PYGZlt{}level\PYGZgt{}\PYG{o}{]} \PYGZlt{}message\PYGZgt{}
facility : \PYG{l+s+s2}{\PYGZdq{}local0\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local1\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local2\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local3\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local4\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local5\PYGZdq{}},
\PYG{l+s+s2}{\PYGZdq{}local6\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}local7\PYGZdq{}}
level: \PYG{l+s+s2}{\PYGZdq{}alert\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}crit\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}debug\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}emerg\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}err\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}error\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}info\PYGZdq{}},
\PYG{l+s+s2}{\PYGZdq{}none\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}notice\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}panic\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}warn\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}warning\PYGZdq{}}
\end{sphinxVerbatim}

While the facility and level parameters are optional, it is good to know
that there is a significant behavioral difference when the optional
\textless{}facility\textgreater{}.\textless{}level\textgreater{} is specified. When iRule logs messages without the
facility and/or level, they are rate-limited as a class and subsequently
logged messages within the rate-limit period may be suppressed even
though they are textually different. However, when the \textless{}facility\textgreater{} and/or
\textless{}level\textgreater{} are specified, the log messages are not rate-limited (though
syslog-ng will still perform suppression of repeated duplicates).

Whew, that’s a lot of options. Lucky for you all that unless you are
doing some customization in syslog-ng regarding the different facilities
and levels, you can stick with the defaults of “local0” and “error”
which are the defaults. Actually, we’ve made it even easier than that
for you, in that you can omit the level parameter and we’ll default it
for you. In almost every iRule you will see on DevCentral, the following
syntax is used and in 99\% of the cases, it will be all that you need.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
log local0. \PYG{l+s+s2}{\PYGZdq{}message goes here\PYGZdq{}}
\end{sphinxVerbatim}

This will ensure that the log messages are not rate limited and go
directly to the log files and that they will be stored in the system log
file: /var/log/ltm.

A practical example

What and what not to log really depends on your iRule and what you are
trying to accomplish with it. If you are trying to process a HTTP
request, it’s probably a good idea to log the inputs to your iRule such
as \sphinxurl{HTTP::host} and \sphinxurl{HTTP::uri}, as well as any temporary variables you are
using if processing those string values. Let’s look at the following iRule.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}}
  switch \PYGZhy{}glob \PYG{o}{[}HTTP::uri\PYG{o}{]} \PYG{o}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}/app1\PYGZbs{}*\PYGZdq{}} \PYG{o}{\PYGZob{}}
      pool app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.gif\PYGZdq{}} \PYGZhy{}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.jpg\PYGZdq{}} \PYG{o}{\PYGZob{}}
      pool images\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    default \PYG{o}{\PYGZob{}}
      pool def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

This seems fairly straight forward. All requests to the “/app1”
application will be sent to the app1\_pool pool, all files with the
“.gif” and “.jpg” extensions will be routed to the images\_pool pool,
and all other requests will be sent to the def\_pool pool. Then you go
to test your application and none of the images for the app1 application
are being displayed. The way to go about debugging this issue would be
to log the inputs and log the decision elements of the iRules logic to
determine the source of the problem.

Your first thought is to go to the webserver logs for the image servers
and see why the requests are not being honored. To your surpise, the
logs show no requests on the image servers. Your next obvious step is to
put some debugging in your iRule to see exactly what’s going on.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}}
  log local0. \PYG{l+s+s2}{\PYGZdq{}Request: [HTTP::uri]\PYGZdq{}}
  switch \PYGZhy{}glob \PYG{o}{[}HTTP::uri\PYG{o}{]} \PYG{o}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}/app1\PYGZbs{}*\PYGZdq{}} \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to app1\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.gif\PYGZdq{}} \PYGZhy{}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.jpg\PYGZdq{}} \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to images\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool images\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    default \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to def\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

Then when you run your traffic, you will see something like this in the
logs

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Request: /app1/index.html
Sending request to app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
Request: /js/file.js
Sending request to def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
Request: /app1/smile.gif
Sending request to app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
\end{sphinxVerbatim}

What! I thought all image files were supposed to be sent to the
images\_pool pool but they are being sent to the app1\_pool pool. Since
the condition of searching for “/app1” was before the “gif/”jpg” test,
it matched and requests were sent to the app1\_pool pool of servers. Now
that you have this information, it’s fairly easy to reorder the
conditions in the switch statement to ensure all image request go to the
images\_pool pool.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}}
  log local0. \PYG{l+s+s2}{\PYGZdq{}Request: [HTTP::uri]\PYGZdq{}}
  switch \PYGZhy{}glob \PYG{o}{[}HTTP::uri\PYG{o}{]} \PYG{o}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.gif\PYGZdq{}} \PYGZhy{}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.jpg\PYGZdq{}} \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to images\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool images\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    \PYG{l+s+s2}{\PYGZdq{}/app1\PYGZbs{}*\PYGZdq{}} \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to app1\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    default \PYG{o}{\PYGZob{}}
      log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to def\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      pool def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

Now to your pleasure, the images are displaying in your application.
Just for kicks you look at the logs and see something like the
following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Request: /app1/index.html
Sending request to app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
Request: /js/file.js
Sending request to def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
Request: /app1/smile.gif
Sending request to images\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}poo
\end{sphinxVerbatim}

All is good, the app is working, and all images are being displayed
properly. You’re done right? WRONG…

\sphinxstylestrong{Remove Logging in Production}

Debug logging is a great tool when testing your application deployments,
or even when fixing an issue with production servers. But, log messages
do fill up the system logs and the system disks are only so big. In most
cases, debug logging should be disabled when you’ve got all the kinks
worked out. This can be done in several ways:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Remove the log commands from the iRule. This is probably the easiest
to implement, just delete the log lines and click save. This option
will reduce the clutter in your iRule and makes it easier to read.

\item {} 
Comment out the log commands with a \# sign. This will enable you to
easily restore the log commands if another situation comes up where
you need to figure out a new app error. Just uncomment the log lines,
click save, and you are back in business.

\item {} 
Use conditional log statements based on global variables. By wrapping
log statements with an if statement testing the value of a variable,
you can make turning on and off logging as simple as changing a
variable. The above iRule could be written like this.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}}
  \PYG{n+nb}{set} DEBUG \PYG{l+m}{1}
  \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{n+nv}{\PYGZdl{}DEBUG} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}} log local0. \PYG{l+s+s2}{\PYGZdq{}Request: [HTTP::uri]\PYGZdq{}} \PYG{o}{\PYGZcb{}}
  switch \PYGZhy{}glob \PYG{o}{[}HTTP::uri\PYG{o}{]} \PYG{o}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.gif\PYGZdq{}} \PYGZhy{}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}*.jpg\PYGZdq{}} \PYG{o}{\PYGZob{}}
      \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{n+nv}{\PYGZdl{}DEBUG} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}} log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to images\PYGZbs{}\PYGZus{}pool\PYGZdq{}}
      \PYG{o}{\PYGZcb{}}
      pool images\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    \PYG{l+s+s2}{\PYGZdq{}/app1\PYGZbs{}*\PYGZdq{}} \PYG{o}{\PYGZob{}}
      \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{n+nv}{\PYGZdl{}DEBUG} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}} log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to app1\PYGZbs{}\PYGZus{}pool\PYGZdq{}} \PYG{o}{\PYGZcb{}}
      pool app1\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
    default \PYG{o}{\PYGZob{}}
      \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{n+nv}{\PYGZdl{}DEBUG} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}} log local0. \PYG{l+s+s2}{\PYGZdq{}Sending request to def\PYGZbs{}\PYGZus{}pool\PYGZdq{}} \PYG{o}{\PYGZcb{}}
      pool def\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}pool
    \PYG{o}{\PYGZcb{}}
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

Then by setting DEBUG to 1 will enable logging and setting it to 0 will
turn logging off. The method you use will solely depend on your own
situation. Options 1 and 2 take no CPU overhead in the log processing,
while option 3 still requires performing a Boolean test on a variable.
For hundreds of thousands of requests, this can add up.

\end{enumerate}


\subsection{Wrapping it up}
\label{\detokenize{class7/modules/module2:wrapping-it-up}}
First thing to know and imprint in your mind is that logging is your
friend. You should get in the habit of including some form of logging in
all new iRule development to speed up diagnosing issues. Just make sure
that you remember to disable those log commands when you move your iRule
into production so that you keep from filling up the BIG-IP’s
filesystem.

For more information on the log command see the following link:

\sphinxurl{https://devcentral.f5.com/wiki/iRules.log.ashx}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.02 - Describe the results of iRule errors}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/900/sol13905.html?sr=46137011}

\sphinxstylestrong{iRule Errors}

When an iRule contains an error, such as a missing variable, the system
generates a TCL error indicating the missing or incorrect element. A TCL
runtime error aborts the affected instance of the iRule, and may cause
the associated connection to be reset. The error message can provide
valuable information when creating and troubleshooting iRule syntax.

If the error message occurs during operation or while creating an iRule,
use the information in the error message to troubleshoot the iRule
syntax. If the error occurs after upgrading the BIG-IP system to a new
software release, refer to the DevCentral site and verify whether any
portion of the iRule syntax (such as an iRule command) was deprecated or
changed.

\sphinxstylestrong{Error Message}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{*Error Message: 01220001:3: TCL error*}
\end{sphinxVerbatim}

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{*01220001:3: TCL error: /Common/broken \PYGZlt{}RULE\PYGZbs{}\PYGZus{}INIT\PYGZgt{} \PYGZhy{} can\PYGZsq{}t read \PYGZdq{}b\PYGZdq{}: no}
\PYG{g+go}{such variable while executing \PYGZdq{}set a \PYGZdl{}b\PYGZdq{}*}
\PYG{g+go}{*01220001:3: TCL error: MyiRule \PYGZlt{}HTTP\PYGZbs{}\PYGZus{}RESPONSE\PYGZgt{} \PYGZhy{} wrong \PYGZsh{} args: should}
\PYG{g+go}{be \PYGZdq{}\PYGZdq{}persist add uie \PYGZlt{}key\PYGZgt{}\PYGZdq{} while executing \PYGZdq{}persist add uie}
\PYG{g+go}{[HTTP::cookie \PYGZdq{}cookie\PYGZbs{}\PYGZus{}name\PYGZdq{}]\PYGZdq{} *}
\PYG{g+go}{*01220001:3: TCL error: MyiRule \PYGZhy{} Out of bounds (line 2) invoked from}
\PYG{g+go}{within \PYGZdq{}HTTP::payload replace 0 \PYGZdl{}content\PYGZbs{}\PYGZus{}length [string repeat \PYGZdq{}X\PYGZdq{}}
\PYG{g+gp}{\PYGZdl{}}content\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}length\PYG{o}{]}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{*}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.03 Given specific traffic and configuration containing a simple iRule determine the result of the iRule on the traffic}
\label{\detokenize{class7/modules/module2:objective-2-03-given-specific-traffic-and-configuration-containing-a-simple-irule-determine-the-result-of-the-irule-on-the-traffic}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.03 - Use an iRule to resolve application issues related to traffic steering and/or application data}

\sphinxurl{https://devcentral.f5.com/articles/routing-traffic-by-uri-using-irule}

\sphinxstylestrong{Routing traffic by URI using iRule}

DevCentral has a good article on this topic as an example.

The Challenge:

When a user conducts a search on a website and is directed to one of the
servers, the search information is cached on that server. If another
user searches for that same data but the LTM load balances to the other
server, the cached data from the first server does him no good. So to
solve this caching problem, the customer wants traffic that contains a
specific search parameter to be routed to the second server (as long as
the server is available). Specifically in this case, when a user loads a
page and the URI starts with /path/* that traffic should be sent to
Server\_2.

The picture below shows a representation of what the customer wants to
accomplish:

\noindent\sphinxincludegraphics{{p09}.jpeg}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

The Solution:

So, the question becomes: How does the customer ensure all /path/*
traffic is sent to a specific server? Well, you guessed it…the
ubiquitous and loveable iRule! Everyone had a pretty good idea an iRule
would be used to solve this problem, but what does that iRule look like?
Well, here it is!!

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}}
  \PYG{k}{if} \PYG{o}{\PYGZob{}} \PYG{o}{[}string tolower \PYG{o}{[}HTTP::path\PYG{o}{]}\PYG{o}{]} starts\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}with \PYG{l+s+s2}{\PYGZdq{}/path/\PYGZdq{}} \PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}
    persist none
    \PYG{n+nb}{set} pm \PYG{o}{[}lsearch \PYGZhy{}inline \PYG{o}{[}active\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}members \PYGZhy{}list \PYGZlt{}pool name\PYGZgt{}\PYG{o}{]}
    x.x.x.x\PYG{l+s+se}{\PYGZbs{}*}\PYG{o}{]}
    catch \PYG{o}{\PYGZob{}} pool \PYGZlt{}pool name\PYGZgt{} member \PYG{o}{[}lindex \PYG{n+nv}{\PYGZdl{}pm} \PYG{l+m}{0}\PYG{o}{]} \PYG{o}{[}lindex \PYG{n+nv}{\PYGZdl{}pm} \PYG{l+m}{1}\PYG{o}{]} \PYG{o}{\PYGZcb{}}
  \PYG{o}{\PYGZcb{}}
\PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

Let’s talk through the specifics of this solution…

For efficiency, start by checking the least likely condition. If an
HTTP\_REQUEST comes in, immediately check for the “/path/” string. Keep
in mind the “string tolower” command on the \sphinxurl{HTTP::path} before the
comparison to “/path/” to ensure the cases match correctly. Also, notice
the use of \sphinxurl{HTTP::path} instead of the full URI for the
comparison…there’s no need to use the full URI for this check.

Next, turn off persistence just in case another profile or iRule is
forcing the connection to persist to a place other than the beloved
Server\_2.

Then, search all active members in the pool for the Server\_2 IP address
and port. The “lsearch -inline” ensures the matching value is returned
instead of just the index. The “active\_members -list” is used to ensure
we get a list of IP addresses and ports, not just the number of active
members. Note the asterisk behind the IP address in the search
command…this is needed to ensure the port number is included in the
search. Based on the searches, the resulting values are set in a
variable called “pm”.

Next, use the catch command to stop any TCL errors from causing
problems. Because we are getting the active members list, it’s possible
that the pool member we are trying to match is NOT active and therefore
the pool member listed in the pool command may not be there…this is
what might cause that TCL error. Then send the traffic to the correct
pool member, which requires the IP and port. The astute observer and
especially the one familiar with the output of “active\_members -list”
will notice that each pool member returned in the list is already
pre-formatted in “ip port” format. However, just using the pm variable
in the pool command returns a TCL error, likely because the pm variable
is a single object instead of two unique objects. So, the lindex is used
to pull out each element individually to avoid the TCL error.

Testing:

Our team tested the iRule by adding it to a development site and then
accessing several pages on that site. We made sure the pages included
“/path/” in the URIs! We used tcpdump on the BIG-IP to capture the
transactions (tcpdump -ni 0.0 -w/var/tmp/capture1.pcap tcp port 80 -s0)
and then downloaded them locally and used Wireshark for analysis. Using
these tools, we determined that all the “/path/” traffic routed to
Server\_2 and all other traffic was still balanced between Server\_1 and
Server\_2. So, the iRule worked correctly and it was ready for prime
time!

Special thanks to Jason Rahm and Joe Pruitt for their outstanding
technical expertise and support in solving this challenge!

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.04 Interpret AVR information to identify performance issues or application attacks}
\label{\detokenize{class7/modules/module2:objective-2-04-interpret-avr-information-to-identify-performance-issues-or-application-attacks}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Explain how to modify profile settings using information from the AVR}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/4.html\#conceptid}

\sphinxstylestrong{Changing the default values in the Analytics profile}

Reported information that is captured by AVR can be used to help you
understand what is happening with the application and possible tune
settings in the BIG-IP configuration.

You may have users experiencing slow Page Load Times which is the length
of time it takes for application web pages to load on client-side
browsers. This information is useful if end users report that an
application is slow, and you want to determine the cause of the problem.
Adjusting the TCP profile to account for Cell or WAN based users on the
client side may help improve the issue or understanding that the content
is large and perhaps doing some simple compression may help the user
experience.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Explain how to use advanced filters to narrow output data from AVR}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/2.html\#conceptid}

You can review charts that show statistical information about traffic to
your web applications. The charts provide visibility into application
behavior, user experience, transactions, and data center resource usage.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Statistics \textgreater{} Analytics \textgreater{} HTTP. The Overview
screen opens.

\item {} 
From the Override time range to list, select a new time frame to
apply to all of the widgets in the overview.

Tip: Within each widget you can override the default time range, as
needed.

\item {} 
For each widget, select the data format and the time range to
display, as needed.

\item {} 
From the menu bar, select the type of statistics you want to view.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Select this option
&\sphinxstyletheadfamily 
To see these application statistics
\\
\hline
Overview
&
Top statistical information about traffic on your system or managed systems, such as the top virtual servers, top URLs accessed, and top applications. You can customize the information that is displayed.
\\
\hline
Transactions
&
The HTTP transaction rate (transactions per second) passing through the web applications, and the number of transactions to and from the web applications.
\\
\hline
Latency \textgreater{} Server Latency
&
The number of milliseconds it takes from the time a request arrives at the virtual server until a response arrives at the virtual server.
\\
\hline
Latency \textgreater{} Page Load Time
&
The number of milliseconds it takes for a web page to fully load on a client browser, from the time the user clicks a link or enters a web address until the web page displays in its entirety.
\\
\hline
Throughput \textgreater{} Request Throughput
&
HTTP request throughput in bits per second.
\\
\hline
Throughput \textgreater{} Response Throughput
&
HTTP response throughput in bits per second.
\\
\hline
Sessions \textgreater{} New Sessions
&
The number of transactions that open new sessions, in sessions per second.
\\
\hline
Sessions \textgreater{} Concurrent Sessions
&
The total number of open and active sessions at a given time, until they time out.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The charts display information based on the settings you enabled in the Analytics profile.

\item {} 
From the View By list, select the specific network object type for
which you want to display statistics. You can also click Expand
Advanced Filters to filter the information that displays.

\item {} 
To focus in on the specific details you want more information about,
click the chart or the details. The system refreshes the charts and
displays information about the item.

\item {} 
On the screen, the system displays the path you followed to reach the
current display, including the items you clicked. For example, to
review throughput details for a particular virtual server, follow
these steps:
\begin{itemize}
\item {} 
From the Throughput menu, choose Request Throughput.

\item {} 
From the View By list, select Virtual Servers. The charts show
throughput statistics for all virtual servers on this BIG-IP system.
You can point on the charts to display specific numbers.

\item {} 
Click the virtual server you want more information about. You can
either click a part of the pie chart or click the name of the virtual
server in the Details table. The charts show throughput statistics
for that virtual server, and shows the path you used to display the
information.

\item {} 
To view information about other applications or retrace your path,
click a link (in blue) in the path displayed by the charts.

As you drill down into the statistics, you can locate more details
and view information about a specific item on the charts.

\end{itemize}

\end{enumerate}

You can continue to review the collected metrics on the system viewing
transactions, latency, throughput, and sessions. As a result, you become
more familiar with the system, applications, resource utilization, and
more, and you can view the statistics in clear graphical charts, and
troubleshoot the system as needed.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.04 - Identify potential latency increases within an application}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/3.html\#conceptid}

\sphinxstylestrong{Investigating the server latency of applications}

You can review statistics concerning server latency on the Analytics
charts. Server latency is how long it takes (in milliseconds) from the
time a request reaches the BIG-IP system, for it to proceed to the web
application server, and return a response to the BIG-IP system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Statistics \textgreater{} Analytics \textgreater{} HTTP. The Overview
screen opens.

\item {} 
From the Latency menu, choose Server Latency. A chart shows the
server latency for all applications and virtual servers associated
with all Analytics profiles.

\item {} 
To view server latency for a specific application, in the Details
table, select only that application. The charts show latency only for
the selected application.

\item {} 
To view server latency for a specific virtual server:
\begin{itemize}
\item {} 
In the View By list, select Virtual Servers. The charts show latency
for all virtual servers.

\item {} 
In the Details list near the charts, click the virtual server you are
interested in. The charts show latency only for the selected virtual
server.

\end{itemize}

\item {} 
If further investigation is needed, in the View By setting, select
other entities to view charts that show latency for other collected
entities included in the Analytics profile, for example, specific
pool members, URLs, countries, or client IP addresses.

\end{enumerate}

Tip: If you are concerned about server latency, you can configure the
Analytics profile so that it sends an alert when the average server
latency exceeds a number of milliseconds for some period of time.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.05 Interpret AVR information to identify LTM device misconfiguration}
\label{\detokenize{class7/modules/module2:objective-2-05-interpret-avr-information-to-identify-ltm-device-misconfiguration}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain how to use AVR to trace application traffic}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0.pdf}

\sphinxstylestrong{AVR to trace application traffic}

This implementation describes how to set up the BIG-IP system to collect
application traffic so that you can troubleshoot problems that have
become apparent by monitoring application statistics. For example, by
examining captured requests and responses, you can investigate issues
with latency, throughput, or reduced transactions per second to
understand what is affecting application performance.

When Application Visibility and Reporting (AVR) is provisioned, you can
create an Analytics profile that includes traffic capturing
instructions. The system can collect application traffic locally,
remotely, or both. If the system is already monitoring applications, you
can also update an existing Analytics profile to make it so that it
captures traffic.

If logging locally, the system logs the first 1000 transactions and
displays charts based on the analysis of those transactions. If logging
remotely, the system logs information on that system; log size is
limited only by any constraints of the remote logging system. To see
updated application statistics, you can clear the existing data to
display the current statistics.

\sphinxstylestrong{Prerequisites for capturing application traffic}

After you finish a basic networking configuration of the BIG-IP system,
you must complete the following tasks as prerequisites for setting up
application statistics collection:
\begin{itemize}
\item {} 
Provision Application Visibility and Reporting (AVR): System \textgreater{}
Resource Provisioning

\item {} 
Create an iAppsTM application service (go to iApp \textgreater{} Application
Services), or configure at least one virtual server with a pool
pointing to one or more application servers.

\item {} 
The Traffic Sampling Ratio must be set to all in the default
Analytics profile.

\end{itemize}

You can set up the system for capturing traffic locally or remotely (or
both).

Tip: Before setting up traffic capturing, it is a good idea to
clear the captured transaction log. On the Captured Transactions
screen, click Clear All to clear all previously captured data
records.

\sphinxstylestrong{Capturing traffic for troubleshooting}

To set up traffic capturing, the Transaction Sampling Ratio of the
default analytics profile must be set to All.

You can configure the BIG-IP system to capture application traffic and
store the information locally or remotely (on syslog servers or SIEM
devices, such as Splunk). To do this, you create an Analytics profile
designed for capturing traffic. The profile instructs the BIG-IP system
to collect a portion of application traffic using the Application
Visibility and Reporting module.

Note: You typically use traffic capturing if you notice an
application issue, such as trouble with throughput or latency,
discovered when examining application statistics, and want to
troubleshoot the system by examining actual transactions.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Local Traffic \textgreater{} Profiles \textgreater{} Analytics.

Tip: If Analytics is not listed, this indicates that Application
Visibility and Reporting (AVR) is not provisioned, or you do not
have rights to create profiles.

The Analytics screen opens and lists all Analytics profiles that are
on the system, including a default profile called analytics.

\item {} 
Click Create.

The New Analytics Profile screen opens. By default, the settings are
initially the same as in the default analytics profile.

\item {} 
In the Profile Name field, type a name for the Analytics profile.

\item {} 
To the right of the General Configuration area, click the Custom
check box.

The settings in the area become available for modification.

\item {} 
For Traffic Capturing Logging Type, specify where to store captured
traffic.
\begin{itemize}
\item {} 
To store traffic locally, click Internal. You can view details on the
Statistics: Captured Transactions screen. This option is selected by
default.

\item {} 
To store traffic on a remote logging server, click External and type
the Remote Server IP Address and Remote Server Port number.

\end{itemize}

Tip: If you specify remote logging for multiple applications,
you can use the Remote Server Facility filter to sort the data for
each.

\item {} 
In the Included Objects area, specify the virtual servers for which
to capture application statistics:
\begin{itemize}
\item {} 
For the Virtual Servers setting, click Add.

A popup lists the virtual servers that you can assign to the
Analytics profile.

\item {} 
From the Select Virtual Server popup list, select the virtual servers
to include and click Done.

Note: You need to have previously configured the virtual servers
(with an HTTP profile) for them to appear in the list. Also, you can
assign only one Analytics profile to a virtual server so the list
shows only virtual servers that have not been assigned an Analytics
profile.

Special considerations apply if using Analytics on a BIG-IP system
with both Application Security ManagerTM and Access Policy
ManagerTM, where security settings (in Portal Access WebTop or an
iRule) redirect traffic from one virtual server to a second one. In
this case, you need to attach the Analytics profile to the second
virtual server to ensure that the charts show accurate statistics.

\end{itemize}

\item {} 
In the Statistics Gathering Configuration, for Collected Metrics,
select the statistics you want the system to collect:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
Server Latency
&
Tracks how long it takes to get data from the application server to the BIG-IP system (selected by default).
\\
\hline
Page Load Time
&
Tracks how long it takes an application user to get a complete response from the application, including network latency and completed page processing.

\sphinxstylestrong{Note:} End user response times and latencies can vary significantly based on geography and connection types.
\\
\hline
Throughput
&
Saves information about HTTP request and response throughput (selected by default).
\\
\hline
User Sessions
&
Stores the number of unique user sessions. For Timeout, type the number of minutes of user non-activity to allow before the system considers the session to be over. If using transaction sampling, this option is not available.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\item {} 
For Collected Entities, select the entities for which you want the system to collect statistics:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
URLs
&
Collects the requested URLs.
\\
\hline
Countries
&
Saves the name of the country where the request came from based on the client IP address.
\\
\hline
Client IP Addresses
&
Saves the IP address where the request originated. The address saved also depends on whether the request has an XFF (X-forwarded-for) header and whether Trust XFF is selected.
\\
\hline
Response Codes
&
Saves HTTP response codes that the server returned to requesters (selected by default).
\\
\hline
User Agents
&
Saves information about browsers used when making the request.
\\
\hline
Methods
&
Saves HTTP methods in requests (selected by default).
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\item {} 
In the Capture Filter area, from the Capture Requests and Capture
Responses lists, select the options that indicate the part of the
traffic to capture.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Option
&\sphinxstyletheadfamily 
Description
\\
\hline
None
&
Specifies that the system does not capture request (or response) data.
\\
\hline
Headers
&
Specifies that the system captures request (or response) header data only.
\\
\hline
Body
&
Specifies that the system captures the body of requests (or responses) only.
\\
\hline
All
&
Specifies that the system captures all request (or response) data.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\item {} 
Depending on the application, customize the remaining filter settings
to capture the portion of traffic to that you need for
troubleshooting.

Tip: By focusing in on the data and limiting the type of
information that is captured, you can troubleshoot particular areas
of an application more quickly. For example, capture only requests
or responses, specific status codes or methods, or headers
containing a specific string.

\item {} 
Click Finished.

\end{enumerate}

The BIG-IP system captures the application traffic described by the
Analytics profile for 1000 transactions locally (or until system limits
are reached). If logging remotely, the system logs information on that
system; log size is limited only by constraints of the remote logging
system.

Note: System performance is affected when traffic is being captured.

\sphinxstylestrong{Reviewing captured traffic}

Before you can review captured traffic details on the BIG-IP system, you
need to have created an Analytics profile that is capturing application
traffic locally. The settings you enable in the Capture Filter area of
the profile determine what information the system captures. You need to
associate the Analytics profile with one or more virtual servers, or
with an iApps application service.

The system starts capturing application traffic as soon as you enable it
on the Analytics profile. You can review the captured transactions
locally on the BIG-IP system. The system logs the first 1000
transactions.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click System \textgreater{} Logs \textgreater{} Captured Transactions.

The Captured Transactions screen opens and lists all of the captured
transactions.

\item {} 
Optionally, use the time period and filter settings to limit which
transactions are listed.

\item {} 
In the Captured Traffic area, click any transaction that you want to
examine.

Details of the request will display on the screen.

\item {} 
Review the general details of the request.

Tip: The general details, such as the response code or the size
of the request and response, help with troubleshooting.

\item {} 
For more information, click Request or Response to view the contents
of the actual transaction. Review the data for anything unexpected,
and other details that will help with troubleshooting the
application.

\item {} 
On the Captured Transactions screen, click Clear All to clear all
previously captured data records (including those not displayed on
the screen) and start collecting transactions again.

The system captures up to 1000 transactions locally and displays
them on the screen. Captured transactions are visible a few seconds
after they occur.

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.05 - Explain how latency trends identify application tier bottlenecks}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_analytics/manuals/product/avr-implementations-11-5-0/3.html\#conceptid}

Latency is a classic network performance metric, which at the basic
level requires the evaluation of timestamps applied to the same packet
as it passes through two locations in the network. By comparing the
timestamps, the latency of the network segment can be monitored. Many
networked applications and services rely on low latency in order to
function correctly.

If you have established latency times for transport traffic in your
network and you are seeing latency grow or exceed a threshold that
causes user acceptance to drop for an application, you can use it as a
basis to look into changes or setting that may be causing additional
latency. Gathering the information and keep track of changes is the key
to identifying application tier issues.

\sphinxstylestrong{Investigating the server latency of applications}

Before you can investigate server latency, you need to have created an
Analytics profile that is logging statistics internally on the BIG-IP
system. The Analytics profile must be associated with one or more
virtual servers, or an iApps application service. If your browser is IE8
or earlier, you need to have Adobe Flash Player installed on the
computer from which you plan to review the data.

Note: Newer browsers (Internet Explorer 9 or later, Firefox 3.6 or
later, or Chrome 14 or later) support viewing Analytics charts with no
additional plug-in. If using older browsers (Internet Explorer 8 or
earlier, Firefox 3.5 or earlier, or Chrome 13 or earlier), Adobe Flash
Player (version 8 or later) must be installed on the computer where you
plan to view Analytics charts.

You can review statistics concerning server latency on the Analytics
charts. Server latency is how long it takes (in milliseconds) from the
time a request reaches the BIG-IP system, for it to proceed to the web
application server, and return a response to the BIG-IP system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
On the Main tab, click Statistics \textgreater{} Analytics \textgreater{} HTTP. The Overview
screen opens.

\item {} 
From the Latency menu, click Server Latency. A chart shows the server
latency for all applications and virtual servers associated with all
Analytics profiles.

\item {} 
To view server latency for a specific application, in the Details
table, select only that application. The charts show latency only for
the selected application.

\item {} 
To view server latency for a specific virtual server:
\begin{itemize}
\item {} 
In the View By list, select Virtual Servers. The charts show latency
for all virtual servers.

\item {} 
In the Details list near the charts, click the virtual server you are
interested in. The charts show latency only for the selected virtual
server.

\end{itemize}

\item {} 
If further investigation is needed, in the View By setting, select
other entities to view charts that show latency for other collected
entities included in the Analytics profile, for example, specific
pool members, URLs, countries, or client IP addresses.

\end{enumerate}

Tip: If you are concerned about server latency, you can configure
the Analytics profile so that it sends an alert when the average server
latency exceeds a number of milliseconds for some period of time.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.06 Given a set of headers or traces, determine the root cause of an HTTP/HTTPS application problem}
\label{\detokenize{class7/modules/module2:objective-2-06-given-a-set-of-headers-or-traces-determine-the-root-cause-of-an-http-https-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain how to interpret response codes}

\sphinxurl{http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html}

\sphinxstylestrong{Response Codes}

The Status-Code element is a 3-digit integer result code of the attempt
to understand and satisfy the request. The Reason-Phrase is intended to
give a short textual description of the Status-Code. The Status-Code is
intended for use by automata and the Reason-Phrase is intended for the
human user. The client is not required to examine or display the Reason-
Phrase.

The first digit of the Status-Code defines the class of response. The
last two digits do not have any categorization role. There are 5 values
for the first digit:
\begin{itemize}
\item {} 
1xx: Informational - Request received, continuing process

\item {} 
2xx: Success - The action was successfully received, understood, and
accepted

\item {} 
3xx: Redirection - Further action must be taken in order to complete
the request

\item {} 
4xx: Client Error - The request contains bad syntax or cannot be
fulfilled

\item {} 
5xx: Server Error - The server failed to fulfill an apparently valid
request

\end{itemize}

\sphinxstylestrong{Status Code Definitions}

Each Status-Code is described below, including a description of which
method(s) it can follow and any meta information required in the
response.

\sphinxstylestrong{Informational 1xx}

This class of status code indicates a provisional response, consisting
only of the Status-Line and optional headers, and is terminated by an
empty line. There are no required headers for this class of status code.
Since HTTP/1.0 did not define any 1xx status codes, servers must not
send a 1xx response to an HTTP/1.0 client except under experimental
conditions.

A client must be prepared to accept one or more 1xx status responses
prior to a regular response, even if the client does not expect a 100
(Continue) status message. A user agent MAY ignore an unexpected 1xx
status response.

Proxies must forward 1xx responses, unless the connection between the
proxy and its client has been closed, or unless the proxy itself
requested the generation of the 1xx response. (For example, if a proxy
adds a “Expect: 100-continue” field when it forwards a request, then it
need not forward the corresponding 100 (Continue) response(s).)

\sphinxstylestrong{100 Continue}

The client should continue with its request. This interim response is
used to inform the client that the initial part of the request has been
received and has not yet been rejected by the server. The client should
continue by sending the remainder of the request or, if the request has
already been completed, ignore this response. The server must send a
final response after the request has been completed.

\sphinxstylestrong{101 Switching Protocols}

The server understands and is willing to comply with the client’s
request, via the Upgrade message header field, for a change in the
application protocol being used on this connection. The server will
switch protocols to those defined by the response’s Upgrade header field
immediately after the empty line, which terminates the 101 response.

The protocol should be switched only when it is advantageous to do so.
For example, switching to a newer version of HTTP is advantageous over
older versions, and switching to a real-time, synchronous protocol might
be advantageous when delivering resources that use such features.

\sphinxstylestrong{Successful 2xx}

This class of status code indicates that the client’s request was
successfully received, understood, and accepted.

\sphinxstylestrong{200 OK}

The request has succeeded. The information returned with the response is
dependent on the method used in the request, for example:

\sphinxstylestrong{GET} an entity corresponding to the requested resource is sent in the
response;

\sphinxstylestrong{HEAD} the entity-header fields corresponding to the requested
resource are sent in the response without any message-body;

\sphinxstylestrong{POST} an entity describing or containing the result of the action;

\sphinxstylestrong{TRACE} an entity containing the request message as received by the
end server.

\sphinxstylestrong{201 Created}

The request has been fulfilled and resulted in a new resource being
created. The newly created resource can be referenced by the URI(s)
returned in the entity of the response, with the most specific URI for
the resource given by a Location header field. The response should
include an entity containing a list of resource characteristics and
location(s) from which the user or user agent can choose the one most
appropriate. The media type given in the Content-Type header field
specifies the entity format. The origin server must create the resource
before returning the 201 status code. If the action cannot be carried
out immediately, the server should respond with 202 (Accepted) response
instead.

A 201 response may contain an ETag response header field indicating the
current value of the entity tag for the requested variant just created.

\sphinxstylestrong{202 Accepted}

The request has been accepted for processing, but the processing has not
been completed. The request might or might not eventually be acted upon,
as it might be disallowed when processing actually takes place. There is
no facility for re-sending a status code from an asynchronous operation
such as this.

The 202 response is intentionally non-committal. Its purpose is to allow
a server to accept a request for some other process (perhaps a
batch-oriented process that is only run once per day) without requiring
that the user agent’s connection to the server persist until the process
is completed. The entity returned with this response should include an
indication of the request’s current status and either a pointer to a
status monitor or some estimate of when the user can expect the request
to be fulfilled.

\sphinxstylestrong{203 Non-Authoritative Information}

The returned metainformation in the entity-header is not the definitive
set as available from the origin server, but is gathered from a local or
a third-party copy. The set presented may be a subset or superset of the
original version. For example, including local annotation information
about the resource might result in a superset of the metainformation
known by the origin server. Use of this response code is not required
and is only appropriate when the response would otherwise be 200 (OK).

\sphinxstylestrong{204 No Content}

The server has fulfilled the request but does not need to return an
entity-body, and might want to return updated metainformation. The
response may include new or updated metainformation in the form of
entity-headers, which if present should be associated with the requested
variant.

If the client is a user agent, it should not change its document view
from that which caused the request to be sent. This response is
primarily intended to allow input for actions to take place without
causing a change to the user agent’s active document view, although any
new or updated metainformation should be applied to the document
currently in the user agent’s active view.

The 204 response must not include a message-body, and thus is always
terminated by the first empty line after the header fields.

\sphinxstylestrong{205 Reset Content}

The server has fulfilled the request and the user agent should reset the
document view, which caused the request to be sent. This response is
primarily intended to allow input for actions to take place via user
input, followed by a clearing of the form in which the input is given so
that the user can easily initiate another input action. The response
must not include an entity.

\sphinxstylestrong{206 Partial Content}

The server has fulfilled the partial GET request for the resource. The
request must have included a Range header field indicating the desired
range, and may have included an If-Range header field to make the
request conditional.

The response must include the following header fields:
\begin{itemize}
\item {} 
Either a Content-Range header field indicating the range included
with this response, or a multipart/byteranges Content-Type including
Content-Range fields for each part. If a Content-Length header field
is present in the response, its value must match the actual number of
OCTETs transmitted in the message-body.

\item {} 
Date

\item {} 
ETag and/or Content-Location, if the header would have been sent in a
200 response to the same request

\item {} 
Expires, Cache-Control, and/or Vary, if the field-value might differ
from that sent in any previous response for the same variant

\end{itemize}

If the 206 response is the result of an If-Range request that used a
strong cache validator, the response should not include other
entity-headers. If the response is the result of an If-Range request
that used a weak validator, the response must not include other
entity-headers; this prevents inconsistencies between cached
entity-bodies and updated headers. Otherwise, the response must include
all of the entity-headers that would have been returned with a 200 (OK)
response to the same request.

A cache must not combine a 206 response with other previously cached
content if the ETag or Last-Modified headers do not match exactly.

A cache that does not support the Range and Content-Range headers must
not cache 206 (Partial) responses.

\sphinxstylestrong{Redirection 3xx}

This class of status code indicates that further action needs to be
taken by the user agent in order to fulfill the request. The user agent
may carry out the action required without interaction with the user if
and only if the method used in the second request is GET or HEAD. A
client should detect infinite redirection loops, since such loops
generate network traffic for each redirection.

Note: previous versions of this specification recommended a
maximum of five redirections. Content developers should be aware
that there might be clients that implement such a fixed limitation.

\sphinxstylestrong{300 Multiple Choices}

The requested resource corresponds to any one of a set of
representations, each with its own specific location, and agent- driven
negotiation information is being provided so that the user (or user
agent) can select a preferred representation and redirect its request to
that location.

Unless it was a HEAD request, the response should include an entity
containing a list of resource characteristics and location(s) from which
the user or user agent can choose the one most appropriate. The media
type given in the Content-Type header field specifies the entity format.
Depending upon the format and the capabilities of the user agent,
selection of the most appropriate choice may be performed automatically.
However, this specification does not define any standard for such
automatic selection.

If the server has a preferred choice of representation, it should
include the specific URI for that representation in the Location field;
user agents may use the Location field value for automatic redirection.
This response is cacheable unless indicated otherwise.

\sphinxstylestrong{301 Moved Permanently}

The requested resource has been assigned a new permanent URI and any
future references to this resource should use one of the returned URIs.
Clients with link editing capabilities ought to automatically re-link
references to the Request-URI to one or more of the new references
returned by the server, where possible. This response is cacheable
unless indicated otherwise.

The Location field in the response should give the new permanent URI.
Unless the request method was HEAD, the entity of the response should
contain a short hypertext note with a hyperlink to the new URI(s).

If the 301 status code is received in response to a request other than
GET or HEAD, the user agent must not automatically redirect the request
unless it can be confirmed by the user, since this might change the
conditions under which the request was issued.

Note: When automatically redirecting a POST request after
receiving a 301 status code, some existing HTTP/1.0 user agents will
erroneously change it into a GET request.

\sphinxstylestrong{302 Found}

The requested resource resides temporarily under a different URI. Since
the redirection might be altered on occasion, the client should continue
to use the Request-URI for future requests. This response is only
cacheable if indicated by a Cache-Control or Expires header field.

The temporary URI should be given by the Location field in the response.
Unless the request method was HEAD, the entity of the response should
contain a short hypertext note with a hyperlink to the new URI(s).

If the 302 status code is received in response to a request other than
GET or HEAD, the user agent must not automatically redirect the request
unless it can be confirmed by the user, since this might change the
conditions under which the request was issued.

Note: RFC 1945 and RFC 2068 specify that the client is not allowed to change the method
on the redirected request. However, most existing user agent implementations treat 302 as
if it were a 303 response, performing a GET on the Location field-value regardless of the
original request method. The status codes 303 and 307 have been added for servers that
wish to make unambiguously clear which kind of reaction is expected of the client.

\sphinxstylestrong{303 See Other}

The response to the request can be found under a different URI and
should be retrieved using a GET method on that resource. This method
exists primarily to allow the output of a POST-activated script to
redirect the user agent to a selected resource. The new URI is not a
substitute reference for the originally requested resource. The 303
response must not be cached, but the response to the second (redirected)
request might be cacheable.

The Location field in the response should give the different URI. Unless
the request method was HEAD, the entity of the response should contain a
short hypertext note with a hyperlink to the new URI(s).

Note: Many pre-HTTP/1.1 user agents do not understand the 303
status. When interoperability with such clients is a concern, the
302 status code may be used instead, since most user agents react to
a 302 response as described here for 303.

\sphinxstylestrong{304 Not Modified}

If the client has performed a conditional GET request and access is
allowed, but the document has not been modified, the server should
respond with this status code. The 304 response must not contain a
message-body, and thus is always terminated by the first empty line
after the header fields.

The response must include the following header fields:
\begin{itemize}
\item {} 
Date, unless its omission is required

If a clockless origin server obeys these rules, and proxies and
clients add their own Date to any response received without one (as
already specified by RFC 2068), caches will operate correctly.

\item {} 
ETag and/or Content-Location, if the header would have been sent in a
200 response to the same request

\item {} 
Expires, Cache-Control, and/or Vary, if the field-value might differ
from that sent in any previous response for the same variant

\end{itemize}

If the conditional GET used a strong cache validator, the response
should not include other entity-headers. Otherwise (i.e., the
conditional GET used a weak validator), the response must not include
other entity-headers; this prevents inconsistencies between cached
entity-bodies and updated headers.

If a 304 response indicates an entity not currently cached, then the
cache must disregard the response and repeat the request without the
conditional.

If a cache uses a received 304 response to update a cache entry, the
cache must update the entry to reflect any new field values given in the
response.

\sphinxstylestrong{305 Use Proxy}

The requested resource must be accessed through the proxy given by the
Location field. The Location field gives the URI of the proxy. The
recipient is expected to repeat this single request via the proxy. 305
responses must only be generated by origin servers.

Note: RFC 2068 was not clear that 305 was intended to redirect a
single request, and to be generated by origin servers only. Not
observing these limitations has significant security consequences.

\sphinxstylestrong{306 (Unused)}

The 306 status code was used in a previous version of the specification,
is no longer used, and the code is reserved.

\sphinxstylestrong{307 Temporary Redirect}

The requested resource resides temporarily under a different URI. Since
the redirection may be altered on occasion, the client should continue
to use the Request-URI for future requests. This response is only
cacheable if indicated by a Cache-Control or Expires header field.

The temporary URI should be given by the Location field in the response.
Unless the request method was HEAD, the entity of the response should
contain a short hypertext note with a hyperlink to the new URI(s), since
many pre-HTTP/1.1 user agents do not understand the 307 status.
Therefore, the note should contain the information necessary for a user
to repeat the original request on the new URI.

If the 307 status code is received in response to a request other than
GET or HEAD, the user agent must not automatically redirect the request
unless it can be confirmed by the user, since this might change the
conditions under which the request was issued.

\sphinxstylestrong{Client Error 4xx}

The 4xx class of status code is intended for cases in which the client
seems to have erred. Except when responding to a HEAD request, the
server should include an entity containing an explanation of the error
situation, and whether it is a temporary or permanent condition. These
status codes are applicable to any request method. User agents should
display any included entity to the user.

If the client is sending data, a server implementation using TCP should
be careful to ensure that the client acknowledges receipt of the
packet(s) containing the response, before the server closes the input
connection. If the client continues sending data to the server after the
close, the server’s TCP stack will send a reset packet to the client,
which may erase the client’s unacknowledged input buffers before they
can be read and interpreted by the HTTP application.

\sphinxstylestrong{400 Bad Request}

The server due to malformed syntax could not understand the request. The
client should not repeat the request without modifications.

\sphinxstylestrong{401 Unauthorized}

The request requires user authentication. The response must include a
WWW-Authenticate header field containing a challenge applicable to the
requested resource. The client MAY repeat the request with a suitable
Authorization header field. If the request already included
Authorization credentials, then the 401 response indicates that
authorization has been refused for those credentials. If the 401
response contains the same challenge as the prior response, and the user
agent has already attempted authentication at least once, then the user
should be presented the entity that was given in the response, since
that entity might include relevant diagnostic information. HTTP access
authentication is explained in “HTTP Authentication: Basic and Digest
Access Authentication”.

\sphinxstylestrong{402 Payment Required}

This code is reserved for future use.

\sphinxstylestrong{403 Forbidden}

The server understood the request, but is refusing to fulfill it.
Authorization will not help and the request should not be repeated. If
the request method was not HEAD and the server wishes to make public why
the request has not been fulfilled, it should describe the reason for
the refusal in the entity. If the server does not wish to make this
information available to the client, the status code 404 (Not Found) can
be used instead.

\sphinxstylestrong{404 Not Found}

The server has not found anything matching the Request-URI. No
indication is given of whether the condition is temporary or permanent.
The 410 (Gone) status code should be used if the server knows, through
some internally configurable mechanism, that an old resource is
permanently unavailable and has no forwarding address. This status code
is commonly used when the server does not wish to reveal exactly why the
request has been refused, or when no other response is applicable.

\sphinxstylestrong{405 Method Not Allowed}

The method specified in the Request-Line is not allowed for the resource
identified by the Request-URI. The response must include an Allow header
containing a list of valid methods for the requested resource.

\sphinxstylestrong{406 Not Acceptable}

The resource identified by the request is only capable of generating
response entities which have content characteristics not acceptable
according to the accept headers sent in the request.

Unless it was a HEAD request, the response should include an entity
containing a list of available entity characteristics and location(s)
from which the user or user agent can choose the one most appropriate.
The media type given in the Content-Type header field specifies the
entity format. Depending upon the format and the capabilities of the
user agent, selection of the most appropriate choice MAY be performed
automatically. However, this specification does not define any standard
for such automatic selection.

Note: HTTP/1.1 servers are allowed to return responses which are
not acceptable according to the accept headers sent in the request.
In some cases, this may even be preferable to sending a 406
response. User agents are encouraged to inspect the headers of an
incoming response to determine if it is acceptable.

If the response could be unacceptable, a user agent should temporarily
stop receipt of more data and query the user for a decision on further
actions.

\sphinxstylestrong{407 Proxy Authentication Required}

This code is similar to 401 (Unauthorized), but indicates that the
client must first authenticate itself with the proxy. The proxy must
return a Proxy-Authenticate header field containing a challenge
applicable to the proxy for the requested resource. The client may
repeat the request with a suitable Proxy-Authorization header field.
HTTP access authentication is explained in “HTTP Authentication: Basic
and Digest Access Authentication”.

\sphinxstylestrong{408 Request Timeout}

The client did not produce a request within the time that the server was
prepared to wait. The client may repeat the request without
modifications at any later time.

\sphinxstylestrong{409 Conflict}

The request could not be completed due to a conflict with the current
state of the resource. This code is only allowed in situations where it
is expected that the user might be able to resolve the conflict and
resubmit the request. The response body should include enough
information for the user to recognize the source of the conflict.
Ideally, the response entity would include enough information for the
user or user agent to fix the problem; however, that might not be
possible and is not required.

Conflicts are most likely to occur in response to a PUT request. For
example, if versioning were being used and the entity being PUT included
changes to a resource which conflict with those made by an earlier
(third-party) request, the server might use the 409 response to indicate
that it can’t complete the request. In this case, the response entity
would likely contain a list of the differences between the two versions
in a format defined by the response Content-Type.

\sphinxstylestrong{410 Gone}

The requested resource is no longer available at the server and no
forwarding address is known. This condition is expected to be considered
permanent. Clients with link editing capabilities should delete
references to the Request-URI after user approval. If the server does
not know, or has no facility to determine, whether or not the condition
is permanent, the status code 404 (Not Found) should be used instead.
This response is cacheable unless indicated otherwise.

The 410 response is primarily intended to assist the task of web
maintenance by notifying the recipient that the resource is
intentionally unavailable and that the server owners desire that remote
links to that resource be removed. Such an event is common for
limited-time, promotional services and for resources belonging to
individuals no longer working at the server’s site. It is not necessary
to mark all permanently unavailable resources as “gone” or to keep the
mark for any length of time \textendash{} that is left to the discretion of the
server owner.

\sphinxstylestrong{411 Length Required}

The server refuses to accept the request without a defined Content-
Length. The client may repeat the request if it adds a valid
Content-Length header field containing the length of the message-body in
the request message.

\sphinxstylestrong{412 Precondition Failed}

The precondition given in one or more of the request-header fields
evaluated to false when it was tested on the server. This response code
allows the client to place preconditions on the current resource
metainformation (header field data) and thus prevent the requested
method from being applied to a resource other than the one intended.

\sphinxstylestrong{413 Request Entity Too Large}

The server is refusing to process a request because the request entity
is larger than the server is willing or able to process. The server may
close the connection to prevent the client from continuing the request.

If the condition is temporary, the server should include a Retry-After
header field to indicate that it is temporary and after what time the
client may try again.

\sphinxstylestrong{414 Request-URI Too Long}

The server is refusing to service the request because the Request-URI is
longer than the server is willing to interpret. This rare condition is
only likely to occur when a client has improperly converted a POST
request to a GET request with long query information, when the client
has descended into a URI “black hole” of redirection (e.g., a redirected
URI prefix that points to a suffix of itself), or when the server is
under attack by a client attempting to exploit security holes present in
some servers using fixed-length buffers for reading or manipulating the
Request-URI.

\sphinxstylestrong{415 Unsupported Media Type}

The server is refusing to service the request because the entity of the
request is in a format not supported by the requested resource for the
requested method.

\sphinxstylestrong{416 Requested Range Not Satisfiable}

A server should return a response with this status code if a request
included a Range request-header field, and none of the range-specifier
values in this field overlap the current extent of the selected
resource, and the request did not include an If-Range request-header
field. (For byte-ranges, this means that the first- byte-pos of all of
the byte-range-spec values were greater than the current length of the
selected resource.)

When this status code is returned for a byte-range request, the response
should include a Content-Range entity-header field specifying the
current length of the selected resource. This response must not use the
multipart/byteranges content- type.

\sphinxstylestrong{417 Expectation Failed}

This server could not meet the expectation given in an Expect
request-header field, or, if the server is a proxy, the server has
unambiguous evidence that the next-hop server could not meet the
request.

\sphinxstylestrong{Server Error 5xx}

Response status codes beginning with the digit “5” indicate cases in
which the server is aware that it has erred or is incapable of
performing the request. Except when responding to a HEAD request, the
server should include an entity containing an explanation of the error
situation, and whether it is a temporary or permanent condition. User
agents should display any included entity to the user. These response
codes are applicable to any request method.

\sphinxstylestrong{500 Internal Server Error}

The server encountered an unexpected condition, which prevented it from
fulfilling the request.

\sphinxstylestrong{501 Not Implemented}

The server does not support the functionality required to fulfill the
request. This is the appropriate response when the server does not
recognize the request method and is not capable of supporting it for any
resource.

\sphinxstylestrong{502 Bad Gateway}

The server, while acting as a gateway or proxy, received an invalid
response from the upstream server it accessed in attempting to fulfill
the request.

\sphinxstylestrong{503 Service Unavailable}

The server is currently unable to handle the request due to a temporary
overloading or maintenance of the server. The implication is that this
is a temporary condition, which will be alleviated after some delay. If
known, the length of the delay may be indicated in a Retry-After header.
If no Retry-After is given, the client should handle the response as it
would for a 500 response.

Note: The existence of the 503 status code does not imply that a
server must use it when becoming overloaded. Some servers may wish
to simply refuse the connection.

\sphinxstylestrong{504 Gateway Timeout}

The server, while acting as a gateway or proxy, did not receive a timely
response from the upstream server specified by the URI (e.g. HTTP, FTP,
LDAP) or some other auxiliary server (e.g. DNS) it needed to access in
attempting to complete the request.

Note: Note to implementers: some deployed proxies are known to
return 400 or 500 when DNS lookups time out.

\sphinxstylestrong{505 HTTP Version Not Supported}

The server does not support, or refuses to support, the HTTP protocol
version that was used in the request message. The server is indicating
that it is unable or unwilling to complete the request using the same
major version as the client, as described in section 3.1, other than
with this error message. The response should contain an entity
describing why that version is not supported and what other protocols
that server supports.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain the function of HTTP headers within different HTTP applications (Cookies, Cache Control, Vary, Content Type \& Host)}

\sphinxurl{https://f5.com/resources/white-papers/fundamentals-of-http}

\sphinxstylestrong{HTTP Headers}

HTTP headers carry information about behavior and application state
between the browser and the server. These headers can be modified and
examined by the browser and the server, as well as intermediary devices
such as web acceleration solutions and application delivery controllers.
The headers sent by the browser notify the web server of the browser’s
capabilities. The headers sent by the web server tell the browser how to
treat the content.

The most important browser headers, in terms of end-user performance,
are:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
HTTP version (HTTP/1.0 or HTTP/1.1)

\item {} 
Accept-Encoding: gzip, deflate

\item {} 
Connection: Keep-Alive

\item {} 
If - * headers

\item {} 
Cache-Control or Pragma no-cache

\end{enumerate}

The first three items are interrelated. HTTP 1.0 does not include
compression\textendash{}indicated by the Accept-Encoding: gzip, deflate header, or
connection keep-alives. Compression can reduce the byte count of text by
6:1 to 8:1. This often translates into a 40-50 percent reduction in size
for a page. Connection: Keep-Alive will reuse TCP connections for
subsequent requests and will save on the latency incurred by the 3-way
hand-shake, and 4-way tear-down required for TCP connections on every
request. Keeping connections open is important in emerging web-based
applications that utilize Web 2.0 technology such as AJAX (Asynchronous
JavaScript and XML) to perform real-time updates of content because it
reduces the overhead associated with opening and closing TCP
connections.

The various If-* headers, such as If-Modified-Since, will enable the
web server to send a response that indicates the content has not been
modified if this is true. This can potentially turn a 200KB download
into a 1KB download, as the browser will respond to the 304 Not Modified
response by loading the referenced content from the browser’s cache.
However, a lot of If-* requests for static content can result in
unnecessary round trips. This can really slow end-user performance. The
no-cache header and its relatives—no-store, private, must-revalidate,
and proxy-revalidate—request that proxies and, sometimes, web servers
not cache the response to the request. Honoring those requests can cause
the servers to do a lot more work because they must always return the
full content rather than enable the browser to use a cached version.

The most important web server headers, in terms of end-user performance,
are:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
The HTTP version (either HTTP/1.0 or HTTP/1.1) at the beginning of
the status line

\item {} 
Connection: Keep-Alive/Close

\item {} 
Encoding: gzip, deflate

\item {} 
The various cache-control headers, especially max-age

\item {} 
Content-Type:

\item {} 
Date:

\item {} 
Accept-Ranges: bytes

\end{enumerate}

Again, the first three items are inter-related and are meant to impart
the same information as when sent by the browser. The cache-control
headers are very important because they can be used to store items in
the browser cache and avoid future HTTP requests altogether. However,
using cached data runs the risk of using out-dated data if the content
changes before the cached object expires. Content-type is important for
telling the browser how to handle the object. This is most important for
content that the browser hands off to plug-ins (Flash, Microsoft Office
documents, etc.). It is also the biggest clue to the true function of
that object in the web application. Improper content types will often
result in slower, but not broken web applications. The Date header is
very important because it affects how the browser interprets the
cache-control headers. It is important to make sure the date on the
server is set correctly so that this field is accurate. The
Accept-Ranges header is only important when downloading PDF documents.
It enables the browser to know that it can request the PDF document one
page at a time.


\bigskip\hrule\bigskip


\sphinxurl{https://f5.com/resources/white-papers/fundamentals-of-http}

\sphinxstylestrong{Cookies}

Cookies are sent by the web server to the browser as an HTTP header and
used to store all sorts of information about a user’s interaction with
the site. Generally speaking the use of cookies will not affect the
performance of an application, unless they are encrypted for security
purposes. The reason encrypted cookies can affect performance is because
the web server needs to decrypt them before use, and the
encryption/decryption process is resource intensive. The more encrypted
cookies that are used by a site, the longer it takes for the web server
to process them into a readable format.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/5000/100/sol5157.html?sr=46612722}

\sphinxstylestrong{Vary}

The HTTP Vary header, documented in RFC2616, is set by an origin web
server (OWS) and contains request-header information. This information
is used to determine whether a proxy server is permitted to reply to a
subsequent request without re-validating the content from the OWS.

The BIG-IP HTTP cache (referred to as RAM Cache in BIG-IP versions prior
to 11.0.0) uses the information from the Vary header to cache responses
from the OWS. The OWS can include information within the Vary header to
determine which resource the server returns in its response. For
example, if a page is optimized for a particular web browser, the OWS
response may return the Vary: User-Agent HTTP header. The proxy server
then uses this information to determine whether to return a cached copy
of the response to subsequent requests, or to query the OWS for the
resource again (a subsequent client request containing a different
User-Agent value forces the proxy to query the OWS for the resource
again).

This behavior can require a proxy server (including the BIG-IP HTTP
cache) to use up excess disk space to cache the same response.

For example:

Client A’s request for a URI contains the following header:

User-Agent: agent1

The server’s response includes the following headers:

Vary: User-Agent, Accept-Encoding

The BIG-IP system then stores the page, noting the User-Agent and
Accept-Encoding headers from the client’s request.

Client B then requests the same URI, but the request has a User-Agent
header containing agent2. The BIG-IP system ignores the existing cache
entry (since the User-Agent is different), forwards the request to the
server, and caches the response as a separate entry.

Beginning with BIG-IP 9.2, you can use the iRule CACHE::userkey
\textless{}keystring\textgreater{} command to instruct the cache to cache the information based
on the parameter that the administrator specifies. You can use this
command to prevent multiple caches of the same information.
Additionally, you can use the CACHE::useragent and CACHE::acceptencoding
commands to override the behavior described in the previous example,
such as, have a cache based on a group of User-Agent values rather than
store an entry for each User-Agent header seen, and cause duplication.

For example, the following iRule sets the cache behavior based on the
information that the User-Agent has on the customer’s initial request,
not on honoring User-Agent or Accept-Encoding when found in the server’s
Vary header:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
when HTTP\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}REQUEST \PYG{o}{\PYGZob{}} \PYG{n+nb}{set} user\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}key \PYG{l+s+s2}{\PYGZdq{}[HTTP::header User\PYGZhy{}Agent]\PYGZdq{}}
CACHE::userkey \PYG{n+nv}{\PYGZdl{}user}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}key \PYG{o}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The user\_key can be defined as any string found in the HTTP
request that the administrator wants to use to build cache
responses.
\end{sphinxadmonition}

You can use the previously listed iRule commands, even when the server
does not set a Vary header, which allows the administrator to control
the behavior outside of the server.

\sphinxstylestrong{Content-Type}

The MIME type of the body of the request (used with POST and PUT
requests)

\sphinxstylestrong{Host}

The host value is represented by the domain name of the server (for
virtual hosting), and the TCP port number on which the server is
listening. The port number may be omitted if the port is the standard
port for the service requested.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain HTTP methods (GET, POST, etc.)}

\sphinxurl{https://f5.com/resources/white-papers/fundamentals-of-http}

\sphinxurl{http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html}

\sphinxstylestrong{HTTP Methods}

When you open up a browser and request a web page (either by setting a
default page or by entering a Uniform Resource Locater or URL), the
first thing that happens is that the browser relies upon the operating
system to resolve the host name in the URL to an IP address. Normally
this is done via a DNS (Domain Name System) query over UDP (User
Datagram Protocol) on port 53. However, if the host is listed in the
local hosts file, the operating system will not make a DNS query.

When the IP address is obtained, the browser will attempt to open a TCP
(Transmission Control Protocol) connection to the web server, usually on
port 80. Once the TCP connection is made, the browser will issue an HTTP
request to the server using the connection. The request comprises a
header section, and possibly a body section (this is where things like
POST data go). Once the request is sent, the browser will wait for the
response. When the web server has assembled the response, it is sent
back to the browser for rendering.

The base request comprises a method, the URI (Uniform Resource
Indicator) of the web page or resource being requested, and the HTTP
version desired (1.0 or 1.1). The method may be one of:
\begin{itemize}
\item {} 
Get

\item {} 
Post

\item {} 
Put

\item {} 
Delete

\item {} 
Head

\end{itemize}

Web servers almost universally support GET and POST, with the difference
between them being the way in which query parameters are represented.
With the GET method, all query parameters are part of the URI. This
restricts the length of the parameters because a URI is generally
limited to a set number of characters. Conversely, all parameters are
included within the body of the request when using the POST method and
there is usually no limit on the length of the body. PUT and DELETE,
though considered important for emerging technology architectures such
as REST (Representational State Transfer), are considered potentially
dangerous as they enable the user to modify resources on the web server.
These methods are generally disabled on web servers and not supported by
modern web browsers.

The HTTP response consists of a header section and a body. The header
section tells the browser how to treat the body content and the browser
renders the content for viewing. Each HTTP response includes a status
code, which indicates the status of the request. The most common status
codes are:

200 OK. This indicates success

304 Not Modified. This shows that the resource in question has not
changed and the browser should load it from its cache instead. This is
only used when the browser performs a conditional GET request.

404 Not Found. This suggests that the resource requested cannot be found
on the server.

401 Authorization Required. This indicates that the resource is
protected and requires valid credentials before the server can grant
access.

500 Internal Error. This signifies that the server had a problem
processing the request.

While most developers do not need to know these status codes as they are
not used within D/HTML, AJAX (Asynchronous Javascript and XML)
developers may need to recognize these codes as part of their
development efforts.

Most HTTP responses will also contain references to other objects within
the body that will cause the browser to automatically request these
objects as well. Web pages often contain more than 30 other object
references required to complete the page.

When retrieving these referenced objects, the default browser behavior
is to open two TCP connections per host seen in the references. With
Internet Explorer there is a Windows registry setting that limits this
to a total of eight TCP connections. There is a similar setting in
Firefox, but its maximum is 24 TCP connections.

Get

The GET method means retrieve whatever information (in the form of an
entity) is identified by the Request-URI. If the Request-URI refers to a
data-producing process, it is the produced data, which shall be returned
as the entity in the response and not the source text of the process,
unless that text happens to be the output of the process.

The semantics of the GET method change to a “conditional GET” if the
request message includes an If-Modified-Since, If-Unmodified-Since,
If-Match, If-None-Match, or If-Range header field. A conditional GET
method requests that the entity be transferred only under the
circumstances described by the conditional header field(s). The
conditional GET method is intended to reduce unnecessary network usage
by allowing cached entities to be refreshed without requiring multiple
requests or transferring data already held by the client.

The semantics of the GET method change to a “partial GET” if the request
message includes a Range header field. A partial GET requests that only
part of the entity be transferred. The partial GET method is intended to
reduce unnecessary network usage by allowing partially retrieved
entities to be completed without transferring data already held by the
client.

The response to a GET request is cacheable if and only if it meets the
requirements for HTTP caching.

\sphinxstylestrong{PUT}

The PUT method requests that the enclosed entity be stored under the
supplied Request-URI. If the Request-URI refers to an already existing
resource, the enclosed entity SHOULD be considered as a modified version
of the one residing on the origin server. If the Request-URI does not
point to an existing resource, and that URI is capable of being defined
as a new resource by the requesting user agent, the origin server can
create the resource with that URI. If a new resource is created, the
origin server MUST inform the user agent via the 201 (Created) response.
If an existing resource is modified, either the 200 (OK) or 204 (No
Content) response codes SHOULD be sent to indicate successful completion
of the request. If the resource could not be created or modified with
the Request-URI, an appropriate error response SHOULD be given that
reflects the nature of the problem. The recipient of the entity MUST NOT
ignore any Content-* (e.g. Content-Range) headers that it does not
understand or implement and MUST return a 501 (Not Implemented) response
in such cases.

If the request passes through a cache and the Request-URI identifies one
or more currently cached entities, those entries SHOULD be treated as
stale. Responses to this method are not cacheable.

The fundamental difference between the POST and PUT requests is
reflected in the different meaning of the Request-URI. The URI in a POST
request identifies the resource that will handle the enclosed entity.
That resource might be a data-accepting process, a gateway to some other
protocol, or a separate entity that accepts annotations. In contrast,
the URI in a PUT request identifies the entity enclosed with the request
the user agent knows what URI is intended and the server MUST NOT
attempt to apply the request to some other resource. If the server
desires that the request be applied to a different URI, it MUST send a
301 (Moved Permanently) response; the user agent MAY then
make its own decision regarding whether or not to redirect the request.

Many different URIs MAY identify a single resource. For example, an
article might have a URI for identifying “the current version” which is
separate from the URI identifying each particular version. In this case,
a PUT request on a general URI might result in several other URIs being
defined by the origin server.

HTTP/1.1 does not define how a PUT method affects the state of an origin
server.

Unless otherwise specified for a particular entity-header, the
entity-headers in the PUT request SHOULD be applied to the resource
created or modified by the PUT.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.06 - Explain how to decode POST data}

You can decode post data within an iRule if you are trying to manipulate
or rewrite a URL data.


\bigskip\hrule\bigskip


\sphinxurl{https://devcentral.f5.com/codeshare?sid=523}

And there are plenty of online encoding and decoding tools you can use
if you are just trying to see what is being passed in your browser. The
following site is one example of an online tool.


\bigskip\hrule\bigskip


\sphinxurl{https://www.url-encode-decode.com/}

URL encoding stands for encoding certain characters in a URL by
replacing them with one or more character-triplets that consist of the
percent character “\%” followed by two hexadecimal digits. The two
hexadecimal digits of the triplet(s) represent the numeric value of the
replaced character.

The term URL encoding is a bit inexact because the encoding procedure is
not limited to URLs (Uniform Resource Locators) but can also be applied
to any other URIs (Uniform Resource Identifiers) such as URNs (Uniform
Resource Names). Therefore, the term percent-encoding should be
preferred.

For worldwide interoperability, URIs have to be encoded uniformly. To
map the wide range of characters used worldwide into the 60 or so
allowed characters in a URI, a two-step process is used:
\begin{itemize}
\item {} 
Convert the character string into a sequence of bytes using the UTF-8
encoding

\item {} 
Convert each byte that is not an ASCII letter or digit to \%HH, where
HH is the hexadecimal value of the byte

\end{itemize}

For example, the string: François ,would be encoded as: Fran\%C3\%A7ois

(The “ç” is encoded in UTF-8 as two bytes C3 (hex) and A7 (hex), which
are then written as the three characters “\%c3” and “\%a7” respectively.)
This can make a URI rather long (up to 9 ASCII characters for a single
Unicode character), but the intention is that browsers only need to
display the decoded form, and many protocols can send UTF-8 without the
\%HH escaping.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.07 Given a set of headers or traces, determine a solution to an HTTP/HTTPS application problem}
\label{\detokenize{class7/modules/module2:objective-2-07-given-a-set-of-headers-or-traces-determine-a-solution-to-an-http-https-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - Investigate the cause of a specific response code}

\sphinxurl{https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes}

\sphinxstylestrong{Determine cause of a specific response code}

There are many possible response codes as we covered in section 2.06.

404 Not Found

The 404 status code, or a Not Found error, means that the user is able
to communicate with the server but it is unable to locate the requested
file or resource.

404 errors can occur in a large variety of situations. If the user is
unexpectedly receiving a 404 Not Found error, here are some questions to
ask while troubleshooting:
\begin{itemize}
\item {} 
Does the link that directed the user to your server resource have a
typographical error in it?

\item {} 
Did the user type in the wrong URL?

\item {} 
Does the file exist in the correct location on the server? Was the
resource was moved or deleted on the server?

\item {} 
Does the server configuration have the correct document root
location?

\item {} 
Does the user that owns the web server worker process have privileges
to traverse to the directory that the requested file is in? (Hint:
directories require read and execute permissions to be accessed)

\item {} 
Is the resource being accessed a symbolic link? If so, ensure the web
server is configured to follow symbolic links.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - Investigate the cause of an SSLHandshake failure}

\sphinxurl{https://support.f5.com/csp/article/K15292}

\sphinxstylestrong{Troubleshooting SSLHandshake failures}

SSL handshake overview

SSL communication consists of a series of messages exchanged between two
parties (client and server). The SSL handshake between a client and
server consists of nine steps, and appears as follows.

\noindent\sphinxincludegraphics{{p102}.png}

Identifying SSL handshake failures

When troubleshooting SSL handshake failures, it is important to identify
the stage in which the failure occurs. For example, if the failure
occurs during the initial negotiation phase, the client and server may
not have agreed on the complete list of parameters, such as protocol
version or cipher. For information about identifying handshake failures,
refer to the following sections.

Negotiation stage

During the negotiation phase, the client starts the SSL communication
between the two systems by presenting the SSL options to the server, and
the server responds by selecting the options it supports. This stage
defines the parameters for the secure channel. If the client and server
do not agree on the complete list of options, the handshake will fail,
often with very little diagnostic data. The most common failures during
the negotiation stage involve the following incompatible components:
protocols, ciphers, secure renegotiation options, or client certificate
requests.

To understand failures in the negotiation stage, it is important to
understand the client and server behavior during the message exchange.
\begin{itemize}
\item {} 
The ClientHello offers the highest protocol version supported by the
client. If the server does not support the client’s protocol version,
the server must send a “protocol\_version” alert message and close
the connection. If the server responds with a lower protocol version,
the client then decides whether to downgrade the protocol or
terminate the SSL handshake.

\item {} 
The ClientHello also offers a list of supported cipher suites, in the
preferred order. The server then typically chooses the highest cipher
level shared by both. If the server does not support the ciphers from
the client’s list, the connection is terminated.

\end{itemize}

Negotiation phase handshake examples
\begin{itemize}
\item {} 
Successful negotiation

In the following example, the client offered protocol TLSv1.2
(version 3.3) and the server downgraded the protocol to TLSv1.0
(version 3.1). The server also chose the preferred cipher from the
client’s list:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0003 \PYG{o}{(}\PYG{l+m}{0}.0003\PYG{o}{)} C\PYGZgt{}SV3.3\PYG{o}{(}\PYG{l+m}{79}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.3
cipher suites
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA256
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA256
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0008 \PYG{o}{(}\PYG{l+m}{0}.0005\PYG{o}{)} S\PYGZgt{}CV3.1\PYG{o}{(}\PYG{l+m}{74}\PYG{o}{)} Handshake
ServerHello
Version \PYG{l+m}{3}.1
cipherSuite TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
\end{sphinxVerbatim}

\item {} 
Unsuccessful negotiation

\end{itemize}

In the following examples, the client and server fail to agree on the
SSL protocol version in the first example, and the SSL cipher in the
second example.

Example 1: The client and server unsuccessfully negotiate the protocol.
The server does not support protocol version below TLS1 (version 3.1)
and the client does not support protocol versions above SSLv3 (version
3.0):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0012 \PYG{o}{(}\PYG{l+m}{0}.0012\PYG{o}{)} C\PYGZgt{}SV3.0\PYG{o}{(}\PYG{l+m}{47}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.0
cipher suites
SSL\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0013 \PYG{o}{(}\PYG{l+m}{0}.0000\PYG{o}{)} S\PYGZgt{}CV0.0\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} Alert
level fatal
value handshake\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}failure
\end{sphinxVerbatim}

Example 2: The client and server unsuccessfully negotiate a cipher; the
server does not support any of the client’s ciphers. This is a common
failure:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0012 \PYG{o}{(}\PYG{l+m}{0}.0012\PYG{o}{)} C\PYGZgt{}SV3.1\PYG{o}{(}\PYG{l+m}{58}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.2
cipher suites
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}DH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}anon\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}MD5
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0013 \PYG{o}{(}\PYG{l+m}{0}.0000\PYG{o}{)} S\PYGZgt{}CV3.2\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} Alert
level fatal
value handshake\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}failure
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The SSL alert message (Alert 2 level fatal) is marginally
useful and means an unrecoverable error has occurred. If the virtual
server is using a Client SSL profile, you may be able to enable
useful message logging by modifying the SSL logging level to debug.
\end{sphinxadmonition}

ChangeCipherSpec (client)

During the client’s ChangeCipherSpec phase, the client initializes the
options that were negotiated by both parties. This phase marks the point
when the parties change the secure channel parameters from using
asymmetric (public key) to symmetric (shared key) encryption. A
handshake failure during this phase may relate to SSL message corruption
or issues with the SSL implementation itself.

ChangeCipherSpec (server)

During the server’s ChangeCipherSpec phase, the server initializes the
options that were negotiated by both parties. This phase marks the point
when the parties change the secure channel parameters from using
asymmetric (public key) to symmetric (shared key) encryption. A
handshake failure during this phase may relate to SSL message corruption
or issues with the SSL implementation itself.

Application phase

Messages marked as application\_data indicate that data is being
successfully encrypted. Failures in the application phase indicate
application layer events. For example, a client’s request for a document
that results in an HTTP 500 error, may cause a failure during this
phase. To diagnose failures during the application phase, you must
decrypt the SSL session using a utility, such as ssldump.

Enabling SSL debug logging

You can enable SSL debug logging on the BIG-IP system, test SSL
connections for the virtual server using a web browser or the OpenSSL
client, and then review the debug log files. Doing so will provide more
useful logging information when troubleshooting SSL handshake failures.

Note: Beginning in 12.0.0, the BIG-IP system automatically logs SSL
handshake failure information through standard logging; the use of debug
logging for SSL handshake failures is not required.

For example, with debug logging enabled, the system logs error messages
similar to the /var/log/ltm file that appear similar to the following:
\begin{itemize}
\item {} 
The client and server unsuccessfully negotiate the protocol version:

debug tmm3{[}9261{]}: 01260009:7: Connection error:
ssl\_hs\_rxhello:4409: unsupported version (70)

\item {} 
The client and server unsuccessfully negotiate a cipher:

debug tmm1{[}9261{]}: 01260009:7: Connection error:
ssl\_select\_suite:4133: no shared ciphers (40)

\end{itemize}

To enable SSL debug logging, perform the following procedure:

Impact of procedure: F5 recommends that you return the SSL log level to
the default value after you complete the troubleshooting steps. Leaving
debug logging enabled when the system is in normal production mode may
generate excessive logging and cause poor performance.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the TMOS Shell (tmsh) by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To enable SSL debug logging, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
modify /sys db log.ssl.level value Debug
\end{sphinxVerbatim}

\begin{sphinxadmonition}{important}{Important:}
After you test SSL connections for the virtual server using a
web browser or OpenSSL client, you should disable SSL debug logging by
typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
modify /sys db log.ssl.level value Warning
\end{sphinxVerbatim}
\end{sphinxadmonition}

\end{enumerate}

Testing SSL connections (using s\_client)

After you enable SSL debug logging on the BIG-IP system, you should test
SSL connections for the virtual server using a web browser or other
utility, such as the OpenSSL utility, s\_client, or cURL. Using the
s\_client utility may provide additional debugging information that you
can use to troubleshoot the issue. After making several requests to the
virtual server, you can review and analyze the debug log files on the
BIG-IP system.

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line of a Linux host (with a current version of
OpenSSL) that can access the SSL virtual server.

\item {} 
To test SSL connections for the virtual server, use the following
command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
  openssl s\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}client \PYGZhy{}connect \PYGZlt{}virtual\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}server\PYGZgt{}:\PYGZlt{}port\PYGZgt{}

For example:

.. code\PYGZhy{}block:: bash

   openssl s\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}client \PYGZhy{}connect \PYG{l+m}{10}.12.23.115:443
\end{sphinxVerbatim}

\item {} 
If the handshake attempt fails, take note of SSL errors returned by
the s\_client utility.

\item {} 
If the handshake succeeds, type the following at the prompt:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
GET / HTTP/1.0
\end{sphinxVerbatim}

\item {} 
Press Enter twice.

The HTML page should display.

\end{enumerate}

Reviewing log messages related to SSL handshake failures

After you test SSL connections using a web browser or OpenSSL client,
you should review the BIG-IP log files for debug error messages related
to the SSL handshake. To do so, perform the following procedure:

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the BIG-IP command line.

\item {} 
Use a Linux text utility to review the /var/log/ltm file. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tail \PYGZhy{}f /var/log/ltm
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
To filter the log information for SSL errors only, use the
grep command. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cat /var/log/ltm \PYG{l+s+se}{\PYGZbs{}\textbar{}}grep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}ssl\PYGZsq{}}
\end{sphinxVerbatim}
\end{sphinxadmonition}

\item {} 
Review the debug logs for SSL handshake failure or SSL alert codes.

\end{enumerate}

Additionally, you can use the grep or egrep commands to filter for
specific SSL-related keywords in the log files. To do so, refer to the
following commands:

To display log messages related to cipher or profile, use the grep or
egrep commands to search for certain patterns in the /var/log/ltm file.

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}cipher \PYGZbs{}\textbar{} profile\PYGZsq{}} /var/log/ltm
\end{sphinxVerbatim}

You may observe messages similar to the following examples.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{SSL message}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
01260014:3: Cipher \textless{}cipher\textgreater{} negotiated is not configured in profile \textless{}profile\_name\textgreater{}
&
The cipher negotiated by the client and server is not supported in one of the SSL profiles
\\
\hline
01260026:4: No shared ciphers between SSL peers \textless{}client\_IP\textgreater{}:\textless{}server\_IP\textgreater{}
&
None of the SSL ciphers sent by the client match the configured ciphers in the Client SSL profile. This error can occur when an older SSL client using a less secure cipher attempts to connect to the virtual server
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

To display log messages related to ssl and tps, use the grep or egrep
commands to search for certain patterns in the /var/log/ltm file.

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}ssl.\PYGZbs{}*tps\PYGZsq{}} /var/log/ltm
\end{sphinxVerbatim}

You may observe messages similar to the following example.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{SSL message}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
err tmm\textless{}instance\textgreater{}{[}\textless{}pid\textgreater{}{]}: 01260008:3: SSL transaction (TPS) rate limit reached
&
The BIG-IP system is handling a large number of Secure Socket Layer (SSL) connections and the number of SSL TPS connections reaches or exceeds the licensed limit.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Packet tracing using the ssldump utility

The ssldump utility is a protocol analyzer for SSL that identifies TCP
connections from a chosen packet trace or network interface and attempts
to interpret the packets as SSL traffic. When the ssldump utility
identifies SSL traffic, it decodes the records and displays them in text
to standard output. If provided with the private key that was used to
encrypt the connections, the ssldump utility may also be able to decrypt
the connections and display the application data traffic. You can use
the ssldump utility to examine, decrypt, and decode SSL-encrypted packet
streams that are processed by the BIG-IP system. For information about
using ssldump to troubleshoot SSL handshake failures, refer to K10209:
Overview of packet tracing with the ssldump utility.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.07 - Predict the browser caching behavior when application data is received (headers and HTML)}

\sphinxurl{https://www.f5.com/services/resources/white-papers/caching-behavior-of-web-browsers}

\sphinxstylestrong{Browser Caching Behavior}

When a user visits a web page, the contents of that page can be stored
in the browser’s cache so it doesn’t need to be re-requested and
re-downloaded. Efficiently using the browser cache can improve end user
response times and reduce bandwidth utilization.

The cache-ability of an item on the browser is determined by:
\begin{itemize}
\item {} 
The response headers returned from the origin web server. If the
headers indicate that content should not be cached then it won’t be.

\item {} 
A validator such as an ETag or Last-Modified header must be present
in the response.

\end{itemize}

If an item is considered cacheable, the browser will retrieve the item
from cache on repeat visits if it is considered “fresh.” Freshness is
determined by:
\begin{itemize}
\item {} 
A valid expiration time that is still within the fresh period.

\item {} 
The browser settings as explained below.

\end{itemize}

If a representation is stale or does not have a valid expiration date,
the browser will ask the web server of origin to validate the content to
confirm that the copy it has can be served. The web server will then
return a 304 to let the browser know that the local cached copy is still
good to use. If the content has changed, the web server returns a 200
response code and delivers the new version.

How the browser cache is used is dependent on three main things:
\begin{itemize}
\item {} 
Browser settings

\item {} 
The web site (HTML code and HTTP headers)

\item {} 
How the user loads the page

\end{itemize}

In most instances the cache behavior of content is controlled by the
Cache-Control and Expires HTTP headers. Cache-Control headers specify
whether or not the content can be cached and for how long. The values
can include:
\begin{itemize}
\item {} 
no-cache \textendash{} Do not cache this content

\item {} 
private \textendash{} Can be cached by browsers, but not shared/public caches

\item {} 
max-age \textendash{} Set in seconds; specifies the maximum amount of time
content is considered fresh

\end{itemize}

The inclusion of just an Expires header with no Cache-Control header
indicates that the content can be cached by both browsers and
public/shared caches and is considered stale after the specified date
and time as shown below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}Status\PYGZhy{}Line\PYG{o}{)} HTTP/1.1 \PYG{l+m}{200} OK
Content\PYGZhy{}Length \PYG{l+m}{4722}
Content\PYGZhy{}Type image/gif
Date Fri, \PYG{l+m}{31} Aug \PYG{l+m}{2007} \PYG{l+m}{10}:20:29 GMT
Expires Sun, \PYG{l+m}{17} Jan \PYG{l+m}{2038} \PYG{l+m}{19}:14:07 GMT
Last\PYGZhy{}Modified Wed, \PYG{l+m}{07} Jun \PYG{l+m}{2006} \PYG{l+m}{23}:55:38 GMT
URL in cache? Yes
Expires \PYG{l+m}{19}:14:07 Sun, \PYG{l+m}{17} Jan \PYG{l+m}{2038} GMT
Last Modification \PYG{l+m}{23}:55:38 Wed, \PYG{l+m}{07} Jun \PYG{l+m}{2006} GMT
Last Cache Update \PYG{l+m}{10}:20:32 Friday, August \PYG{l+m}{31}, \PYG{l+m}{2007} GMT
Last Access \PYG{l+m}{10}:20:31 Friday, August \PYG{l+m}{31}, \PYG{l+m}{2007} GMT
ETag
Hit Count \PYG{l+m}{1}
\end{sphinxVerbatim}

If no Cache-Control or Expires headers are present, the browser will
cache the content with no expiration date as illustrated below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Headers:
\PYG{o}{(}Status\PYGZhy{}Line\PYG{o}{)} HTTP/1.1 \PYG{l+m}{200} OK
Accept\PYGZhy{}Ranges bytes
Connection Keep\PYGZhy{}Alive
Content\PYGZhy{}Length \PYG{l+m}{221}
Content\PYGZhy{}Type Image/gif
Date Fri, \PYG{l+m}{31} Aug \PYG{l+m}{2007} \PYG{l+m}{10}:27:06 GMT
Last\PYGZhy{}Modified Fri, \PYG{l+m}{02} Jun \PYG{l+m}{2006} \PYG{l+m}{09}:46:32 GMT
URL in cache? Yes
Expires \PYG{o}{(}Not \PYG{n+nb}{set}\PYG{o}{)}
Last Modification \PYG{l+m}{09}:46:32 Friday, June \PYG{l+m}{02}, \PYG{l+m}{2006} GMT
Last Cache Update \PYG{l+m}{10}:26:32 Friday, August \PYG{l+m}{31}, \PYG{l+m}{2007} GMT
Last Access \PYG{l+m}{10}:26:31 Friday, August \PYG{l+m}{31}, \PYG{l+m}{2007} GMT
ETag
Hit Count \PYG{l+m}{1}
\end{sphinxVerbatim}

Some web developers have opted to use META Tags to control how content
can be cached as opposed to setting cache parameters in the HTTP
headers. Using the HTTP header is the preferred and recommended way of
controlling the cache behavior.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.08 Given a direct trace, a trace through the LTM device, and other relevant information, compare the traces to determine the root cause of an HTTP/HTTPS application problem}
\label{\detokenize{class7/modules/module2:objective-2-08-given-a-direct-trace-a-trace-through-the-ltm-device-and-other-relevant-information-compare-the-traces-to-determine-the-root-cause-of-an-http-https-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.08 - Given a failed HTTP request and LTM configuration data determine if the connection is failing due to the LTM configuration}

\sphinxstylestrong{Configuration Problem Determination}

This Objective and Example are very broad. They have to be to cover all
of the possible issues you can run into. A detailed understanding of why
the application is failing will allow you to correct the issue. I will
focus on SNAT issues for this example. There can be many other reasons
an application is failing.

When you are troubleshooting scenarios and looking at packet traces you
may need to recognize if SNAT needs to be enabled or disabled in the
BIG-IP flow. When SNAT is not enabled the client IP address will remain
the same on both sides of the flow. When SNAT is enabled the client ip
address will be changed to an IP address controlled by the BIG-IP.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-1/17.html}

In the most common client-server network configuration, the Local
Traffic Manager™ standard address translation mechanism ensures that
server responses return to the client through the BIG-IP® system,
thereby reversing the original destination IP address translation. This
typical network configuration is as follows:

The server nodes are on the same subnet as the BIG-IP system.

The client nodes are on a different subnet from the server nodes.

The BIG-IP system is the default gateway for the server subnet.

However, there are atypical network configurations in which the standard
BIG-IP system address translation sequence by itself does not ensure
that server responses use the required return path. Examples of these
atypical configurations are:

When clients and servers are on the same network

If you want to load balance requests to server nodes that are on the
same network as the client nodes, you can create a SNAT so that server
responses are sent back through the virtual server, rather than directly
from the server node to the client node. Otherwise, problems can occur
such as the client rejecting the response because the source of the
response does not match the destination of the request. Known as virtual
server bounceback, this SNAT configuration causes the source of the
response to match the destination of the request, thus ensuring that the
client node accepts the response. You can use this kind of configuration
when you want to load balance requests from web servers to application
servers on the same network.

When the default gateway of the server node is not the BIG-IP system

For various reasons, the server node’s default route cannot always be
defined to be a route back through the BIG-IP system. Again, this can
cause problems such as the client rejecting the response because the
source of the response does not match the destination of the request.
The solution is to create a SNAT. When Local Traffic Manager then
translates the client node’s source IP address in the request to the
SNAT address, this causes the server node to use that SNAT address as
its destination address when sending the response. This, in turn, forces
the response to return to the client node through the BIG-IP system
rather than through the server node’s default gateway.

When using the OneConnect feature

Local Traffic Manager OneConnect™ feature allows client requests to
re-use idle server-side connections. Without a SNAT, the source IP
address in the server-side connection remains the address of the client
node that initially established the connection, regardless of which
other client nodes re-use the connection. Although this is not an issue
for traffic routing, you might find it confusing when examining various
types of system output. A SNAT solves this problem.

Note: Using a SNAT for inbound connections can impact the availability
of ephemeral ports. This can lead to the SNAT being unable to process
additional connections until some source ports become available.

This image shows a typical problem for client-initiated connections when
Local Traffic Manager is not defined as the server’s default gateway,
and you have not configured a SNAT for inbound traffic.

\noindent\sphinxincludegraphics{{p112}.png}

Client rejects response due to non-matching destination and source IP
addresses

To prevent these problems, you can configure an inbound SNAT. An inbound
SNAT translates the original client source IP address in a request to a
BIG-IP system virtual server or BIG-IP system self IP address, forcing
subsequent server response to return directly to Local Traffic Manager.
When an inbound SNAT is configured on the system, Local Traffic Manager
translates not only the destination IP address in the request (using the
standard address translation mechanism), but also the source IP address
in the request (using a SNAT).

The figure below shows that by configuring a SNAT, you ensure that the
response returns through the BIG-IP system instead of through the
default gateway, thus ensuring that the client can accept the server
response.

\noindent\sphinxincludegraphics{{p122}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.09 Given a direct trace, a trace through the LTM device, and other relevant information, compare the traces to determine a solution to an HTTP/HTTPS application problem}
\label{\detokenize{class7/modules/module2:objective-2-09-given-a-direct-trace-a-trace-through-the-ltm-device-and-other-relevant-information-compare-the-traces-to-determine-a-solution-to-an-http-https-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.09 - Investigate the cause of an SSL Handshake failure}

\sphinxurl{https://support.f5.com/csp/article/K15292\#id}

Identifying SSL handshake failures

When troubleshooting SSL handshake failures, it is important to identify
the stage in which the failure occurs. For example, if the failure
occurs during the initial negotiation phase, the client and server may
not have agreed on the complete list of parameters, such as protocol
version or cipher. For information about identifying handshake failures,
refer to the following sections.

Negotiation stage

During the negotiation phase, the client starts the SSL communication
between the two systems by presenting the SSL options to the server, and
the server responds by selecting the options it supports. This stage
defines the parameters for the secure channel. If the client and server
do not agree on the complete list of options, the handshake will fail,
often with very little diagnostic data. The most common failures during
the negotiation stage involve the following incompatible components:
protocols, ciphers, secure renegotiation options, or client certificate
requests.

To understand failures in the negotiation stage, it is important to
understand the client and server behavior during the message exchange.

The ClientHello offers the highest protocol version supported by the
client. If the server does not support the client’s protocol version,
the server must send a “protocol\_version” alert message and close the
connection. If the server responds with a lower protocol version, the
client then decides whether to downgrade the protocol or terminate the
SSL handshake.

The ClientHello also offers a list of supported cipher suites, in the
preferred order. The server then typically chooses the highest cipher
level shared by both. If the server does not support the ciphers from
the client’s list, the connection is terminated.

Negotiation phase handshake examples

Successful negotiation

In the following example, the client offered protocol TLSv1.2 (version
3.3) and the server downgraded the protocol to TLSv1.0 (version 3.1).
The server also chose the preferred cipher from the client’s list:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0003 \PYG{o}{(}\PYG{l+m}{0}.0003\PYG{o}{)} C\PYGZgt{}SV3.3\PYG{o}{(}\PYG{l+m}{79}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.3
cipher suites
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA256
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA256
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0008 \PYG{o}{(}\PYG{l+m}{0}.0005\PYG{o}{)} S\PYGZgt{}CV3.1\PYG{o}{(}\PYG{l+m}{74}\PYG{o}{)} Handshake
ServerHello
Version \PYG{l+m}{3}.1
cipherSuite TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
Unsuccessful negotiation
\end{sphinxVerbatim}

In the following examples, the client and server fail to agree on the
SSL protocol version in the first example, and the SSL cipher in the
second example.

Example 1: The client and server unsuccessfully negotiate the protocol.
The server does not support protocol version below TLS1 (version 3.1)
and the client does not support protocol versions above SSLv3 (version
3.0):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0012 \PYG{o}{(}\PYG{l+m}{0}.0012\PYG{o}{)} C\PYGZgt{}SV3.0\PYG{o}{(}\PYG{l+m}{47}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.0
cipher suites
SSL\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RSA\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}AES\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{256}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}CBC\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}SHA
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0013 \PYG{o}{(}\PYG{l+m}{0}.0000\PYG{o}{)} S\PYGZgt{}CV0.0\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} Alert
level fatal
value handshake\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}failure
\end{sphinxVerbatim}

Example 2: The client and server unsuccessfully negotiate a cipher; the
server does not support any of the client’s ciphers. This is a common
failure:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{0}.0012 \PYG{o}{(}\PYG{l+m}{0}.0012\PYG{o}{)} C\PYGZgt{}SV3.1\PYG{o}{(}\PYG{l+m}{58}\PYG{o}{)} Handshake
ClientHello
Version \PYG{l+m}{3}.2
cipher suites
TLS\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}DH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}anon\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}WITH\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}RC4\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYG{l+m}{128}\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}MD5
\PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{0}.0013 \PYG{o}{(}\PYG{l+m}{0}.0000\PYG{o}{)} S\PYGZgt{}CV3.2\PYG{o}{(}\PYG{l+m}{2}\PYG{o}{)} Alert
level fatal
value handshake\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}failure
\end{sphinxVerbatim}

Note: The SSL alert message (Alert 2 level fatal) is marginally useful
and means an unrecoverable error has occurred. If the virtual server is
using a Client SSL profile, you may be able to enable useful message
logging by modifying the SSL logging level to debug.

ChangeCipherSpec (client)

During the client’s ChangeCipherSpec phase, the client initializes the
options that were negotiated by both parties. This phase marks the point
when the parties change the secure channel parameters from using
asymmetric (public key) to symmetric (shared key) encryption. A
handshake failure during this phase may relate to SSL message corruption
or issues with the SSL implementation itself.

ChangeCipherSpec (server)

During the server’s ChangeCipherSpec phase, the server initializes the
options that were negotiated by both parties. This phase marks the point
when the parties change the secure channel parameters from using
asymmetric (public key) to symmetric (shared key) encryption. A
handshake failure during this phase may relate to SSL message corruption
or issues with the SSL implementation itself.

Application phase

Messages marked as application\_data indicate that data is being
successfully encrypted. Failures in the application phase indicate
application layer events. For example, a client’s request for a document
that results in an HTTP 500 error, may cause a failure during this
phase. To diagnose failures during the application phase, you must
decrypt the SSL session using a utility, such as ssldump.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.09 - Given a failed HTTP request and LTM configuration data determine if the connection is failing due to the LTM configuration}

\sphinxstylestrong{Configuration Problem Determination}

This Objective and Example are very broad. They have to be to cover all
of the possible issues you can run into. A detailed understanding of why
the application is failing will allow you to correct the issue. I will
focus on SSL termination for this example. There can be many other
reasons an application is failing.

When you are troubleshooting scenarios and looking at packet traces you
may need to recognize if SSL termination (offloading) is correctly
applied to the application’s BIG-IP flow. When SSL termination is
enabled the virtual server will listen for encrypted traffic and then
decrypt the traffic as it sends it to the destination server. This means
the servers are configured to listen on http while the virtual server is
listening on https. Many times an administrator can make configuration
mistakes depending on the requirement to decrypt and re-encrypt.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-ssl-administration-11-5-0/3.html\#unique\_1885783063}

About SSL offload

When you want the BIG-IP system to process application traffic over SSL,
you can configure the system to perform the SSL handshake that
destination servers normally perform. This ability for the BIG-IP system
to offload SSL processing from a destination server is an important
feature of the BIG-IP system.

The most common way to configure the BIG-IP system is to create a Client
SSL profile, which makes it possible for the BIG-IP system to decrypt
client requests before sending them on to a server, and encrypt server
responses before sending them back to the client.

Within a Client SSL profile specifically, you can specify multiple
certificate/key pairs, one per key type. This enables the system to
accept all types of cipher suites that a client might support as part of
creating a secure connection. The system then decrypts the client data,
manipulates any headers or payload according to the way that you
configured the Client SSL profile, and by default, sends the request in
clear text to the target server for processing.

For those sites that require enhanced security on their internal
network, you can configure a Server SSL profile. With a Server SSL
profile, the BIG-IP system re-encrypts the request before sending it to
the destination server. When the server returns an encrypted response,
the BIG-IP system decrypts and then re-encrypts the response, before
sending the response back to the client.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.10 Given a scenario, determine which protocol analyzer tool and its options are required to resolve an application issue}
\label{\detokenize{class7/modules/module2:objective-2-10-given-a-scenario-determine-which-protocol-analyzer-tool-and-its-options-are-required-to-resolve-an-application-issue}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Identify application issues based on a protocol analyzer trace}

To determine application issues, you will need to be familiar with how
to gather packet traces and what the output should look like when
applications are performing correctly. Since applications pass through
the BIG-IP, a mis-configuration of the BIG-IP can cause an application
fail. But if an app is broken, it will still be broken regardless of how
it is accessed. This can only be learned by doing captures of working
and broken application traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Explain how to follow a conversation from client-side and server-side traces}

\sphinxurl{https://support.f5.com/csp/article/K411}

\sphinxstylestrong{Following a Conversation in a Capture}

When you have a proxy in the middle of a conversation flow as you do
when using a BIG-IP and you need to capture and see the complete
conversation, you will first need to successfully capture the data from
both sides of the proxy. This can be done in a few different ways.

You can do a separate capture on each side of the proxy by defining the
interface on which the traffic is received and egresses. Here we did it
based on VLAN names:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}i external \PYGZhy{}s0 \PYGZhy{}w/var/tmp/extcap.cap

tcpdump \PYGZhy{}i internal \PYGZhy{}s0 \PYGZhy{}w/var/tmp/intcap.cap
\end{sphinxVerbatim}

This will give you two separate files to parse through side-by-side and
try to follow the conversation.

You can do a single capture of all traffic using the loopback interface:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}i \PYG{l+m}{0}.0 \PYGZhy{}s0 \PYGZhy{}w/var/tmp/fullcap.cap
\end{sphinxVerbatim}

This will give you a single file to parse for both sides of the
conversation.

Gathering the data is the easy part. You can read the files in any way
you prefer but a tool like Wireshark makes the task much easier. You
need to look at each side of the conversation and find the corelating
flow. This can be done by right-clicking on a packet and filtering the
conversation. You can filter by IP or TCP. TCP conversation filter will
show you the flow of the TCP request.

\noindent\sphinxincludegraphics{{p131}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

You can find the start of a conversation by looking for the SYN that
starts a TCP 3-way handshake in each of the captures. On the external
side you can see the client IP (10.1.10.1) connect to the virtual server
listener (10.1.101.100).

\noindent\sphinxincludegraphics{{p142}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

On the internal side you can see the client IP (10.1.10.1) connect to
the physical server (10.1.20.11). The BIG-IP when load balancing will
translate destination IP from the Virtual Server IP address to the
physical server IP address as the packet passes, leaving the Client IP
the same.

\noindent\sphinxincludegraphics{{p152}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Other settings such as enabling SNAT on the BIG-IP can affect the Client
IP address on the internal side of the conversation.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Explain how SNAT and OneConnect effect protocol analyzer traces}

\sphinxstylestrong{SNAT and OneConnect}

SNAT and OneConnect can have a direct impact on your captures since they
both modify the typical connection flows in the system. SNAT does a
Source Network Address Translation thus if configured a source IP
addresses may change from one side of the full proxy to the other.
OneConnect is essentially TCP multiplexing and when enabled will attempt
to reuse existing established connections for the subsequent
connections. Both of these settings can cause you to get lost when
trying to follow connections from client to server and back again.

\sphinxurl{https://support.f5.com/csp/article/K13637}

Beginning in BIG-IP 11.2.0, you can use the p interface modifier with
the n modifier to capture traffic with TMM information for a specific
flow and its related peer flow. The p modifier allows you to capture a
specific traffic flow through the BIG-IP system from end to end, even
when the configuration uses a secure network address translation (SNAT)
or OneConnect. For example, the following command searches for traffic
to or from client 10.0.0.1 on interface 0.0:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}ni \PYG{l+m}{0}.0:nnnp \PYGZhy{}s0 \PYGZhy{}c \PYG{l+m}{100000} \PYGZhy{}w /var/tmp/capture.dmp host \PYG{l+m}{10}.0.0.1
\end{sphinxVerbatim}

After tcpdump identifies a related flow, the flow is marked in TMM, and
every subsequent packet in the flow (on both sides of the BIG-IP system)
is written to the capture file.

Important: This modifier produces large amounts of data and can cause
significant resource utilization. This additional resource demand may
cause poor performance or a system failure if the BIG-IP system is at
high resource utilization. Use this modifier only with very specific
filters.

Note: This modifier continues to produce flow information for the life
of the connection. Subsequent tcpdump captures reveal flow information
from previous tcpdump captures using the :p modifier if the connection
is still active. To clear flow information from previous use, run the
tcpdump command without the :p modifier using a filter that matches no
information in the flow and ensure some traffic has been received by the
BIG-IP system for the flow.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Explain how to decrypt SSL traffic for protocol analysis}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/10000/200/sol10209.html}

\sphinxstylestrong{ssldump}

The Secure Socket Layer (SSL) protocol is used to encrypt sensitive data
for transmission on the Internet. If a BIG-IP LTM system is contributing
to a technical issue, it may be helpful to decrypt the application data
to better understand the issue. The ssldump utility is an SSL/TLS
network protocol analyzer, which identifies TCP connections from a
chosen packet trace or network interface and attempts to interpret them
as SSL/TLS traffic. When the ssldump utility identifies SSL/TLS traffic,
it decodes the records and displays them in text to standard output. If
provided with the private key that was used to encrypt the connections,
the ssldump utility may also be able to decrypt the connections and
display the application data traffic.

You can use the ssldump utility to examine, decrypt, and decode
SSL-encrypted packet streams managed by the BIG-IP system. The ssldump
utility can act on packet streams real-time as they traverse the system,
or on a packet capture file saved in the libpcap format, such as that
produced by the tcpdump utility. Although it is possible for the ssldump
utility to decode and display live traffic real-time as it traverses the
BIG-IP system, it is rarely the most effective method to examine the
voluminous and complex output of the ssldump utility. Capturing the
target traffic to a file using the tcpdump utility, then decoding the
file using the ssldump utility offers a better opportunity to examine
the traffic in detail.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.10 - Explain how to recognize the different causes of slow traffic (e.g., drops, RSTs, retransmits, ICMP errors, demotion from CMP)}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/9000/800/sol9812.html?sr=46608010}

\sphinxstylestrong{Causes of slow traffic}

There can be many different reasons for slow traffic or poor network
performance and to end users of a network-based application it all seems
the same “The network is slow”. Any of these topics or combination of
topics can cause the network to seem slow.


\bigskip\hrule\bigskip


\sphinxstylestrong{Resets}

\sphinxurl{http://blogs.technet.com/b/networking/archive/2009/08/12/where-do-resets-come-from-no-the-stork-does-not-bring-them.aspx}

The BIG-IP system will close a TCP connection by sending a TCP RST
packet to a client and/or pool member under a variety of circumstances.
Depending on the specific BIG-IP configuration object, you can adjust
the BIG-IP system reset behavior from the default behavior by using the
Configuration utility or command line.

There are many reasons for resets, but some common causes of resets are
as follows:

Global settings:
\begin{itemize}
\item {} 
Adaptive Reaping

To prevent SYN flood attacks, and to preserve memory, the BIG-IP
system can prevent new connections by sending a TCP RST packet to
the client when memory usage increases beyond the reaper high-water
mark setting. The TCP RST packet is sent on the client side of the
connection, and the source IP address of the reset is the relevant
BIG-IP LTM object IP address for which the SYN request was destined.

Note: For more information, refer to K5670: Overview of adaptive
connection reaping (11.5.x and earlier) and K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x).

\item {} 
TM.RejectUnmatched

By default, the TM.RejectUnmatched BigDB variable is set to true,
and the BIG-IP system sends a TCP RST packet in response to a
non-SYN packet that matches a virtual server address and port or
self IP address and port, but does not match an established
connection. The BIG-IP system also sends a TCP RST packet in
response to a packet that matches a virtual server address, or self
IP address, but specifies an invalid port. The TCP RST packet is
sent on the client side of the connection, and the source IP address
of the reset is the relevant BIG-IP LTM object address or self IP
address for which the packet was destined. If TM.RejectUnmatched is
set to false, the system silently drops unmatched packets.

\item {} 
TM.MaxRejectRate

The TM.MaxRejectRate BigDB variable can reduce the effects of a
denial-of-service (DoS) attack by allowing you to limit the number
of TCP RSTs or ICMP unreachable packets that the BIG-IP system sends
in response to incoming connections that cannot be matched with
virtual server connections. The default value for the
TM.MaxRejectRate db key is 250 TCP RSTs or 250 ICMP unreachable
packets, per second.

Note: For more information, refer to K13151: Configuring the rate at
which the BIG-IP system issues TCP RSTs or ICMP unreachable packets
(11.x - 13.x).

\end{itemize}

Virtual servers:
\begin{itemize}
\item {} 
Virtual server connection limits

When a virtual server connection limit is configured, and the
maximum number of concurrent connections is exceeded for the virtual
server, the BIG-IP system sends a TCP RST packet in response to
connection attempts. The TCP RST packet is sent on the client side
of the connection, and the source IP address of the reset is the
relevant virtual server IP address.

\item {} 
Reject virtual servers

A Reject virtual server always sends a TCP RST packet in response to
a connection attempt. The TCP RST packet is sent on the client side
of the connection, and the source IP address of the reset is the
relevant virtual server IP address.

Note: For more information, refer to K8082: Overview of TCP
connection setup for BIG-IP LTM virtual server types.

\end{itemize}

Pools:
\begin{itemize}
\item {} 
No available pool members

When all pool members are unavailable due to being disabled, forced
offline, or down, the BIG-IP RST behavior varies slightly depending
on the virtual server type. If the virtual server references a TCP
profile (Standard virtual server type), the system allows the
three-way TCP handshake to complete before sending the TCP RST to
the client. If the virtual server references a FastL4 profile, the
system sends a TCP RST packet in response to a connection attempt.
The TCP RST packet is sent on the client side of the connection, and
the source IP address of the reset is the relevant virtual server IP
address.

\item {} 
Pool member or node connection limits

When a pool member or node connection limit is configured, and the
maximum number of concurrent connections is exceeded for the pool
member or node, the BIG-IP system resets the connection attempt. The
TCP RST packet is sent on the client side of the connection, and the
source IP address of the reset is the relevant virtual server IP
address.

Note: For more information, refer to K9849: The BIG-IP system sends
a TCP RST packet when the system reaches a pool member or node
connection limit.

\end{itemize}

Profiles:
\begin{itemize}
\item {} 
Protocol profile idle timeouts (if the Reset On Timeout setting is
enabled)

The BIG-IP system tracks connection flows by adding an entry to the
connection table. When the connection flow becomes idle, the BIG-IP
system starts a timer and closes the connection with a TCP RST
packet when the connection reaches the idle session timeout. The TCP
RST packet is sent on the client and server side of the connection,
and the source IP address of the reset is the relevant virtual
server IP address. If the connection flow is associated with
multiple profiles that specify different idle session timeout
values, the connection will be closed when the idle time reaches the
smaller value.

Note: For more information, refer to K7606: Overview of BIG-IP idle
session time-outs and K7166: Changing the idle timeout for a
protocol profile.

\item {} 
Maximum Segment Retransmission

The BIG-IP LTM system resets TCP connections after sending eight
retransmissions for a connection. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant virtual server IP address.

Note: For more information, refer to K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x) and K7381: The BIG-IP
resets TCP connections after sending eight retransmissions for a
connection.

\item {} 
Maximum SYN Retransmissions

The BIG-IP LTM system resets TCP connections after sending three SYN
retransmissions for a connection. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant virtual server IP address.

Note: For more information, refer to K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x), and K10372: BIG-IP LTM
resets TCP connections after sending three SYN retransmissions for a
connection.

\end{itemize}

SNATs:
\begin{itemize}
\item {} 
Unacknowledged SYN requests for SNAT objects

The BIG-IP LTM system terminates a SNAT flow with a TCP RST packet
after processing three unacknowledged SYN requests for the
connection.

Note: For more information, refer to K7829: Nascent SNAT connections
are reset when the retransmission backoff time exceeds the TCP
Handshake Timeout.

\item {} 
Idle connection timeouts for SNAT objects

When a SNAT connection flow becomes idle and reaches the idle
session timeout, the BIG-IP system closes the connection with a TCP
RST packet.

Note: For more information, refer to K7606: Overview of BIG-IP idle
session time-outs.

\item {} 
SNAT port exhaustion

A SNAT supports approximately 64,000 concurrent connections per
destination IP. A high volume of requests can exceed the 64,000
connection limit and result in TCP port exhaustion.

Note: For more information, refer to K7820: Overview of SNAT features.

Note: Connections processed by a SNAT object are also frequently
processed by a virtual server object. The source address of the TCP RST
packet will vary depending on whether the connection is processed by a
SNAT object alone, or whether the connection is also processed by a
virtual server.

\end{itemize}

Monitors:
\begin{itemize}
\item {} 
BIG-IP health monitors

Certain BIG-IP monitors may use a TCP RST packet to close the
monitor connection when the remote service returns a prompt. For
example, the tcp monitor initiates a TCP connection to the remote
service. If the service returns a prompt after the connection is
established (for example, FTP or SSH), the tcp monitor considers the
service to be up, and sends a TCP RST packet to the service.

The following BIG-IP monitor types may use a TCP RST packet to close
the monitor connection quickly after receiving matched content:

\item {} 
The tcp\_half\_open monitor performs a simple check on the pool
member service by sending a TCP SYN packet to the service port. When
the monitor receives the SYN-ACK packet from the pool member, the
monitor considers the service to be up, and sends a TCP RST packet to
the service instead of completing the three-way handshake. The TCP
RST packet is typically sent on the server side of the connection,
and the source IP address of the reset is the relevant self IP
address of the VLAN.

\item {} 
The HTTP monitor may send TCP reset packets to close the monitor
connection as soon as the health check receive string is matched,
even if the BIG-IP system has not yet received the entire object that
was requested in the HTTP monitor send string. Closing the monitor
connection in this way saves BIG-IP system resources.

\end{itemize}

iRules:
\begin{itemize}
\item {} 
iRules commands

An iRule can be configured to close TCP connections using a TCP RST
packet. For example, the reject iRule command closes the TCP
connection by sending a TCP RST packet to the TCP peer, as
appropriate, for the protocol. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant BIG-IP LTM object address with which the iRule
is associated.

Note: For more information, refer to the DevCentral site. A
DevCentral login is required to access this content.

\item {} 
Improperly configured iRules

An iRule with proper syntax but improper logic can be saved but may
cause traffic to be reset.

\end{itemize}

Packet filters:
\begin{itemize}
\item {} 
Packet filter rules

A packet filter configured with an action of Reject for certain TCP
traffic will force the system to reject the packet, and send a TCP
RST packet to the sender.

\end{itemize}

\sphinxstylestrong{Application Reset}

This situation also generates a lot of calls and, unfortunately, is
determined typically by process of elimination. In other words, there is
no other reason for the reset so it must have come from the application.
I hate saying that, but that really is the answer. If we look at the
network traffic and see no reason for TCP itself to have sent the reset,
such as the other examples above, then it must have been sent from the
application. As I mentioned in the first paragraph, this is perfectly
legitimate and may even be desirable. This is a common practice in an
application that is making a large number of short-lived TCP
connections. Such an application can cause port exhaustion on the server
due to so many ports being in a Time Wait state. However, application
developers need to understand why the Time Wait state exists before just
resetting all connections.

Note: It is possible to look at the code for an application and
see if it is performing a Winsock function close (socket). If this
is done on a connection where data has been set, then this will
generate the Reset. You can also see this in Winsock logging. If
this function is called on a TCP connection where only the Three Way
Handshake has been completed, but no data has been sent, it will
result in the graceful close of the connection using Fin frames.

\sphinxstylestrong{Dropped packets}

A dropped packet on a network can cause a overhead on your network. It
is likely that if a packet is dropped more than one packet will have to
be resent. This is caused when network fragmentation occurs. As a
network interface is placing packets on the wire it is following an MTU
size limit for each packet. If the operating system is sending data to
the network that is in a way that is larger than the MTU size the
interface will break it up into packets that will fit the MTU. So when
one packet is lost it must resend all the packets for that data not just
the one lost packet.

\sphinxstylestrong{Retransmits}

A retransmit at a TCP level will likely mean that the TCP session data
has to be resent and if there is also fragmentation occurring at the
network layer it will compound the issue as mentioned in the dropped
packet section above.

ICMP Errors

ICMP Errors can add to an already taxed network. If you are under an
ICMP DOS attack the ICMP errors will add to the overhead that has to be
processed.

ICMP messages are typically used for diagnostic or control purposes or
generated in response to errors in IP operations (as specified in RFC
1122). ICMP errors are directed to the source IP address of the
originating packet.

ICMP error messages contain a data section that includes the entire IPv4
header, plus the first eight bytes of data from the IPv4 packet that
caused the error message. The ICMP packet is then encapsulated in a new
IPv4 packet.


\bigskip\hrule\bigskip


\sphinxstylestrong{CMP Demotion}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/14000/200/sol14248.html?sr=46608046}

CMP should not be confused with Symmetric Multi-Processing (SMP). SMP
architecture is used in multiple operating systems. SMP operates by
allowing operating systems and software applications that are optimized
for SMP to use the multiple processors that are available to the
operating system. SMP performs this operation by spreading multiple
threads across multiple processors, which allows for faster processing
and more efficient use of system resources, as multiple threads can be
processed simultaneously instead of waiting in a queue to be processed.
CMP uses a similar approach to leverage multiple processing units by
spawning a separate instance of the TMM process on each processing unit
that is available to the system. While SMP may be used for any process,
CMP processing is available only to the BIG-IP TMM process for the sole
purpose of providing more dedicated resources to manage load balanced
traffic. With multiple TMM instances simultaneously processing traffic,
system performance is enhanced, and traffic management capacity is
expanded.

Even if CMP is enabled on a virtual server, the BIG-IP system demotes a
virtual server with incompatible features from CMP processing. This
means it will run slower due to the CMP feature being turned off.

If the virtual server has been demoted, the CMP Mode line of the TMSH
show ltm virtual \textless{}virtual\_server\_name\textgreater{} command reports none, disable,
or single to indicate that CMP has been demoted for the virtual server.

The command output would appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{g+go}{Ltm::Virtual Server: CMP\PYGZus{}vip}
\PYG{g+go}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{g+go}{Status}
\PYG{g+go}{Availability : available}
\PYG{g+go}{State : enabled}
\PYG{g+go}{Reason : The virtual server is available}
\PYG{g+go}{CMP : enabled}
\PYG{g+go}{CMP Mode : single}
\PYG{g+go}{Destination : 10.11.10.212:80}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.11 Given a trace and necessary supporting documentation, determine the root cause of an application problem}
\label{\detokenize{class7/modules/module2:objective-2-11-given-a-trace-and-necessary-supporting-documentation-determine-the-root-cause-of-an-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.11 - Analyze a tcpdump to identify application or configuration problems.}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/1000/800/sol1893.html}

\sphinxstylestrong{Packet trace analysis}

To determine application issues, you will need to be familiar with how
to gather packet traces and what the output should look like when
applications are performing correctly. Since applications pass through
the BIG-IP, a mis-configuration of the BIG-IP can cause an application
fail. But if an app is broken, it will still be broken regardless of how
it is accessed. This can only be learned by doing captures of working
and broken application traffic.

When you are troubleshooting scenarios and looking at packet traces you
may need to recognize that the application is not working due to
anything from of the network design to application requirements.

\sphinxstylestrong{Network Design example}

Settings related to SNAT may need to be enabled or disabled in the
BIG-IP flow. When SNAT is not enabled the client IP address will remain
the same on both sides of the flow. When SNAT is enabled the client IP
address will be changed to an IP address controlled by the BIG-IP.

If the application server does not have a return path in the network to
the original requesting client IP address, that passes through the
BIG-IP, then SNAT will need to be enabled to force the return traffic
back to the BIG-IP. This will allow the BIG-IP to respond to the
original request from the client correctly.

\sphinxstylestrong{Application Requirements}

Recognizing applications issues can be harder than recognizing most
network issues. It might not be hard to recognize an SSL handshake issue
as described in section 2.09 but an issue with persistence may be hard
to see in a packet capture. If you have feedback from the testers or
users defining the issue you may be able to more quickly pinpoint that
the issue revolves around persistence. If you are looking at a trace you
may have to look past the TCP and into the HTTP headers and or payload
to find the issue.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.12 Given a trace and necessary supporting documentation, determine a solution to an application problem}
\label{\detokenize{class7/modules/module2:objective-2-12-given-a-trace-and-necessary-supporting-documentation-determine-a-solution-to-an-application-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.12 - Analyze a tcpdump to identify application or configuration problems}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/1000/800/sol1893.html}

\sphinxstylestrong{Packet trace analysis}

To determine application issues, you will need to be familiar with how
to gather packet traces and what the output should look like when
applications are performing correctly. Since applications pass through
the BIG-IP, a mis-configuration of the BIG-IP can cause an application
fail. But if an app is broken, it will still be broken regardless of how
it is accessed. This can only be learned by doing captures of working
and broken application traffic.

When you are troubleshooting scenarios and looking at packet traces you
may need to recognize that the application is not working due to
anything from of the network design to application requirements.

\sphinxstylestrong{Network Design example}

Settings related to SNAT may need to be enabled or disabled in the
BIG-IP flow. When SNAT is not enabled the client IP address will remain
the same on both sides of the flow. When SNAT is enabled the client IP
address will be changed to an IP address controlled by the BIG-IP.

If the application server does not have a return path in the network to
the original requesting client IP address, that passes through the
BIG-IP, then SNAT will need to be enabled to force the return traffic
back to the BIG-IP. This will allow the BIG-IP to respond to the
original request from the client correctly.

\sphinxstylestrong{Application Requirements}

Recognizing applications issues can be harder than recognizing most
network issues. It might not be hard to recognize an SSL handshake issue
as described in section 2.09 but an issue with persistence may be hard
to see in a packet capture. If you have feedback from the testers or
users defining the issue you may be able to more quickly pinpoint that
the issue revolves around persistence. If you are looking at a trace you
may have to look past the TCP and into the HTTP headers and or payload
to find the issue.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.13 Given a scenario, determine from where the protocol analyzer data should be collected}
\label{\detokenize{class7/modules/module2:objective-2-13-given-a-scenario-determine-from-where-the-protocol-analyzer-data-should-be-collected}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.13 - Explain how to decrypt SSL traffic for protocol analysis}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/10000/200/sol10209.html}

\sphinxstylestrong{ssldump}

The Secure Socket Layer (SSL) protocol is used to encrypt sensitive data
for transmission on the Internet. If a BIG-IP LTM system is contributing
to a technical issue, it may be helpful to decrypt the application data
to better understand the issue. The ssldump utility is an SSL/TLS
network protocol analyzer, which identifies TCP connections from a
chosen packet trace or network interface and attempts to interpret them
as SSL/TLS traffic. When the ssldump utility identifies SSL/TLS traffic,
it decodes the records and displays them in text to standard output. If
provided with the private key that was used to encrypt the connections,
the ssldump utility may also be able to decrypt the connections and
display the application data traffic.

You can use the ssldump utility to examine, decrypt, and decode
SSL-encrypted packet streams managed by the BIG-IP system. The ssldump
utility can act on packet streams real-time as they traverse the system,
or on a packet capture file saved in the libpcap format, such as that
produced by the tcpdump utility. Although it is possible for the ssldump
utility to decode and display live traffic real-time as it traverses the
BIG-IP system, it is rarely the most effective method to examine the
voluminous and complex output of the ssldump utility. Capturing the
target traffic to a file using the tcpdump utility, then decoding the
file using the ssldump utility offers a better opportunity to examine
the traffic in detail.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.13 - Explain how to recognize the different causes of slow traffic (e.g., drops, RSTs, retransmits, ICMP errors, demotion from CMP)}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/9000/800/sol9812.html?sr=46608010}

\sphinxstylestrong{Causes of slow traffic}

There can be many different reasons for slow traffic or poor network
performance and to end users of a network-based application it all seems
the same “The network is slow”. Any of these topics or combination of
topics can cause the network to seem slow.


\bigskip\hrule\bigskip


\sphinxstylestrong{Resets}

\sphinxurl{http://blogs.technet.com/b/networking/archive/2009/08/12/where-do-resets-come-from-no-the-stork-does-not-bring-them.aspx}

The BIG-IP system will close a TCP connection by sending a TCP RST
packet to a client and/or pool member under a variety of circumstances.
Depending on the specific BIG-IP configuration object, you can adjust
the BIG-IP system reset behavior from the default behavior by using the
Configuration utility or command line.

There are many reasons for resets, but some common causes of resets are
as follows:

Global settings:
\begin{itemize}
\item {} 
Adaptive Reaping

To prevent SYN flood attacks, and to preserve memory, the BIG-IP
system can prevent new connections by sending a TCP RST packet to
the client when memory usage increases beyond the reaper high-water
mark setting. The TCP RST packet is sent on the client side of the
connection, and the source IP address of the reset is the relevant
BIG-IP LTM object IP address for which the SYN request was destined.

Note: For more information, refer to K5670: Overview of adaptive
connection reaping (11.5.x and earlier) and K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x).

\item {} 
TM.RejectUnmatched

By default, the TM.RejectUnmatched BigDB variable is set to true,
and the BIG-IP system sends a TCP RST packet in response to a
non-SYN packet that matches a virtual server address and port or
self IP address and port, but does not match an established
connection. The BIG-IP system also sends a TCP RST packet in
response to a packet that matches a virtual server address, or self
IP address, but specifies an invalid port. The TCP RST packet is
sent on the client side of the connection, and the source IP address
of the reset is the relevant BIG-IP LTM object address or self IP
address for which the packet was destined. If TM.RejectUnmatched is
set to false, the system silently drops unmatched packets.

\item {} 
TM.MaxRejectRate

The TM.MaxRejectRate BigDB variable can reduce the effects of a
denial-of-service (DoS) attack by allowing you to limit the number
of TCP RSTs or ICMP unreachable packets that the BIG-IP system sends
in response to incoming connections that cannot be matched with
virtual server connections. The default value for the
TM.MaxRejectRate db key is 250 TCP RSTs or 250 ICMP unreachable
packets, per second.

Note: For more information, refer to K13151: Configuring the rate at
which the BIG-IP system issues TCP RSTs or ICMP unreachable packets
(11.x - 13.x).

\end{itemize}

Virtual servers:
\begin{itemize}
\item {} 
Virtual server connection limits

When a virtual server connection limit is configured, and the
maximum number of concurrent connections is exceeded for the virtual
server, the BIG-IP system sends a TCP RST packet in response to
connection attempts. The TCP RST packet is sent on the client side
of the connection, and the source IP address of the reset is the
relevant virtual server IP address.

\item {} 
Reject virtual servers

A Reject virtual server always sends a TCP RST packet in response to
a connection attempt. The TCP RST packet is sent on the client side
of the connection, and the source IP address of the reset is the
relevant virtual server IP address.

Note: For more information, refer to K8082: Overview of TCP
connection setup for BIG-IP LTM virtual server types.

\end{itemize}

Pools:
\begin{itemize}
\item {} 
No available pool members

When all pool members are unavailable due to being disabled, forced
offline, or down, the BIG-IP RST behavior varies slightly depending
on the virtual server type. If the virtual server references a TCP
profile (Standard virtual server type), the system allows the
three-way TCP handshake to complete before sending the TCP RST to
the client. If the virtual server references a FastL4 profile, the
system sends a TCP RST packet in response to a connection attempt.
The TCP RST packet is sent on the client side of the connection, and
the source IP address of the reset is the relevant virtual server IP
address.

\item {} 
Pool member or node connection limits

When a pool member or node connection limit is configured, and the
maximum number of concurrent connections is exceeded for the pool
member or node, the BIG-IP system resets the connection attempt. The
TCP RST packet is sent on the client side of the connection, and the
source IP address of the reset is the relevant virtual server IP
address.

Note: For more information, refer to K9849: The BIG-IP system sends
a TCP RST packet when the system reaches a pool member or node
connection limit.

\end{itemize}

Profiles:
\begin{itemize}
\item {} 
Protocol profile idle timeouts (if the Reset On Timeout setting is
enabled)

The BIG-IP system tracks connection flows by adding an entry to the
connection table. When the connection flow becomes idle, the BIG-IP
system starts a timer and closes the connection with a TCP RST
packet when the connection reaches the idle session timeout. The TCP
RST packet is sent on the client and server side of the connection,
and the source IP address of the reset is the relevant virtual
server IP address. If the connection flow is associated with
multiple profiles that specify different idle session timeout
values, the connection will be closed when the idle time reaches the
smaller value.

Note: For more information, refer to K7606: Overview of BIG-IP idle
session time-outs and K7166: Changing the idle timeout for a
protocol profile.

\item {} 
Maximum Segment Retransmission

The BIG-IP LTM system resets TCP connections after sending eight
retransmissions for a connection. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant virtual server IP address.

Note: For more information, refer to K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x) and K7381: The BIG-IP
resets TCP connections after sending eight retransmissions for a
connection.

\item {} 
Maximum SYN Retransmissions

The BIG-IP LTM system resets TCP connections after sending three SYN
retransmissions for a connection. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant virtual server IP address.

Note: For more information, refer to K14813: Detecting and
mitigating DoS/DDoS attacks (11.4.x - 12.x), and K10372: BIG-IP LTM
resets TCP connections after sending three SYN retransmissions for a
connection.

\end{itemize}

SNATs:
\begin{itemize}
\item {} 
Unacknowledged SYN requests for SNAT objects

The BIG-IP LTM system terminates a SNAT flow with a TCP RST packet
after processing three unacknowledged SYN requests for the
connection.

Note: For more information, refer to K7829: Nascent SNAT connections
are reset when the retransmission backoff time exceeds the TCP
Handshake Timeout.

\item {} 
Idle connection timeouts for SNAT objects

When a SNAT connection flow becomes idle and reaches the idle
session timeout, the BIG-IP system closes the connection with a TCP
RST packet.

Note: For more information, refer to K7606: Overview of BIG-IP idle
session time-outs.

\item {} 
SNAT port exhaustion

A SNAT supports approximately 64,000 concurrent connections per
destination IP. A high volume of requests can exceed the 64,000
connection limit and result in TCP port exhaustion.

Note: For more information, refer to K7820: Overview of SNAT
features.

Note: Connections processed by a SNAT object are also frequently
processed by a virtual server object. The source address of the TCP RST
packet will vary depending on whether the connection is processed by a
SNAT object alone, or whether the connection is also processed by a
virtual server.

\end{itemize}

Monitors:
\begin{itemize}
\item {} 
BIG-IP health monitors

Certain BIG-IP monitors may use a TCP RST packet to close the
monitor connection when the remote service returns a prompt. For
example, the tcp monitor initiates a TCP connection to the remote
service. If the service returns a prompt after the connection is
established (for example, FTP or SSH), the tcp monitor considers the
service to be up, and sends a TCP RST packet to the service.

The following BIG-IP monitor types may use a TCP RST packet to close
the monitor connection quickly after receiving matched content:

\item {} 
The tcp\_half\_open monitor performs a simple check on the pool
member service by sending a TCP SYN packet to the service port. When
the monitor receives the SYN-ACK packet from the pool member, the
monitor considers the service to be up, and sends a TCP RST packet to
the service instead of completing the three-way handshake. The TCP
RST packet is typically sent on the server side of the connection,
and the source IP address of the reset is the relevant self IP
address of the VLAN.

\item {} 
The HTTP monitor may send TCP reset packets to close the monitor
connection as soon as the health check receive string is matched,
even if the BIG-IP system has not yet received the entire object that
was requested in the HTTP monitor send string. Closing the monitor
connection in this way saves BIG-IP system resources.

\end{itemize}

iRules:
\begin{itemize}
\item {} 
iRules commands

An iRule can be configured to close TCP connections using a TCP RST
packet. For example, the reject iRule command closes the TCP
connection by sending a TCP RST packet to the TCP peer, as
appropriate, for the protocol. The TCP RST packet is sent on the
client side of the connection, and the source IP address of the
reset is the relevant BIG-IP LTM object address with which the iRule
is associated.

Note: For more information, refer to the DevCentral site. A
DevCentral login is required to access this content.

\item {} 
Improperly configured iRules

An iRule with proper syntax but improper logic can be saved but may
cause traffic to be reset.

\end{itemize}

Packet filters:
\begin{itemize}
\item {} 
Packet filter rules

A packet filter configured with an action of Reject for certain TCP
traffic will force the system to reject the packet, and send a TCP
RST packet to the sender.

\end{itemize}

\sphinxstylestrong{Application Reset}

This situation also generates a lot of calls and, unfortunately, is
determined typically by process of elimination. In other words, there is
no other reason for the reset so it must have come from the application.
I hate saying that, but that really is the answer. If we look at the
network traffic and see no reason for TCP itself to have sent the reset,
such as the other examples above, then it must have been sent from the
application. As I mentioned in the first paragraph, this is perfectly
legitimate and may even be desirable. This is a common practice in an
application that is making a large number of short-lived TCP
connections. Such an application can cause port exhaustion on the server
due to so many ports being in a Time Wait state. However, application
developers need to understand why the Time Wait state exists before just
resetting all connections.

Note: It is possible to look at the code for an application and
see if it is performing a Winsock function close (socket). If this
is done on a connection where data has been set, then this will
generate the Reset. You can also see this in Winsock logging. If
this function is called on a TCP connection where only the Three Way
Handshake has been completed, but no data has been sent, it will
result in the graceful close of the connection using Fin frames.

\sphinxstylestrong{Dropped packets}

A dropped packet on a network can cause a overhead on your network. It
is likely that if a packet is dropped more than one packet will have to
be resent. This is caused when network fragmentation occurs. As a
network interface is placing packets on the wire it is following an MTU
size limit for each packet. If the operating system is sending data to
the network that is in a way that is larger than the MTU size the
interface will break it up into packets that will fit the MTU. So when
one packet is lost it must resend all the packets for that data not just
the one lost packet.

\sphinxstylestrong{Retransmits}

A retransmit at a TCP level will likely mean that the TCP session data
has to be resent and if there is also fragmentation occurring at the
network layer it will compound the issue as mentioned in the dropped
packet section above.

ICMP Errors

ICMP Errors can add to an already taxed network. If you are under an
ICMP DOS attack the ICMP errors will add to the overhead that has to be
processed.

ICMP messages are typically used for diagnostic or control purposes or
generated in response to errors in IP operations (as specified in RFC
1122). ICMP errors are directed to the source IP address of the
originating packet.

ICMP error messages contain a data section that includes the entire IPv4
header, plus the first eight bytes of data from the IPv4 packet that
caused the error message. The ICMP packet is then encapsulated in a new
IPv4 packet.


\bigskip\hrule\bigskip


\sphinxstylestrong{CMP Demotion}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/14000/200/sol14248.html?sr=46608046}

CMP should not be confused with Symmetric Multi-Processing (SMP). SMP
architecture is used in multiple operating systems. SMP operates by
allowing operating systems and software applications that are optimized
for SMP to use the multiple processors that are available to the
operating system. SMP performs this operation by spreading multiple
threads across multiple processors, which allows for faster processing
and more efficient use of system resources, as multiple threads can be
processed simultaneously instead of waiting in a queue to be processed.
CMP uses a similar approach to leverage multiple processing units by
spawning a separate instance of the TMM process on each processing unit
that is available to the system. While SMP may be used for any process,
CMP processing is available only to the BIG-IP TMM process for the sole
purpose of providing more dedicated resources to manage load balanced
traffic. With multiple TMM instances simultaneously processing traffic,
system performance is enhanced, and traffic management capacity is
expanded.

Even if CMP is enabled on a virtual server, the BIG-IP system demotes a
virtual server with incompatible features from CMP processing. This
means it will run slower due to the CMP feature being turned off.

If the virtual server has been demoted, the CMP Mode line of the TMSH
show ltm virtual \textless{}virtual\_server\_name\textgreater{} command reports none, disable,
or single to indicate that CMP has been demoted for the virtual server.

The command output would appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{g+go}{Ltm::Virtual Server: CMP\PYGZbs{}\PYGZus{}vip}
\PYG{g+go}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{g+go}{Status}
\PYG{g+go}{Availability : available}
\PYG{g+go}{State : enabled}
\PYG{g+go}{Reason : The virtual server is available}
\PYG{g+go}{CMP : enabled}
\PYG{g+go}{CMP Mode : single}
\PYG{g+go}{Destination : 10.11.10.212:80}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.13 - Chose the appropriate protocol analyzer for troubleshooting a given problem (e.g., Wireshark, tcpdump, ssldump)}

\sphinxstylestrong{Which packet capture tool should be used to resolve an application issue?}

There are many different tools that can do a packet capture. Some are a
physical bump in the wire (e.g. protocol analyzer on a tap port)
capturing data as it flows through the device, while others are software
running on a node (e.g. Wireshark on a PC, tcpdump on a Linux system)
that promiscuously (promiscuous network interface is required) listens
on the wire for traffic flow. You can also do a capture on the BIG-IP
using tcpdump. Doing a capture on the BIG-IP will create overhead on the
system and may negatively affect system performance of a device which is
controlling network flow to production systems. So, choosing how and
where to capture data is very important.

The rules are simple. You need to gather the packet capture where the
problem is occurring on the network, when the problem is happening. A
packet capture, no matter the tool used to gather it, is going to show
you the conversations between the nodes. Some tools are easier than
others to use to filter and read conversations. Some gathering tools
like tcpdump provide only the ability to read the capture (-r).
Wireshark is one of the better tools to use due to strong filtering
capabilities.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.13 - Identify application issues based on a protocol analyzer trace}

To determine application issues, you will need to be familiar with how
to gather packet traces and what the output should look like when
applications are performing correctly. Since applications pass through
the BIG-IP, a mis-configuration of the BIG-IP can cause an application
fail. But if an app is broken, it will still be broken regardless of how
it is accessed. This can only be learned by doing captures of working
and broken application traffic.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.13 - Explain how SNAT and OneConnect effect protocol analyzer traces}

\sphinxstylestrong{SNAT and OneConnect}

SNAT and OneConnect can have a direct impact on your captures since they
both modify the typical connection flows in the system. SNAT does a
Source Network Address Translation thus if configured a source IP
addresses may change from one side of the full proxy to the other.
OneConnect is essentially TCP multiplexing and when enabled will attempt
to reuse existing established connections for the subsequent
connections. Both of these settings can cause you to get lost when
trying to follow connections from client to server and back again.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K13637}

Beginning in BIG-IP 11.2.0, you can use the p interface modifier with
the n modifier to capture traffic with TMM information for a specific
flow and its related peer flow. The p modifier allows you to capture a
specific traffic flow through the BIG-IP system from end to end, even
when the configuration uses a secure network address translation (SNAT)
or OneConnect. For example, the following command searches for traffic
to or from client 10.0.0.1 on interface 0.0:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}ni \PYG{l+m}{0}.0:nnnp \PYGZhy{}s0 \PYGZhy{}c \PYG{l+m}{100000} \PYGZhy{}w /var/tmp/capture.dmp host \PYG{l+m}{10}.0.0.1
\end{sphinxVerbatim}

After tcpdump identifies a related flow, the flow is marked in TMM, and
every subsequent packet in the flow (on both sides of the BIG-IP system)
is written to the capture file.

Important: This modifier produces large amounts of data and can cause
significant resource utilization. This additional resource demand may
cause poor performance or a system failure if the BIG-IP system is at
high resource utilization. Use this modifier only with very specific
filters.

Note: This modifier continues to produce flow information for the life
of the connection. Subsequent tcpdump captures reveal flow information
from previous tcpdump captures using the :p modifier if the connection
is still active. To clear flow information from previous use, run the
tcpdump command without the :p modifier using a filter that matches no
information in the flow and ensure some traffic has been received by the
BIG-IP system for the flow.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.14 Given a trace, identify monitor issues}
\label{\detokenize{class7/modules/module2:objective-2-14-given-a-trace-identify-monitor-issues}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.14 - Explain how to capture and interpret monitor traffic using protocol analyzer}

\sphinxurl{https://support.f5.com/csp/article/K12531}

\sphinxurl{https://support.f5.com/csp/article/K411}

\sphinxstylestrong{Capture and Interpret Monitor Traffic}

Health monitors originate from the non-floating self IP addresses of
both the active and standby BIG-IP systems. This means when you need
capture monitor traffic from a BIG-IP to another device you will need to
filter for traffic originating from the non-floating self IP addresses.

The following capture would gather http based monitor traffic:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tcpdump \PYGZhy{}s0 src host \PYGZlt{}non\PYGZhy{}floating self IP address\PYGZgt{} and dst port \PYG{l+m}{80}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.14 - Explain how to obtain needed input and output data to create the monitors}

You can use external tools to try to gather the information necessary to
configure a monitor. For example, a tool like CURL will allow you to
make a http based URL request to a server and will display the requested
webpage data in text format. This way you know the http request string
to use in the monitor and know what comes back and can choose what part
of the response to put in the receive string of the monitor.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
curl http://www.f5.com

\PYGZlt{}html\PYGZgt{}
\PYGZlt{}head\PYGZgt{}\PYGZlt{}title\PYGZgt{}301 Moved Permanently\PYGZlt{}/title\PYGZgt{}\PYGZlt{}/head\PYGZgt{}
\PYGZlt{}body \PYG{n+nv}{bgcolor}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}white\PYGZdq{}}\PYGZgt{}
\PYGZlt{}center\PYGZgt{}\PYGZlt{}h1\PYGZgt{}301 Moved Permanently\PYGZlt{}/h1\PYGZgt{}\PYGZlt{}/center\PYGZgt{}
\PYGZlt{}hr\PYGZgt{}\PYGZlt{}center\PYGZgt{}CloudFront\PYGZlt{}/center\PYGZgt{}
\PYGZlt{}/body\PYGZgt{}
\PYGZlt{}/html\PYGZgt{}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-1/15.html}

\sphinxstylestrong{Creating Monitors}

You create a custom monitor when the values defined in a pre-configured
monitor do not meet your needs, or no pre-configured monitor exists for
the type of monitor you are creating.

When you create a custom monitor, you use the BIG-IP Configuration
utility or a command line utility to: give the monitor a unique name,
specify a monitor type, and, if a monitor of that type already exists,
import settings and their values from the existing monitor. You can then
change the values of any imported settings.

You must base each custom monitor on a monitor type. When you create a
monitor, the BIG-IP Configuration utility displays a list of monitor
types. To specify a monitor type, simply choose the one that corresponds
to the service you want to check. For example, if you want to want to
create a monitor that checks the health of the HTTP service on a pool,
you choose HTTP as the monitor type.

If you want to check more than one service on a pool or pool member (for
example HTTP and HTTPS), you can associate more than one monitor on that
pool or pool member.

Checking services is not the only reason for implementing a monitor. If
you want to verify only that the destination IP address is alive, or
that the path to it through a transparent node is alive, use one of the
simple monitors, icmp or tcp\_echo. Or, if you want to verify TCP only,
use the monitor tcp.

Monitor destinations

By default, the value for the Alias Address setting in the monitors is
set to the wildcard * Addresses, and the Alias Service Port setting is
set to the wildcard * Ports. This value causes the monitor instance
created for a pool, pool member, or node to take that node’s address or
address and port as its destination. You can, however, replace either or
both wildcard symbols with an explicit destination value, by creating a
custom monitor. An explicit value for the Alias Address and/or Alias
Service Port setting is used to force the instance destination to a
specific address and/or port which might not be that of the pool, pool
member, or node.

The ECV monitor types HTTP, HTTPS, and TCP include the settings Send
String and Receive String for the send string and receive expression,
respectively.

The most common Send String value is GET /, which retrieves a default
HTML page for a web site. To retrieve a specific page from a web site,
you can enter a Send String value that is a fully qualified path name:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s+s2}{\PYGZdq{}GET /www/support/customer\PYGZbs{}\PYGZus{}info\PYGZbs{}\PYGZus{}form.html\PYGZdq{}}
\end{sphinxVerbatim}

The Receive String value is the text string that the monitor looks for
in the returned resource. The most common Receive String values contain
a text string that is included in a particular HTML page on your site.
The text string can be regular text, HTML tags, or image names.

The sample Receive String value below searches for a standard HTML tag:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s+s2}{\PYGZdq{}\PYGZlt{}HEAD\PYGZgt{}\PYGZdq{}}
\end{sphinxVerbatim}

You can also use the default null Receive String value {[}“”{]}. In this
case, any content retrieved is considered a match. If both the Send
String and Receive String fields are left empty, only a simple
connection check is performed.

For HTTP and FTP monitor types, you can use the special values GET or
hurl in place of Send String and Receive String values. For FTP monitors
specifically, the GET value should specify the full path to the file to
retrieve.

Transparent and Reverse modes

The normal and default behavior for a monitor is to ping the destination
pool, pool member, or node by an unspecified route, and to mark the node
up if the test is successful. However, with certain monitor types, you
can specify a route through which the monitor pings the destination
server. You configure this by specifying the Transparent or Reverse
setting within a custom monitor.

Transparent setting

Sometimes it is necessary to ping the aliased destination through a
transparent pool, pool member, or node. When you create a custom monitor
and set the Transparent setting to Yes, Local Traffic Manager forces the
monitor to ping through the pool, pool member, or node with which it is
associated (usually a firewall) to the pool, pool member, or node. (That
is, if there are two firewalls in a load balancing pool, the destination
pool, pool member, or node is always pinged through the pool, pool
member, or node specified; not through the pool, pool member, or node
selected by the load balancing method.) In this way, the transparent
pool, pool member, or node is tested: if there is no response, the
transparent pool, pool member, or node is marked as down.

Common examples are checking a router, or checking a mail or FTP server
through a firewall. For example, you might want to check the router
address 10.10.10.53:80 through a transparent firewall 10.10.10.101:80.
To do this, you create a monitor called http\_trans in which you specify
10.10.10.53:80 as the monitor destination address, and set the
Transparent setting to Yes. Then you associate the monitor http\_trans
with the transparent pool, pool member, or node.

This causes the monitor to check the address 10.10.10 53:80 through
10.10.10.101:80. (In other words, the BIG-IP system routes the check of
10.10.10.53:80 through 10.10.10.101:80.) If the correct response is not
received from 10.10.10.53:80, then 10.10.10.101:80 is marked down.

Reverse setting

With the Reverse setting set to Yes, the monitor marks the pool, pool
member, or node down when the test is successful. For example, if the
content on your web site home page is dynamic and changes frequently,
you may want to set up a reverse ECV service check that looks for the
string “Error”. A match for this string means that the web server was
down.

By default, when a monitor detects that a resource (that is, a node or a
pool member) is unavailable, the BIG-IP system marks the resource as
down and routes traffic to the next appropriate resource as dictated by
the active load balancing method. When the monitor next determines that
the resource is available again, the BIG-IP system marks the resource as
up and immediately considers the resource to be available for load
balancing connection requests. While this process is appropriate for
most resources, there are situations where you want to manually
designate a resource as available, rather than allow the BIG-IP system
to do that automatically. You can manually designate a resource as
available by configuring the Manual Resume setting of the monitor.

For example, consider a monitor that you assigned to a resource to track
the availability of an HTML file, index.html, for a web site. During the
course of a business day, you decide that you need to restart the system
that hosts the web site. The monitor detects the restart action and
informs the BIG-IP system that the resource is now unavailable. When the
system restarts, the monitor detects that the index.html file is
available, and begins sending connection requests to the web site.
However, the rest of the web site might not be ready to receive
connection requests. Consequently, the BIG-IP system sends connection
requests to the web site before the site can respond effectively.

To prevent this problem, you can configure the Manual Resume setting of
the monitor. When you set the Manual Resume setting to Yes, you ensure
that the BIG-IP system considers the resource to be unavailable until
you manually enable that resource.

Resumption of connections

If you have a resource (such as a pool member or node) that a monitor
marked as down, and the resource has subsequently become available
again, you must manually re-enable that resource if the monitor’s Manual
Resume setting is set to Yes. Manually re-enabling the resource allows
the BIG-IP system to resume sending connections to that resource.

The procedure for manually re-enabling a resource varies depending on
whether the resource is a pool, a pool member, or a node.

The Time Until Up feature

By default, the BIG-IP system marks a pool member or node as up
immediately upon receipt of the first correct response to a ping
command.

The Time Until Up feature provides a way to adjust the default behavior.
This feature allows the system to delay the marking of a pool member or
node as up for some number of seconds after receipt of the first correct
response. The purpose of this feature is to ensure that the monitor
marks the pool member or node as up only after the pool member or node
has consistently responded correctly to the BIG-IP system during the
defined time period. With this feature, you ensure that a pool member or
node that is available only momentarily, after sending one correct
response, is not marked as up.

A Time Until Up value of 0 causes the default behavior. When the Time
Until Up value is a non-0 value, the BIG-IP system marks a pool member
or node as up only when all pool member or node responses during the
Time Until Up period are correct.

Dynamic ratio load balancing

You can configure Dynamic Ratio load balancing for pools that consist of
RealNetworks RealServer servers, Microsoft Windows servers equipped with
Windows Management Instrumentation (WMI), or any server equipped with an
SNMP agent such as the UC Davis SNMP agent or Windows 2000 Server SNMP
agent.

To implement Dynamic Ratio load balancing for these types of servers,
BIG-IP Local Traffic Manager provides a special monitor plug-in file and
a performance monitor for each type of server. The exception is a server
equipped with an SNMP agent. In this case, Local Traffic Manager
provides the monitor only; no special plug-in file is required for a
server running an SNMP agent.

You must install the monitor plug-in on each server to be monitored, and
you must create a performance monitor that resides on the BIG-IP system.
Once you have created a monitor, the monitor communicates directly with
the server plug-in.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 2.15 Given a monitor issue, determine an appropriate solution}
\label{\detokenize{class7/modules/module2:objective-2-15-given-a-monitor-issue-determine-an-appropriate-solution}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.15 - Determine appropriate monitor and monitor timing based on application and server limitations}

\sphinxurl{https://support.f5.com/csp/article/K12531}

\sphinxstylestrong{Monitor timing}

Interval/timeout ratio

You must configure an appropriate interval/timeout ratio for simple
monitors. In most cases, the timeout value should be equal to three
times the interval value, plus one. For example, the default ratio is
5/16 (three times 5 plus one equals 16). Verify that the ratio is
properly defined.

There are some applications that may require different timers and some
of those settings may be shown in the following article under the
details of each specific type of monitor


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/3.html}

\sphinxstylestrong{Application appropriate monitor}

The following tables describe the functional categories of health
monitors, and list the available BIG-IP monitors within each category.
Unless otherwise specified, each monitor is used by Local Traffic
Manager, Global Traffic Manager, and Link Controller.

Address-check monitors

An address-check monitor is a simple monitor that pings an IP address to
verify that the address can be reached on a network.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Address-check monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Gateway ICMP}
&
Uses Internet Control Message Protocol (ICMP) to make a simple resource check. The check is successful if the monitor receives a response to an ICMP\_ECHO datagram.
\\
\hline
\sphinxstylestrong{ICMP}
&
Makes a simple node check. The check is successful if the monitor receives a response to an ICMP\_ECHO datagram.
\\
\hline
\sphinxstylestrong{TCP Echo}
&
Verifies Transmission Control Protocol (TCP) connections. The check is successful if the BIG-IP system receives a response to a TCP Echo message.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Service-check monitors

A service-check monitor determines whether a service is available by
opening a connection to an IP address and port.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Service-check monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Diameter}
&
Monitors servers running the Diameter authentication service. After configuring a Diameter monitor, associate the monitor with a load balancing pool. The BIG-IP system then attempts to establish a TCP connection with a server in the pool. After successfully establishing a connection, the Diameter monitor sends a Capabilities-Exchanging-Request (CER) message to the server. The monitor then waits to receive a Capabilities-Exchanging-Answer (CEA) message, as well as a result code of DIAMETER\_SUCCESS (2001).
\\
\hline
\sphinxstylestrong{FirePass}
&
Checks the health of FirePass systems.
\\
\hline
\sphinxstylestrong{Inband}
&
Performs passive monitoring as part of client requests. This monitor, when acting as a client, attempts to connect to a pool member. If the pool member does not respond to a connection request after a user-specified number of tries within a user-specified period, the monitor marks the pool member as down. After the monitor has marked the pool member as down, and after a user-specified period has passed, the monitor again tries to connect to the pool member (if so configured).
\\
\hline
\sphinxstylestrong{NNTP}
&
Checks the status of Usenet News traffic. The check is successful if the monitor retrieves a newsgroup identification line from the server. An \sphinxstylestrong{NNTP} monitor requires a newsgroup name (for example, alt.cars.mercedes) and, if necessary, a user name and password.
\\
\hline
\sphinxstylestrong{MSSQL}
&
Performs service checks on Microsoft SQL Server-based services such as Microsoft SQL Server versions 6.5 and 7.0.
\\
\hline
\sphinxstylestrong{MySQL}
&
Checks the status of a MySQL database server. The check is successful if the monitor is able to connect to the server, log in as the indicated user, and log out.
\\
\hline
\sphinxstylestrong{Oracle}
&
Checks the status of an Oracle database server. The check is successful if the monitor is able to connect to the server, log in as the indicated user, and log out.
\\
\hline
\sphinxstylestrong{POP3}
&
Checks the status of Post Office Protocol (POP) traffic. The check is successful if the monitor is able to connect to the server, log in as the indicated user, and log out. A \sphinxstylestrong{POP3} monitor requires a user name and password.
\\
\hline
\sphinxstylestrong{PostgreSQL}
&
Checks the status of a PostgreSQL database server. The check is successful if the monitor is able to connect to the server, log in as the indicated user, and log out.
\\
\hline
\sphinxstylestrong{RADIUS}
&
Checks the status of Remote Access Dial-in User Service (RADIUS) servers. The check is successful if the server authenticates the requesting user. A RADIUS monitor requires a user name, a password, and a shared secret string for the code number.
\\
\hline
\sphinxstylestrong{RADIUS Accounting}
&
Checks the status of Remote Access Dial-in User Service (RADIUS) accounting servers. A RADIUS Accounting monitor requires a user name and a shared secret string for the code number.
\\
\hline
\sphinxstylestrong{RPC}
&
Checks the availability of specific programs that reside on a remote procedure call (RPC) server. This monitor uses the \sphinxstylestrong{rpcinfo} command to query the RPC server and verify the availability of a given program.
\\
\hline
\sphinxstylestrong{SASP}
&
Verifies the availability of a IBM Group Workload Manager. This monitor uses the Server/Application State Protocol (SASP) to communicate with the Group Workload Manager. The monitor queries the Group Workload Manager for information on the current weights of each managed resource. These weights determine which resource currently provides the best response time. When the monitor receives this information from the Group Workload Manager (GWM), it configures the dynamic ratio option for the resources, allowing the BIG-IP system to select the most appropriate resource to respond to a connection request.

Note: When you assign an \sphinxstylestrong{SASP} monitor, the monitor initially marks the resources as down. This change in status occurs because the GWM might not yet have information pertaining to its resources. As soon as the monitor receives the results of its query, it changes the status as needed. In most configurations, the monitor receives these results within a few seconds.
\\
\hline
\sphinxstylestrong{SIP}
&
Checks the status of SIP Call-ID services. By default, this monitor type issues an SIP OPTIONS request to a server device. However, you can use alternative protocols instead: \sphinxstylestrong{TCP}, \sphinxstylestrong{UDP}, \sphinxstylestrong{TLS}, and \sphinxstylestrong{SIPS} (that is, Secure SIP).
\\
\hline
\sphinxstylestrong{SMB}
&
Verifies the availability of a Server Message Block/Common Internet File System (SMB/CIFS) server. Use this monitor to check the availability of the server as a whole, the availability of a specific service on the server, or the availability of a specific file used by a service.
\\
\hline
\sphinxstylestrong{SOAP}
&
Tests a web service based on the Simple Object Access Protocol (SOAP). The monitor submits a request to a SOAP-based web service, and optionally, verifies a return value or fault.
\\
\hline
\sphinxstylestrong{TCP Half Open}
&
Monitors the associated service by sending a TCP SYN packet to the service. As soon as the monitor receives the SYN-ACK packet, the monitor marks the service as up.
\\
\hline
\sphinxstylestrong{UDP}
&
Verifies the User Datagram Protocol (UDP) service by attempting to send UDP packets to a pool, pool member, or virtual server and receiving a reply.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Content-check monitors

A content-check monitor sends a command to a server and examines that
server’s response to ensure that it is serving appropriate content.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Content-check monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{DNS}
&
Checks the status of Domain Name Server (DNS) servers, by sending a specific string, and verifying receipt of that string. The check is successful if the DNS server responds with a specified string within a specified period.
\\
\hline
\sphinxstylestrong{HTTP}
&
Checks the status of Hypertext Transfer Protocol (HTTP) traffic. Like a TCP monitor, an HTTP monitor attempts to receive specific content from a web page, and unlike a TCP monitor, might send a user name and password.

Note: An HTTP monitor can monitor Outlook® Web Access (OWA) in Microsoft® Exchange Server 2007 and Microsoft® SharePoint® 2007 web sites that require NT LAN Manager (NTLM) authentication. NTLM authentication requires a send string that complies with HTTP/1.1, a user name, and a password.
\\
\hline
\sphinxstylestrong{HTTPS}
&
Checks the status of Hypertext Transfer Protocol Secure (HTTPS) traffic. An HTTPS monitor attempts to receive specific content from a web page protected by SSL security. The check is successful when the content matches the \sphinxstylestrong{Receive String} value.

Note: An HTTP monitor can monitor Outlook® Web Access (OWA) in Microsoft® Exchange Server 2007 and Microsoft® SharePoint® 2007 web sites that require NT LAN Manager (NTLM) authentication. NTLM authentication requires a send string that complies with HTTP/1.1, a user name, and a password.
\\
\hline
\sphinxstylestrong{https\_443}
&
Checks the status of Hypertext Transfer Protocol Secure (HTTPS) traffic, by using port 443.
\\
\hline
\sphinxstylestrong{LDAP}
&
Checks the status of Lightweight Directory Access Protocol (LDAP) servers. A check is successful if entries are returned for the base and filter specified. An LDAP monitor requires a user name, a password, and base and filter strings.
\\
\hline
\sphinxstylestrong{Scripted}
&
Generates a simple script that reads a file that you create. The file contains send and expect strings to specify lines that you want to send or that you expect to receive.
\\
\hline
\sphinxstylestrong{SMTP}
&
Checks the status of Simple Mail Transport Protocol (SMTP) servers. This monitor type checks only that the server is up and responding to commands. The check is successful if the mail server responds to the standard \sphinxstylestrong{SMTP HELO} and \sphinxstylestrong{QUIT} commands.
\\
\hline
\sphinxstylestrong{TCP}
&
Verifies the Transmission Control Protocol (TCP) service by attempting to receive specific content from a resource. The check is successful when the content matches the \sphinxstylestrong{Receive String} value.
\\
\hline
\sphinxstylestrong{WAP}
&
Monitors Wireless Application Protocol (WAP) servers. The common usage for the \sphinxstylestrong{WAP} monitor is to specify the \sphinxstylestrong{Send String} and \sphinxstylestrong{Receive String} settings only. The \sphinxstylestrong{WAP} monitor functions by requesting a URL and finding the string in the \sphinxstylestrong{Receive String} setting in the data returned by the URL response.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Path-check monitors

A path-check monitor determines whether traffic can flow through a given
device to an arbitrary endpoint. The monitor sends a packet through the
network device, or to a remote server, to verify that the traffic can
actually pass through the network device, and not just to the device.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Path-check monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Gateway ICMP}
&
Uses Internet Control Message Protocol (ICMP) to make a simple resource check. The check is successful if the monitor receives a response to an ICMP\_ECHO datagram.
\\
\hline
\sphinxstylestrong{ICMP}
&
Makes a simple node check. The check is successful if the monitor receives a response to an ICMP\_ECHO datagram.
\\
\hline
\sphinxstylestrong{TCP Echo}
&
Verifies Transmission Control Protocol (TCP) connections. The check is successful if the BIG-IP system receives a response to a TCP Echo message.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Application-check monitors

An application-check monitor is typically a custom monitor or external
monitor that tests a specific application. For example, an FTP monitor
connects, logs in by using a user ID and password, changes to a
specified directory, and requests a specific file. This monitor succeeds
when the file is received.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Application-check monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{BIG-IP}
&
Gathers metrics and statistics information that the Local Traffic Manager acquires through the monitoring of its own resources. Typically, it is sufficient to assign only the BIG-IP monitor to a Local Traffic Manager. When you want to verify the availability of a specific resource managed by the Local Traffic Manager, F5 recommends that you first assign the appropriate monitor to the resource through the Local Traffic Manager, and then assign a BIG-IP monitor to the Local Traffic Manager through the Global Traffic Manager. This configuration provides the most efficient means of tracking resources managed by a BIG-IP system.
\\
\hline
\sphinxstylestrong{BIG-IP Link}
&
Gathers metrics and statistics information that the Link Controller™ acquires through the monitoring of its own resources. When you use the Global Traffic Manager in a network that contains a Link Controller, you must assign a BIG-IP Link monitor to the Link Controller. This monitor is automatically assigned to the Link Controller if you do not manually assign it.
\\
\hline
\sphinxstylestrong{External}
&
Enables you to create your own monitor type.
\\
\hline
\sphinxstylestrong{FTP}
&
Attempts to download a specified file to the /var/tmp directory, and if the file is retrieved, the check is successful. Note that once the file has been successfully downloaded, the BIG-IP system does not save it.
\\
\hline
\sphinxstylestrong{IMAP}
&
Checks the status of Internet Message Access Protocol (IMAP) traffic. An IMAP monitor is essentially a POP3 type of monitor with the addition of the Folder setting. The check is successful if the monitor is able to log into a server and open the specified mail folder.
\\
\hline
\sphinxstylestrong{Module Score}
&
Enables global and local traffic management systems to load balance in a proportional manner to local traffic management virtual servers associated with the BIG-IP® Application Acceleration Manager and Application Security Manager™. When you configure a \sphinxstylestrong{Module Score} monitor, the local traffic management system uses SNMP to pull the gtm\_score values from the downstream virtual servers and set the dynamic ratios on the associated upstream local traffic management pool members or nodes.

The \sphinxstylestrong{Module Score} monitor retrieves the gtm\_score values from the virtual server and the gtm\_vs\_score values associated with the virtual server. Then, if a pool name is not specified, this monitor sets the dynamic ratio on the node that is associated with the virtual server.

The BIG-IP system uses the lowest non-zero value of the gtm\_vs\_score values to set the dynamic ratio. If all gtm\_vs\_score values are zero, then the gtm\_score value is used to set the dynamic ratios. If you specify a pool name in the monitor definition, then the dynamic ratio is set on the pool member.
\\
\hline
\sphinxstylestrong{Virtual Location}
&
Optimizes end-user response time in environments with dynamic distribution of application resources across multiple data centers. When using the \sphinxstylestrong{Virtual Location} monitor, the BIG-IP sets the \sphinxstylestrong{Priority Group} value of all local pool members to \sphinxstylestrong{2} (a higher priority). When a member of a load balancing pool migrates to a remote data center the \sphinxstylestrong{Virtual Location} monitor lowers the members \sphinxstylestrong{Priority Group} value to \sphinxstylestrong{1} (a lower priority). This value adjustment results in subsequent connections being sent to local pool members only if available. If no local pool members are available, connections are sent to the remote pool member.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Performance monitors

A performance monitor interacts with the server (as opposed to virtual
server) to examine the server load and to acquire information about the
condition of virtual servers.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

\sphinxstylestrong{Performance monitor}
&
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{BIG-IP}
&
Collects data from Global Traffic Manager and Local Traffic Manager. Typically, the Local Traffic Manager probes local pool members and provides the results to Global Traffic Manager.

Note: When the BIG-IP monitor fails, all virtual servers for that Local Traffic Manager system are marked unavailable, regardless of the results of individual virtual server probes.
\\
\hline
\sphinxstylestrong{BIG-IP Link}
&
Gathers metrics and statistics information acquired through the monitoring of Global Traffic Manager or Link Controller resources.
\\
\hline
\sphinxstylestrong{SNMP}
&
Checks the performance of a server that runs an SNMP agent to load balance to that server. A custom \sphinxstylestrong{snmp\_gtm} import setting is assigned to servers that are not developed by F5.
\\
\hline
\sphinxstylestrong{SNMP DCA}
&
Checks the performance of a server running an SNMP agent such as UC Davis, for the purpose of load balancing traffic to that server. With this monitor you can define ratio weights for CPU, memory, and disk use.
\\
\hline
\sphinxstylestrong{SNMP DCA Base}
&
Checks the performance of servers that are running an SNMP agent, such as UC Davis. However, you should use this monitor only when you want the load balancing destination to be based solely on user data, and not CPU, memory, or disk use.
\\
\hline
\sphinxstylestrong{Real Server}
&
Checks the performance of a node that is running the RealSystem Server data collection agent. The monitor then dynamically load balances traffic accordingly.
\\
\hline
\sphinxstylestrong{WMI}
&
Checks the performance of a node that is running the Windows Management Infrastructure (WMI) data collection agent, and then dynamically load balances traffic accordingly. Generally, you would use a WMI monitor with dynamic ratio load balancing.

Note: When using the \sphinxstylestrong{GetWinMediaInfo} command with a WMI monitor, Microsoft® Windows Server® 2003 and Microsoft® Windows Server® 2008 require the applicable version of Windows Media® Services to be installed on each server.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2.15 - Describe how to modify monitor settings to resolve monitor problems}

\sphinxurl{https://support.f5.com/csp/article/K12531\#3}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-monitors-reference-11-5-0/1.html}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm-concepts-11-5-0/14.html}

\sphinxstylestrong{Checking Monitor setting}

Verifying monitor settings

You must verify that monitor settings are properly defined for your
environment. F5 recommends that in most cases the timeout value should
be equal to three times the interval value, plus one. For example, the
default timeout/interval ratio is 5/16 (three times 5 plus one equals
16). This setting prevents the monitor from marking the node as down
before sending the last check.

Simple monitors

You can use a simple monitor to verify the status of a destination node
(or the path to the node through a transparent device). Simple monitors
only monitor the node address itself, not individual protocols,
services, or applications on a node. The BIG-IP system provides the
following pre-configured simple monitor types: gateway\_icmp, icmp,
tcp\_echo, tcp\_half\_open. If you determine that a simple monitor is
marking a node as down, you can verify the following settings:
\begin{itemize}
\item {} 
Interval/timeout ratio

You must configure an appropriate interval/timeout ratio for simple
monitors. In most cases, the timeout value should be equal to three
times the interval value, plus one. For example, the default ratio
is 5/16 (three times 5 plus one equals 16). Verify that the ratio is
properly defined.

\item {} 
Transparent

A transparent monitor uses a path through the associated node to
monitor the aliased destination. Verify that the destination target
device is reachable and configured properly for the monitor.

\end{itemize}

Use the tcpdump command to capture monitor traffic.

If you are unable to determine the cause of a failing health monitor,
you may have to perform packet captures on the BIG-IP system. This is
discussed in Objective 2.14.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\section{Section 3 - Identify and Resolve LTM Device Issues}
\label{\detokenize{class7/modules/module3:section-3-identify-and-resolve-ltm-device-issues}}\label{\detokenize{class7/modules/module3::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.01 Interpret log file messages and/or command line output to identify LTM device issues}
\label{\detokenize{class7/modules/module3:objective-3-01-interpret-log-file-messages-and-or-command-line-output-to-identify-ltm-device-issues}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Interpret log file messages to identify LTM device issues}

\sphinxurl{https://support.f5.com/csp/article/K14426}

\sphinxstylestrong{Identifying hardware issues}

This can be a very broad topic because there are a very large number of
hardware errors that can occur. Every log message will contain an ID
number and will be followed by a description in the log.

Example:

Back in version 11.4 the pendsect feature was added to the TMOS software
that periodically checks for pending sector alerts and resolves them.
The pendsect feature is configured to run daily. The pendsect messages
provide improved disk error detection and correction. The system logs
the pendsect messages to the /var/log/user.log file.

When the pendsect process runs and no errors are detected or corrected,
the system logs messages that appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{warning pendsect[21788]: pendsect: /dev/sdb no Pending Sectors detected}
\end{sphinxVerbatim}

When the pendsect process detects and corrects an error, the system logs
messages that appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{warning pendsect[19772]: Recovered LBA:230000007}
\PYG{g+go}{warning pendsect[19772]: Drive /dev/sda partition UNKNOWN}
\PYG{g+go}{warning pendsect[19772]: File affected NONE}
\end{sphinxVerbatim}

When the pendsect process detects an error and is unable to correct the
error, the system logs messages that appear similar to the following
example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{warning pendsect[20702]: seek(1) error[25] recovery of LBA:226300793 not complete}
\PYG{g+go}{warning pendsect[20702]: Drive: /dev/sda filesystem type: Undetermined}
\PYG{g+go}{warning pendsect[20702]: File affected: NONE}
\end{sphinxVerbatim}

Recommended Actions

If pendsect reports an uncorrectable error, or if you suspect a possible
disk failure, you can perform the End-User Diagnostic (EUD) SMART test
to test the drive. For information about the EUD utility, and links to
the latest release notes, refer to K7172: Overview of the End User
Diagnostics software.

Beginning in BIG-IP 11.4.0, you can also use the platform\_check command
to collect the SMART test data from the drive. The disk portion of the
command output indicates a Pass or Fail status for the drive and logs
detailed information to the /var/log/platform\_check file.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Interpret the qkview heuristic results}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-iq-centralized-mgmt/manuals/product/bigiq-central-mgmt-monitoring-reports-5-3-0/9.html}

\sphinxstylestrong{Troubleshooting using iHealth}

The F5 iHealth server is a tool that helps you troubleshoot potential
issues. It does this by analyzing configuration, logs, command output,
password security, license compliance, and so on.

From F5 BIG-IQ Centralized Management, you can create a snapshot of a
configuration in the form of a QKView file and then upload it to the F5
iHealth server. The file is compared to the iHealth database, which
contains known issues, common configuration errors, and F5 published
best practices. F5 returns an iHealth report you can use to identify any
potential issues that you need to attend to.

\sphinxstyleemphasis{Troubleshoot potential issues by viewing an iHealth device report}

After you upload a QKView file for one or more BIG-IP devices, the F5
iHealth server returns a device report.

Review the device report so you can address any potential issues or
vulnerabilities. From the report, you can access and sort heuristics
associated with a device.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
At the top of the screen, click Monitoring.

\item {} 
On the left, click REPORTS \textgreater{} Device \textgreater{} iHealth \textgreater{} Device Reports .

\item {} 
Click the Open link next to the report you want to view.

\item {} 
To sort the heuristics for a report you’ve opened, select an option
from the All Importance and/or the All Flags list.

\item {} 
You can add a flag to a specific heuristic by selecting the check box
next to it, and selecting a flag from the All Flags list.

\item {} 
To view more details about a specific heuristic, click on its link.

\item {} 
To view an article on the AskF5 Knowledge Center database to get more
information about this heuristic, click the solution link.

\end{enumerate}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Identify appropriate methods to troubleshoot NTP}

\sphinxurl{https://support.f5.com/csp/article/K14120}

\sphinxstylestrong{NTP}

NTP is a protocol for synchronizing the clocks of computer systems over
the network. On BIG-IP systems, accurate timestamps are essential to
guarantee the correct behavior of a number of features. While in most
cases it is sufficient to configure a couple of time servers that the
BIG-IP system will use to update its system time, it is also possible to
define more advanced NTP configurations on the BIG-IP system.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K10240}

When the BIG-IP system clock is not showing the correct time zone, or
the date and time is not synchronized correctly, this could be caused by
incorrect NTP configuration or a communication issue with a valid NTP
peer server. The procedures in this article show how you may check the
NTP daemon process, verify the NTP configuration, query the NTP peer
server, and check the network connectivity to the NTP peer server.

When verifying the NTP peer server communication, you can use the ntpq
utility. The command generates output with the fields that are explained
in the following table.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Field}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Definition}
\\
\hline
prefix to the \sphinxstylestrong{remote}
field
&\begin{itemize}
\item {} 
An asterisk (*) character indicates that the peer has been declared the system peer and lends its variables to the system variables.

\item {} 
A plus sign (+) indicates that the peer is a survivor and a candidate for the combining algorithm.

\item {} 
A space, x, period (.), dash (-), or hash (\#) character indicates that this peer is not being used for synchronization because it either does not meet the requirements, is unreachable, or is not needed.

\end{itemize}
\\
\hline
\sphinxstylestrong{remote}
&
The \sphinxstylestrong{remote} field is the address of the remote peer.
\\
\hline
\sphinxstylestrong{refid}
&
The \sphinxstylestrong{refid} field is the Reference ID which identifies the server or reference clock with which the remote peer synchronizes, and its interpretation depends on the value of the stratum field (explained in the \sphinxstylestrong{st} definition). For stratum 0 (unspecified or invalid), the refid is an ascii value used for debugging. Example: INIT or STEP. For stratum 1 (reference clock), the refid is an ascii value used to specify the type of external clock source. Example: NIST refers to NIST telephone modem. For strata 2 through 15, the refid is the address of the next lower stratum server used for synchronization.
\\
\hline
\sphinxstylestrong{st}
&
The \sphinxstylestrong{st} field is the stratum of the remote peer. Primary servers (servers with an external reference clock such as GPS) are assigned stratum 1. A secondary NTP server which synchronizes with a stratum 1 server is assigned stratum 2. A secondary NTP server which synchronizes with a stratum 2 server is assigned stratum 3. Stratum 16 is referred to as “MAXSTRAT,” is customarily mapped to stratum value 0, and therefore indicates being unsynchronized. Strata 17 through 255 are reserved.
\\
\hline
\sphinxstylestrong{t}
&
The \sphinxstylestrong{t} field is the type of peer: local, unicast, multicast, or broadcast.
\\
\hline
\sphinxstylestrong{when}
&
The \sphinxstylestrong{when} field is the time since the last response to a poll was received (in seconds).
\\
\hline
\sphinxstylestrong{poll}
&
The \sphinxstylestrong{poll} field is the polling interval (in seconds). This value starts low (example: 64) and over time, as no changes are detected, this polling value increases incrementally to the configured max polling value (example: 1024).
\\
\hline
\sphinxstylestrong{reach}
&
The \sphinxstylestrong{reach} field is the reachability register. The octal shift register records results of the last eight poll attempts.
\\
\hline
\sphinxstylestrong{delay}
&
The \sphinxstylestrong{delay} field is the current estimated delay; the transit time between these peers in milliseconds.
\\
\hline
\sphinxstylestrong{offset}
&
The \sphinxstylestrong{offset} field is the current estimated offset; the time difference between these peers in milliseconds.
\\
\hline
\sphinxstylestrong{jitter}
&
The \sphinxstylestrong{jitter} field is the current estimated dispersion; the variation in delay between these peers in milliseconds.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.01 - Identify license problems based on the log file messages and statistics}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/releasenotes/related/log-messages.html\#A01010044}

\sphinxstylestrong{Licensing based log messages}

There are multiple types of log messages that could occur around
licensing.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{01010044 : \PYGZdq{}\PYGZpc{}s feature \PYGZpc{}s licensed\PYGZdq{}}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Location:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{/var/log/ltm}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Conditions:}

This message does not necessarily denote a problem. It displays the
license status of BIG-IP device’s component.

When status for component X is “licensed”, this log displays the message:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{Component X is licensed.}
\end{sphinxVerbatim}

When the component is not licensed, the message is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{Component X is NOT licensed.}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Impact:}

If the message is “Component X is licensed”, there is no impact. It
is an informative message.

If the message is “Component X is not licensed”, then you cannot use
the mentioned component/feature.

\sphinxstyleemphasis{Recommended Action:}

If you want to use a component that is not currently licensed, you
need to activate the license.


\bigskip\hrule\bigskip


When the system statistics show bandwidth of the licensed feature is
running at the max level you may see logs reflecting that the system is
exceeding the licensed limit.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{01010045 : Bandwidth utilization is \PYGZpc{}d Mbps, exceeded \PYGZpc{}d\PYGZpc{}\PYGZpc{} of Licensed \PYGZpc{}d Mbps}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Location:}

/var/log/ltm

\sphinxstyleemphasis{Conditions:}

This message appears when the system is using more bandwidth that it was licensed to use.

\sphinxstyleemphasis{Impact:}

The system will not perform at its full potential with a limited license.

\sphinxstyleemphasis{Recommended Action:}

A license with better bandwidth utilization would stop this message from appearing.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.02 Identify the appropriate command to use to determine the cause of an LTM device problem}
\label{\detokenize{class7/modules/module3:objective-3-02-identify-the-appropriate-command-to-use-to-determine-the-cause-of-an-ltm-device-problem}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Identify hardware problems based on the log file messages and statistics}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/releasenotes/related/log-messages.html}

\sphinxstylestrong{Identify Hardware Problems}

This can be a very broad topic because there are a very large number of
hardware errors that can occur. Every log message will begin with an ID
number and will be followed by a description in the log. The list of
possible log messages is long and memorizing them is not required, but
understanding how to read the messages and where logs can be found are
important. You will find many hardware related log messages in
/var/log/ltm and when you see LCD in the location that means it will
echo to the LCD screen of the device.

\sphinxstylestrong{Log Message Example}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{012a0028 : \PYGZpc{}s}
\end{sphinxVerbatim}

\sphinxstyleemphasis{Location:}

/var/log/ltm, LCD

\sphinxstyleemphasis{Conditions:}

AOM has indicated that a temperature sensor has crossed a ‘warning’ threshold.

\sphinxstyleemphasis{Impact:}

Integrity of the hardware could be at risk if overheating is not mitigated.

\sphinxstyleemphasis{Recommended Action:}
\begin{itemize}
\item {} 
Check the fan status of the unit using ‘tmsh show sys hardware’.

\item {} 
Inspect the LCD and/or /var/log/ltm for any fan related problems.

\item {} 
Ensure that ambient room temperature in which the device is located
has sufficient cooling.

\item {} 
Inspect /var/log/ltm and /var/log/sel around the time of the message
for any additional indications as to why the unit might be starting
to overheat.

\end{itemize}

You can also correlate information in the performance statistics to
hardware errors in the logs.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Identify resource exhaustion problems based on the log file messages and statistics}

\sphinxurl{https://support.f5.com/csp/article/K14813}

\sphinxstylestrong{Identify resource exhaustion problems}

There can be many types of resource exhaustion issues to troubleshoot.
This example is based on memory exhaustion due to a SYN flood. Your exam
may contain other types.

Detecting DoS and DDoS attacks

The BIG-IP system provides methods to detect ongoing or previous DoS and
DDoS attacks on the system. To detect these attacks, perform the
following procedures:

The BIG-IP SYN cookie feature protects the system against SYN flood
attacks and allows the BIG-IP system to maintain connections when the
SYN queue begins to fill up during an attack.

Reviewing SYN cookie threshold log messages

The BIG-IP system may log one or more error messages that relate to SYN
cookie protection to the /var/log/ltm file. Messages that relate to SYN
cookie protection appear similar to the following examples:
\begin{itemize}
\item {} 
When the virtual server exceeds the SYN Check Activation Threshold,
the system logs an error message similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{warning tmm5[18388]: 01010038:4: Syncookie threshold 0 exceeded,}
\PYG{g+go}{virtual = 10.11.16.238:80}
\end{sphinxVerbatim}

\item {} 
When hardware SYN cookie mode is active for a virtual server, the
system logs an error message similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{notice tmm5[18388]: 01010240:5: Syncookie HW mode activated, server}
\PYG{g+go}{= 10.11.16.238:80, HSB modId = 1}
\end{sphinxVerbatim}

\item {} 
When hardware SYN cookie mode is not active for a virtual server, the
system logs an error message similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{notice tmm5[18388]: 01010241:5: Syncookie HW mode exited, server =}
\PYG{g+go}{10.11.16.238:80, HSB modId = 1 from HSB}
\end{sphinxVerbatim}

\end{itemize}

Reviewing maximum reject rate log messages

The tm.maxrejectrate db key allows you to adjust the number of TCP RSTs
or ICMP unreachable packets that the BIG-IP system sends in response to
incoming client-side or server-side packets that cannot be matched with
existing connections to BIG-IP virtual servers, self IP addresses, or
Secure Network Address Translations (SNATs). A high number of maximum
reject rate messages may indicate that the BIG-IP system is experiencing
a DoS/DDoS attack.

The BIG-IP system may log error messages that relate to SYN cookie
protection to the /var/log/ltm file. Messages that relate to SYN cookie
protection appear similar to the following examples:
\begin{itemize}
\item {} 
When the number of packets that match a virtual IP address or a self
IP address exceeds the tm.maxrejectrate threshold, but the packets
specify an invalid port, the system stops sending RST packets in
response to the unmatched packets and logs an error message to the
/var/log/ltm file that appears similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{011e0001:4: Limiting closed port RST response from 299 to 250}
\PYG{g+go}{packets/sec}
\end{sphinxVerbatim}

\item {} 
When the number of packets that match a virtual address and port, or
a self IP address and port, exceeds the tm.maxrejectrate threshold,
but the packet is not a TCP SYN packet and does not match an
established connection, the system stops sending RST packets in
response to the unmatched packets. The system also logs an error
message to the /var/log/ltm file that appears similar to the
following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{011e0001:4: Limiting open port RST response from 251 to 250}
\PYG{g+go}{packets/sec}
\end{sphinxVerbatim}

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Identify connectivity problems based on the log files}

\sphinxurl{https://support.f5.com/csp/article/K53419416}

\sphinxstylestrong{Virtual Server Processing Order}

There can be many types of connectivity issues to troubleshoot. This
Error Message example is based on connectivity failure between an HA
pair. Your exam may contain other types.

Error Message

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{01071431:5: Attempting to connect to CMI peer \PYGZlt{}IP address\PYGZgt{} port \PYGZlt{}port\PYGZgt{}}
\end{sphinxVerbatim}

In this error message, note the following:
\begin{itemize}
\item {} 
\textless{}IP address\textgreater{} is the remote BIG-IP system’s configured failover IP
address, used for failover operations.

\item {} 
\textless{}port\textgreater{} is the remote BIG-IP system’s configured failover TCP service
port, used for failover operations.

\end{itemize}

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{01071431:5: Attempting to connect to CMI peer 192.168.10.100 port 6699}
\end{sphinxVerbatim}

Message Location

You may encounter this message in the following location:
\begin{itemize}
\item {} 
/var/log/ltm

\end{itemize}

Description

This message occurs when all of the following conditions are met:
\begin{itemize}
\item {} 
You have multiple BIG-IP systems in a high availability (HA)
configuration.

\item {} 
The master control process daemon (mcpd) starts and attempts to
connect to a peer BIG-IP system in the trust domain or general
network issues exist, such as routing or switching failures, which
prevent connectivity between BIG-IP systems in the trust domain.

\end{itemize}

A trust domain is a collection of BIG-IP devices that trust each other.
The devices can synchronize, fail over their BIG-IP configuration data,
and exchange status and failover messages on a regular basis.

Impact

If this error message appears unaccompanied by other messages, then
there is no impact on the BIG-IP system. If other messages are logged
along with this error message, you can use those messages to
troubleshoot the impact on the BIG-IP system. For example, if a general
network issue occurs and the local BIG-IP system is unable to connect to
a remote peer BIG-IP system, a message appearing similar to the
following example is logged:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{01071431:5: Attempting to connect to CMI peer 192.168.10.100 port 6699}

\PYG{g+go}{0107142f:3: Can\PYGZsq{}t connect to CMI peer 192.168.10.100, port:6699, Transport endpoint is not connected}
\end{sphinxVerbatim}

Recommended Actions

If logged messages indicate that the BIG-IP system is impacted, ensure
that the self IP addresses for the BIG-IP devices in the cluster are
correct and that the network allows proper connectivity between the
devices.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.02 - Determine the appropriate log file to examine to determine the cause of the problem}

\sphinxurl{https://support.f5.com/csp/article/K16197}

\sphinxstylestrong{Logging}

BIG-IP log files include important diagnostic information about the
events that are occurring on the BIG-IP system. Some of the events
pertain to the Linux host. For example, the Linux host generates system
messages that pertain to the Linux host operating system, including
messages that are logged during system startup, and information logged
by the background daemons that run on the system. Other events are
specific to the BIG-IP operating system. For example, the BIG-IP
operating system generates messages that pertain to local and global
traffic events, and configuration changes (audit logging).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Local logging

By default, the BIG-IP system logs events locally and stores messages in
the /var/log directory. For BIG-IP events, the system routes messages
from the errdefs subsystem through syslog-ng to the local log files. For
non-BIG-IP events, the system routes messages directly through syslog-ng
to the local log files. In addition, you can configure the system to use
the high-speed logging mechanism (HSL) to store the logs in either the
syslog or the MySQL database.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Remote logging

You can configure the system to use the HSL mechanism to log messages to
a pool of remote log servers. If the BIG-IP system processes a high
volume of traffic or generates an excessive amount of log files, F5
recommends that you configure remote logging.


\bigskip\hrule\bigskip


\sphinxstylestrong{BIG-IP log types}

Each type of event is stored locally in a separate log file, and the
information stored in each log file varies depending on the event type.
All log files for these event types are in the /var/log directory.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Type}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Log file}
\\
\hline
audit
&
The audit event messages are messages that the BIG-IP system logs as a result of changes to the BIG-IP system configuration. Logging audit events is optional.
&
\sphinxstylestrong{/var/log/audit}
\\
\hline
boot
&
The boot messages contain information that is logged when the system boots.
&
\sphinxstylestrong{/var/log/boot.log}
\\
\hline
cron
&
When the \sphinxstylestrong{cron} daemon starts a \sphinxstylestrong{cron} job, the daemon logs the information about the \sphinxstylestrong{cron} job in this file.
&
\sphinxstylestrong{/var/log/cron}
\\
\hline
daemon
&
The daemon messages are logged by various daemons that run on the system.
&
\sphinxstylestrong{/var/log/daemon.log}
\\
\hline
dmesg
&
The dmesg messages contain kernel ring buffer information that pertains to the hardware devices that the kernel detects during the boot process.
&
\sphinxstylestrong{/var/log/dmesg}
\\
\hline
GSLB
&
The GSLB messages pertain to global traffic management events.
&
\sphinxstylestrong{/var/log/gtm}
\\
\hline
httpd
&
The httpd messages contain the Apache Web server error log.
&
\sphinxstylestrong{/var/log/httpd/httpd\_errors}
\\
\hline
kernel
&
The kernel messages are logged by the Linux kernel.
&
\sphinxstylestrong{/var/log/kern.log}
\\
\hline
local traffic
&
The local traffic messages pertain specifically to the BIG-IP local traffic management events.
&
\sphinxstylestrong{/var/log/ltm}
\\
\hline
mail
&
The mail messages contain the log information from the mail server that is running on the system.
&
\sphinxstylestrong{/var/log/maillog}
\\
\hline
packet filter
&
The packet filter messages are those that result from the use of packet filters and packet-filter rules.
&
\sphinxstylestrong{/var/log/pktfilter}
\\
\hline
security
&
The secure log messages contain information related to authentication and authorization privileges.
&
\sphinxstylestrong{/var/log/secure}
\\
\hline
system
&
The system event messages are based on global Linux events, and are not specific to BIG-IP local traffic management events.
&
\sphinxstylestrong{/var/log/messages}
\\
\hline
TMM
&
The TMM log messages are those that pertain to Traffic Management Microkernel events.
&
\sphinxstylestrong{/var/log/tmm}
\\
\hline
user
&
The user log messages contain information about all user level logs.
&
\sphinxstylestrong{/var/log/user.log}
\\
\hline
webui
&
The webui log messages display errors and exception details that pertain to the Configuration utility.
&
\sphinxstylestrong{/var/log/webui.log}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\bigskip\hrule\bigskip


\sphinxstylestrong{Log message format}

Log messages are formatted differently depending on the type of log and
the component that generated the event messages. The log formats are
discussed in the following sections.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Local traffic log message format

The local traffic (ltm) log messages generated by the BIG-IP system
include the following types of information:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZlt{}time stamp\PYGZgt{} \PYGZlt{}host name\PYGZgt{} \PYGZlt{}level\PYGZgt{} \PYGZlt{}service[pid]\PYGZgt{} \PYGZlt{}message code\PYGZgt{} \PYGZlt{}message text\PYGZgt{}}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Time stamp: The time/date that the system logged the message

\item {} 
Host name: The host name of the BIG-IP system that generated the
message

\item {} 
Service: The name of the service (and process ID) that generated the
message

\item {} 
Message code: The code that is associated with the message. The code
is comprised of the following sub-codes:

\item {} 
Product Code: The first two hex digits form the product code. For
example, 0x01 is the BIG-IP product code.

\item {} 
Subset Code: The third and fourth hex digits are the subset code. For
example, 0x2a is the subset code for LIBHAL.

\item {} 
Message Number: The next four digits form the message number within a
module.

\item {} 
Severity Level: The last digit between the colon symbols is the
severity level, with 0 being the highest severity level.

\item {} 
Message text: The description of the event that caused the system to
log the message.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Linux host log message format

Most log messages generated by the Linux host include a format similar
to the local traffic logs with the exception of the message code.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Audit log message format

The audit log messages generated by the BIG-IP system include the
following types of information:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{\PYGZlt{}time stamp\PYGZgt{} \PYGZlt{}host name\PYGZgt{} \PYGZlt{}level\PYGZgt{} \PYGZlt{}service[pid]\PYGZgt{} \PYGZlt{}message code\PYGZgt{} \PYGZlt{}user\PYGZgt{} \PYGZlt{}event\PYGZgt{}}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Time stamp: The time/date that the system logged the message

\item {} 
Host name: The host name of the BIG-IP system that generated the
message

\item {} 
Service: The name of the service (and process ID) that generated the
message

\item {} 
Message code: The code that is associated with the message (refer to
the previous Local traffic log message format section for Message
code sub-code definitions)

\item {} 
User: The name of the user who made the configuration change, the
user’s partition, and the user’s permission level

\item {} 
Event: The description of the configuration change or event that
caused the system to log the message

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.03 Analyze performance data to identify a resource problem on an LTM device}
\label{\detokenize{class7/modules/module3:objective-3-03-analyze-performance-data-to-identify-a-resource-problem-on-an-ltm-device}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.03 - Analyze performance data to identify a resource problem on an LTM device}

All of the statistical information related to the LTM’s performance can
be seen by navigating in the GUI to Statistics \textgreater{} Performance.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p162}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{p172}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K15468}

\sphinxstylestrong{Understanding BIG-IP CPU usage}

The Traffic Management Microkernel (TMM) processes all load-balanced
traffic on the BIG-IP system. TMM runs as a real-time user process
within the BIG-IP operating system (TMOS). CPU and memory resources are
explicitly provisioned in the BIG-IP configuration.

Understanding BIG-IP CPU usage

The following factors influence the manner in which TMM uses the CPU:
\begin{itemize}
\item {} 
The number of processors installed in the BIG-IP system

\item {} 
The BIG-IP version

\item {} 
The modules for which the BIG-IP system is licensed

\end{itemize}

CPU utilization on single CPU, single core systems

CPU resources are explicitly provisioned in the BIG-IP configuration.
When TMM is idle or processing low volumes of traffic, TMM yields idle
cycles to other processes.

CPU utilization on multi-CPU / multi-core systems

Prior to BIG-IP 11.5.0, each logical CPU core is assigned a separate TMM
instance, and each core processes both data plane (TMM-specific) tasks
and control plane (non-TMM-specific) tasks.

Beginning in BIG-IP 11.5.0, data plane tasks and control plane tasks use
separate logical cores on systems with Intel Hyper-Threading Technology
(HT Technology) CPUs. Even-numbered logical cores (hyperthreads) are
allocated to TMM, while odd numbered cores are available for other
processes.

Using the tmsh utility to view TMM CPU usage
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the TMOS Shell (tmsh) by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To display TMM CPU utilization and other statistical information for
TMM instances, type the following tmsh command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
show /sys tmm\PYGZhy{}info
\end{sphinxVerbatim}

For example, the following tmsh command is showing CPU usage for TMM 0.0 (Output truncated):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{Sys::TMM: 0.0}
\PYG{g+go}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{g+go}{CPU Usage Ratio (\PYGZpc{})}
\PYG{g+go}{Last 5 Seconds 3}
\PYG{g+go}{Last 1 Minute 3}
\PYG{g+go}{Last 5 Minutes 2}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
System CPU utilization is calculated by the following sets of values:
\end{sphinxadmonition}

\item {} 
Average over all TMM CPUs (all even CPUs)

\item {} 
Average over ‘all odd CPUs except the last one’ (The reason for
leaving out the last CPU is due to an analysis plane that was spiking
the last CPU numbers.)

\end{enumerate}

The higher of these values are presented as the overall system CPU
usage.


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K16419}

\sphinxstylestrong{Understanding BIG-IP Memory usage}

When administering a BIG-IP system, it is important to understand how
the system allocates memory. In general, BIG-IP memory usage falls into
the following categories:
\begin{itemize}
\item {} 
Traffic Management Microkernel (TMM) memory usage

\item {} 
Linux host memory usage

\item {} 
Swap usage

\end{itemize}

TMM runs as a real-time user process within the Linux host operating
system. The BIG-IP system statically assigns memory resources to TMM and
potentially to other module-related processes, depending on module
provisioning. The remaining memory is available for all other Linux host
processes.

The BIG-IP system creates swap usage space during software installation
on disk. Swap space is available to the Linux kernel.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{TMM memory usage}

The BIG-IP data plane includes one or more TMM processes to manage
traffic on the BIG-IP system. The BIG-IP system statically assigns
memory resources to TMM.

The following information summarizes TMM memory:
\begin{itemize}
\item {} 
The BIG-IP system assigns a dedicated pool of memory to each TMM
process.

\item {} 
TMM memory is not available for the Linux kernel to reassign to other
host processes. The system never considers TMM memory as available.

\item {} 
TMM memory cannot be swapped to disk.

\item {} 
The TMM memory management subsystem allocates and clears memory pages
in the following manner:

\item {} 
TMM allocates static memory to hash tables (for example, the
connection flow table).

\item {} 
TMM dynamically allocates memory pages for temporary objects (for
example, persistence records and buffered connection data).

\item {} 
Memory sweepers periodically reap unused memory as needed from TMM
objects.

\item {} 
When possible, TMM caches dynamic allocations to improve performance
when new objects require the same allocations.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Linux memory usage}

The system may allocate remaining memory to other processes on the Linux
host and kernel threads.

The following information summarizes Linux host memory usage:
\begin{itemize}
\item {} 
Linux allocates most available memory to buffers and disk caching,
which gives the appearance of high memory usage but allows the system
to run more efficiently.

\item {} 
Linux utilities, such as top and free, may report that only a small
amount of memory is free. This is normal behavior; cached memory can
be reclaimed quickly if a program needs memory.

\item {} 
To see memory used by buffers and disk caching, view the -/+
buffers/cache row where top and free report these memory structures.
Add these values to the reported amount of free memory to estimate
the total amount of physical memory the processes are not currently
using.

\item {} 
The Linux kernel sometimes copies memory pages to swap. This is known
as swapping memory.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Swap memory usage}

The following information summarizes swap memory usage:
\begin{itemize}
\item {} 
It is normal for a Linux system, including the BIG-IP system, to use
a small amount of swap. The Linux kernel sometimes prefers to swap
idle processes memory to disk so that more physical memory is
available for more active processes, buffers, and caches.

\item {} 
Physical memory is much faster than swap, and prioritizing buffers
and caches allows the kernel to optimize performance of disk-heavy
processes such as databases.

\item {} 
A higher percentage of swap use is normal when provisioned modules
make heavy use of the disk.

\item {} 
Excessive swap usage may be a sign that the system is experiencing
memory pressure. You should investigate in the following cases:

\item {} 
The system uses a very high percentage of swap memory.

\item {} 
The percentage of swap memory usage increases over time.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Understanding BIG-IP memory statistics}

You can view BIG-IP memory statistics using BIG-IP utilities or Linux
command line utilities. It is normal for Linux utilities, such as top
and free, to report a small amount of free memory. This expected
behavior occurs due to Linux disk caching. F5 recommends that you use
the Configuration utility or the TMOS Shell (tmsh) to view memory
statistics on the BIG-IP system.

You can view BIG-IP memory statistics, including TMM memory usage, other
(Linux) memory usage, swap usage, and memory allocated to TMM hash
tables and cache objects. To do so, use the following utilities:
\begin{itemize}
\item {} 
tmsh show /sys memory

\item {} 
Configuration utility: Statistics \textgreater{} Module Statistics \textgreater{} Memory

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Memory statistics (BIG-IP 10.x - 11.5.4)}

In BIG-IP 10.x - 11.5.4, the Configuration utility tmsh report memory
allocated to buffers and caches as used memory. As a result, it may
appear that the host system is using all available memory. The system
reports memory statistics in the following ways:
\begin{itemize}
\item {} 
System Memory

\item {} 
Host Total: The amount of memory available to Linux or non-TMM
processes.

\item {} 
Host Used: The amount of memory in use by Linux or non-TMM processes.

\item {} 
TMM Total: The amount of memory available to TMM processes.

\item {} 
TMM Used: The amount of memory in use by TMM processes for traffic
management.

\item {} 
Subsystem memory/memory pool name

\item {} 
Indicates the name and memory utilization of TMM hash tables and
cache objects.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.04 Given a scenario, determine the cause of an LTM device failover}
\label{\detokenize{class7/modules/module3:objective-3-04-given-a-scenario-determine-the-cause-of-an-ltm-device-failover}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.04 - Explain the effect of network failover settings on the LTM device}

\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/bigip-device-service-clustering-admin-11-5-0/8.html}

\sphinxstylestrong{What triggers failover?}

The BIG-IP system initiates failover according to any of several events
that you define. These events fall into these categories:

System fail-safe

With system fail-safe, the BIG-IP system monitors various hardware
components, as well as the heartbeat of various system services. You can
configure the system to initiate failover whenever it detects a
heartbeat failure.

Gateway fail-safe

With gateway fail-safe, the BIG-IP system monitors traffic between an
active BIG-IP system in a device group and a pool containing a gateway
router. You can configure the system to initiate failover whenever some
number of gateway routers in a pool of routers becomes unreachable.

VLAN fail-safe

With VLAN fail-safe, the BIG-IP system monitors network traffic going
through a specified VLAN. You can configure the system to initiate
failover whenever the system detects a loss of traffic on the VLAN and
the fail-safe timeout period has elapsed.

HA groups

With an HA group, the BIG-IP system monitors trunk, pool, or cluster
health to create an HA health score for a device. You can configure the
system to initiate failover whenever the health score falls below
configurable levels.

Auto-failback

When you enable auto-failback, a traffic group that has failed over to
another device fails back to a preferred device when that device is
available. If you do not enable auto-failback for a traffic group, and
the traffic group fails over to another device, the traffic group
remains active on that device until that device becomes unavailable.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.04 - Explain the relationship between serial and network failover}

\sphinxurl{https://support.f5.com/csp/article/K2397}

\sphinxstylestrong{Network Failover}

Network failover is based on heartbeat detection where the system sends
heartbeat packets over the internal network.

The system uses the primary and secondary failover addresses to send
network failover heartbeat packets. For more information about the
BIG-IP mirroring and network failover transport protocols, refer to the
following articles:
\begin{itemize}
\item {} 
\sphinxhref{https://support.f5.com/csp/article/K9057}{K9057: Service port and protocol used for BIG-IP network
failover}

\item {} 
\sphinxhref{https://support.f5.com/csp/article/K7225}{K7225: Transport protocol used for BIG-IP connection and persistence
mirroring}

\end{itemize}

The BIG-IP system considers the peer down after the
Failover.NetTimeoutSec timeout value is exceeded. The default value of
Failover.NetTimeoutSec is three seconds, after which the standby unit
attempts to switch to an active state. The following database entry
represents the default settings for the failover time configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{Failover.NetTimeoutSec = 3}
\end{sphinxVerbatim}

Device Service Clustering (DSC) was introduced in BIG-IP 11.0.0 and
allows many new features such as synchronization and failover between
two or more devices. Network failover provides communication between
devices for synchronization, failover, and mirroring and is required for
the following deployments:
\begin{itemize}
\item {} 
Sync-Failover device groups containing three or more devices

\item {} 
Active-active configurations between two BIG-IP platforms

\item {} 
BIG-IP VIPRION platforms

\item {} 
BIG-IP Virtual Edition

\end{itemize}

An active-active pair must communicate over the network to indicate the
objects and resources they service. Otherwise, if network communications
fail, the two systems may attempt to service the same traffic management
objects, which could result in duplicate IP addresses on the network.

Network issues may cause BIG-IP systems to enter into active-active
mode. To avoid this issue, F5 recommends that you dedicate one interface
on each system to perform only failover communications and, when
possible, directly connect these two interfaces with an Ethernet cable
to avoid network problems that could cause the systems to go into an
active-active state.

Important: When you directly connect two BIG-IP systems with an Ethernet
cable, do not change the speed and duplex settings of the interfaces
involved in the connection. If you do, depending on the BIG-IP software
version, you may be required to use a crossover cable. For more
information, refer to \sphinxhref{https://support.f5.com/csp/article/K9787}{K9787: Auto MDI/MDIX behavior for BIG-IP
platforms}.

If you configure a BIG-IP high-availability pair to use network
failover, and the hardwired failover cable also connects the two units,
hardwired failover always has precedence; if network failover traffic is
compromised, the two units do not fail over because the hardwired
failover cable still connects them.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Hardwired failover}

Hardwired failover is also based on heartbeat detection, where one
BIG-IP system continuously sends voltage to another. If a response does
not initiate from one BIG-IP system, failover to the peer occurs in less
than one second. When BIG-IP redundant devices connect using a hardwired
failover cable, the system automatically enables hardwired failover.

The maximum hardwired cable length is 50 feet. Network failover is an
option if the distance between two BIG-IP systems exceeds the acceptable
length for a hardwired failover cable.

Note: For information about the failover cable wiring pinouts, refer to
K1426: Pinouts for the failover cable used with BIG-IP platforms.

Hardwired failover can only successfully be deployed between two
physical devices. In this deployment, hardwired failover can provide
faster failover response times than network failover.

Hardwired failover is only a heartbeat and carries no status
information. Communication over the network is necessary for certain
features to function properly. For example, Traffic Management
Microkernel (TMM) uses the network to synchronize packets and flow state
updates to peers for connection mirroring. To enable proper state
reporting and mirroring, F5 recommends that you configure network
failover in addition to hardwired failover.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.04 - Differentiate between unicast and multicast network failover modes}

\sphinxurl{https://support.f5.com/csp/article/K2397}

\sphinxstylestrong{Failover IP addresses}

These are the IP addresses that you want the BIG-IP system to use when
another device in the device group fails over to the local device. You
can specify two types of addresses: unicast and multicast.

For appliance platforms, specifying two unicast addresses should
suffice. For VIPRION platforms, you should also retain the default
multicast address that the BIG-IP system provides.

The recommended unicast addresses for failover are:
\begin{itemize}
\item {} 
The self IP address that you configured for either VLAN HA or VLAN
internal. If you created VLAN HA when you initially ran the Setup
utility on the local device, F5 recommends that you use the self IP
address for that VLAN. Otherwise, use the self IP address for VLAN
internal.

\item {} 
The IP address for the local management port.

\end{itemize}


\bigskip\hrule\bigskip


\sphinxurl{https://support.f5.com/csp/article/K90231443}

\sphinxstylestrong{Secure Network Failover}

When you configure BIG-IP device group members to use network failover,
the systems communicate over the configured failover addresses. By
default, the systems use UDP port 1026 for unicast network failover
traffic.

You can configure the BIG-IP system to pass network failover traffic
over a secure channel. When you enable the failover.secure db variable,
the system protects the failover connections to peer devices using DTLS
and certificate authentication. Configuring secure network failover
traffic may be beneficial when network traffic is configured to pass
over a public network.

You should be aware of the following when you configure the BIG-IP
system to pass network failover traffic over a secure channel:
\begin{itemize}
\item {} 
Secure network failover requires that one or more unicast failover IP
address is defined for device group members.

\item {} 
Enabling secure network failover disables the multicast network
failover feature.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.04 - Identify the cause of failover using logs and statistics}

\sphinxurl{https://support.f5.com/csp/article/K95002127}

\sphinxstylestrong{Reviewing the log files for failover messages}

The BIG-IP system logs messages related to failover in the /var/log/ltm
file and the /var/log/audit file. After you locate a log message that
indicates a failover occurrence, you can review the log files
surrounding the failover event to help determine the cause of the
failover. To review log files related to failover issues, refer to the
following commands:

Impact of procedure: Performing the suggested actions should not have a
negative impact on your system.

To display the /var/log/ltm file, use a Linux command similar to the
following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
less /var/log/ltm
\end{sphinxVerbatim}

To display log messages related to the system transitioning to an active
or standby state, use the grep or egrep commands to search for certain
patterns in the /var/log/ltm file similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}active\textbar{}standby\PYGZsq{}} /var/log/ltm
\end{sphinxVerbatim}

To display the /var/log/audit log file, use a Linux command similar to
the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
less /var/log/audit
\end{sphinxVerbatim}

To display log messages related to the system administratively
transitioning to a standby state, use the following egrep command to
search for patterns related to the device being placed in the standby
state in the /var/log/audit file.

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}cmd\PYGZus{}sod go standby\textbar{}sys failover standby\PYGZsq{}} /var/log/audit
\end{sphinxVerbatim}

You may observe messages similar to the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Active/Standby message}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
010c0019:5: Active
&
The device has transitioned to an active state.
\\
\hline
010c0053:5: Active for traffic group \textless{}traffic\_group\textgreater{}.
&
The device has transitioned to active for the specified traffic group.
\\
\hline
010c0018:5: Standby
&
The device has transitioned to a standby state.
\\
\hline
010c0052:5: Standby for traffic group \textless{}traffic\_group\textgreater{}
&
The device has transitioned to active for the specified traffic group.
\\
\hline
010c0026:5: Failover condition, active attempting to go standby
&
The device has encountered a failover condition and is attempting to transition to a standby state.
\\
\hline
01070417:6: AUDIT - user admin - RAW: Request to run /usr/bin/cmd\_sod go standby\textless{}traffic group\textgreater{} GUI.
&
User admin requested standby using the Configuration utility.
\\
\hline
01420002:5: AUDIT - pid=30246 user=root folder=/Common module=(tmos)\# status={[}Command OK{]} cmd\_data=run sys failover standby
&
User admin requested standby using  \sphinxstylestrong{tmsh}.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

To display log messages related to failover or fail-safe, use the grep
or egrep commands to search for certain patterns in the /var/log/ltm
file. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}failover\textbar{}failsafe\PYGZsq{}} /var/log/ltm
\end{sphinxVerbatim}

You may observe messages similar to the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Failover/Fail-safe message}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
010c0026:5: Failover condition, active attempting to go standby
&
The device has encountered a failover condition and is attempting to transition to a standby state.
\\
\hline
01140029:4: HA pool\_memb\_down \textless{}pool\textgreater{} fails action is failover
&
A component has detected an HA failure condition and is requesting the system take corrective action.
\\
\hline
010c002b:5: Traffic group \textless{}traffic\_group\textgreater{} received a targeted failover command for \textless{}IP\_addr\textgreater{}
&
The active device has received a failover command that was issued by an administrator.
\\
\hline
01140029:5: HA daemon\_heartbeat \textless{}daemon\textgreater{} fails action is failover and restart
&
The noted daemon failed to update its heartbeat signal, causing a failover action.
\\
\hline
01140043:0: Ha feature nic\_failsafe reboot requested
&
The system has detected an issue with the High-Speed Bridge (HSB) data path and has triggered a reboot action.
\\
\hline
01010023:2: Switchboard failsafe action indicated by \textless{}daemon\textgreater{}, exiting
&
The system has detected a switchboard issue and will execute the configured fail-safe action.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

To display log messages related to watchdog or overdog, use the grep or
egrep commands to search for certain patterns in the /var/log/ltm file.

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
egrep \PYGZhy{}i \PYG{l+s+s1}{\PYGZsq{}watchdog\textbar{}overdog\PYGZsq{}} /var/log/ltm
\end{sphinxVerbatim}

You may observe messages similar to the following:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Watchdog/overdog message}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
1140101:6: Overdog daemon shutdown
&
The \sphinxstylestrong{watchdog} daemon (\sphinxstylestrong{overdog}) has shut down and  \sphinxstylestrong{watchdog} monitoring is no longer active.
\\
\hline
01140100:6: Overdog daemon startup
&
The HA watchdog is now active.
\\
\hline
01140103:5: Watchdog touch enabled with \textless{}number\textgreater{} seconds.
&
The system  \sphinxstylestrong{watchdog} process (\sphinxstylestrong{overdog}) has initiated the hardware watchdog feature.
\\
\hline
01140104:5: Watchdog touch disabled
&
The hardware  \sphinxstylestrong{watchdog} process (\sphinxstylestrong{overdog}) has disarmed the hardware watchdog and stopped periodic updates.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\subsection{Objective - 3.05 Given a scenario, determine the cause of loss of high availability and/or sync failure}
\label{\detokenize{class7/modules/module3:objective-3-05-given-a-scenario-determine-the-cause-of-loss-of-high-availability-and-or-sync-failure}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.05 - Explain how the high availability concepts relate to one another}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/900/sol13946.html}

\sphinxstylestrong{DSC components}

DSC provides the foundation for centralized management and
high-availability features in BIG-IP 11.x, including the following
components:
\begin{itemize}
\item {} 
Device trust and trust domains

Device trust establishes trust relationships between BIG-IP devices
through certificate-based authentication. Each device generates a
device ID key and Secure Socket Layer (SSL) certificate upon upgrade
or installation. A trust domain is a collection of BIG-IP devices
that trust each other, and can synchronize and fail over their
BIG-IP configuration data, as well as regularly exchange status and
failover messages.

When the local BIG-IP device attempts to join a device trust with a
remote BIG-IP device, the following applies:

\item {} 
If the local BIG-IP device is added as a peer authority device, the
remote BIG-IP device presents a certificate signing request (CSR) to
the local device, which then signs the CSR and returns the
certificate along with its CA certificate and key.

\item {} 
If the local BIG-IP device is added as a subordinate (non-authority)
device, the remote BIG-IP device presents a CSR to the local device,
which then signs the CSR and returns the certificate. The CA
certificate and key are not presented to the remote BIG-IP device.
The subordinate device is unable to request other devices to join the
device trust.

\item {} 
Device groups

A device group is a collection of BIG-IP devices that reside in the
same trust domain and are configured to securely synchronize their
BIG-IP configuration and failover when needed. Device groups can
initiate a ConfigSync operation from the device group member with
the desired configuration change. You can create two types of device
groups:

\item {} 
A Sync-Failover device group contains devices that synchronize
configuration data and support traffic groups for failover purposes.

\item {} 
A Sync-Only device group contains devices that synchronize
configuration data, but do not synchronize failover objects and do
not fail over to other members of the device group.

\item {} 
Traffic groups

A traffic group represents a collection of related configuration
objects that are configured on a BIG-IP device. When a BIG-IP device
becomes unavailable, a traffic group can float to another device in
a device group.

\item {} 
Folders

A folder is a container for BIG-IP configuration objects. You can
use folders to set up synchronization and failover of configuration
data in a device group. You can sync all configuration data on a
BIG-IP device, or you can sync and fail over objects within a
specific folder only.

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.05 - Explain the relationship between device trust and device groups}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/900/sol13946.html}

\sphinxstylestrong{Relationship between Device Trust and Device Group}

For a Big-IP device to be added to a Device Group there must be an
established trust between the devices in that Device Group and the new
device. This is done through certificate-based authentication between
the devices which establishes a Device Trust or trust domain.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.05 - Identify the cause of ConfigSync failures}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/900/sol13946.html}

\sphinxstylestrong{ConfigSync Failures}

F5 introduced the DSC architecture in BIG-IP 11.x. DSC provides the
framework for ConfigSync and other high availability (HA) features, such
as failover for BIG-IP device groups.

Note: The DSC technology is also referred to as centralized management
infrastructure (CMI).

This article provides steps to troubleshoot ConfigSync and the
underlying DSC components. DSC and ConfigSync include the following
elements:

\sphinxstylestrong{CMI communication channel}

The BIG-IP system uses SSL certificates to establish a trust
relationship between devices. In a device trust, BIG-IP devices can act
as certificate signing authorities, peer authorities, or subordinate
non-authorities. When acting as a certificate signing authority, the
BIG-IP device signs x509 certificates for another BIG-IP device that is
in the local trust domain. The BIG-IP device for which a certificate
signing authority device signs its certificate is known as a subordinate
non-authority device. The BIG-IP system uses the following certificates
to establish a secure communication channel.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{File name}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Configuration utility location}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
/config/ssl/ssl.crt/dtdi.crt
&
Device Management \textgreater{} Device Trust \textgreater{} Identity
&
The dtdi.crt is the identity certificate that is used by a device to validate its identity with another device.
\\
\hline
/config/ssl/ssl.key/dtdi.key
&
Not applicable
&
The dtdi.key is the corresponding key file used by a device to validate its identity with another device.
\\
\hline
/config/ssl/ssl.crt/dtca.crt
&
Device Management \textgreater{} Device Trust \textgreater{} Local Domain
&
The dtca.crt is the CA root certificate for the trust network.
\\
\hline
/config/ssl/ssl.key/dtca.key
&
Not applicable
&
The dtca.key is the CA root key for the trust network.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

When the DSC components are properly defined, the device group members
establish a communication channel to accommodate device group
communication and synchronization. The CMI communication channel allows
the mcpd process that runs on the device group member to exchange MCP
messages and commit ID updates to determine which device has the latest
configuration and is eligible to synchronize its configuration to the
group. After the ConfigSync IP addresses are defined on each device, and
the device group is created, the devices establish the communication
channel, as follows:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
A user updates the configuration of a BIG-IP device group member
using the Configuration utility or TMOS Shell (tmsh).

\item {} 
The configuration change is communicated to the local mcpd process.

\item {} 
The mcpd process communicates the new configuration and commit ID to
the local TMM process.

\item {} 
The local TMM process sends the configuration and commit ID update to
remote TMM processes over the communication channel.

\item {} 
The remote TMM process translates the port to 6699 and connects to
its mcpd process.

\item {} 
The remote mcpd process loads the new configuration into memory, and
writes the configuration changes to the appropriate configuration
files.

\end{enumerate}

\sphinxstylestrong{Automatic Sync}

If you enable the Automatic Sync feature for a device group, the BIG-IP
system automatically synchronizes changes to a remote peer system’s
running configuration but does not save the changes to the configuration
files on the peer device. This behavior is by design and recommended for
larger configurations to avoid a long ConfigSync duration due to large
configurations.

In some cases, you may want to configure Automatic Sync to update the
running configuration and save the configuration to the configuration
files on the remote peer devices. For information, refer to K14624:
Configuring the Automatic Sync feature to save the configuration on the
remote devices.

Beginning in BIG-IP 11.4.0, the Automatic Sync feature is available for
both Sync-Only and Sync-Failover device groups. In addition, the
automatic sync behavior can be configured to be either full or
incremental. For more information, refer to K14809: Auto Sync is
possible for Sync-Failover device groups.

\sphinxstylestrong{Symptoms}

DSC and ConfigSync issues may result in the following symptoms:
\begin{itemize}
\item {} 
Device group members have configuration discrepancies.

\item {} 
The system displays status messages that indicate a synchronization
or device trust issue.

\item {} 
The BIG-IP system logs error messages related to device trust or the
ConfigSync process.

\end{itemize}

\sphinxstylestrong{Procedures}

When you investigate a possible device service clustering or ConfigSync
issue, you should first verify that the required configuration elements
are set for all device group members. If the required elements are set,
then attempt a ConfigSync operation. If ConfigSync fails, the BIG-IP
system generates Sync status messages that you can use to diagnose the
issue. Use the following procedures to troubleshoot DSC and ConfigSync:

\sphinxstylestrong{Troubleshooting a ConfigSync operation}

Attempt a ConfigSync operation to gather diagnostic information to help
you troubleshoot ConfigSync/DSC issues. To troubleshoot the ConfigSync
operation, perform the following procedures:

\sphinxstylestrong{Verifying the required elements for ConfigSync/DSC}

For DSC and ConfigSync to function properly, you must verify that
required configuration elements are set. To do so, review the following
requirement information.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Requirement}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Configuration utility location}
&\sphinxstyletheadfamily 
\sphinxstylestrong{tmsh location}
\\
\hline
Licensing and provisioning
&
Device group members must have the same product licensing and module provisioning.

Note: For exceptions, refer to the \sphinxstylestrong{BIG-IP licensing and provisioning requirements} section in \sphinxhref{https://support.f5.com/csp/article/K8665}{*K8665: BIG-IP redundant configuration hardware and software parity requirements*}
&
\sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{License}
&
\sphinxstylestrong{tmsh show /sys license
tmsh show /sys provision}
\\
\hline
Software versions
&
Device group members must run the same BIG-IP software version.
&
\sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Software Management}
&
\sphinxstylestrong{tmsh show /sys software}
\\
\hline
Management IP
&
Each device must have a unique management IP address, netmask, and management route.
&
\sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Platform}
&
l \sphinxstylestrong{ist /sys management-ip
list /sys management-route}
\\
\hline
NTP
&
Network Time Protocol (NTP) is required for all device group members.
&
\sphinxstylestrong{System} \textgreater{} \sphinxstylestrong{Configuration}\textgreater{}  \sphinxstylestrong{Device} \textgreater{} \sphinxstylestrong{NTP}
&
\sphinxstylestrong{tmsh list /sys ntp servers}
\\
\hline
ConfigSync IP
&
Self IP addresses for ConfigSync must be defined and routable between device group members. F5 recommends that the addresses reside on a dedicated HA VLAN.
&
\sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Devices}
&
\sphinxstylestrong{tmsh list /cm device \textless{}device\textgreater{} configsync-ip}
\\
\hline
Failover IP
&
Self IP addresses for failover must be defined and routable between device group members (for Sync-Failover device groups).
&
\sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Devices}
&
\sphinxstylestrong{tmsh list /cm device \textless{}device\textgreater{} unicast-address}
\\
\hline
Ports
&
Device group members should be able to communicate over ports 443, 4353, 1026 (UDP), and 22 (recommended).
BIG-IP ASM requires the following additional Policy Sync TCP ports: 6123-6128.
&
Not applicable
&
Not applicable
\\
\hline
Device trust
&
Device trust must be established for device group members.
&
\sphinxstylestrong{Device Management **\textgreater{}  **Device Trust}
&
\sphinxstylestrong{tmsh show /cm device-group device\_trust\_group}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{Reviewing common reasons for ConfigSync failures}

If you experience ConfigSync issues after you first establish device
trust, after rebooting, or upgrading, review the following common
reasons for ConfigSync failure:
\begin{itemize}
\item {} 
The devices have an IP address conflict

IP address conflicts are common causes of ConfigSync failure during
initial device group setup. If the ConfigSync or failover IP address
conflicts with another device, the systems will fail to establish a
trust relationship, ConfigSync operations will fail, and the systems
will fail to detect the active or next-active device. BIG-IP systems
experiencing an IP address conflict log error messages to the
/var/log/ltm file that appear similar to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{warning tmm[11178]: 01190004:4: address conflict detected for}
\PYG{g+go}{10.0.0.1 (00:0c:29:16:33:f6) on vlan 4093}
\end{sphinxVerbatim}

\item {} 
One or more devices are not reachable on the network

Self IP addresses used for ConfigSync and failover must be routable
between device group members. Prior to establishing device trust,
make sure the devices are online and can communicate using the
defined self IP addresses. For example, make sure you can ping the
management IP address and ConfigSync IP addresses of other devices.

\item {} 
The software versions do not match

If you recently upgraded one of the device group members, you should
verify that the other device group members are also upgraded and
running the same software version. BIG-IP device group members must
run the same BIG-IP software version for ConfigSync operations to
work between group members; this includes the major, minor, and
maintenance software version numbers. By default, the hotfix and
point release version numbers are not required to match among device
group members when performing ConfigSync operations.

\item {} 
The BIG-IP configuration fails to load

If you experience ConfigSync issues after upgrading or loading a UCS
file on a device, verify whether the configuration failed to load.
To do so, type the following command from the command line, correct
reported validation errors, and attempt to reload the configuration:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh load sys config verify
\end{sphinxVerbatim}

\end{itemize}

\sphinxstylestrong{Viewing the commit ID updates}

When you troubleshoot a ConfigSync issue, it is helpful to determine
which device group member has the latest commit ID update and contains
the most recent configuration. You can then decide whether to replicate
the newer configuration to the group, or perform a ConfigSync operation
that replicates an older configuration to the group, thus overwriting a
newer configuration.

To display the commit ID and the commit ID time stamps for the device
group, perform the following procedure:

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the BIG-IP command line.

\item {} 
To display the commit IDs for the device group, type the following
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh run /cm watch\PYGZhy{}devicegroup\PYGZhy{}device
\end{sphinxVerbatim}

\item {} 
Locate the relevant device group and review the cid.id and cid.time
columns.

For example, the following output shows that the sync\_test device
group has three members, and device bigip\_a has the latest
configuration as indicated by the cid.id (commit ID number) and
cid.time (commit ID timestamp) columns:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{devices \PYGZlt{}devgroup [device   cid.id   cid.orig   cid.time   last\PYGZus{}sync}
\PYG{g+go}{20 21 sync\PYGZus{}test   bigip\PYGZus{}a   32731    bigip\PYGZus{}a    14:27:00   : :}
\PYG{g+go}{20 21 sync\PYGZus{}test   bigip\PYGZus{}b   1745     bigip\PYGZus{}a    13:39:24   13:42:04}
\PYG{g+go}{20 21 sync\PYGZus{}test   bigip\PYGZus{}c   1745     bigip\PYGZus{}a    13:39:24   13:42:04}
\end{sphinxVerbatim}

\end{enumerate}

Note: Multiple devices with identical information are collapsed into
a single row that displays in green.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Perform steps 1 through 3 on all devices in the device group.

\item {} 
Compare the commit ID updates for each device with each device group
member. If the commit ID updates are different between devices, or a
device is missing from the list, proceed to the Troubleshooting DSC
section.

\end{enumerate}

\sphinxstylestrong{Verifying a ConfigSync operation}

When troubleshooting a ConfigSync issue, attempt a ConfigSync operation
and verify the sync status message. If the ConfigSync operation fails,
the BIG-IP system generates a sync status message that you can use to
diagnose the issue. To attempt a ConfigSync operation, perform one of
the following three procedures:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Configuration utility}

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the Configuration utility.

\item {} 
Navigate to Device Management \textgreater{} Overview.

\item {} 
For Device Groups, click the name of the device group you want to
synchronize.

\item {} 
For Devices, click the appropriate device.

\item {} 
Click the synchronization operation.

\item {} 
Click Sync.

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{tmsh}

Impact of procedure: Performing the following procedure should not have
a negative impact on your system.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to tmsh by typing the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
tmsh
\end{sphinxVerbatim}

\item {} 
To synchronize the configuration to the device group, use the
following command syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
run /cm config\PYGZhy{}sync \PYGZlt{}option\PYGZgt{} \PYGZlt{}device\PYGZus{}group\PYGZgt{}
\end{sphinxVerbatim}

For example, to synchronize the local device configuration to the
device group, type the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
run /cm config\PYGZhy{}sync to\PYGZhy{}group \PYGZlt{}device\PYGZus{}group\PYGZgt{}
\end{sphinxVerbatim}

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Verifying the sync status}

After you attempt the ConfigSync operation, you can verify the
synchronization status messages and begin to troubleshoot the issue. To
verify the synchronization status, refer to the following utilities.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Utility}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Page or command}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Configuration utility
&
\sphinxstylestrong{Device Management} \textgreater{} \sphinxstylestrong{Overview}
&
The  \sphinxstylestrong{Device Groups} section displays the ConfigSync status for device groups.
The  \sphinxstylestrong{Devices} section displays the ConfigSync status for devices.
\\
\hline
\sphinxstylestrong{tmsh}
&
\sphinxstylestrong{tmsh show /cm sync-status}
&
Displays the ConfigSync status of the local device and any recommended synchronization actions.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Understanding sync status messages}

The BIG-IP system displays ConfigSync status messages for device groups
and specific devices. Common synchronization status messages are
displayed in the following tables.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Synchronization status messages for device groups}

The BIG-IP system displays a number of specific synchronization status
messages for each device group. Use the following table to help you
troubleshoot messages that you might encounter.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Sync status}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Summary}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Details}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Recommendation}
\\
\hline
Awaiting Initial Sync
&
The device group is awaiting the initial ConfigSync
&
The device group was recently created and has either not yet made an initial sync, or the device has no configuration changes to be synced.
&
Sync one of the devices to the device group.
\\
\hline
Awaiting Initial Sync
&
hostname-1, hostname-2, etc. awaiting the initial ConfigSync
&
One or more device group members have not yet synced their data to the other device group members, or a device group member has not yet received a synchronization from another member.
&
Sync the device that has the most current configuration to the device group.
\\
\hline
Changes Pending
&
Changes pending
&
One or more device group members have recent configuration changes that have not been synchronized to the other device group members.
&
Sync the device that has the most current configuration to the device group.
\\
\hline
Changes Pending
&
There is a possible change conflict between hostname-1, hostname-2, etc.
&
There is a possible conflict among two or more devices because more than one device contains changes that have not been synchronized to the device group.
&
View the individual synchronization status of each device group member, and then sync the device that has the most current configuration to the device group.
\\
\hline
Not All Devices Synced
&
hostname-1, hostname-2, etc. did not receive last sync successfully
&
One or more of the devices in the device group does not contain the most current configuration.
&
View the individual synchronization status of each device group member, and then sync the device that has the most current configuration to the device group.
\\
\hline
Sync Failure
&
A validation error occurred while syncing to a remote device
&
The remote device was unable to sync due to a validation error.
&
Review the  \sphinxstylestrong{/var/log/ltm} log file on the affected device.
\\
\hline
Unknown
&
The local device is not a member of the selected device group
&
The device that you are logged in to is not a member of the selected device group.
&
Add the local device to the device group.
\\
\hline
Unknown
&
Not logged in to the primary cluster member
&
The system cannot determine the synchronization status of the device group because you are logged in to a secondary cluster member instead of the primary cluster member. This status pertains to VIPRION systems only.
&
Use the primary cluster IP address to log in to the primary cluster member.
\\
\hline
Unknown
&
Error in trust domain
&
The trust relationships among devices in the device group are not properly established.
&
On the local device, reset device trust and then re-add all relevant devices to the local trust domain.
\\
\hline
None
&
X devices with Y different configurations
&
The configuration time for two or more devices in the device group differs from the configuration time of the other device group members. This condition causes one of the following synchronization status messages to appear for each relevant device:
Device\_name awaiting initial ConfigSync
Device\_name made last configuration change on date\_time
&
Sync the device that has the most current configuration to the device group.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Synchronization status messages for devices}

The BIG-IP system displays a number of specific synchronization status
messages for individual devices. Use the following table to help you
troubleshoot messages that you might encounter.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Sync status}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Summary}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Recommendation}
\\
\hline
Awaiting Initial Sync
&
The local device is waiting for the initial ConfigSync. The device has not received a sync from another device and has no configuration changes to be synced to other members of the device group.
&
Determine what device has the latest configuration and perform a ConfigSync from the device.
\\
\hline
Changes Pending
&
The device has recent configuration changes that have not been synced to other device group members.
&
Sync the device to the device group.
\\
\hline
Awaiting Initial Sync with Changes Pending
&
The configuration on the device has changed since joining the device group, or the device has not received a sync from another device but has configuration changes to be synced to other device group members.
&
Determine the device with the latest configuration and perform a ConfigSync operation from the device.
\\
\hline
Does not have the last synced configuration, and has changes pending
&
The device received at least one synchronization previously, but did not receive the last synchronized configuration, and the configuration on the device has changed since the last sync.
&
Determine the device with the latest configuration and perform a ConfigSync operation from the device.
\\
\hline
Disconnected
&
The iQuery communication channel between the devices was terminated or disrupted. This may be a result of one of the following:
The disconnected device is not a member of the local trust domain.
The disconnected device does not have network access to one or more device group members.
&
Join the disconnected device to the local trust domain.
Verify that the devices have network access using the ConfigSync IP addresses.
\\
\hline
Device does not recognize membership in this group
&
The local device does not recognize that it is a member of the device group.
&
Add the device to the device group.
\\
\hline
No ConfigSync address has been specified for this device
&
The device does not have a ConfigSync IP address.
&
Configure a ConfigSync IP address for the device.
\\
\hline
Does not have the last synced configuration
&
The device previously received the configuration from other device group members, but did not receive the last synced configuration.
&
Perform a ConfigSync operation to sync the device group to the local device.
\\
\hline
In Sync periodically changes to Changes Pending
&
If the device Sync status changes without notice, determine whether a third party script or device is making the changes.
&
Review the \sphinxstylestrong{/var/log/audit} file to see if a third party script or device made configuration changes. Look for \sphinxstylestrong{create}, \sphinxstylestrong{modify} or \sphinxstylestrong{delete} commands in the audit log. For example:

list cli preference pager
create\_if \{ cli\_preference \{ cli\_preference\_user\_name …
modify cli preference pager disabled
quit
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Reviewing the log files for ConfigSync error messages}

The BIG-IP system logs messages related to ConfigSync and DSC to the
/var/log/ltm file. To review log files related to ConfigSync and DSC
issues, refer to the following commands:
\begin{itemize}
\item {} 
To display the /var/log/ltm file, use a Linux command similar to the
following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cat /var/log/ltm
\end{sphinxVerbatim}

\item {} 
To display log messages related to DSC or CMI, use a command similar
to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
grep \PYGZhy{}i cmi /var/log/ltm
\end{sphinxVerbatim}

\item {} 
To display log messages related to ConfigSync, use a command similar
to the following example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
grep \PYGZhy{}i configsync /var/log/ltm
\end{sphinxVerbatim}

\end{itemize}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3.05 - Explain the relationship between traffic groups and LTM objects}

\sphinxurl{https://support.f5.com/kb/en-us/solutions/public/13000/900/sol13946.html}

\sphinxstylestrong{Traffic groups and Configuration Objects}

A traffic group represents a collection of related configuration objects
that are configured on a BIG-IP device. When a BIG-IP device becomes
unavailable, a traffic group can float to another device in a device
group. The ability to do logical grouping of configuration objects based
on failure scenarios it a powerful tool for high availability.


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3. 05 - Interpret log messages to determine the cause of high availability issues}

\sphinxurl{https://support.f5.com/csp/article/K47046731}

\sphinxstylestrong{Interpret log messages}

You will need to be familiar with reviewing logs and recognizing HA
errors. The following is an example of an error you may see in the logs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{0107142f:3: Can\PYGZsq{}t connect to CMI peer \PYGZlt{}ip\PYGZus{}address\PYGZgt{}, \PYGZlt{}reason\PYGZgt{}}
\end{sphinxVerbatim}

In this error message, note the following:
\begin{itemize}
\item {} 
\textless{}ip\_address\textgreater{} is the remote BIG-IP system’s IP address.

\item {} 
\textless{}reason\textgreater{} is a detailed reason why connection attempts to the remote
BIG-IP system are failing.

\end{itemize}

For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{0107142f:3: Can\PYGZsq{}t connect to CMI peer 10.11.23.140, TMM outbound}
\PYG{g+go}{listener not yet created}

\PYG{g+go}{0107142f:3: Can\PYGZsq{}t connect to CMI peer 192.168.10.100, port:6699,}
\PYG{g+go}{Transport endpoint is not connected}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The BIG-IP system will continue connection attempts until
successfully connected.
\end{sphinxadmonition}

Message Location:
\begin{itemize}
\item {} 
The /var/log/ltm file

\end{itemize}

Description:

This message occurs when one of the following conditions is met:
\begin{itemize}
\item {} 
The local BIG-IP system’s Traffic Management Microkernel (TMM) has
not initialized or established a listener.

\item {} 
The remote BIG-IP system’s TMM has not initialized or established a
listener.

\item {} 
There are general network issues, such as routing or switching
failures, preventing connectivity between the BIG-IP systems.

\end{itemize}

Impact:

Local and remote BIG-IP systems are unable to perform configuration
synchronizations (ConfigSync).

Recommended Actions:
\begin{itemize}
\item {} 
Ensure that the BIG-IP systems have correct self IP definitions, and
the network allows proper connectivity between the BIG-IP systems.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}



\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Conclusion}
\label{\detokenize{class7/modules/module3:conclusion}}
This document is intended as a study guide for the F5 301b \textendash{} LTM
Specialist: Maintain and Troubleshoot exam. This study guide is not an
all-inclusive document that will guarantee a passing grade on the exam.
It is intended to be a living doc and any feedback or material that you
feel should be included, to help exam takers better prepare, can be sent
to \sphinxhref{mailto:F5CertGuides@f5.com}{F5CertGuides@f5.com}.

Thank you for using this study guide to prepare the 301b \textendash{} LTM
Specialist exam and good luck with your certification goals.

Thanks

Eric Mitchell

Sr. Systems Engineer - Global SI


\chapter{F5 302 - BIG-IP DNS Specialist Study Guide 11/01/19}
\label{\detokenize{class9/class9:f5-302-big-ip-dns-specialist-study-guide-11-01-19}}\label{\detokenize{class9/class9::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\begin{sphinxadmonition}{caution}{Caution:}
302 CONTENT IS NOT YET DEVELOPMENT and will be published when complete.
\end{sphinxadmonition}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 302 - BIG-IP DNS Specialist}

Welcome to the 302 - BIG-IP DNS Specialist compiled Study Guide. The purpose of
this guide is to help you prepare for the F5 302 - BIG-IP DNS Specialist exam.
The contents of this document are based on the F5 302 - BIG-IP DNS Specialist
Exam Blueprint for TMOS v12.1.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the reference the linked information easier
without having to search through a formal appendix.

This guide also references some resources. Those books are a great source of
information on Domain Name Services (DNS) and BIG-IP Domain Name Services
(BIG-IP DNS).

The F5 Certified BIG-IP Administrator (F5-CA), which is made up of the 101 -
App Delivery Fundamentals and 201 - TMOS Administration exams, stand as a
pre-requisite to this exam.

Taking certified F5 BIG-IP DNS training, such as Configuring BIG-IP DNS v12,
will surely help with the topics of this exam but does not teach directly to
the exam content. Hands on administrative experience with the BIG-IP platform
licensed with BIG-IP DNS will reinforce many of the topics contained in the
302 - BIG-IP DNS Specialist exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}

\sphinxstylestrong{Printed References}

These referenced books are and important and should be considered basic reading
material for this exam.

(Ref:1) Kozierok, Charles M. 2005. The TCP/IP Guide. No Starch Press, Inc. San Francisco, CA. 94103. ISBN 1-59327-047-X  pp 947 -1080

(Ref:2) Liu, Cricket and Albitz, Paul. 2006. DNS and BIND, Fifth Edition. O’Reilly Media, Inc. Sebastopol, CA. 95472. ISBN 978-0-596-10057-5


\section{Section 1 - Design and Architect}
\label{\detokenize{class9/modules/module1:section-1-design-and-architect}}\label{\detokenize{class9/modules/module1::doc}}

\section{Section 2 - Implement}
\label{\detokenize{class9/modules/module2:section-2-implement}}\label{\detokenize{class9/modules/module2::doc}}

\section{Section 3 - Test and Troubleshoot}
\label{\detokenize{class9/modules/module3:section-3-test-and-troubleshoot}}\label{\detokenize{class9/modules/module3::doc}}

\section{Section 4 - Operations and Support}
\label{\detokenize{class9/modules/module4:section-4-operations-and-support}}\label{\detokenize{class9/modules/module4::doc}}

\subsection{Conclusion}
\label{\detokenize{class9/modules/module4:conclusion}}

\chapter{F5 303 - BIG-IP ASM Specialist Study Guide 11/01/19}
\label{\detokenize{class11/class11:f5-303-big-ip-asm-specialist-study-guide-11-01-19}}\label{\detokenize{class11/class11::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\begin{sphinxadmonition}{caution}{Caution:}
303 CONTENT IS NOT YET DEVELOPMENT and will be published when complete.
\end{sphinxadmonition}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 303 - BIG-IP ASM Specialist}

Welcome to the 303 - BIG-IP ASM Specialist compiled Study Guide. The purpose of
this guide is to help you prepare for the F5 303 - BIG-IP ASM Specialist exam.
The contents of this document are based on the F5 303 - BIG-IP ASM Specialist
Exam Blueprint for TMOS v12.1.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the reference the linked information easier
without having to search through a formal appendix.

The F5 Certified BIG-IP Administrator (F5-CA), which is made up of the 101 -
App Delivery Fundamentals and 201 - TMOS Administration exams, stand as a
pre-requisite to this exam.

Taking certified F5 BIG-IP ASM training, such as Configuring BIG-IP ASM v12,
will surely help with the topics of this exam but does not teach directly to
the exam content. Hands on administrative experience with the BIG-IP platform
licensed with BIG-IP ASM will reinforce many of the topics contained in the
303 - BIG-IP ASM Specialist exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}

\sphinxstylestrong{Printed References}

These referenced books are and important and should be considered basic readin
material for this exam.


\section{Section 1 - Architecture/Design and Policy Creation}
\label{\detokenize{class11/modules/module1:section-1-architecture-design-and-policy-creation}}\label{\detokenize{class11/modules/module1::doc}}

\section{Section 2 - Policy Maintenance and Optimization}
\label{\detokenize{class11/modules/module2:section-2-policy-maintenance-and-optimization}}\label{\detokenize{class11/modules/module2::doc}}

\section{Section 3 - Review Event Logs and Mitigate Attacks}
\label{\detokenize{class11/modules/module3:section-3-review-event-logs-and-mitigate-attacks}}\label{\detokenize{class11/modules/module3::doc}}

\section{Section 4 - Troubleshoot}
\label{\detokenize{class11/modules/module4:section-4-troubleshoot}}\label{\detokenize{class11/modules/module4::doc}}

\subsection{Conclusion}
\label{\detokenize{class11/modules/module4:conclusion}}

\chapter{F5 304 - BIG-IP APM Specialist Study Guide 11/01/19}
\label{\detokenize{class13/class13:f5-304-big-ip-apm-specialist-study-guide-11-01-19}}\label{\detokenize{class13/class13::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\begin{sphinxadmonition}{caution}{Caution:}
304 CONTENT IS NOT YET DEVELOPMENT and will be published when complete.
\end{sphinxadmonition}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 304 - BIG-IP APM Specialist}

Welcome to the 304 - BIG-IP APM Specialist compiled Study Guide. The purpose of
this guide is to help you prepare for the F5 304 - BIG-IP APM Specialist exam.
The contents of this document are based on the F5 304 - BIG-IP APM Specialist
Exam Blueprint for TMOS v12.1.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the reference the linked information easier
without having to search through a formal appendix.

The F5 Certified BIG-IP Administrator (F5-CA), which is made up of the 101 -
App Delivery Fundamentals and 201 - TMOS Administration exams, stand as a
pre-requisite to this exam.

Taking certified F5 BIG-IP APM training, such as Configuring BIG-IP APM v12,
will surely help with the topics of this exam but does not teach directly to
the exam content. Hands on administrative experience with the BIG-IP platform
licensed with BIG-IP APM will reinforce many of the topics contained in the 304
- BIG-IP APM Specialist exam.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}

\sphinxstylestrong{Printed References}

These referenced books are and important and should be considered basic reading
material for this exam.


\section{Section 1 - Authentication, Authorization, an Accounting (AAA), Single Sign-On (SSO), Federated Authorization, Mobile Device Management (MDM)}
\label{\detokenize{class13/modules/module1:section-1-authentication-authorization-an-accounting-aaa-single-sign-on-sso-federated-authorization-mobile-device-management-mdm}}\label{\detokenize{class13/modules/module1::doc}}

\section{Section 2 - Network and Application Access}
\label{\detokenize{class13/modules/module2:section-2-network-and-application-access}}\label{\detokenize{class13/modules/module2::doc}}

\section{Section 3 - Visual Policy Editor}
\label{\detokenize{class13/modules/module3:section-3-visual-policy-editor}}\label{\detokenize{class13/modules/module3::doc}}

\section{Section 4 - Deploy and Maintain iApps}
\label{\detokenize{class13/modules/module4:section-4-deploy-and-maintain-iapps}}\label{\detokenize{class13/modules/module4::doc}}

\section{Section 5 - Administrating and Troubleshooting BIG-IP APM}
\label{\detokenize{class13/modules/module5:section-5-administrating-and-troubleshooting-big-ip-apm}}\label{\detokenize{class13/modules/module5::doc}}

\section{Section 6 - Security}
\label{\detokenize{class13/modules/module6:section-6-security}}\label{\detokenize{class13/modules/module6::doc}}

\subsection{Conclusion}
\label{\detokenize{class13/modules/module6:conclusion}}

\chapter{F5 401 - Security Solution Expert Study Guide 11/01/19}
\label{\detokenize{class15/class15:f5-401-security-solution-expert-study-guide-11-01-19}}\label{\detokenize{class15/class15::doc}}
\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 401 - Security Solution Expert}

Welcome to the 401 - Security Solution Expert compiled Study Guide. The purpose
of this guide is to help you prepare for the F5 401 - Security Solution Expert
exam. The contents of this document are based on the F5 401 - Security Solution
Expert Blueprint Guide.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the reference the linked information easier
without having to search through a formal appendix.

The F5 Certified BIG-IP Administrator (F5-CA), F5 Certified Technology
Specialist LTM (F5-CTS, LTM), F5 Certified Technology Specialist ASM
(F5-CTS, ASM) and the F5 Certified Technology Specialist APM (F5-CTS, APM)
stand as a pre-requisite to this exam.

Field experience with everything F5 is essential to passing this exam, as well
as a strong working knowledge of IT security principles.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}


\section{Original 401 Study Guide Created by Darshan Kirtikumar Doshi}
\label{\detokenize{class15/modules/module1:original-401-study-guide-created-by-darshan-kirtikumar-doshi}}\label{\detokenize{class15/modules/module1::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

This document has not been updated since it’s orignial posting as a PDF by Darshan.

I have not updated this material, but am simply republishing it in this repo.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Disclaimer

The information provided in this document is designed to provide helpful
information on F5 401 Security Solution Expert exam. This is an independent
Study Guide, and should NOT be used as replacement to hands on experience with
F5 Security products or official F5 trainings. Also this document is not
intended to guarantee a passing grade on the exam.

Notice that this is NOT an official F5 document and as such \sphinxstyleemphasis{not} supported by F5.

Introduction
This Independent Study Guide is prepared using public F5 resources and other
internet resources. The exam is heavily focused on “AFM, ASM, LTM, APM and
F5 DNS (formerly known as GTM)” modules. Most of the sections in the document
contains hyperlink at the end of the topic. It is highly recommended to refer
all the hyperlinks for detailed information about any topic.

Note: The guide will be continually improved and suggestions on the content
are very welcome. If you have comments or would like to have relevant notes,
and materials added to this document, please send an email to \sphinxhref{mailto:darshandkd@gmail.com}{darshandkd@gmail.com}

Good luck!

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{GENERAL / SYSTEM}
\label{\detokenize{class15/modules/module1:general-system}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{BIG IP Packet Processing Order}

The following snippet is quite useful to understand the packet processing flow at each layer of BIG-IP.

\noindent\sphinxincludegraphics{{1p110}.png}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Updated on - December 2015:
Source - \sphinxurl{https://devcentral.f5.com/Portals/0/Users/053/01/85301/TMOS\_Order\_of\_Operations\_v2.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{BIG-IP Traffic Processing Order}

A couple of pretty interesting and useful videos on YouTube for
Packet Processing Order \textendash{} for version 11.X - \sphinxurl{https://www.youtube.com/watch?v=bYfcNIndSPQ\&t=47s}
for version 12.X \sphinxurl{https://www.youtube.com/watch?v=qCLEw5xIZ7s}

It is strongly recommended to go through version 12.X YouTube video as it talks about all the modules listed below.
\begin{itemize}
\item {} 
Packet Filter

\item {} 
AFM

\item {} 
FLOW\_INIT (An iRule Event i.e. when FLOW\_INIT)

\item {} 
LTM

\item {} 
APM

\item {} 
ASM

\end{itemize}

Note: Packet processing at different modules take place if the module is provisioned and configured.

FLOW\_INIT

This event is triggered (once for TCP and unique UDP/IP flows) after packet filters, but before AFM, and TMM work occurs. The use cases for this event are:
\begin{itemize}
\item {} 
Override ACL action

\item {} 
Bandwidth control on both client/server flows

\item {} 
Routing to another Vip

\item {} 
Marking qos tos/dscp on both client/server flows

\end{itemize}

Source - \sphinxurl{https://devcentral.f5.com/wiki/iRules.FLOW\_INIT.ashx}

The packet is first evaluated by the Packet Filter The next is FLOW\_INIT, then by AFM, then by LTM , then by APM.  And at last ASM processes the traffic, then hands the traffic back to LTM to finish up with. ASM sits off to
the side and either tells LTM to proceed or hands out a block page.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Local Logging Directories}

Source - \sphinxurl{https://support.f5.com/kb/en-us/solutions/public/16000/100/sol16197.html}

BIG-IP log types

Each type of event is stored locally in a separate log file, and the information stored in each log file varies depending on the event type. All log files for these event types are in the /var/log directory.

Type Description Log file

\sphinxstylestrong{audit:} The audit event messages are messages that the BIG- /var/log/audit IP system logs as a result of changes to the BIG-IP system configuration. Logging audit events is optional.

\sphinxstylestrong{boot:} The boot messages contain information that is logged /var/log/boot.log when the system boots.

\sphinxstylestrong{cron:} When the cron daemon starts a cron job, the daemon /var/log/cron logs the information about the cron job in this file.

\sphinxstylestrong{daemon:} The daemon messages are logged by various daemons /var/log/daemon.log that run on the system.

\sphinxstylestrong{dmesg:} The dmesg messages contain kernel ring buffer /var/log/dmesg information that pertains to the hardware devices that the kernel detects during the boot process.

\sphinxstylestrong{GSLB:} The GSLB messages pertain to global traffic /var/log/gtm management events.

\sphinxstylestrong{httpd:} The httpd messages contain the Apache Web server /var/log/httpd/httpd\_errors error log.

\sphinxstylestrong{kernel:} The kernel messages are logged by the Linux kernel. /var/log/kern.log

\sphinxstylestrong{local traffic:} The local traffic messages pertain specifically to the /var/log/ltm BIG-IP local traffic management events.

\sphinxstylestrong{mail:} The mail messages contain the log information from the /var/log/maillog mail server that is running on the system.

\sphinxstylestrong{packet filter:} The packet filter messages are those that result from /var/log/pktfilter the use of packet filters and packet-filter rules.

\sphinxstylestrong{security:} The secure log messages contain information related to /var/log/secure authentication and authorization privileges.

\sphinxstylestrong{system:} The system event messages are based on global Linux /var/log/messages events, and are not specific to BIG-IP local traffic management events.

\sphinxstylestrong{TMM:} The TMM log messages are those that pertain to Traffic /var/log/tmm Management Microkernel events.

\sphinxstylestrong{user:} The user log messages contain information about all /var/log/user.log user level logs.

\sphinxstylestrong{webui:} The webui log messages display errors and exception /var/log/webui.log details that pertain to the Configuration utility.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{NTP peer server communication}
\label{\detokenize{class15/modules/module1:ntp-peer-server-communication}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Source - \sphinxurl{https://support.f5.com/csp/article/K10240}

When the BIG-IP system clock is not showing the correct timezone, or the date and time is not synchronized correctly, this could be caused by incorrect NTP configuration or a communication issue with a valid NTP peer server.

When verifying the NTP peer server communication, you can use the ntpq utility. The command generates output with the fields that are explained in the following table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Field}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Definition}
\\
\hline
prefix to the remote field
&\begin{itemize}
\item {} 
An asterisk (*) character indicates that the peer has been declared the system peer and lends its variables to the system variables.

\item {} 
A plus sign (+) indicates that the peer is a survivor and a candidate for the combining algorithm.

\item {} 
A space, x, period (.), dash (-), or hash (\#) character indicates that this peer is not being used for synchronization because it either does not meet the requirements, is unreachable, or is not needed.

\end{itemize}
\\
\hline
remote
&
The remote field is the address of the remote peer.
\\
\hline
refid
&
The refid field is the Reference ID which identifies the server or reference clock with which the remote peer synchronizes, and its interpretation depends on the value of the stratum field (explained in the st definition). For stratum 0 (unspecified or invalid), the refid is an ascii value used for debugging. Example: INIT or STEP. For stratum 1 (reference clock), the refid is an ascii value used to specify the type of external clock source. Example: NIST refers to NIST telephone modem. For strata 2 through 15, the refid is the address of the next lower stratum server used for synchronization.
\\
\hline
\sphinxstylestrong{st}
&
The \sphinxstylestrong{st} field is the stratum of the remote peer. Primary servers (servers with an external reference clock such as GPS) are assigned stratum 1. A secondary NTP server which synchronizes with a stratum 1 server is assigned stratum 2. A secondary NTP server which synchronizes with a stratum 2 server is assigned stratum 3. Stratum 16 is referred to as “MAXSTRAT,” is customarily mapped to stratum value 0, and therefore indicates being unsynchronized. Strata 17 through 255 are reserved.
\\
\hline
\sphinxstylestrong{t}
&
The \sphinxstylestrong{t} field is the type of peer: local, unicast, multicast, or broadcast.
\\
\hline
\sphinxstylestrong{when}
&
The \sphinxstylestrong{when} field is the time since the last response to a poll was received (in seconds).
\\
\hline
\sphinxstylestrong{poll}
&
The \sphinxstylestrong{poll} field is the polling interval (in seconds). This value starts low (example: 64) and over time, as no changes are detected, this polling value increases incrementally to the configured max polling value (example: 1024).
\\
\hline
\sphinxstylestrong{reach}
&
The \sphinxstylestrong{reach} field is the reachability register. The octal shift register records results of the last eight poll attempts.
\\
\hline&\\
\hline
\sphinxstylestrong{delay}
&
The delay field is the current estimated delay; the transit time between these peers in milliseconds.
\\
\hline
\sphinxstylestrong{offset}
&
The offset field is the current estimated offset; the time difference between these peers in milliseconds.
\\
\hline
\sphinxstylestrong{jitter}
&
The jitter field is the current estimated dispersion; the variation in delay between these peers in milliseconds.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Example of a successful NTP peer server query}
\label{\detokenize{class15/modules/module1:example-of-a-successful-ntp-peer-server-query}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If the local \sphinxstylestrong{ntpd} process can communicate, or attempts to
communicate with a declared NTP peer server, the output from the
\sphinxstylestrong{ntpq} command appears like the following example:

\# ntpq -np
remote refid st t when poll reach delay offset jitter
172.28.4.133 10.10.10.251 4 u 482 1024 377 0.815 -10.010 0.345

In the previous example, the remote server information refid, stratum,
delay, offset, jitter displays, indicating that the servers are successfully
exchanging information. The value of \sphinxstylestrong{377} in the \sphinxstylestrong{reach} column
indicates that the server was successfully reached during each of the last
eight attempts, and the value of \sphinxstylestrong{482} in the \sphinxstylestrong{when} column indicates
that the last response was received from the remote peer 482 seconds ago,
which is within the polling interval of 1024 seconds.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Example of a failed NTP peer server query

If the local \sphinxstylestrong{ntpd} process fails to communicate with an NTP peer
server, the output from the \sphinxstylestrong{ntpq} command may appear similar to the
following example:

\# ntpq -np remote refid st t when poll reach delay offset jitter
172.28.4.133 .INIT. 16 u - 64 0 0.000 0.000 0000.00

\sphinxstyleemphasis{Note: An **st*} (stratum) of \sphinxstylestrong{16} means that the destination NTP
server is unreachable or is not considered a viable candidate.*

In this example, the remote server information (\sphinxstylestrong{refid}, \sphinxstylestrong{stratum},
\sphinxstylestrong{delay}, \sphinxstylestrong{offset}, \sphinxstylestrong{jitter}) is not available. The value
\sphinxstylestrong{.INIT.} in the \sphinxstylestrong{refid} column indicates that NTP is initializing,
and the server has not yet been reached. The value of \sphinxstylestrong{0} (zero) in
the \sphinxstylestrong{reach} column indicates that the server has not been reached
during any of the last eight attempts. The absence of a value in the
\sphinxstylestrong{when} column indicates that no data has been received from the remote
peer since the local \sphinxstylestrong{ntpd} process was started. The \sphinxstylestrong{poll} value of
\sphinxstylestrong{64} is still at the MINPOLL value, which indicates that NTP was
recently restarted.

NTP has a MINPOLL and MAXPOLL value, which it uses to determine the
optimal time between updates with the reference server. If \sphinxstylestrong{jitter} is
low, and there are no changes in data received, NTP automatically
incrementally increases the \sphinxstylestrong{poll} value until it reaches MAXPOLL, or
1024 seconds.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Example of a successful NTP preferred peer server query

If the local \sphinxstylestrong{ntpd} process communicates or attempts to communicate
with a declared \sphinxstylestrong{preferred} NTP peer server, the output from the
\sphinxstylestrong{ntpq} command appears similar to the following example:

\# ntpq -np

remote refid st t when poll reach delay offset jitter
172.28.4.133 10.10.10.251 4 u 482 1024 377 0.815 -10.010 0.345
172.28.4.134 10.10.10.252 6 u 482 1024 179 0.215 -1.010 0.545

In the previous example, \sphinxstylestrong{172.28.4.133} is the preferred server, or
current time source, and is designated by the backslash symbol. Any
remaining servers available for use are indicated by the ‘+’ symbol.
When initially configured, NTPd can take up to a few minutes to
calculate and designate the current preferred time source.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

MEMCACHE

Source -
\sphinxurl{https://devcentral.f5.com/articles/the-power-of-the-proxy-request-routing-memcached}

By definition, \sphinxstylestrong{Memcached} is a general-purpose distributed memory
caching system. It is often used to speed up dynamic database-driven
websites by caching data and objects in RAM to reduce the number of
times an external data source (such as a database or API) must be read.

As an example, Memcache is like load balancing Bluecoat (forward proxy)
systems behind F5 systems using the CARP algorithm. Where one or
Bluecoat Systems as a pool member will be load balanced and Bluecoat
will not only send the web traffic outside, but also caches the
responses to serve better experience to the users. Btw, Bluecoat as a
vendor uses Memcache and other variant of the same for serving web
content faster.

Similarly, F5 Administrator can have any other caching server or server
farm as pool.

A good example of real time MEMCACHED users are facebook, google,
salesforce and most of the social media websites.

However Memcache also has its own limitation. Any shared instance of
memcache is insecure today. memcache doesn’t have a way to Authenticate
which means that:

user1 can read anything user2 ’caches’ it also means that user1 can
write anything that user2 reads (cache poisoning)

Even with latest version SASL authentication — you are authenticating
to the whole cache, and can still read poison someone else’s data.

Source - \sphinxurl{https://www.cloudlinux.com/forum/forum18/topic273} (Read thread
\#5)

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Internet Content Adaptation Protocol

\begin{DUlineblock}{0em}
\item[] The Learn F5 website has quite useful ICAP video training available.
\item[] ICAP is HTTP like protocol and follow (almost) the same response
status code. \sphinxstylestrong{ICAP Methods} (RFC 3507)
\end{DUlineblock}

\sphinxstylestrong{ICAP Response Status Code} (from RFC 3507)


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Sr. No}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
1
&
OPTIONS
&\\
\hline
2
&
REQMOD
&
Can be used to ask ICAP Server to modify Requests
\\
\hline
3
&
RESPMOD
&
Can be used to ask ICAP Server to modify Response
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Sr. No}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Status Code}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
1
&
100
&
Continue after ICAP Preview, Client is still sending the request to the ICAP Server, and client should send any requests that is queued.
\\
\hline
2
&
204
&
No modifications needed
\\
\hline
3
&
400
&
Bad request
\\
\hline
4
&
404
&
ICAP Server not found
\\
\hline
5
&
405
&
Method not allowed for service (e.g., RESPMOD requested for service that supports only REQMOD).
\\
\hline
6
&
408
&
Request timeout. ICAP server gave up waiting for a request from an ICAP client.
\\
\hline
7
&
500
&
Server error. Error on the ICAP server, such as “out of disk space”.
\\
\hline
8
&
501
&
Method not implemented. This response is illegal for an OPTIONS request since implementation of OPTIONS is mandatory.
\\
\hline
9
&
502
&
Bad Gateway. This is an ICAP proxy and proxying produced an error.
\\
\hline
10
&
503
&
Service overloaded. The ICAP server has exceeded a maximum connection limit associated with this service; the ICAP client should not exceed this limit in the future.
\\
\hline
11
&
505
&
ICAP version not supported by server.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

ICAP has similar structure as HTTP. URL Structure example:

\begin{DUlineblock}{0em}
\item[] • icap://10.11.12.13:1344/reqmod
\item[] • icap://10.11.12.13/reqmod?mode=sanitize
\end{DUlineblock}

ICAP URI example

\noindent\sphinxincludegraphics{{1p210}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p35}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p41}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

ICAP Header contains the type of REQUEST followed by other ICAP headers,
and Client/Server requested URL as a body (i.e. \sphinxstyleemphasis{ICAP Payload Origin
Client request}) as appears in above example. In the same way, when ICAP
Response back to the Proxy Server, it indicates the response to Proxy
server in ICAP Header, and Response for Original Client/Server requested
URL as a body (.i.e. \sphinxstyleemphasis{403 Forbidden content response}).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Creating a custom client-side ICAP profile

You create this ICAP profile when you want to use an ICAP server to wrap
an HTTP request in an ICAP message before the BIG-IP system sends the
request to a pool of web servers. The profile specifies the HTTP
request-header values that the ICAP server uses for the ICAP message.

After you create the ICAP profile, you can assign it to an internal
virtual server so that the HTTP request that the BIG-IP system sends to
an ICAP server is wrapped in an ICAP message, as per the settings you
specified in the ICAP profile.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Creating a custom Request Adapt profile

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_ltm/manuals/product/ltm}-
implementations-11-3-0/12.html

You create a Request Adapt type of profile when you want a standard HTTP
virtual server to forward HTTP requests to an internal virtual server
that references a pool of ICAP servers. A Request Adapt type of profile
instructs the HTTP virtual server to send an HTTP request to a named
internal virtual server for possible request modification.

After you perform this task, the BIG-IP system contains a Request Adapt
profile that a standard HTTP virtual server can use to forward an HTTP
request to an internal virtual server for ICAP traffic.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Third party Web Application Testing / Security / Auditing Tools}
\label{\detokenize{class15/modules/module1:third-party-web-application-testing-security-auditing-tools}}
This section talks about generic security, web application testing and
auditing tools. None of the tools are F5 proprietary, but it helps great
to test/audit your web applications and then you can use suitable F5
modules to protect against. The section is not very detailed, If you
want to browse more information you can refer “source” hyperlink or
Google is your friend!

It isn’t required to have hands on practice for each of them. However to
have brief knowledge about each of them is mandatory.

\sphinxstylestrong{1. DIG}

Source -
\sphinxurl{http://www.cyberciti.biz/faq/linux-unix-dig-command-examples-usage-syntax/}

Use dig command for DNS lookup and to query DNS name servers for various
resource record.

\sphinxstyleemphasis{Syntax}

dig Hostname
dig DomaiNameHere
dig @DNS-server-name Hostname
dig @DNS-server-name IPAddress
dig @DNS-server-name Hostname\textbar{}IPAddress

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{2. DIG for DNSSEC} \textendash{}
Source -
\sphinxurl{http://backreference.org/2010/11/17/dnssec-verification-with-dig/}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{3. NMAP}

Source -
\sphinxurl{https://www.cyberciti.biz/networking/nmap-command-examples-tutorials/}

nmap is short for Network Mapper. It is an open source security tool for
network exploration, security scanning and auditing. However, nmap
command comes with lots of options that can make the utility more robust
and difficult to follow for new users.

The purpose of this post is to introduce a user to the nmap command line
tool to scan a host and/or network, so to find out the possible
vulnerable points in the hosts. You will also learn how to use Nmap for
offensive and defensive purposes.

Some NMAP examples are as following.

1: Scan a single host or an IP address (IPv4) nmap 192.168.1.1

2: Scan multiple IP address or subnet (IPv4) nmap 192.168.1.1
192.168.1.2 192.168.1.3
\#\# works with same subnet i.e. 192.168.1.0/24

3: Excluding hosts/networks (IPv4)
nmap 192.168.1.0/24 \textendash{}exclude 192.168.1.5

4: Detect remote operating system running on Host(s) nmap -O
192.168.1.1
nmap -v -O \textendash{}osscan-guess 192.168.1.1

5: Scan a network and find out which servers and devices are up and
running nmap -sP 192.168.1.0/24

6: Scan a host when protected by the firewall nmap -PN 192.168.1.1
nmap -PN server1.cyberciti.biz

Look for more NMAP options by clicking on the “Source”

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{4. HTTPWatch}

Source - \sphinxurl{http://help.httpwatch.com/gettingstarted.html} Tutorial -
\sphinxurl{https://www.youtube.com/watch?v=bfVwj4lCfgU}

HttpWatch integrates with Internet Explorer and Mozilla Firefox to
provide unrivaled levels of HTTP monitoring, without the need for
separately configured proxies or network sniffers. Simply interact with
a web site and HttpWatch will display a log of requests and responses
alongside the web page itself. It even shows interactions between the
browser and its cache. Each HTTP transaction can be examined to see the
values of headers, cookies, query strings and other HTTP related data.

Commercial web sites often use technologies such as HTTP compression,
SSL encryption and chunked encoding to provide the best levels of
security and performance. HttpWatch works with these technologies to
provided a detail view of HTTP activity within Internet Explorer.

HttpWatch has two components; a plug-in used to collect, view and save
HTTP traffic within IE or Firefox, and a standalone log file viewer know
as HttpWatch Studio.

If you would like to go through HTTPWatch tutorian on YouTube, click on
“Source2” above.

\sphinxstylestrong{5. Cain \& Able}

Source - \sphinxurl{https://en.wikipedia.org/wiki/Cain\_and\_Abel\_(software})

Cain \& Abel is a password recovery tool for Microsoft Operating Systems.
It allows easy recovery of several kind of passwords by sniffing the
network. It is more known for Network sniffing i.e. sniffing password
within LAN.

This can also create DoS Attak on the LAN network as it creates many
fake packets for processing thereby making unable for other HOST to make
a request on the network.

\sphinxstylestrong{6. THC Hydra}

\sphinxstylestrong{Source - http://tools.kali.org/password-attacks/hydra}

Hydra is a parallelized login cracker which supports numerous
protocols to attack. It is very fast and flexible, and new modules
are easy to add. This tool makes it possible for researchers and
security consultants to show how easy it would be to gain
unauthorized access remotely. It is known to generate effective
Brute-force attack.

\sphinxstylestrong{7. John The Ripper}

\sphinxstylestrong{Source - https://en.wikipedia.org/wiki/John\_the\_Ripper}

John the Ripper is a free password cracking software tool.
Initially developed for the Unix operating system, it now runs on
fifteen different platforms (eleven of which are architecture-specific
versions of Unix, DOS, Win32, BeOS, and OpenVMS).

How does \sphinxstyleemphasis{John The Ripper} compare to \sphinxstyleemphasis{THC Hydra}?
THC Hydra, or simply ‘Hydra’, is another very popular password hacking
tool that is often referred to in the same context as John The Ripper.
The easiest way to describe the difference between John The Ripper (JTR)
and THC Hydra is that JTR is an offline password cracker whilst Hydra
is an online password cracker.

\sphinxstylestrong{8. OWASP ZAP (Zed Attack Proxy)}

\sphinxstylestrong{Source - https://en.wikipedia.org/wiki/OWASP\_ZAP}

OWASP ZAP (short for Zed Attack Proxy) is an open-source web application
security scanner. It is intended to be used by both those new to
application security as well as professional penetration testers.

It is one of the most active OWASP projects and has been given Flagship
status. It is also fully internationalized and is being translated into
over 25 languages.

When used as a proxy server it allows the user to manipulate all the
traffic that passes through it, including traffic using https.

It can also run in a ‘daemon’ mode which is then controlled via a REST
Application programming interface.

This cross-platform tool is written in Java and is available in all the
popular operating systems including Microsoft Windows, Linux and Mac OS X.

Some of the built in features include: Intercepting proxy server,
Traditional and AJAX Web crawlers, Automated scanner, Passive scanner,
Forced browsing, Fuzzer, WebSocket support, Scripting languages, and
Plug-n-Hack support. It has a plugin-based architecture and an online
‘marketplace’ which allows new or updated features to be added. The GUI
control panel is easy to use.

\sphinxstylestrong{9. Burp Suite}

Source - \sphinxurl{https://en.wikipedia.org/wiki/Burp\_suite}

Burp Suite created by PortSwigger Web Security is a Java based software
platform of tools for performing security testing of web applications.
The suite of products can be used to combine automated and manual
testing techniques and consists of a number of different tools, such as
a proxy server, a web spider, scanner, intruder, repeater, sequencer,
decoder, collaborator and extender.

\sphinxstylestrong{10. Fiddler}

Source - \sphinxurl{https://en.wikipedia.org/wiki/Fiddler\_(software})

Fiddler captures HTTP and HTTPS traffic and logs it for the user to
review (the latter by implementing man- in-the-middle interception using
self-signed certificates).{[}6{]}

Fiddler can also be used to modify (“fiddle with”) HTTP traffic for
troubleshooting purposes as it is being sent or received.{[}5{]} By default,
traffic from Microsoft’s WinINET HTTP(S) stack is automatically directed
to the proxy at runtime, but any browser or Web application (and most
mobile devices) can be configured to route its traffic through Fiddler.

Fiddler is variant of HTTPWatch. However it supports more number of
features, functionalities and its free to use unlike HTTPWatch.

\sphinxstylestrong{11. W3af}

Source - \sphinxurl{http://tools.kali.org/web-applications/w3af}

w3af (web application attack and audit framework) is an open-source web
application security scanner. The project provides a vulnerability
scanner and exploitation tool for Web applications. It provides

information about security vulnerabilities for use in penetration
testing engagements. The scanner offers a graphical user interface and a
command-line interface.

\sphinxstylestrong{12. HTTrack}

Source - \sphinxurl{https://en.wikipedia.org/wiki/HTTrack}

HTTrack is a free and open source Web crawler and offline browser.
HTTrack allows users to download World Wide Web sites from the Internet
to a local computer. By default, HTTrack arranges the downloaded site by
the original site’s relative link-structure. The downloaded (or
“mirrored”) website can be browsed by opening a page of the site in a
browser.

\sphinxstyleemphasis{HTTrack is a good tool to test F5 ASM Web Scrapping feature.}

HTTrack can also update an existing mirrored site and resume interrupted
downloads. HTTrack is configurable by options and by filters
(include/exclude), and has an integrated help system. There is a basic
command line version and two GUI versions (WinHTTrack and WebHTTrack);
the former can be part of scripts and cron jobs.

HTTrack can follow links that are generated with basic JavaScript and
inside Applets or Flash, but not complex links (generated using
functions or expressions) or server-side image maps.

Compliances and Standards

\sphinxstylestrong{PCI-DSS} (Payment\_Card\_Industry\_Data\_Security\_Standard) \textendash{}
Source: Wikipedia

The Payment Card Industry Data Security Standard (PCI DSS) is a
proprietary information security standard for organizations that handle
branded credit cards from the major card schemes including Visa,
MasterCard, American Express, Discover, and JCB. The PCI Standard is
mandated by the card brands and administered by the Payment Card
Industry Security Standards Council. The standard was created to
increase controls around cardholder data to reduce credit card fraud.
Validation of compliance is performed annually, either by an external
Qualified Security Assessor (QSA) or by a firm specific Internal
Security Assessor (ISA) that creates a Report on Compliance (ROC) for
organizations handling large volumes of transactions, or by Self-
Assessment Questionnaire (SAQ) for companies handling smaller volumes.

Requirements

The PCI Data Security Standard specifies twelve requirements for
compliance, organized into six logically related groups called “control
objectives”.

Each version of PCI DSS has divided these twelve requirements into a
number of sub-requirements differently, but the twelve high-level
requirements have not changed since the inception of the standard.

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Control objectives}
&\sphinxstyletheadfamily 
\sphinxstylestrong{PCI DSS requirements}
\\
\hline
Build and maintain a secure network
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Install and maintain a firewall configuration to protect cardholder data

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Do not use vendor-supplied defaults for system passwords and other security parameters

\end{enumerate}
\\
\hline
Protect cardholder data
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Protect stored cardholder data

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Encrypt transmission of cardholder data across open, public networks

\end{enumerate}
\\
\hline
Maintain a vulnerability management program
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Use and regularly update anti-virus software on all systems commonly affected by malware

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
Develop and maintain secure systems and applications

\end{enumerate}
\\
\hline
Implement strong access control measures
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{6}
\item {} 
Restrict access to cardholder data by business need-to-know

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{7}
\item {} 
Assign a unique ID to each person with computer access

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{8}
\item {} 
Restrict physical access to cardholder data

\end{enumerate}
\\
\hline
Regularly monitor and test networks
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{9}
\item {} 
Track and monitor all access to network resources and cardholder data

\end{enumerate}
\\
\hline&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{10}
\item {} 
Regularly test security systems and processes

\end{enumerate}
\\
\hline
Maintain an information security policy
&\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{11}
\item {} 
Maintain a policy that addresses information security

\end{enumerate}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

FIPS (Federal Information Processing Standards) \textendash{} Source: Wikipedia

Federal Information Processing Standards (FIPS) are publicly announced
standards developed by the United States federal government for use in
computer systems by non-military government agencies and government
contractors.

FIPS standards are issued to establish requirements for various purposes
such as ensuring computer security and interoperability, and are
intended for cases in which suitable industry standards do not already
exist.{[}1{]} Many FIPS specifications are modified versions of standards
used in the technical communities, such as the American National
Standards Institute (ANSI), the Institute of Electrical and Electronics
Engineers (IEEE), and the International Organization for Standardization
(ISO).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{DAST \textendash{} Dynamic Application Security Testing}

Dynamic application security testing, is essentially a tool set for
finding and the remediation of vulnerabilities in a web-based
application. Essentially, you open up a DAST tool and feed it a url to a
website or a web service, this includes web-based applications. The tool
will first crawl the site, much like a search engine, and index the
entire site. Then it will use this information to build out a site map
and learn how to move around the site, sometimes in ways the developer
didn’t intend. After figuring out ways to traverse the site, the tool
will spend the bulk of its time performing attacks against the site.
This includes all of the major attack types: sql injection, cross site
request forgery, cross site scripting, etc., and practically any other
vulnerability you can think of.

Source -
\sphinxurl{https://joshcodev.wordpress.com/2013/06/12/dast-dynamic-application-security-testing/}

BIG-IP ASM blocks web application attacks to help protect against a
broad spectrum of threats, including the most sophisticated
application-level DDoS and SQL injection attacks. It also helps secure
interactive web apps that use the latest development methodologies, such
as AJAX widgets, JSON payloads, and the Google Web Toolkit.

Advanced DAST integrations can scan web apps and coordinate with BIG-IP
ASM to patch vulnerabilities in minutes. By integrating contextual
information about incoming IP addresses and IP Intelligence service
databases, BIG-IP ASM secures applications against constantly changing
threats.

Source -
\sphinxurl{https://www.f5.com/pdf/products/big-ip-application-security-manager-overview.pdf}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{Industry Standard Security terminologies}
\label{\detokenize{class15/modules/module1:industry-standard-security-terminologies}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{CIA (Confidentiality, Integrity and Availability)} - Also known as
the CIA triad, is a model designed to guide policies for information
security within an organization. The model is also sometimes referred to
as the AIC triad (availability, integrity and confidentiality) to avoid
confusion with the Central Intelligence Agency. The elements of the
triad are considered the three most crucial components of security.

In this context, confidentiality is a set of rules that limits access to
information, integrity is the assurance that the information is
trustworthy and accurate, and availability is a guarantee of reliable
access to the information by authorized people.

Source -
\sphinxurl{http://whatis.techtarget.com/definition/Confidentiality-integrity-and-availability-CIA}

\sphinxstylestrong{Asset} \textendash{} People, property, and information. People may include
employees and customers along with other invited persons such as
contractors or guests. Property assets consist of both tangible and
intangible items that can be assigned a value. Intangible assets include
reputation and proprietary information. Information may include
databases, software code, critical company records, and many other
intangible items.

An asset is what we’re trying to protect.

\sphinxstylestrong{Threat}

Anything that can exploit a vulnerability, intentionally or
accidentally, and obtain, damage, or destroy an asset.

A threat is what we’re trying to protect against.

\sphinxstylestrong{Vulnerability}

Weaknesses or gaps in a security program that can be exploited by
threats to gain unauthorized access to an asset.

A vulnerability is a weakness or gap in our protection efforts.

\sphinxstylestrong{Risk}

The potential for loss, damage or destruction of an asset as a result
of a threat exploiting a vulnerability. Risk is the intersection of
assets, threats, and vulnerabilities.

Source -
\sphinxurl{https://www.threatanalysis.com/2010/05/03/threat-vulnerability-risk-commonly-mixed-up-terms/}

\sphinxstylestrong{OWASP}

The Open Web Application Security Project (OWASP) is an online community
which creates freely-available articles, methodologies, documentation,
tools, and technologies in the field of web application security.

Source \textendash{} Wikipedia

\sphinxstylestrong{OWASP Top 10}

The OWASP Top 10 represents a broad consensus on the most critical web
application security flaws. The errors on this list occur frequently in
web applications, are often easy to find, and easy to exploit.

\sphinxstylestrong{Current OWASP Top 10 are as following.}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Injection

\item {} 
Broken Authentication and Session Management (XSS)

\item {} 
Cross Site Scripting (XSS)

\item {} 
Insecure Direct Object References

\item {} 
Security Misconfiguration

\item {} 
Sensitive Data Exposure

\item {} 
Missing Function Level Access Control

\item {} 
Cross Site Request Forgery (CSRF)

\item {} 
Using Components with Known Vulnerabilities

\item {} 
Unvalidated Redirects and Forwards

\end{enumerate}

Source - \sphinxurl{https://www.veracode.com/directory/owasp-top-10}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{LOCAL TRAFFIC MANAGER (LTM)}
\label{\detokenize{class15/modules/module1:local-traffic-manager-ltm}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Secure Socket Layer (SSL)}

Client-side traffic refers to connections between a client system and
the BIG-IP system. Server-side traffic refers to connections between the
BIG-IP system and a target server system:

\sphinxstylestrong{Managing client-side SSL traffic}

When you enable the BIG-IP system to manage client-side SSL traffic, the
BIG-IP system terminates incoming SSL connections by decrypting the
client request. The BIG-IP system then sends the request, in clear text,
to a target server. Next, the BIG-IP system retrieves a clear-text
response (such as a web page) and encrypts the request, before sending
the web page back to the client. During the process of terminating an
SSL connection, the BIG-IP system can, as an option, perform all the SSL
certificate verification functions normally handled by the target web
server.

\sphinxstylestrong{Managing server-side SSL traffic}

When you enable the BIG-IP system to manage server-side SSL traffic, the
BIG-IP system enhances the security of your network by re-encrypting a
decrypted request before sending it on to a target server. In addition
to this re-encryption, the BIG-IP system can, as an option, perform the
same verification functions for server certificates that the BIG-IP
system can for client certificates.

\sphinxstylestrong{SSL Bridging}

Source - \sphinxurl{https://f5.com/glossary/ssl-bridging}

SSL bridging is a process where a device, usually located at the edge of
a network, decrypts SSL traffic and then re-encrypts it before sending
it on to the Web server. SSL bridging can be useful when the edge device
performs deep-packet inspection to verify that the contents of the
SSL-encrypted transmission are safe, or if there are security concerns
about unencrypted traffic traversing the internal network.

\sphinxstylestrong{SSL Offloading / Termination}

Source - \sphinxurl{https://f5.com/glossary/ssl-offloading}

SSL offloading relieves a Web server of the processing burden of
encrypting and/or decrypting traffic sent via SSL, the security protocol
that is implemented in every Web browser. The processing is offloaded to
a separate device designed specifically to perform SSL acceleration or
SSL termination.

SSL termination capability is particularly useful when used in
conjunction with clusters of SSL VPNs, because it greatly increases the
number of connections a cluster can handle.

BIG-IP® Local Traffic Manager with the SSL Acceleration Feature Module
performs SSL offloading.

\sphinxstylestrong{SSL Bypass / Pass through}

For compliance, any other security reason or any custom requirement, you
may need to use SSL Bypass feature on F5 LTM. In this case, you don’t
terminate the connection on F5 hence have minimal control to manipulate
the stream of the traffic, however you can still retain Load Balancing
and other L3-L4 features in place. In such scenario, content hosting or
any other device in between is processing the SSL traffic, and F5 is
just load balancing / packet switching / forwarding \& receiving the
traffic, without any visibility on stream or application traffic.

\sphinxstylestrong{SSL Bridging vs SSL Offloading}

Source -
\sphinxurl{https://devcentral.f5.com/questions/ssl-bridging-vs-ssl-offloading}

Client SSL profile and NO Server SSL profile on the VS = SSL Offloading
Client SSL profile and Server SSL profile on the VS = SSL Bridging

\sphinxstylestrong{Configuring the cipher strength for SSL profiles}

Source - \sphinxurl{https://support.f5.com/csp/article/K13171}
BIG-IP Secure Sockets Layer (SSL) profiles can use ciphers from two
different SSL stacks;

The NATIVE stack is built into the Traffic Management Microkernel (TMM),
and the COMPAT stack is based on the OpenSSL library.

The NATIVE stack is an optimized SSL stack that the BIG-IP system can
use to leverage hardware acceleration for most SSL ciphers. F5
recommends that you use the NATIVE stack because it is suitable for most
SSL connections.

\sphinxstylestrong{Default cipher list for SSL profiles}

When you configure an SSL profile on the BIG-IP system, you can manually
specify the ciphers available for SSL connections, or you can use the
default cipher string, DEFAULT. The default cipher string only uses SSL
ciphers from the NATIVE SSL stack.

\sphinxstylestrong{Note:} When you use the \sphinxstylestrong{!} symbol preceding a cipher, the SSL
profile permanently removes the cipher from the cipher list, even if it
is explicitly stated later in the cipher string. When you use the \sphinxstylestrong{\textendash{}}
symbol preceding a cipher, the SSL profile removes the cipher from the
cipher list, but it can be added back to the cipher list if there are
later options that allow it.

\sphinxstylestrong{Example}:
To remove SSLv2 from the DEFAULT SSL profile, you can use the
following cipher string in the SSL Profile.

DEFAULT:!SSLv2

F5 recommends that you use the DEFAULT cipher string for Client and
Server SSL profiles. However, you can configure an SSL profile to use a
custom cipher suite. By applying different profiles to different virtual
servers, you can make Client SSL virtual servers more or less permissive
than others.

For example, you can use this approach to allow only strong ciphers,
thereby enforcing the PCI requirement for strong cryptography and
eliminating Weak Supported SSL Ciphers Suite violations.

\sphinxstylestrong{SSL Troubleshooting with SSLDUMP}

Source - \sphinxurl{https://support.f5.com/csp/article/K10209}

The \sphinxstylestrong{ssldump} utility is an SSL/TLS network protocol analyzer, which
identifies TCP connections from a chosen packet trace or network
interface and attempts to interpret them as SSL/TLS traffic. When
the \sphinxstylestrong{ssldump} utility identifies SSL/TLS traffic, it decodes the
records and displays them in text to standard output. If provided with
the private key that was used to encrypt the connections, the
\sphinxstylestrong{ssldump} utility may also be able to decrypt the connections and
display the application data traffic.

You can use the \sphinxstylestrong{ssldump} utility to examine, decrypt, and decode
SSL-encrypted packet streams managed by the BIG-IP system. The
\sphinxstylestrong{ssldump} utility can act on packet streams real-time as they
traverse the system, or on a packet capture file saved in the
\sphinxstylestrong{libpcap} format, such as that produced by the \sphinxstylestrong{tcpdump} utility.
Although it is possible for the \sphinxstylestrong{ssldump} utility to decode and
display live traffic real-time as it traverses the BIG-IP system, it
is rarely the most effective method to examine the voluminous and
complex output of the \sphinxstylestrong{ssldump} utility. Capturing the target traffic
to a file using the \sphinxstylestrong{tcpdump} utility, then decoding the file using
the \sphinxstylestrong{ssldump} utility offers a better opportunity to examine the
traffic in detail.

\sphinxstylestrong{Overview of ssldump}

Source -
\sphinxurl{https://devcentral.f5.com/articles/troubleshooting-tls-problems-with-ssldump}

ssldump -A -d -k \textless{}key file\textgreater{} -n -i \textless{}capture VLAN\textgreater{} \textless{}traffic expression\textgreater{}

-A Print all fields

-d Show application data when private key is provided via -k

-k Private key file, found in /config/ssl/ssl.key/; the key file can be
located under client SSL profile

\begin{DUlineblock}{0em}
\item[] -n Do not try to resolve PTR records for IP addresses
\item[] -i The capture VLAN name is the ingres VLAN for the TLS traffic
\end{DUlineblock}

Scenario 1: Virtual server missing a client SSL profile

The client SSL profile defines what certificate and private key to use,
a key passphrase if needed, allowed ciphers, and a number of other
options related to TLS communications. Without a client SSL profile, a
virtual server has no knowledge of any of the parameters necessary to
create a TLS session. After you’ve configured a few hundred HTTPS
virtual servers this configuration step becomes automatic, but most of
us mortals have missed step at one point or another and left ourselves
scratching our heads.

We’ll set up a test virtual that has all the necessary configuration
options for an HTTPS profile, except for the omission of the client SSL
profile. The client will open a connection to the virtual on port 443, a
TCP connection will be established, and the client will send a
‘ClientHello’. Normally the server would then respond with ServerHello,
but in this case there is no response and after some period of time (5
minutes is the default timeout for the browser) the connection is
closed. This is what the ssldump would look like for a missing client
SSL profile:

New TCP connection \#1: 10.0.0.10(46226) \textless{}-\textgreater{} 10.0.0.20(443) 1 1 0.0011
(0.0011) C\textgreater{}SV3.1(84) Handshake

ClientHello Version 3.1 random{[}32{]}=

4c b6 3b 84 24 d7 93 7f 4b 09 fa f1 40 4f 04 6e
\begin{quote}

af f7 92 e1 3b a7 3a c2 70 1d 34 dc 9d e5 1b c8 cipher suites
TLS\_DHE\_RSA\_WITH\_AES\_256\_CBC\_SHA
{[}a number of other cipher suites{]}
TLS\_RSA\_EXPORT\_WITH\_RC2\_CBC\_40\_MD5
TLS\_RSA\_EXPORT\_WITH\_RC4\_40\_MD5
\end{quote}

Unknown value 0xff compression methods

unknown value NULL

1 299.9883 (299.9871) C\textgreater{}S TCP FIN

1 299.9883 (0.0000) S\textgreater{}C TCP FIN

Scenario 2: Client and server do not share a common cipher suite

This is a common scenario when really old browsers try to connect to
servers with modern cipher suites. We have purposely configured our SSL
profile to only accept one cipher suite (TLS\_RSA\_WITH\_AES\_256\_CBC\_
SHA in this case). When we try connect to the virtual using a 128-bit
key, the connection is immediately closed with no ServerHello from the
virtual server. The differentiator here, while small, is the quick
closure of the connection and the ‘TCP FIN’ that arises from the server.
This is unlike the behavior of the missing SSL profile, because the
server initiates the connection teardown and there is no connection
timeout. The differences, while subtle, hint at the details of the
problem:

New TCP connection \#1: 10.0.0.10(49342) \textless{}-\textgreater{} 10.0.0.20(443) 1 1 0.0010
(0.0010) C\textgreater{}SV3.1(48) Handshake

ClientHello Version 3.1 random{[}32{]}=

4c b7 41 87 e3 74 88 ac 89 e7 39 2d 8c 27 0d c0
\begin{quote}

6e 27 da ea 9f 57 7c ef 24 ed 21 df a6 26 20 83 cipher suites
TLS\_RSA\_WITH\_AES\_128\_CBC\_SHA
Unknown value 0xff
\end{quote}

compression methods unknown value
\begin{quote}

NULL
1 0.0011 (0.0000) S\textgreater{}C TCP FIN
\end{quote}

1 0.0022 (0.0011) C\textgreater{}S TCP FIN

For detailed read on SSLDUMP, please refer the MAN page on this URL.

\sphinxurl{https://linux.die.net/man/1/ssldump}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{BIG-IP DNS}
\label{\detokenize{class15/modules/module1:big-ip-dns}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

DNS Records types

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_gtm/manuals/product/gtm\_config\_guide\_10\_1/}
gtm\_zfd.html

Types of resource records

This section describes the common resource records that the ZoneRunner
utility supports. For information on additional resource record types,
see \sphinxstylestrong{DNS and BIND}, 4th edition, Albitz and Liu.

The types of resource records are:
\begin{itemize}
\item {} 
SOA (Start of authority)
The start of authority resource record, SOA, starts every zone
file and indicates that a name server is the best source of information
for a particular zone. The SOA record indicates that a name server is
authoritative for a zone. There must be exactly one SOA record per zone.
Unlike other resource records, you create a SOA record only when you
create a new master zone file.

\item {} 
A (Address)
The Address record, or A record, lists the IP address for a given
host name. The name field is the hosts name, and the address is the
network interface address. There should be one A record for each
IP address of the machine.

\item {} 
AAAA (IPv6 Address)
The IPv6 Address record, or AAAA record, lists the 128-bit IPv6
address for a given host name.

\item {} 
CNAME (Canonical Name)
The Canonical Name resource record, CNAME, specifies an alias or
nickname for the official, or canonical, host name. This record must
be the only one associated with the alias name. It is usually easier
to supply one A record for a given address and use CNAME records to
define alias host names for that address.

\item {} 
DNAME (Delegation of Reverse Name)
The Delegation of Reverse Name resource record, DNAME, specifies the
reverse lookup of an IPv6 address. These records substitute the
suffix of one domain name with another. The DNAME record instructs the
Global Traffic Manager (or any DNS server) to build an alias that
substitutes a portion of the requested IP address with the data stored
in the DNAME record.

\item {} 
HINFO (Host Information)
The Host Information resource record, HINFO, contains information
on the hardware and operating system relevant to the Global Traffic
Manager (or other DNS).

\item {} 
MX (Mail Exchanger)
The Mail Exchange resource record, MX, defines the mail system(s)
for a given domain.

\item {} 
NS (Name Server)
The name server resource record, NS, defines the name servers for
a given domain, creating a delegation point and a subzone. The first
\sphinxstylestrong{name} field specifies the zone that is served by the name server that
is specified in the \sphinxstylestrong{name servers} name field. Every zone needs at
least one name server.

\item {} 
PTR (Pointer)
A name pointer resource record, PTR, associates a host name with
a given IP address. These records are used for reverse name lookups.

\item {} 
SRV (Service)
The Service resource record, SRV, is a pointer that allows an
alias for a given service to be redirected to another domain. For example,
if the fictional company SiteRequest had an FTP archive hosted on
\sphinxstylestrong{archive.siterequest.com}, the IT department can create an SRV record
that allows an alias, \sphinxstylestrong{ftp.siterequest.com} to be redirected to
\sphinxstylestrong{archive.siterequest.com}.

\item {} 
TXT (Text)
The Text resource record, TXT, allows you to supply any string of
information, such as the location of a server or any other relevant
information that you want available.

\end{itemize}

\sphinxstylestrong{BIG-IP DNS GSLB Load Balancing Methods}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_gtm/manuals/product/gtm-concepts-11-3-0/1.html}

\sphinxstyleemphasis{Static load balancing methods}

This table describes the static load balancing methods available in
BIG-IP Global Traffic Manager (GTM).


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{7}{\X{1}{7}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Recommended Use}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Wide}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Preferred Method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Alternate Method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Fallback Method}
\\
\hline
Drop Packet
&
BIG-IP GTM drops the DNS request.
&
\begin{DUlineblock}{0em}
\item[] Use Drop Packet for
\item[] the Alternate load balancing method when you want to ensure that GTM does not offer in
\end{DUlineblock}

a response a virtual server that is potentially unavailable.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
Fallback IP
&
BIG-IP GTM distributes DNS name resolution requests to a virtual server that you specify. This virtual server is not monitored for availability.
&
Use Fallback IP for the fallback load balancing method when you want GTM to return a disaster recovery site when the preferred and alternate load balancing methods do not return an available virtual server.
&
No
&
No
&
No
&
Yes
\\
\hline
Global Availability
&
\begin{DUlineblock}{0em}
\item[] BIG-IP GTM distributes DNS name resolution requests to the first available virtual server
\item[] in a pool. BIG-IP GTM starts at the top of a manually configured list of virtual servers and sends requests to the first available virtual server in the list. Only when the virtual server becomes unavailable does BIG-IP GTM send requests to
\end{DUlineblock}

the next virtual server in the list. Over time, the first virtual server in the list receives the most requests and the last virtual server in the list receives the least requests.
&
Use Global
Availability when you have specific virtual servers that you want to handle most of the requests.
&
Yes
&
Yes
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{7}{\X{1}{7}|}}
\hline
\sphinxstyletheadfamily 
None
&\sphinxstyletheadfamily 
BIG-IP GTM distributes DNS name resolution requests skipping
either the next available pool in a multiple pool configuration or the current load balancing method. If all pools are unavailable, BIG-IP GTM returns an aggregate of the IP addresses of all the virtual servers in the pool using BIND.
&\sphinxstyletheadfamily 
Use None for the alternate and fallback methods when you want to limit each pool to a single load balancing method. If the preferred load balancing method fails, GTM offers the next pool in a load balancing response.
&\sphinxstyletheadfamily 
No
&\sphinxstyletheadfamily 
No
&\sphinxstyletheadfamily 
Yes
&\sphinxstyletheadfamily 
Yes
\\
\hline
Ratio
&
BIG-IP GTM distributes DNS name resolution requests among the virtual servers in a pool or among pools in a multiple pool configuration

using \sphinxstyleemphasis{weighted round robin,} a load balancing pattern in which requests are distributed among several resources based on a priority level or weight assigned to each resource.
&
Use Ratio when you want to send twice as many connections to a fast server and half as many connections to a slow server.
&
Yes
&
Yes
&
Yes
&
Yes
\\
\hline
Return to DNS
&
BIG-IP GTM immediately distributes DNS name resolution requests to an LDNS for resolution.
&
Use Return to DNS when you want to temporarily remove a pool from service. You can also use Return to DNS when you want to limit a

pool in a single pool configuration to only one or two load balancing attempts.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
Round Robin
&
BIG-IP GTM distributes DNS name resolution requests in a circular
and sequential pattern among the virtual servers in a pool. Over time each virtual server receives an equal number of requests.
&
Use Round Robin when you want to distribute requests equally among all virtual servers in a pool.
&
Yes
&
Yes
&
Yes
&
Yes
\\
\hline
Static Persist
&
\begin{DUlineblock}{0em}
\item[] BIG-IP GTM distributes DNS name resolution requests to the first available virtual server
\item[] in a pool using the
\item[] persist mask with the source IP address of
\item[] the LDNS and a hash algorithm to determine the order of the virtual servers in the list. This hash algorithm orders
\item[] the virtual servers in the list differently for each LDNS that is passing traffic to the system taking into account the specified CIDR of the LDNS. Each LDNS (and thus each client) generally resolves to the same virtual server; however, when the selected
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] virtual server becomes unavailable, BIG-IP
\item[] GTM sends requests to another virtual server
\item[] until the original virtual server becomes available. Then BIG-IP GTM again resolves requests to that virtual server.
\end{DUlineblock}
&
Use Static Persist when you want requests from a specific LDNS to resolve to a specific virtual server.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
Topology
&
BIG-IP GTM distributes DNS name resolution requests using proximity-based load balancing. BIG-IP

\begin{DUlineblock}{0em}
\item[] GTM determines
\item[] the proximity of the resource by comparing location information derived from the
\item[] DNS message to the topology records in
\item[] a topology statement you have configured.
\end{DUlineblock}
&
Use Topology when you want to send requests from a
client in a particular geographic region to
a data center or server located in that region.
&
Yes
&
Yes
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Dynamic load balancing methods}

This table describes the dynamic load balancing methods available in
BIG-IP Global Traffic Manager (GTM).


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Name}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Wide
**IP load balancing}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Preferred method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Alternate method}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Fallback method}
\\
\hline
Completion Rate
&
BIG-IP GTM distributes DNS name resolution requests to the virtual server that currently maintains the least number of dropped
or timed-out packets during a transaction between a data center and the client’s LDNS.
&
No
&
Yes
&
No
&
Yes
\\
\hline
CPU
&
BIG-IP GTM distributes DNS name resolution requests to the virtual server that currently has the most CPU processing time available.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Hops
&
BIG-IP GTM distributes DNS name resolution requests to a virtual server in the data
center that has the fewest router hops from the client’s LDNS. BIG-IP GTM uses the traceroute utility to track the number of router hops between a client’s LDNS and each data center.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Kilobytes/ Second
&
BIG-IP GTM distributes DNS name resolution requests to the virtual server that is currently processing the fewest number of kilobytes per second. Use Kilobytes/Second only with virtual servers for which BIG-IP GTM can collect the kilobytes per second metric.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Least Connections
&
BIG-IP GTM distributes DNS name resolution requests to virtual servers on BIG-IP
Local Traffic Manager (LTM) that currently hosts the fewest connections. Use Least Connections only with LTM servers.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Packet Rate
&
BIG-IP GTM distributes DNS name resolution requests to the virtual server that is currently processing the fewest number of packets per second.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
Quality of Service
&
BIG-IP GTM distributes DNS name resolution requests to virtual servers based on a
score assigned to each virtual server that is calculated from current performance metrics. Use Quality of Service only when you have configured BIG-IP GTM to calculate an overall score for each virtual server based on performance metrics.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Round Trip Time
&
BIG-IP GTM distributes DNS name resolution requests to the virtual server with the fastest measured round trip time between a data center and a client’s LDNS.
&
No
&
Yes
&
No
&
Yes
\\
\hline
Virtual Server Score
&
BIG-IP GTM distributes DNS name resolution requests to virtual servers on LTM based on a user-defined ranking. Use Virtual Server Score only with LTM systems on which you have assigned scores to each virtual server.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
Virtual Server Capacity
&
BIG-IP GTM distributes DNS name resolution requests to virtual servers in a list that are weighted by the number of available virtual servers in the pool. The pool with the most available virtual servers is sent more requests; however, over time all the virtual servers in

all the pools are sent requests. If more than one virtual server has the same weight, then BIG-IP GTM distributes DNS requests among those virtual servers using the round-robin load balancing method.
&
No
&
Yes
&
Yes
&
Yes
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{DNSSEC}

A good introductory read on DNSSEC - \sphinxurl{https://ds9a.nl/dnssec/}

To validate the DNSSEC Domains using the “Dig” tool, you can use the
\sphinxstylestrong{+dnssec} argument. If the domain’s RRs are signed by DNSSEC, you
should see “\sphinxstylestrong{ad}” (Authentication Data, rfc 2535) flag set in the
response. However, an RFC was written later stating that “ad” flag is
not useful in DNS Security Extension (rfc 3655).

Example of “dig” for \sphinxstylestrong{DNSSEC} signed RRs, with \sphinxstylestrong{AD} flag in the
response.

\textasciitilde{} dig pir.org +dnssec +multi
\begin{quote}

; \textless{}\textless{}\textgreater{}\textgreater{} DiG 9.8.0 \textless{}\textless{}\textgreater{}\textgreater{} pir.org +dnssec +multi
;; global options: +cmd
;; Got answer:
;; -\textgreater{}\textgreater{}HEADER\textless{}\textless{}- opcode: QUERY, status: NOERROR, id: 29196
;; flags: qr rd ra ad; QUERY: 1, ANSWER: 2, AUTHORITY: 5, ADDITIONAL:
1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags: do; udp: 4096 ;; QUESTION SECTION:
;pir.org. IN A

;; ANSWER SECTION:
pir.org. 300 IN A 173.201.238.128
pir.org. 300 IN RRSIG A 5 2 300 20110419085021 (
\end{quote}

20110405085021 11342 pir.org.
KOPkf7cbufTtAxotksChA3vh5YKCs3s+68N81ZH5hIaU
EUsWhR01mCAeyqmYnT7Oj9LXqENSJIVQUfHSzCEXcYRZ
joJCxHhjLD8D/pVRPcPvV6d92T7IZa9rfjf6VyYjyJld
pF19zAeQQm13Trgc0JtqGs2hM5OOBXsDtMjeuzg= )
\begin{quote}

;; AUTHORITY SECTION:
pir.org. 300 IN NS ns1.yyz1.afilias-nst.info. pir.org. 300 IN NS
ns1.sea1.afilias-nst.info. pir.org. 300 IN NS
ns1.mia1.afilias-nst.info. pir.org. 300 IN NS
ns1.ams1.afilias-nst.info.= pir.org. 300 IN RRSIG NS 5 2 300
20110419085021 (
\end{quote}

20110405085021 11342 pir.org.
wV3PUz9oCmdXq1GYzkoAXk7HskW4TMMCoyaoQjHVI8J5
vMFvWnQYEfiiJQOxHZl9xt/jrDoSkO/Xn0wnGboyMq4c
J6tzXGAPRWIWYoaRlti1HDk3YR1o8fm9utk4a2XgiOSR
olhUaumUnQF+wjfIMdtjWCsBxGAydjQ6nNYoHxE= )
\begin{quote}

;; Query time: 476 msec
;; SERVER: 192.168.1.2\#53(192.168.1.2) ;; WHEN: Tue Apr 5 18:11:22 2011
;; MSG SIZE rcvd: 494
\end{quote}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

DNS Header Flags (There are more Flags other than listed below)


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Bit}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Flag}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Reference}
\\
\hline
\sphinxstylestrong{bit 5}
&
AA
&
Authoritative Answer
&
{[}RFC1035{]}
\\
\hline
\sphinxstylestrong{bit 6}
&
TC
&
Truncated Response
&
{[}RFC1035{]}
\\
\hline
\sphinxstylestrong{bit 7}
&
RD
&
Recursion Desired
&
{[}RFC1035{]}
\\
\hline
\sphinxstylestrong{bit 8}
&
RA
&
Recursion Available
&
{[}RFC1035{]}
\\
\hline
\sphinxstylestrong{bit 9}
&&
Reserved
&\\
\hline
\sphinxstylestrong{bit 10}
&
AD
&
Authentic Data
&
{[}RFC4035{]}
\\
\hline
\sphinxstylestrong{bit 11}
&
CD
&
Checking Disabled
&
{[}RFC4035{]}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{IP INTELLIGENCE}
\label{\detokenize{class15/modules/module1:ip-intelligence}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Source - \sphinxurl{https://www.youtube.com/watch?v=qewaeUu6oiI}

Protection Categories

The IP Intelligence service identifies and blocks IP addresses
associated with a variety of threat sources, including:

\sphinxstylestrong{Windows exploits:} Includes active IP addresses offering or
distributing malware, shell code, rootkits, worms, or viruses.

\sphinxstylestrong{Web attacks:} Includes cross-site scripting, iFrame injection, SQL
injection, cross domain injection, or domain password brute force.

\sphinxstylestrong{Botnets:} Includes botnet command and control channels and infected
zombie machines controlled by the bot master.

\sphinxstylestrong{Scanners:} Includes all reconnaissance, such as probes, host scan,
domain scan, and password brute force. \sphinxstylestrong{Denial of service:} Includes
DoS, DDoS, anomalous SYN flood, and anomalous traffic detection.

\sphinxstylestrong{Reputation:} When enabled, denies access to IP addresses currently
known to be infected with malware or to contact malware distribution
points. Phishing: Includes IP addresses hosting phishing sites or other
kinds of fraud activities, such as click fraud or gaming fraud.

\sphinxstylestrong{Proxy:} Includes IP addresses providing proxy and anonymization
services, as well as The Onion Router (\sphinxstylestrong{TOR}) anonymizer addresses.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p61}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Reference -
\sphinxurl{https://www.f5.com/pdf/products/ip-intelligence-service-ds.pdf}

The requirements for using IP address intelligence are:
\begin{itemize}
\item {} 
The system must have an IP Intelligence license.

\item {} 
The system must have an Internet connection either directly or
through a proxy server.

\item {} 
The system must have DNS configured.

\item {} 
If the BIG-IP system is behind a firewall, make sure that the BIG-IP
system has external access to vector.brightcloud.com using port 443.
That is the IP Intelligence server from which the system gets IP
Intelligence information.

\end{itemize}

To check the reputation of any specific IP address, you can follow the
below steps.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line for the BIG-IP system.

\item {} 
At the prompt, type iprep\_lookup IP\_address where IP\_address is
the address whose reputation you want to verify. For example, to
verify 1.1.1.1:

iprep\_lookup 1.1.1.1

opening database in /var/IpRep/F5IpRep.dat size of IP reputation
database = 41693298

\begin{DUlineblock}{0em}
\item[] iprep threats list for ip = 1.1.1.1 is: bit 4 - Scanners
\item[] bit 5 - Denial of Service
\end{DUlineblock}

\end{enumerate}

Checking the status of the IP intelligence database

You can display the status of the IP Intelligence database to learn when
it was last updated and the number of questionable IP addresses it
contains.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to the command line for the BIG-IP system.

\item {} 
To display IP intelligence database status, type \sphinxstylestrong{tmsh show sys
iprep-status}. The system displays the status. Below is the sample
output of the same command.

/———————————————————————\textendash{}

Sys::IP Reputation Database Status

/———————————————————————\textendash{}

\end{enumerate}
\begin{quote}

Last time the server was contacted for updates Last time an update was
received
Total number of IP Addresses in the database Number of IP Addresses
received in the last update

04/21/2012 09:33:31 04/21/2012 09:33:31 5516336 136
\end{quote}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{DoS Protection using IPI}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p71}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Dynamic Endpoint Visibility \& Enforcement (Dynamic Blacklist \&
Whitelist)

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p81}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{THE F5 DDOS PROTECTION}
\label{\detokenize{class15/modules/module1:the-f5-ddos-protection}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

REFERENCE ARCHITECTURE

The Four Categories of DDoS

While the DDoS threat landscape is constantly evolving, F5 has found
that attacks continue to fall within four attack types: volumetric,
asymmetric, computational, and vulnerability-based. These attack
categories have the following characteristics:

\sphinxstylestrong{Volumetric} —Flood-based attacks that can be at layer 3, 4, or 7.
\sphinxstylestrong{Asymmetric} —Attacks designed to invoke timeouts or session-state changes.
\sphinxstylestrong{Computational} —Attacks designed to consume CPU and memory.
\sphinxstylestrong{Vulnerability-based} —Attacks that exploit software vulnerabilities.

Components of a DDoS Protection Architecture


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Attack Category}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Mitigation Component}
\\
\hline
Volumetric
&
Cloud-Based Scrubbing Service Web Application Firewall
\\
\hline
Asymmetric
&
Web Application Firewall
\\
\hline
Computational
&
Application Delivery Controller Network Firewall
\\
\hline
Vulnerability-Based
&
IP Reputation Database
Intrusion Prevention/Detection Systems (IDS/IPS) Application Delivery Controller
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Multi-Tier DDoS Protection Architecture}

F5 recommends a hybrid cloud on-premises DDoS solution. Volumetric
attacks will be mitigated by \sphinxstylestrong{F5 Silverline} TM DDoS Protection —a
service delivered via the F5 Silverline cloud-based platform.

Silverline DDoS Protection will analyze and remove the bulk of the
attack traffic. Sometimes, a DDoS campaign may include application layer
attacks that must be addressed on premises. These asymmetric and
computational attacks can be mitigated using the network defense and
application defense tiers. The network defense tier is composed of layer
3 and 4 network firewall services and simple load balancing to the
application defense tier. The application defense tier consists of more
sophisticated (and also more CPU-intensive) services including SSL
termination and a web application firewall stack.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p91}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{F5 Components and Capabilities}
\label{\detokenize{class15/modules/module1:f5-components-and-capabilities}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

The F5 components of the DDoS Protection reference architecture include:
\begin{itemize}
\item {} 
Silverline DDoS Protection

\item {} 
BIG-IP® Advanced Firewall ManagerTM (AFM)

\item {} 
BIG-IP® Local Traffic ManagerTM (LTM)

\item {} 
BIG-IP® Global Traffic ManagerTM (GTM) with DNS ExpressTM

\item {} 
BIG-IP® Application Security ManagerTM (ASM)

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily &\sphinxstyletheadfamily 
\sphinxstylestrong{Cloud}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Network Defense}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Application Defense}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DNS}
\\
\hline
\sphinxstylestrong{F5 Components}
&
SilverLine DDoS Protection
&
BIG-IP AFM BIG-IP LTM
&
BIG-IP LTM BIG-IP ASM
&
BIG-IP GTM with DNS ExpressTM
\\
\hline
\sphinxstylestrong{OSI Model}
&
Layers 3 and 4
&
Layers 3 and 4
&
Layer 7
&
DNS
\\
\hline
\sphinxstylestrong{Capabilities}
&
Volumetric scrubbing Traffic dashboarding
&
Network firewall Layer 4 load balancing
IP blacklists
&
SSL termination Web application firewall Secondary load balancing
&
DNS resolution DNSSEC
\\
\hline
\sphinxstylestrong{Attacks Mitigated}
&
Volumetric floods Amplification Protocol whitelisting
&
SYN floods
ICMP floods Malformed packets TCP floods
Known bad actors
&
Slowloris Slow POST Apache Killer RUDY/Keep Dead
SSL attacks
&
UDP floods
DNS floods NXDOMAIN floods
DNSSEC attacks
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Ready Defense subscription as a backup cloud-scrubbing service}

Many customers already have an agreement with an external DDoS scrubbing
service. These organizations can also benefit from having a backup
scrubbing service. Silverline DDoS Protection can be used in this manner
with its Ready DefenseTM subscription. As the organization’s primary
DDoS scrubber, Ready Defense can take over to either assist or
completely mitigate the attack.

\sphinxstylestrong{Always Available subscription as the primary service}

Organizations can use the Silverline DDoS Protection Always AvailableTM
subscription as their primary service to respond to DDoS attacks. They
can replace their existing primary service or delegate their existing
service to be the secondary service.

\sphinxstylestrong{Deployment models}

Silverline DDoS Protection has two main deployment models: routed
configuration and F5 IP ReflectionTM.

Routed configuration is for enterprises that need to protect their
entire network infrastructure. Silverline DDoS Protection leverages
Border Gateway Protocol (BGP) to route all the traffic to its scrubbing
and protection center, and utilizes a Generic Routing Encapsulation
(GRE) tunnel to send the clean traffic back to the origin network.
Routed configuration is a scalable design for enterprises with large
network deployments. It does not require any application-specific
configuration and provides an easy option to turn on or off Silverline
DDoS Protection.

IP Reflection is an alternative asymmetric technique to provide network
infrastructure protection without the need for GRE tunnels.
Organizations with devices that support destination NAT can leverage IP
Reflection. With IP Reflection, there is no need to change any IP
address and the IP address space is not affected as it is with GRE.

\sphinxstylestrong{Return traffic methods used by Silverline DDoS Protection include:}
\begin{itemize}
\item {} 
(AWS) Direct Connect

\item {} 
IP Reflection

\item {} 
GRE tunnels

\item {} 
Proxy

\item {} 
Customer bundles (fiber)
Source -
\sphinxurl{https://f5.com/resources/white-papers/the-f5-ddos-protection-reference-architecture/mode/pdf}

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{APPLICATION FIREWALL MODULE (AFM)}
\label{\detokenize{class15/modules/module1:application-firewall-module-afm}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Reference - Learn F5 AFM getting started training.

Brief Features:
\begin{itemize}
\item {} 
L4 Stateful Full proxy

\item {} 
IPSec, NAT, Advanced Routing, Full SSL, AVR, PSM • DDoS

\end{itemize}
\begin{itemize}
\item {} 
TCP, UDP, DNS, floods, HTTP

\end{itemize}

Over 80 packet types (pre-defined)

Modes of deployment:
\begin{itemize}
\item {} 
AFM can be deployed in two modes as following.

\end{itemize}

ADC Mode (Default) Firewall Mode

\sphinxstylestrong{ADC Mode}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip-afm/manuals/product/network-firewall-policies}-
implementations-12-1-0/8.html

The BIG-IP Network Firewall provides policy-based access control to and
from address and port pairs inside and outside of your network. By
default the network firewall is configured in ADC mode, which is a
default allow configuration, in which all traffic is allowed through the
firewall, and any \sphinxstylestrong{traffic you want to block must be explicitly
specified}.

\sphinxstylestrong{Firewall Mode}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip-afm/manuals/product/network-firewall-policies-implementations-12-1-0/8.html}

The BIG-IP Advanced Firewall Module (AFM) provides policy-based access
control to and from address and port pairs, inside and outside of your
network. In this scenario, the network firewall is configured in
Firewall mode, a default deny configuration, in which all traffic is
blocked through the firewall, and any \sphinxstylestrong{traffic you want to allow must
be explicitly specified}.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p101}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p111}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{The Classification module}

The Classification Module has 2 components,

\sphinxstylestrong{Compiler} \textendash{} Resides in the “Control plane” and compiles the
connection table based on the policy is configured.

\sphinxstylestrong{Classification Engine} \textendash{} Uses the Compiled Classifier to determine the
set of rules matching a packet based on the packet contents and other
relevant input. Resides in the “packet processing path, as part of TMM process”.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p121}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If “No match” found the packet gets dropped with Default Deny rule.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p131}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Context}

The category of object to which the rule applies. Rules can be Global
and apply to all addresses on the BIG-IP system that match the rule, or
they can be specific, applying only to a specific virtual server, self
IP address, route domain, or the management port.

\sphinxstyleemphasis{Context} is processed in this order:
\begin{itemize}
\item {} 
Global

\item {} 
Route domain

\item {} 
Virtual server/self IP Global drop or reject*

\end{itemize}

\sphinxstylestrong{Note:} You can configure the global drop or reject context. The
global drop or reject context is the final context for all traffic,
except Management port traffic. Note that even though it is a global
context, it is not processed first, like the main global context, but
last. If a packet matches no rule in any previous context, the global
drop or reject rule rejects the traffic. The default global rule is
global reject. *

\sphinxstylestrong{Note:} Management port traffic is not affected by the global drop or
reject rule, or by global rules in general. Management port rules must
be specifically configured and applied. *

The above example shows the “\sphinxstylestrong{Context}” of the multiple rules
configured in the AFM System. The “Contexts” in the above example are
“Global, Virtual Server, and Default”.

Request processing order


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{FIREWALL CONTEXT}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DESCRIPTION}
\\
\hline
Global
&
Global policy rules are collected in this firewall context. Global rules apply to all traffic that traverses the firewall, and global rules are checked first.
\\
\hline
Route Domain
&
Route domain policy rules are collected in this context. Route domain rules apply to a specific route domain defined on the server. Route domain policy rules are checked after global rules. If you have not configured a route domain, you can apply route domain rules to Route Domain 0, which is effectively the same as the global rule context; however, if you configure another route domain after this, Route Domain 0 is no longer usable as a global context.
\\
\hline
Virtual Server
&
Virtual server policy rules are collected in this context. Virtual server policy rules apply to the selected existing virtual server only. Virtual server rules are checked after route domain rules.
\\
\hline
Self IP
&
Self IP policy rules apply to a specified self IP address on the device. Self IP policy rules are checked after route domain rules.
\\
\hline
Management Port
&
The management port context collects firewall rules that apply to the management port on the BIG-IP® device. \sphinxstylestrong{Management port rules are checked independently of other rules and are not processed in relation to other contexts}.
\\
\hline
Global Reject
&
The Global Reject rule rejects all traffic that does not match any rule in a previous context, excluding Management Port traffic, which is processed independently.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Firewall Actions}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{FIREWALL ACTION}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DESCRIPTION}
\\
\hline
Accept
&
Allows packets with the specified source, destination, and protocol to pass through the current firewall context. Packets that match the rule, and are \sphinxstylestrong{accepted}, traverse the system as if the firewall is not present.
\\
\hline
Drop
&
Drops packets with the specified source, destination, and protocol. Dropping a packet is a silent action with no notification to the source or destination systems. Dropping the packet causes the connection to be retried until the retry threshold is reached.
\\
\hline
Reject
&
Rejects packets with the specified source, destination, and protocol. Rejecting a packet is a more graceful way to deny a packet, as it sends a destination unreachable message to the sender. For example, if the protocol is TCP, a TCP RST message is sent. One benefit of using Reject is that the sending application is notified, after only one attempt, that the connection cannot be established.
\\
\hline
Accept Decisively
&
\begin{DUlineblock}{0em}
\item[] Allows packets with the specified source, destination, and protocol to pass through the firewall. Packets that match the rule, and
\item[] are \sphinxstylestrong{accepted decisively}, traverse the system as if the firewall is not present, and are not processed by rules in any further context after the \sphinxstylestrong{accept decisively} action applies. If you want a packet
\end{DUlineblock}

to be accepted in one context, and not to be processed in any remaining context or by the default firewall rules, specify the \sphinxstylestrong{accept decisively} action. For example, if you want to allow all packets from Network A to reach every server behind your firewall, you can specify a rule that accepts decisively at the global context, from that Network A, to any port and address. Then, you can specify that all traffic is blocked at a specific virtual server, using the virtual server context. Because traffic from Network A is accepted decisively at the global context, that traffic still traverses the virtual server.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Important} ICMP is handled by the BIG-IP system at the global or
route domain level. Because of this, ICMP messages receive a response
before they reach the virtual server context. You cannot create rule for
ICMP or ICMPv6 on a self IP or virtual server context. You can apply a
rule list to a self IP or virtual server that includes a rule for ICMP
or ICMPv6; however, such a rule will be ignored. To apply firewall
actions to the ICMP protocol, create a rule with the global or route
domain context. ICMP rules are evaluated only for ICMP forwarding
requests, and not for the IP addresses of the BIG-IP system itself.

When you create rules on the network firewall, it is possible that a
rule can either overlap or conflict with an existing rule.

\sphinxstylestrong{Redundant rule}

A rule which has address, user, region, or port information that
completely overlaps with another rule, \sphinxstylestrong{with the same action}. In the
case of a redundant rule, the rule can be removed with no net change in
packet processing because of the overlap with a previous rule or rules.

\sphinxstylestrong{Conflicting rule}

A conflicting rule is a special case of a redundant rule, in which
address, user, region or port information overlaps with another rule,
but the rules \sphinxstylestrong{have different actions}, and thus conflict.

\sphinxstylestrong{Tip:} A rule might be called conflicting even if the result of each
rule is the same. For example, a rule that applies to a specific IP
address is considered in conflict with another rule that applies to the
same IP address, if one has an Accept action and the other has an
action of Accept Decisively, even though the two rules accept
packets.

On a rule list page, redundant or conflicting rules are indicated in the
State column with either (Redundant) or (Conflicting).

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p141}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

This is what the \sphinxstylestrong{Compiler} does, we discussed in “ACL Object
Model”…….

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{DoS Protection}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/dns-dos-firewall}-
implementations-11-4-0/2.html

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p151}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Attack type} \textendash{} Defines the type of attack and sub-categories of the
same.

\sphinxstylestrong{Detection Threshold PPS} \textendash{} An alert. When the particular type of
Category reaches to the defined “Detection of Threshold PPS”, it
generates an alert (if you’ve configured external logging server with
AFM, else local logging).

\sphinxstylestrong{Detection Threshold Percent} \textendash{} Additional flag to determine the
further aggressiveness of the attack, of a particular type of category.
Here, AFM compares the current rate of the particular Category type’s
attack with Last One Hour average packet rate. For example, if the
average rate for the last hour is 1000 packets per second, and you set
the percentage increase threshold to 100, an attack is detected at 100
percent above the average, or 2000 packets per second. When the
threshold is passed, an attack is logged and reported. The system then
automatically institutes a rate limit equal to the average for the last
hour, and all packets above that limit are dropped. The system continues
to check every second until the incoming packet rate drops below the
percentage increase threshold. Rate limiting continues until the rate
drops below the specified limit.

\sphinxstylestrong{Default Internal Rate Limit} - Use \sphinxstylestrong{Specify} to set a value, in
packets per second, which cannot be exceeded by packets of this type.
All packets of this type over the threshold are dropped. Rate limiting
continues until the rate drops below the specified limit again.

Use \sphinxstylestrong{Infinite} to set No value for the threshold. This specifies that
this type of attack is not rate-limited.

DNS \& SIP DoS Attack Prevention

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p161}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{DNS DoS Mitigation}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p171}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{WEBSAFE/MOBILESAFE}
\label{\detokenize{class15/modules/module1:websafe-mobilesafe}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

A good Light Board lesson on Websafe - \sphinxurl{https://youtu.be/FoyXTfTrpgA}

A good read on MobileSafe \textendash{} \sphinxurl{https://www.f5.com/pdf/products/mobilesafe-datasheet.pdf}

A quick read on malicious creatures.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p201}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Websafe training from Learn F5}

How Web browser renders and interpret the code normally.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p211}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Web based Websafe training from Learn F5}

The DOM / Elements and Scripts

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p221}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Websafe training from Learn F5}

The Document and its child elements contains sub-child elements. All the
HTML elements i.e. Body / Head can be modified by the “script” in run
time, without interaction with the web server, and can be executed
solely on client browser.

In above example, the following can be add/modify or remove by the
“Scripts” in run time, without user’s intervention or communicating with
the web servers.

Attribute: “href”, Element:\textless{}input\textgreater{}, Text:”Welcome!”, Attribute:ID,
Attribute: type

All of this events can happen dynamically, without a page refresh, and
without another request to the web server. In short, your users may not
be interacting with the application they think they are.

DOM Vulnerabilities and Security Concerns

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p231}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Web based Websafe training from Learn F5}
Websafe General workflow

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p241}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Web based Websafe training from Learn F5}

License Activation for FPS (Fraud Protection Module)

The FPS License activation can be done from the TMSH, which is 32
characters long string. FPS is a bundle of more than one protection
modules i.e. Websafe / Phishing protection / Malware protection /
automatic transaction detection and application encryption, and license
activation is required for them as well.

WebSafe License Bundle Activation Example:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p251}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Websafe training from Learn F5}

However activating Websafe license only from tmsh, you can receive the
demo license key by contacting F5 concern team, a valid key will have 8
numeric characters as shown in the below example.

WebSafe License Example:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p261}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Web based Websafe training from Learn F5}

You can subscribe for the license as per your requirement.
Once the license is activated, you would see the following options
available in the Configuration Utility.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p271}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reference: Web based Websafe training from Learn F5}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{APPLICATION SECURITY MODULE (ASM)}
\label{\detokenize{class15/modules/module1:application-security-module-asm}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Data guard Protection}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/asm}-
implementations-11-5-0/9.html

In some web applications, a response may contain sensitive user
information, such as credit card numbers or social security numbers
(U.S. only). The Data Guard feature can prevent responses from exposing
sensitive information by masking the data (this is also known as
response scrubbing).

\sphinxstylestrong{Note:} When you mask the data, the system replaces the sensitive data
with asterisks (****). F5 recommends that you enable this
setting especially when the security policy enforcement mode is
transparent. Otherwise, when the system returns a response, sensitive
data could be exposed to the client.

Using Data Guard, you can configure custom patterns using PCRE regular
expressions to protect other forms of sensitive information, and
indicate exception patterns not to consider sensitive. You can also
specify which URLs you want the system to examine for sensitive data.

The system can examine the content of responses for specific types of
files that you do not want to be returned to users, such as ELF binary
files or Microsoft Word documents. File content checking causes the
system to examine responses for the file content types you select, and
to block sensitive file content (depending on the blocking modes), but
it does not mask the sensitive file content.

Data Guard examines responses that have the following content-type
headers: • “text/…”
\begin{itemize}
\item {} 
“application/x-shockwave-flash” • “application/sgml”

\item {} 
“application/x-javascript”

\item {} 
“application/xml”

\item {} 
“application/x-asp”

\item {} 
“application/x-aspx”

\item {} 
“application/xhtml+xml”

\end{itemize}

You can configure one additional user-defined response content-type
using the system variable user\_defined\_accum\_type. If response
logging is enabled, these responses can also be logged.

\sphinxstyleemphasis{DoS Protection}

There are two types of protections you can implement for DoS in ASM.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
TPS Based DoS Protection

\item {} 
Stress Based (formally known as “Latency based”) DoS Protection

\end{enumerate}

\sphinxstylestrong{Note:} The averages for IP address and URL counts are done for each
virtual server, not each DoS L7 profile, in case one DoS L7 profile is
assigned to more than one virtual server. *

TPS Based Anomaly Protection

TPS Based DoS Protection detects DoS attacks from the client side using
the following calculations:  \sphinxstylestrong{Transaction rate during detection
interval}

The average number of requests per second \sphinxstylestrong{sent for} a specific URL,
or \sphinxstylestrong{sent by} a specific IP address. \sphinxstylestrong{Every second}, the system
calculates the average TPS for the last minute (i.e. Last 60 seconds).

Here are some interesting facts about the TPS calculations. As there are
two types of TPS detection, there are two different calculations.
\begin{itemize}
\item {} 
Transaction rate detection interval

\item {} 
Transaction rate history interval

\end{itemize}

For “Transaction rate detection interval”, the ASM calculates short
average for the past 1min, and for “Transaction rate history
interval”, the ASM calculates long average for the past 1hour. Let’s
discuss this in a little detail, read the below.

\sphinxstylestrong{Transaction rate detection interval:} The average number of
requests per second sent, and it is updated every 60 seconds.

BIG-IP ASM calculates short average for the past 1min. It will be
calculated \sphinxstylestrong{1 sec later}.

\sphinxstylestrong{For example}

At 8:59:59 am, it is calculated short average per 1min between
8:58:58 am and 8:59:58 am. At 9:00:00 am, it is calculated short
average per 1min between 8:58:59 am and 8:59:59 am. At 9:00:01 am,
it is calculated short average per 1min between 8:59:00 am and
9:00:00 am. At 9:00:02 am, it is calculated short average per 1min
between 8:59:01 am and 9:00:01 am.

\sphinxstylestrong{Transaction rate history interval:} The average number of
transactions for the past hour, and it is updated every minute (i.e.
60 seconds).

BIG-IP ASM calculates long average the past 1hour. It will be
calculated \sphinxstylestrong{1min later}.

\sphinxstylestrong{For example}

At 8:59:00 am, it is calculated long average per 1hour between 7:58:00
am and 8:58:00 am. At 9:00:00 am, it is calculated long average per
1hour between 7:59:00 am and 8:59:00 am. At 9:01:00 am, it is calculated
long average per 1hour between 8:00:00 am and 9:00:00 am. At 9:02:00 am,
it is calculated long average per 1hour between 8:01:00 am and 9:01:00
am.

TPS Increased by Percentage:

In \sphinxstylestrong{TPS-based detection mode}, if the ratio of the \sphinxstylestrong{*transaction rate
detection interval **to the transaction rate history interval} is
greater than the specific percentage you configure on this screen (i.e.
\sphinxstylestrong{TPS increased by percentage}), the system detects the URL to be under
attack, or the IP address to be attacking. In order to stop the attack,
the system blocks some, or all, requests from the detected IP address
and/to the attacked URL, depending on the configuration of the DoS
profile.

By using the function of “\sphinxstylestrong{TPS increased by}”, if the ASM system
has just processing the traffic in less than 1 min, BIG-IP ASM will not
detect any attack. In that case, the ASM system will depend on the
function

“\sphinxstylestrong{TPS reached}”
For \sphinxstylestrong{IP Detection Criteria}, modify the threshold values as needed.
Source

\sphinxstylestrong{Note:} This setting appears only if Prevention Policy is set to
Source IP-Based Client Side Integrity Defense and/or Source IP-Based
Rate Limiting.

If any of these criteria is met, the system handles the attack according
to the Prevention Policy settings.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{TPS increased by}
&
Specifies that the system considers an IP address to be that of an attacker if the transactions sent per second have increased by this percentage, and the detected TPS is greater than the Minimum TPS Threshold for detection. The default value
is 500\%.
\\
\hline
\sphinxstylestrong{TPS reached}
&
Specifies that the system considers an IP address to be suspicious if the number
of transactions sent per second from an IP address equals, or is greater than, this value. This setting provides an absolute value, so, for example, if an attack increases the number of transactions gradually, the increase might not exceed the TPS increased by threshold and would not be detected. If the TPS reaches the TPS reached value, the system considers traffic to be an attack even if it did not meet
the TPS increased by value. The default value is 200 TPS.
\\
\hline
\sphinxstylestrong{Minimum TPS Threshold for detection}
&
Specifies that the system considers an IP address to be an attacker if the detected TPS for a specific IP address equals, or is greater than, this number, and the TPS increased by number was reached. The default setting is 40 transactions per second.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

For \sphinxstylestrong{URL Detection Criteria}, modify the threshold values as needed.
\sphinxstylestrong{Note:} This setting appears only if Prevention Policy is set to
URL-Based Client Side Integrity Defense and or URL-Based Rate Limiting.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{TPS increased by}
&
Specifies that the system considers a URL to be that of an attacker if the transactions sent per second to the URL have increased by this percentage, and the detected TPS is greater than the Minimum TPS Threshold for detection. The default value is 500\%.
\\
\hline
\sphinxstylestrong{TPS reached}
&
Specifies that the system considers a URL to be suspicious if the number of transactions sent per second to the URL is equal to or greater than this value. This setting provides an absolute value, so, for example, if an attack increases the number of transactions gradually, the increase might not exceed the TPS increased by threshold and would not be detected. If the TPS reaches the TPS reached value, the system considers traffic to be an attack even if it did not meet the TPS increased by value. The default value is 1000 TPS.
\\
\hline
\sphinxstylestrong{Minimum TPS Threshold for detection}
&
Specifies that the system considers a URL to be an attacker if the detected TPS for a specific URL equals, or is greater than, this number, and theTPS increased by number was reached. The default setting is 200 transactions per second.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If any of these criteria is met, the system handles the attack
according to the Prevention Policy settings. For \sphinxstylestrong{Site-Wide Detection
Criteria}, modify the threshold values as needed.
\sphinxstylestrong{Note:} This setting appears only if using site-wide prevention
policies.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{TPS increased by}
&
Specifies that the system considers a whole site to be under attack if the transactions sent per second have increased by this percentage, and the detected TPS is greater than the Minimum TPS Threshold for detection. . The default value is 500\%.
\\
\hline
\sphinxstylestrong{TPS reached}
&
Specifies that the system considers a whole site to be under attack if the number of requests sent per second is equal to or greater than this number. The default value is 10000 TPS.
\\
\hline
\sphinxstylestrong{Minimum TPS Threshold for detection}
&
Specifies that the system considers a whole site to be under attack if the detected TPS is equal to or greater than this number, and the TPS increased by number was reached. The default setting is 2000 TPS.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

If any of these criteria is met, the system handles the attack according
to the Prevention Policy settings.

For the \sphinxstylestrong{Prevention Duration} setting, specify the time spent in each
mitigation step until deciding to move to the next mitigation step.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Escalation Period}
&
Specifies the minimum time spent in each mitigation step before the system moves to the next step when preventing attacks against an attacker IP address or attacked URL. During a DoS attack, the system performs attack prevention for the amount of time configured here for methods enabled in the Prevention Policy. If after this period the attack is not stopped, the system enforces the next enabled prevention step. Type a number between 1 and 3600. The default is 120 seconds.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{De-escalation Period}

Specifies the time spent in the final escalation step until retrying the
steps using the methods enabled in the Prevention Policy. Type a number
(greater than the escalation period) between 0 (meaning no
de-escalation) and 7200 seconds. The default value is 7200 seconds (2
hours).

DoS mitigation is reset after 2 hours even if the detection criteria
still hold regardless of the value set for
the De-escalation Period. If the attack is still taking place, a new
attack occurs and mitigation starts over retrying the steps in the
Prevention Policy. If you set the De-escalation Period to less than 2
hours, the reset occurs more frequently.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Stress-based DoS protection}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/asm-implementations-12-0-0/2.html}

When setting up DoS protection, you can configure the system to prevent
DoS attacks based on the server side (stress-based detection). In
stress-based detection, it takes a latency increase and at least one
suspicious IP address, URL, heavy URL, site-wide entry, or geolocation
for the activity to be considered an attack.

\sphinxstylestrong{Note:} The average latency is measured for each site, that is, for
each virtual server and associated DoS profile. If one virtual server
has multiple DoS profiles (implemented using a local traffic policy),
then each DoS profile has its own statistics within the context of the
virtual server.

Stress-based protection is less prone to false positives than
TPS-based protection because in a DoS attack, the server is reaching
capacity and service/response time is slow: this is impacting all users.
Increased latency can be used as a trigger step for detecting an L7
attack. Following the detection of a significant latency increase, it is
important to determine whether you need further action. After examining
the increase in the requests per second and by comparing these numbers
with past activity, you can identify suspicious versus normal latency
increases.

\sphinxstylestrong{Detection Criteria}, modify the threshold values as needed. If any of
these criteria is met, the system handles the attack according to the
Prevention Policy settings.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Option}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{Latency increased by}
&
Specifies that the system considers traffic to be an attack if the latency has increased by this percentage, and the minimum latency threshold has been reached. The default value is 500\%.
\\
\hline
\sphinxstylestrong{Latency reached}
&
\begin{DUlineblock}{0em}
\item[] Specifies that the system considers traffic to be an attack if the latency is equal to or
\item[] greater than this value. This setting provides an absolute value, so, for example, if an
\item[] attack increases latency gradually, the increase might not exceed the Latency Increased
\item[] by threshold and would not be detected. If server latency reaches the Latency reached value, the system considers traffic to be an attack even if it did not meet the Latency increased
\end{DUlineblock}

by value. The default value is 10000 ms.
\\
\hline
\sphinxstylestrong{Minimum Latency Threshold for detection}
&
Specifies that the system considers traffic to be an attack if the detection interval for a specific URL equals, or is greater than, this number, and at least one of the Latency increased by numbers was reached. The default setting is 200 ms.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

About DoS mitigation methods

When setting up either transaction-based or stress-based DoS protection,
you can specify mitigation methods that determine how the system
recognizes and handles DoS attacks. You can use the following methods:

\sphinxstylestrong{JavaScript challenges} (also called Client-Side Integrity Defense)

You can configure the system to issue a JavaScript challenge to analyze
whether the client is using a legal browser (that can respond to the
challenge) when the system encounters a suspicious IP address, URL,
geolocation, or site-wide criteria. If the client does execute
JavaScript in response to the challenge, the system purposely slows down
the interaction. The Client Side Integrity Defense mitigations are
enacted only when the Operation Mode is set to blocking.

\sphinxstylestrong{CAPTCHA challenges}

Based on the same suspicious criteria, the system can also issue a
CAPTCHA (character recognition) challenge to determine whether the
client is human or an illegal script. Depending on how strict you want
to enforce DoS protection, you can limit the number of requests that are
allowed through to the server or block requests that are deemed
suspicious.

\sphinxstylestrong{Request Blocking}

You can also use can use request blocking in the DoS profile to specify
conditions for when the system blocks requests. Note that the system
only blocks requests during a DoS attack when the Operation Mode for

TPS-based or stress-based detection is set to Blocking. You can use
request blocking to rate limit or block all requests from suspicious IP
addresses, suspicious countries, or URLs suspected of being under
attack.

Site-wide rate limiting also blocks requests to web sites suspected of
being under attack. If you block all requests, the system blocks
suspicious IP addresses and geolocations except those on the whitelist.
If you are using rate limiting, the system blocks some requests
depending on the threshold detection criteria set in the DoS profile.

The mitigation methods that you select are used in the order they appear
on the screen. The system enforces the methods only as needed if the
previous method was not able to stem the attack.

\sphinxstylestrong{DoS Use cases \& Examples}

(ASM Operations guide \textendash{} page \#51)

Securing Web Services

Fine-tuning Advanced XML Security Policy Settings

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/asm-implementations-11-5-0/18.html}

The defense configuration in an XML profile provides formatting and
attack pattern checks for the XML data. The defense configuration
complements the validation configuration to provide comprehensive
security for XML data and web services applications. If your XML
application has special requirements, you can adjust the defense
configuration settings.

The system checks requests that contain XML data to be sure that the
data complies with the various document limits defined in the defense
configuration of the security policy’s XML profile. The system generally
examines the message for compliance to boundaries such as the message’s
size, maximum depth, and maximum number of children. When the system
detects a problem in an XML document, it causes the XML data does not
comply with format settings violation, if the violation is set to Alarm
or Block.

The XML profile is updated if you changed which \sphinxstylestrong{SOAP methods} are
allowed by the security policy. If you disable a SOAP method, and a
request contains that method, the system issues the SOAP method not
allowed violation, and blocks the request if the enforcement mode is set
to blocking.

Detecting and Preventing Web Scraping

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/asm-implementations-11-5-0/4.html}

\sphinxstyleemphasis{Web scraping} is a technique for extracting information from web sites
that often uses automated programs, or bots (short for web robots),
opening many sessions, or initiating many transactions. You can
configure

Application Security Manager (ASM) to detect and prevent various web
scraping activities on web sites that it is protecting.

ASM provides the following methods to address web scraping attacks.
These methods can work independently of each other, or they can work
together to detect and prevent web scraping attacks.

\sphinxstylestrong{Bot detection} investigates whether a web client source is human
by limiting the number of page changes allowed within a specified
time.

You can mitigate web scraping on the web sites Application Security
Manager defends by attempting to determine whether a web client
source is human or a web robot. The bot detection method also
protects web applications against rapid surfing by measuring the
amount of time allowed to change a number of web pages before the
system suspects a bot.

The system checks for rapid surfing and if too many pages are
changed too quickly, it logs Web Scraping detected violations in the
event log, and specifies the attack type of bot detection.

After setting up bot detection, you can also set up fingerprinting,
session opening and session transactions anomaly detection for the
same security policy.

\sphinxstylestrong{Session opening} detects an anomaly when either too many
sessions are opened from an IP address or when the number of sessions
exceeds a threshold from an IP address. Also, session opening can
detect an attack when the number of inconsistencies or session resets
exceeds the configured threshold within the defined time. This method
also identifies as an attack an open session that sends requests that
do not include an ASM cookie.

You can configure how the system protects your web application
against \sphinxstyleemphasis{session opening} web scraping violations that result from
too many sessions originating from a specific IP address,
inconsistencies detected in persistent storage, and when the number
of session resets exceeds the threshold.

\sphinxstylestrong{Note}

The Detection Criteria values all work together. The minimum
sessions value and one of the sessions opened values must be met for
traffic to be considered an attack. However, if the minimum sessions
value is not reached, traffic is never considered an attack even if
the Sessions opened per second increased by value is met.

The system checks for too many sessions being opened from one IP
address, too many cookie deletions, and persistent storage
inconsistencies depending on the options you selected. The system
logs violations in the web scraping event log along with information
about the attack including whether it is a Session Opening Anomaly
by IP Address or Session Resets by Persistent Client Identification

attack type and when it began and ended. The log also includes the type
of violation (Device Identification Integrity or Cookie Deletion
Detection) and the violation numbers.

\sphinxstylestrong{Session transactions anomaly} captures sessions that request too
much traffic, compared to the average amount observed in the web
application. This is based on counting the transactions per session
and comparing that to the average amount observed in the web
application.

You can configure how the system protects your web application
against harvesting, which is detected by counting the number of
transactions per session and comparing that number to a total
average of transactions from all sessions. Harvesting may cause
session transaction anomalies.

When the system detects a session that requests too many
transactions (as compared to normal), all transactions from the
attacking session cause the Web Scraping detected violation to occur
until the end of attack or until the prevention duration expires.

\sphinxstylestrong{Fingerprinting} captures information about browser attributes to
identify a client. It is used when the system fails to detect web
scraping anomalies by using IP addresses, ASM cookies, or persistent
device identification.

Fingerprinting is collecting browser attributes and saving the
information in a special POST data parameter. The system can use the
collected information to identify suspicious clients (potential
bots) and recognize web scraping attacks more quickly.

The system now collects browser attributes to help with web scraping
detection. If you also enabled the Suspicious Clients setting, when
the system detects clients that may be web scraping attempts using
information obtained by fingerprinting, the system records the
attack data, and blocks the suspicious requests.

\sphinxstylestrong{Suspicious clients} used together with fingerprinting, specifies
how the system identifies and protects against potentially malicious
clients; for example, by detecting scraper extensions installed in a
browser.

The BIG-IP system can accurately detect web scraping anomalies only
when response caching is turned off.

Prerequisites for configuring web scraping

For web scraping detection to work properly, you should understand
the following prerequisites:
\begin{itemize}
\item {} 
The web scraping mitigation feature requires that the DNS server is
on the DNS lookup server list.

\item {} 
Client browsers need to have \sphinxstylestrong{JavaScript enabled}, and support
cookies for anomaly detection to work.

\item {} 
Consider disabling response caching. If response caching is enabled,
the system does not protect cached content against web scraping.

\item {} 
The Application Security Manager does not perform web scraping
detection on legitimate search engine traffic. If your web
application has its own search engine, we recommend that you add it
to the system.

\item {} 
Web scraping attack types

\item {} 
Web scraping statistics specify the attack type so you have more
information about why the attack occurred. This shows the web
scraping attack types that can display in the web scraping event log.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Attack Type}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
Bot activity detected
&
Indicates that there are more JavaScript injections than JavaScript replies. Click the attack type link to display the detected injection ratio and the injection ratio threshold.

Note: You cannot configure the Bot activity detected ratio values. This attack type can occur only when the security policy is in Transparent mode.
\\
\hline
Bot Detected
&
Indicates that the system suspects that the web scraping attack was caused by a web robot.
\\
\hline
Session Opening Anomaly by IP
&
Indicates that the web scraping attack was caused by too many sessions being opened from one IP address. Click the attack type link to display the number of sessions opened per second from the IP address, the number of legitimate sessions, and the attack prevention state.
\\
\hline
Session Resets by Persistent Client Identification
&
Indicates that the web scraping attack was caused by too many session resets or inconsistencies occurring within a specified time. Click the attack type link to display the number of resets or inconsistencies that occurred within a number of seconds.
\\
\hline
Suspicious Clients
&
Indicates that the web scraping attack was caused by web scraping extensions on the browser. Click the attack type link to display the scraping extensions found in the browser.
\\
\hline
Transactions per session anomaly
&
Indicates that the web scraping attack was caused by too many transactions being opened during one session. Click the attack type link to display the number of transactions detected on the session.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{User and Session Tracking}

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_asm/manuals/product/asm-implementations-12-0-0/15.html}

Overview: Tracking user sessions using login pages

You can track user sessions using login pages configured from within
Application Security Manager (ASM), or have the policy retrieve the user
names from Access Policy Manager (APM). This implementation describes
how to set up session tracking for a security policy using login pages.
The advantage of using session tracking is that you can identify the
user, session, or IP address that instigated an attack.

Login pages, created manually or automatically, define the URLs,
parameters, and validation criteria required for users to log in to the
application. User and session information is included in the system logs
so you can track a session or user. The system can log activity, or
block a user or session if either generates too many violations.

If you configure session awareness, you can view the user and session
information in the application security charts.

\sphinxstyleemphasis{Monitor user and session information}

Source -
\sphinxurl{https://devcentral.f5.com/questions/session-tracking-with-asm-block-all-vs-delay-blocking-50479}

To monitor user and session information, you first need to set up
session tracking for the security policy.

You can use the reporting tools in Application Security ManagerTM to
monitor user and session details, especially when you need to
investigate suspicious activity that is occurring with certain users,
sessions, or IP addresses.

The Session Tracking Status screen opens and shows the users, sessions,
and IP addresses that the system is currently tracking for this security
policy.

1. From the \sphinxstylestrong{Action} list, select the action by which to filter the
data.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{ACTION}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DESCRIPTION}
\\
\hline
\sphinxstylestrong{All}
&
Specifies that the screen displays all entries. This is the default value.
\\
\hline
\sphinxstylestrong{Block All}
&
Specifies that the system displays sessions whose requests the system blocks after the configured threshold was reached.
\\
\hline
\sphinxstylestrong{Log All Requests}
&
Specifies that the system displays sessions whose requests the system logs after the configured threshold was reached.
\\
\hline
\sphinxstylestrong{Delay Blocking}
&
Specifies that the system displays sessions whose requests the system delayed blocking until the configured threshold was reached.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The difference between “\sphinxstylestrong{block all}” and “\sphinxstylestrong{delay blocking}”
is that with delay blocking you can defer blocking of a
session or an IP address because you want to tolerate a low volume of
violations, instead of immediately blocking any request that violates
the policy. In many cases there is a forensic reason for doing this, in
the event that you wish to observe the actions of a specific client. By
not tracking “user name” you will not be able to view user names or
login pages specifically, but ASM will still track HTTP session
information.

2. From the \sphinxstylestrong{Scope} list, specify the scope (username, session, or IP
address) by which to filter the data.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{OPTION}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DESCRIPTION}
\\
\hline
\sphinxstylestrong{Alt}
&
Specifies that the screen displays all entries. This is the default value.
\\
\hline
\sphinxstylestrong{Username}
&
Specifies that the system displays usernames whose illegal requests exceeded the security policy’s threshold values.
\\
\hline
\sphinxstylestrong{Session}
&
Specifies that the system displays identification numbers of illegal sessions that exceeded the security policy’s threshold values.
\\
\hline
\sphinxstylestrong{IP Address}
&
Specifies that the system displays IP addresses where illegal requests from these IP addresses exceeded the security policy’s threshold values.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{APPLICATION POLICY MODULE (APM)}
\label{\detokenize{class15/modules/module1:application-policy-module-apm}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Portal Access

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_apm/manuals/product/apm-portal}-
access-12-0-0/2.html

Portal access enables end users to access internal web applications with
a web browser from outside the network. With portal access, the BIG-IP®
Access Policy Manager® communicates with back-end servers, and rewrites
links in web application pages so that further requests from the client
browser are directed back to the Access Policy Manager server. With
portal access, the client computer requires no specialized client
software other than a web browser.

Portal access provides clients with secure access to internal web
servers, such as Microsoft® Outlook®Web Access (OWA), Microsoft
SharePoint®, and IBM® Domino® Web Access. Using portal access
functionality, you can also provide access to most web-based
applications and internal web servers.

Portal access differs from network access, which provides direct access
from the client to the internal network. Network access does not
manipulate or analyze the content being passed between the client and
the internal network. The portal access configuration gives the
administrator both refined control over the applications that a user can
access through Access Policy Manager, and content inspection for the
application data. The other advantage of portal access is security. Even
if a workstation might not meet requirements for security for full
network access, such a workstation can be passed by the access policy to
certain required web applications, without allowing full network access.
In a portal access policy, the client computer itself never communicates
directly with the end-point application. That means that all
communication is inspected at a very high level, and any attacks
originating on the client computer fail because the attack cannot
navigate through the links that have been rewritten by the portal access
engine.

Portal access configuration elements

A portal access configuration requires:
\begin{itemize}
\item {} 
A portal access resource including one or more portal access resource
items

\item {} 
An access profile

\item {} 
An access policy that assigns:

\end{itemize}

A portal access resource

A portal access or full webtop
\begin{itemize}
\item {} 
A rewrite profile (you can use the default rewrite profile)

\item {} 
A connectivity profile

\item {} 
A virtual server that assigns the access profile and a rewrite
profile

\end{itemize}

Portal access elements are summarized in the following diagram.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p311}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Understanding portal access patching}

Portal access \sphinxstyleemphasis{patches}, or rewrites, links in web content. Portal
access rewrites links in complex JavaScriptTM, Flash®, CSS, and HTML. In
full patching mode, Access Policy Manager® retrieves content from
back-end servers and rewrites links in that content so it can be
presented to a web browser, as if the content originated from the Access
Policy Manager. Portal access rewrites content to make intranet targets
resolvable, no matter what the intranet host is.

\sphinxstyleemphasis{Understanding full patching mode}

In full patching mode, you can select one or more of the following
content types in which portal access rewrites links.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Patching content type}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
HTML patching
&
Rewrites links in HTML content to redirect to the Access Policy Manager®.
\\
\hline
JavaScript patching
&
Rewrites link content in JavaScript code to redirect requests to the Access Policy Manager.
\\
\hline
CSS patching
&
Rewrites links to CSS files, and within CSS content, to redirect to the Access Policy Manager.
\\
\hline
Flash patching
&
Rewrites links in Flash movies and objects to redirect requests to the Access Policy Manager.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstylestrong{SAML (Security Assertion Markup Language)}

\begin{DUlineblock}{0em}
\item[] SAML Overview on F5 Lightboard
\item[] on YouTube - \sphinxurl{https://www.youtube.com/watch?v=i8wFExDSZv0}
\end{DUlineblock}

SAML can be useful to access multiple services using “assertion” (as an
authenticated token) for authentication, rather than traditional
username and password. SAML can be implemented for on-premises as well
as off-premises (SaaS) or applications hosted in cloud.

In general analogy, assertion means validating your identity with
authentic fact or belief. For example, at many places you require to
present your national ID / Passport etc to access to certain places /
services. In Digital world, precisely in SAML, assertion means the same.
Presenting valid assertion is mandatory before Service Provider grants
the access to the hosted services.

SAML consist of 3 different components as following. • User
\begin{itemize}
\item {} 
Identity Provider (IdP)

\item {} 
Service Provider (SP)

\end{itemize}

\sphinxstylestrong{User} \textendash{} The entity which access the services.

\sphinxstylestrong{IdP} \textendash{} The entity which authenticates and assigns the “assertion”
post successful authentication and passes the assertion (token) to
SP (Service Provider) to grant the user access (if require) based on
the “Access Control” associated with the user privileges.

IdP then keeps the authenticated session for further use in the
memory.

\sphinxstylestrong{SP} - The entity which hosts the services. Such as Office 365 /
Salesforce / WebEx etc.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p321}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{SAML Metadata}

SAML metadata specifies how configuration information is defined and
shared between two communicating entities: a SAML Identity Provider
(IdP) and a SAML service provider.

\sphinxstylestrong{Service provider metadata} provides information about service
provider requirements, such as whether the service provider requires a
signed assertion, the protocol binding support for endpoints
(AssertionConsumerService) and which certificates and keys to use for
signing and encryption.

\sphinxstylestrong{IdP metadata} provides information about IdP requirements, such as
the protocol binding support for endpoints (SingleSignOnService), and
which certificate to use for signing and encryption.

\sphinxstylestrong{Federation}

Source - \sphinxurl{https://www.youtube.com/watch?v=De321sSQf54}

APM systems operate with one another when one APM system is configured
as an IdP and other APM systems are configured as service providers.
This allows a user to authenticate with one APM acting as an IdP, and
then use any number of APM systems, serving as service providers,
without having to re-authenticate.

IdP-initiated and service provider-initiated client connections Access
Policy Manager supports client connections that initiate at the IdP or
at the service provider.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p331}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{BIG IP APM - SECURE WEB GATEWAY (SWG)}
\label{\detokenize{class15/modules/module1:big-ip-apm-secure-web-gateway-swg}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

A Secure Web Gateway (SWG) explicit forward proxy deployment provides an
easy way to handle web requests from users. For explicit forward proxy,
you configure client browsers to point to a forward proxy server. A
forward proxy server establishes a tunnel for SSL traffic. Other virtual
servers (wildcard SSL and wildcard forwarding IP virtual servers) listen
on the tunnel. The listener that best matches the web traffic directed
to the forward proxy server handles the traffic.

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p341}.png}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

In any deployment of explicit forward proxy, you must consider how best
to configure browsers on client systems to point to the proxy server and
how to configure your firewall to prevent users from bypassing the
proxy. This implementation does not explain how to do these tasks.
However, here are some best practices to consider.

Source -
\sphinxurl{https://support.f5.com/kb/en-us/products/big-ip\_apm/manuals/product/apm-secure-web-gateway-implementations-11-5-0/4.html}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Configuration}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Recommendation}
\\
\hline
Client browser
&
Consider using a group policy that points to a Proxy Auto-Configuration (PAC) file to distribute the configuration to clients and periodically update it.
\\
\hline
Firewall
&
A best practice might be to configure the firewall to trust outbound connections from Secure Web Gateway only. Note that possibly not all applications will work with a firewall configured this way. (Secure Web Gateway uses ports 80 and 443.)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

BIG-IP® Access Policy Manager® Secure Web Gateway (SWG) implements a
secure web gateway by adding access control, based on URL
categorization, \sphinxstylestrong{to forward proxy}. The access profile supports both
transparent and explicit forward proxy modes. The access policy includes
support for using a captive portal to collect credentials for
transparent forward proxy mode and \sphinxstylestrong{HTTP 407-based} credential capture
for explicit forward proxy mode. In addition to user identification by
credentials, SWG provides the option to identify users transparently,
providing access based on best effort identification. SWG also supports
SSL traffic inspection.

The benefits that SWG provides include:
\begin{itemize}
\item {} 
URL filtering capability for outbound web traffic.

\item {} 
Identifying malicious content and providing the means to block it.

\item {} 
Applying web application controls for application types, such as
social networking and Internet communication in corporate
environments.

\item {} 
Monitoring and gating outbound traffic to maximize productivity and
meet business needs.

\item {} 
User identification or authentication (or both) tied to monitoring,
and access control compliance and accountability.

\item {} 
Visibility into SSL traffic.

\item {} 
BIG IP APM Secure Web Gateway terminology

\item {} 
Here are some common terms as defined within the context of
BIG-IP®APM Secure Web Gateway (SWG).

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{TERM}
&\sphinxstyletheadfamily 
\sphinxstylestrong{DEFINITION}
\\
\hline
\sphinxstylestrong{application templates}
&
An application template is a collection of parameters (in the form of
F5® iApps® templates) that an administrator defines to create a configuration, such as configuration objects for explicit or transparent forward proxy or for communication between the BIG-IP® system and the F5 DC Agent.
\\
\hline
\sphinxstylestrong{explicit forward proxy}
&
Traffic goes directly from the client browser to the forward proxy server. The forward proxy configuration takes place in the client browser, either manually or using a Proxy Auto-Configuration (PAC) file.
\\
\hline
\sphinxstylestrong{F5 DC Agent}
&
The F5® DC Agent is an optional program that runs on a Windows-based server
in your network. As users log on to Windows domains, the agent makes a best effort to map IP addresses to user names and send them to Secure Web Gateway (SWG).
\\
\hline
\sphinxstylestrong{IF-MAP server}
&
When you configure the BIG-IP system to communicate with the F5 DC Agent, IP address and user name pairs are stored on the BIG-IP system in an IF-MAP server.
\\
\hline
\sphinxstylestrong{transparent forward proxy}
&
The administrator can place the BIG-IP system right in the path of traffic (inline) as the next hop after the gateway, or can use policy-based routing or Web Cache Communication Protocol (WCCP) to send traffic for ports 80 and 443 to Secure Web Gateway.
\\
\hline
\sphinxstylestrong{transparent user identification}
&
The Transparent Identity Import access policy item obtains the IP-address- to-username-mapping from the IF-MAP server. Alone or by pairing this item with another query to look up the user or validate user information, you can allow access through the proxy without requesting credentials. Transparent user identification is not authentication; use it only when you are comfortable accepting a best effort at identifying a user.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Flowchart for SWG Configuration

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\noindent\sphinxincludegraphics{{1p351}.png}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{BIG IQ}
\label{\detokenize{class15/modules/module1:big-iq}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

F5® BIG-IQ® Centralized Management is an intelligent framework for
managing F5 security and application delivery solutions. BIG-IQ
Centralized Management provides a central point of control for F5
physical and virtual devices as well as for the following BIG-IP
software modules:
\begin{itemize}
\item {} 
BIG-IP® Local Traffic ManagerTM (LTM)

\item {} 
BIG-IP® Application Security ManagerTM (ASM)

\item {} 
BIG-IP® Advanced Firewall ManagerTM (AFM)

\item {} 
BIG-IP® Access Policy Manager® (APM)

\item {} 
F5 WebSafeTM and F5 MobileSafe® (monitoring only)

\end{itemize}

F5 BIG-IQ Centralized Management is ideal for organizations that
require central management of F5 devices and modules, license
management of BIG-IP virtual editions (VEs), or central reporting
and alerting on application availability, performance, and security.
BIG-IQ Centralized Management employs role-based access control
(RBAC), empowering application and security teams to manage their
own applications while helping to maintain consistent policies and
procedures across the enterprise.

Central logging, reporting, and auditing

BIG-IQ Centralized Management is a single solution for logging,
reporting on, and auditing your F5 devices. Using BIG-IQ Centralized
Management to log BIG-IP APM, WebSafe, or BIG-IP ASM events requires
a BIG-IQ Logging Node. Speak to your F5 sales representative for
details.

Functions for device management
\begin{itemize}
\item {} 
Centralized software upgrades—Centrally manage BIG-IP upgrades (from
TMOS versions 10.2.0 and above) by uploading TMOS releases into
BIG-IQ Centralized Management and directing the upgrade process for
managed BIG-IP devices from one place. The BIG-IQ Centralized
Management upgrade wizard guides you through the process and guards
against common upgrade errors.

\item {} 
License management—Centrally manage BIG-IP VE licenses, granting and
revoking licenses as business needs change. Gain the flexibility to
license devices only as needed, maximizing the return on your BIG-IP
investment. Assign different license pools to different applications
or tenants for more flexible provisioning.

\item {} 
Utility license usage reporting—Enable utility licensing of BIG-IP
devices by generating and delivering reports of device use over time.

\item {} 
Device discovery and monitoring—Discover, track, and monitor all
BIG-IP devices—whether physical or virtual—including key metrics such
as CPU/memory and disk usage and high availability status. The
cluster view shows trust domains, sync groups, and failover groups.

\item {} 
Configuration, backup, and restore—Use BIG-IQ Centralized Management
as a central repository of BIG-IP configuration files (UCS), and
backup and restore system information on demand or as a scheduled
process.

\item {} 
BIG-IP device cluster support—Monitor high availability (HA) and
clusters for BIG-IP devices.

\item {} 
SSL monitoring—Track and receive alerts on the status of SSL
certificates.

\end{itemize}

Source - \sphinxurl{https://www.f5.com/pdf/products/big-iq-datasheet.pdf}

\begin{DUlineblock}{0em}
\item[] 
\item[] 
\end{DUlineblock}


\section{F5 VULNERABILITY RESPONSE POLICY AND SECURITY AUDIT}
\label{\detokenize{class15/modules/module1:f5-vulnerability-response-policy-and-security-audit}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstyleemphasis{Reporting suspected vulnerabilities}

F5 welcomes any reports of suspected vulnerabilities or other security
concerns with our products.

If you are an F5 customer with an active support contract, please
contact F5 Technical Support via our customer portal, or by phone.

If you are not an F5 customer, please send an email to \sphinxhref{mailto:f5sirt@f5.com}{f5sirt@f5.com}.
You will be contacted by an engineer who will provide you with various
options for secure communication, and work with you to gather the
necessary details to determine an appropriate course of action.

In cases where responsible disclosure is followed, and at the reporter’s
request, F5 will provide attribution to reporters within a public AskF5
article.

\sphinxstyleemphasis{Vulnerability categories}

F5 investigates and prioritizes reports based on the potential
exploitability of the vulnerability. F5 divides security vulnerabilities
into the six categories listed in the following table. For software
releases that are within their standard support phase, F5 provides the
resolutions listed in the \sphinxstylestrong{Action} column whenever technically
feasible. In rare cases, when F5 cannot provide the listed resolution on
a specific version due to technical limitations, customers may need to
upgrade to a different software version to receive the fix.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Severity}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Action}
\\
\hline
Not Vulnerable
&
A product declared by F5 as not vulnerable cannot be exploited through the mechanism listed.
&
None
\\
\hline
Low
&
A vulnerability that may cause an information leak or other minor effects.
&
May fix the vulnerability in a future release.
\\
\hline
Medium
&
A vulnerability that may affect an authenticated user, but has mitigating circumstances. Examples include XSS scripting vulnerabilities available to authenticated users.
&
Where technically feasible, the vulnerability will be fixed in the next available Major, Minor, or Maintenance release.
\\
\hline
High
&
A vulnerability that may affect an authenticated user and could result in escalation of privilege. Examples include CSRF vulnerabilities, SQL injections, and other major vulnerabilities.
&
Where technically feasible, the vulnerability will be fixed in the next available Major, Minor, or Maintenance release.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Severe
&\sphinxstyletheadfamily 
A major vulnerability that may be exploited without authentication or has serious system implications, such as a denial-of-service (DoS).
&\sphinxstyletheadfamily 
Where technically feasible, the vulnerability will be fixed in the next available Major, Minor, or Maintenance release, and hotfixes will be created for select supported releases in the next available Cumulative Hotfix.
\\
\hline
Critical
&
A major vulnerability resulting in code execution that can be exploited without authentication. Examples include Heartbleed and Shellshock.
&
Where technically feasible, the vulnerability will be fixed in the next available Major, Minor, or Maintenance release, and hotfixes will be created for all supported releases as quickly as possible.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxstyleemphasis{Security hotfixes}

F5 is committed to evaluating software within its Standard Support Phase
at the time of public disclosure of the issue. For information about
supported versions, refer to K8986: F5 software life cycle policy.

When critical or severe vulnerabilities are discovered, F5 implements,
tests, and releases security hotfixes for the supported versions of
software where technically feasible per the \sphinxstylestrong{Action} column in the
previous table. For additional information regarding the F5 critical
issue hotfix policy, refer to K4918: Overview of the F5 critical issue
hotfix policy.

\sphinxstyleemphasis{Vulnerability databases}

F5 is committed to staying up-to-date on all of the known security
vulnerabilities, and actively monitors and participates in the following
vulnerability databases:
\begin{itemize}
\item {} 
CERT Coordination Center (CERT/CC)

\item {} 
CVE (Common Vulnerabilities and Exposures)

\end{itemize}

F5 actively monitors and responds to the following databases:
\begin{itemize}
\item {} 
Full Disclosure

\item {} 
Red Hat Security Mailing List

\item {} 
CentOS Security

\end{itemize}

\sphinxstylestrong{Note:} Numerous vulnerability databases exist on the Internet.
F5 participates in only vulnerability database sites that have a
closed-loop notification and feedback system in place. If you are
monitoring vulnerabilities from a different database and discover a
vulnerability with an F5 product, check the vulnerability database
sites to which F5 subscribes, to determine whether the vulnerability
has been addressed. If the issue has not been addressed, please
notify F5 Technical Support.

\sphinxstyleemphasis{Security Updates mailing list}

F5 maintains a mailing list for announcements that relate to security
issues. To subscribe, visit the AskF5 Publication Preference Center
page, provide your email address, select the \sphinxstylestrong{Security Alerts} check
box, and then click \sphinxstylestrong{Submit}. You will receive a confirmation.

Source - \sphinxurl{https://support.f5.com/csp/article/K4602?sr=12234302}

\sphinxstylestrong{CASE STUDIES}

In 401, you will find quite some subsequent questions on case studies.
You may have 4-5 different case studies and 4-5 questions per case
study. I have tried to make some examples which can help you to get a
brief idea to deal with them.

F5 401 SSE Exam Blueprint v2 will soon be having a case studies section.
You can also browse more case studies over there.

\sphinxstylestrong{Caution!}

None of the case studies are derived from the exam. The purpose to
create this section is to share more realistic experience to prepare
better for the exam.

Some of examples are:

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 1:

An organization has following Challenges:
\begin{itemize}
\item {} 
High volumes of SSL traffic during online promotions

\item {} 
Securing service availability in heavy traffic

\item {} 
Protecting against web vulnerabilities and DDoS attack

\end{itemize}

Answer the following questions based on above case study.

1. Which modules of F5 can help customer to overcome the described
challenges?
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Which DDoS feature can help customer to mitigate the attack?

\item {} 
Would you advise Web Scrapping or bot defense?

\end{enumerate}

4. Can Websafe be helpful? If yes, which features of Websafe you can
incorporate?

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 2:

An organization has following challenges:
\begin{itemize}
\item {} 
Limited rack space for moving into private cloud

\item {} 
Authentication for email system on Office 365

\item {} 
Replace old authentication and SSL VPN systems

\end{itemize}

Answer the following questions based on above case study.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Which modules of F5 are suitable for the requirement?

\item {} 
Which platform do you recommend to customer considering limited rack
space?

\item {} 
Which multi-factor authentication can be helpful for secure web
application access?

\item {} 
How would you design your VPE for this requirement in APM?

\item {} 
Which multi factor auth would you suggest?

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 3:

An organization has following challenges:
\begin{itemize}
\item {} 
Deliver fast, quality services for customers

\item {} 
Ensure high application availability

\item {} 
Adapt to support new applications and business growth

\end{itemize}

Answer the following questions based on above case study.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Which modules of F5 can help to resolve all the challenges?

\end{enumerate}

2. How can you ensure highest possible uptime and low latency to the
users while accessing real time applications?

3. How can you ensure high availability and low latency of the
application for the users coming from different geo locations?

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 4:

An organization has following challenges:
\begin{itemize}
\item {} 
Customer demand for faster services

\item {} 
Firewall bottlenecks in the current system

\item {} 
Continued support for multihoming and ISP line redundancy

\item {} 
Need for enhanced security

\end{itemize}

Answer the following questions based on above case study.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Which module of modules of F5 can help to resolve all the challenges?

\end{enumerate}

2. CGNET or PEM can be helpful? Yes? How? No? which other features can
accommodate all the needs?
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
For enhanced security, what additional features can be leveraged?

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 5:

An organization has following challenges:
\begin{itemize}
\item {} 
Ensure constant security, reliability and data integrity, with
attention to those transmitted to suppliers and customers and
published externally through web services (such as portals for the PA)

\item {} 
Reduce costs and rationalize the management of resources

\item {} 
Enhance the performance of a growing number of services, eliminating
potential downtime or operational delays.

\end{itemize}

Answer the following questions based on above case study.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Which module of modules of F5 can help to resolve all the challenges?

\end{enumerate}

2. Which features of APM can be useful? Can you use SSL VPN? Portal
access with/without rewrite?
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
How would you advise on AAA?

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 6:

An organization has following challenges:
\begin{itemize}
\item {} 
Downtime caused by DDoS activity

\item {} 
Limited in-house cloud security expertise

\item {} 
Inadequate visibility into attacks

\end{itemize}

Answer the following questions based on above case study.

1. Which services or modules would you advise to address listed
challenges?

2. Which DDoS solutions offered by F5 can be useful to mitigate the
attack as described in the case study?
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Would you advise customer to use Session tracking in ASM?

\item {} 
Can Silverline DDoS defense be helpful to mitigate the attack?

\end{enumerate}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

Case study 7:

An organization has following challenges:
\begin{itemize}
\item {} 
Limited rack space for moving into private cloud

\item {} 
Authentication for email system on Office 365

\item {} 
Replace old authentication and SSL VPN systems

\end{itemize}

Answer the following questions based on above case study.

1. Which services or modules would you advise to address listed
challenges?
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Can APM be integrated with the current requirement?

\item {} 
What if customer uses SAML?

\item {} 
How can you place APM in that scenario? Can it be IdP or IsP?

\item {} 
How would you deal with SAML metadata configuration?

\end{enumerate}

\sphinxstylestrong{Note:} All the above case studies are extracted from “Customer stories”, on
F5 website. You can refer more customer stories on the following.
\sphinxurl{https://f5.com/solutions/customer-stories}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{All the best!!}


\chapter{F5 402 - Cloud Solutions Study Guide 11/01/19}
\label{\detokenize{class17/class17:f5-402-cloud-solutions-study-guide-11-01-19}}\label{\detokenize{class17/class17::doc}}
\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\begin{sphinxadmonition}{caution}{Caution:}
402 CONTENT IS NOT YET DEVELOPMENT and will be published when complete.
\end{sphinxadmonition}

\begin{DUlineblock}{0em}
\item[] 
\end{DUlineblock}

\sphinxstylestrong{Overview 402 - Cloud Solutions}

Welcome to the 402 - Cloud Solutions compiled Study Guide. The purpose of
this guide is to help you prepare for the F5 402 - Cloud Solutions exam.
The contents of this document are based on the F5 402 - Cloud Solutions
Exam Blueprint version 1 for TMOS v12.1.

\sphinxstylestrong{This study guide provides students with some of the basic foundational
knowledge required to pass the exam.}

\sphinxstyleemphasis{This study guide is a collection of information and therefore not a completely
original work.} The majority of the information is compiled from F5 sources
that are located on Internet. All of the information locations are referenced
at the top of each topic instead of in an Appendix of this document. This was
done to help the reader access the reference the linked information easier
without having to search through a formal appendix.

The F5 Certified BIG-IP Administrator (F5-CA), F5 Certified Technology
Specialist LTM (F5-CTS, LTM), F5 Certified Technology Specialist DNS
(F5-CTS, DNS) stand as a pre-requisite to this exam.

Field experience with everything F5 in the public and private cloud is essential
to passing this exam, as well as a strong working knowledge of cloud architecture principles.

This guide was prepared by an F5 employee but is not an official F5 document
and is \sphinxstyleemphasis{not} supported by F5.

\sphinxstylestrong{Reading = Knowledge = Power}

\sphinxstylestrong{Printed References}

These referenced books are and important and should be considered basic reading
material for this exam.


\section{Section 1 - Foundational Cloud Concepts}
\label{\detokenize{class17/modules/module1:section-1-foundational-cloud-concepts}}\label{\detokenize{class17/modules/module1::doc}}

\section{Section 2 - Cloud Infrastructure Design}
\label{\detokenize{class17/modules/module2:section-2-cloud-infrastructure-design}}\label{\detokenize{class17/modules/module2::doc}}

\section{Section 3 - Cloud Migration}
\label{\detokenize{class17/modules/module3:section-3-cloud-migration}}\label{\detokenize{class17/modules/module3::doc}}

\section{Section 4 - Cloud Deployment}
\label{\detokenize{class17/modules/module4:section-4-cloud-deployment}}\label{\detokenize{class17/modules/module4::doc}}

\section{Section 5 - Cloud Orchestration and Automation}
\label{\detokenize{class17/modules/module5:section-5-cloud-orchestration-and-automation}}\label{\detokenize{class17/modules/module5::doc}}


\renewcommand{\indexname}{Index}

\backcoverpage

\end{document}